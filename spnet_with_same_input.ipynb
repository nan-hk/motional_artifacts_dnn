{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nan-hk/motional_artifacts_dnn/blob/master/spnet_with_same_input.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtfX-RyFrDLb"
      },
      "source": [
        "# Salient Object Detection with Same Modality Input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4siUGnUdrR2t"
      },
      "source": [
        "## Requirement Installiation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAb20yvarCGj",
        "outputId": "05ff6948-75f1-48e5-9644-39865448f0d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 12.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge0YE53jT7T6",
        "outputId": "2c740039-0bab-45f8-abf3-248dc75ec639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting piq\n",
            "  Downloading piq-0.7.0-py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 10.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision!=0.9.*,>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from piq) (0.13.0+cu113)\n",
            "Requirement already satisfied: torch==1.12.0 in /usr/local/lib/python3.7/dist-packages (from torchvision!=0.9.*,>=0.6.1->piq) (1.12.0+cu113)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision!=0.9.*,>=0.6.1->piq) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision!=0.9.*,>=0.6.1->piq) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision!=0.9.*,>=0.6.1->piq) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision!=0.9.*,>=0.6.1->piq) (1.21.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision!=0.9.*,>=0.6.1->piq) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision!=0.9.*,>=0.6.1->piq) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision!=0.9.*,>=0.6.1->piq) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision!=0.9.*,>=0.6.1->piq) (3.0.4)\n",
            "Installing collected packages: piq\n",
            "Successfully installed piq-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install piq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShWXdTv3RNvf"
      },
      "source": [
        "## Different Modalities Dataset\n",
        " \n",
        "\n",
        "1.   RGB as depth dataset without noise\n",
        "2.   Depth as depth dataset with noise\n",
        "3.   GT as GT dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Grv8GfrReKm",
        "outputId": "6068a4f1-06d3-4fd2-9ae0-b5848a9aa099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/traindataset_only_depth.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/tmp\")\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdF4x7UkRzgU"
      },
      "outputs": [],
      "source": [
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/testdataset_only_depth.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/tmp\")\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz5sCv8JQcXM"
      },
      "source": [
        "## Res2Net Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJk30OH8Qg49"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "__all__ = ['Res2Net', 'res2net50_v1b', 'res2net101_v1b']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'res2net50_v1b_26w_4s': 'https://shanghuagao.oss-cn-beijing.aliyuncs.com/res2net/res2net50_v1b_26w_4s-3cf99910.pth',\n",
        "    'res2net101_v1b_26w_4s': 'https://shanghuagao.oss-cn-beijing.aliyuncs.com/res2net/res2net101_v1b_26w_4s-0812c246.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class Bottle2neck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, baseWidth=26, scale = 4, stype='normal'):\n",
        "        \"\"\" Constructor\n",
        "        Args:\n",
        "            inplanes: input channel dimensionality\n",
        "            planes: output channel dimensionality\n",
        "            stride: conv stride. Replaces pooling layer.\n",
        "            downsample: None when stride = 1\n",
        "            baseWidth: basic width of conv3x3\n",
        "            scale: number of scale.\n",
        "            type: 'normal': normal set. 'stage': first block of a new stage.\n",
        "        \"\"\"\n",
        "        super(Bottle2neck, self).__init__()\n",
        "\n",
        "        width = int(math.floor(planes * (baseWidth/64.0)))\n",
        "        self.conv1 = nn.Conv2d(inplanes, width*scale, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(width*scale)\n",
        "        \n",
        "        if scale == 1:\n",
        "          self.nums = 1\n",
        "        else:\n",
        "          self.nums = scale -1\n",
        "        if stype == 'stage':\n",
        "            self.pool = nn.AvgPool2d(kernel_size=3, stride = stride, padding=1)\n",
        "        convs = []\n",
        "        bns = []\n",
        "        for i in range(self.nums):\n",
        "          convs.append(nn.Conv2d(width, width, kernel_size=3, stride = stride, padding=1, bias=False))\n",
        "          bns.append(nn.BatchNorm2d(width))\n",
        "        self.convs = nn.ModuleList(convs)\n",
        "        self.bns = nn.ModuleList(bns)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(width*scale, planes * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stype = stype\n",
        "        self.scale = scale\n",
        "        self.width  = width\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        spx = torch.split(out, self.width, 1)\n",
        "        for i in range(self.nums):\n",
        "          if i==0 or self.stype=='stage':\n",
        "            sp = spx[i]\n",
        "          else:\n",
        "            sp = sp + spx[i]\n",
        "          sp = self.convs[i](sp)\n",
        "          sp = self.relu(self.bns[i](sp))\n",
        "          if i==0:\n",
        "            out = sp\n",
        "          else:\n",
        "            out = torch.cat((out, sp), 1)\n",
        "        if self.scale != 1 and self.stype=='normal':\n",
        "          out = torch.cat((out, spx[self.nums]),1)\n",
        "        elif self.scale != 1 and self.stype=='stage':\n",
        "          out = torch.cat((out, self.pool(spx[self.nums])),1)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Res2Net(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, baseWidth = 26, scale = 4, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(Res2Net, self).__init__()\n",
        "        self.baseWidth = baseWidth\n",
        "        self.scale = scale\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, 3, 1, 1, bias=False)\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.AvgPool2d(kernel_size=stride, stride=stride, \n",
        "                    ceil_mode=True, count_include_pad=False),\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion, \n",
        "                    kernel_size=1, stride=1, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample=downsample, \n",
        "                        stype='stage', baseWidth = self.baseWidth, scale=self.scale))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, baseWidth = self.baseWidth, scale=self.scale))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x0 = self.maxpool(x)\n",
        "        \n",
        "\n",
        "        x1 = self.layer1(x0)\n",
        "        x2 = self.layer2(x1)\n",
        "        x3 = self.layer3(x2)\n",
        "        x4 = self.layer4(x3)\n",
        "\n",
        "        x5 = self.avgpool(x4)\n",
        "        x6 = x5.view(x5.size(0), -1)\n",
        "        x7 = self.fc(x6)\n",
        "\n",
        "        return x7\n",
        "\n",
        "\n",
        "\n",
        "class Res2Net_Ours(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, baseWidth = 26, scale = 4, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(Res2Net_Ours, self).__init__()\n",
        "        \n",
        "        self.baseWidth = baseWidth\n",
        "        self.scale = scale\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, 3, 1, 1, bias=False)\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "       \n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.AvgPool2d(kernel_size=stride, stride=stride, \n",
        "                    ceil_mode=True, count_include_pad=False),\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion, \n",
        "                    kernel_size=1, stride=1, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample=downsample, \n",
        "                        stype='stage', baseWidth = self.baseWidth, scale=self.scale))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, baseWidth = self.baseWidth, scale=self.scale))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x0 = self.maxpool(x)\n",
        "        \n",
        "\n",
        "        x1 = self.layer1(x0)\n",
        "        x2 = self.layer2(x1)\n",
        "        x3 = self.layer3(x2)\n",
        "        x4 = self.layer4(x3)\n",
        "\n",
        "\n",
        "        return x0,x1,x2,x3,x4\n",
        "    \n",
        "    \n",
        "\n",
        "def res2net50_v1b(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b model.\n",
        "    Res2Net-50 refers to the Res2Net-50_v1b_26w_4s.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 4, 6, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net50_v1b_26w_4s'],map_location='cpu'))\n",
        "    return model\n",
        "\n",
        "def res2net101_v1b(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 4, 23, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net101_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def res2net50_v1b_Ours(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b model.\n",
        "    Res2Net-50 refers to the Res2Net-50_v1b_26w_4s.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net_Ours(Bottle2neck, [3, 4, 6, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net50_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "def res2net101_v1b_Ours(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net_Ours(Bottle2neck, [3, 4, 23, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net101_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def res2net50_v1b_26w_4s(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 4, 6, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net50_v1b_26w_4s'],map_location='cpu'))\n",
        "    return model\n",
        "\n",
        "def res2net101_v1b_26w_4s(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 4, 23, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net101_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "def res2net152_v1b_26w_4s(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 8, 36, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net152_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "def Res2Net_model(ind=50):\n",
        "    \n",
        "    if ind == 50:\n",
        "        model_base = res2net50_v1b(pretrained=True)\n",
        "        model      = res2net50_v1b_Ours()\n",
        "\n",
        "    if ind == 101:\n",
        "        model_base = res2net101_v1b(pretrained=True)\n",
        "        model      = res2net101_v1b_Ours()\n",
        "        \n",
        "        \n",
        "    pretrained_dict = model_base.state_dict()\n",
        "    model_dict      = model.state_dict()\n",
        "    \n",
        "    pretrained_dict =  {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "    \n",
        "    model_dict.update(pretrained_dict)\n",
        "    model.load_state_dict(model_dict)\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    images = torch.rand(1, 3, 352, 352)\n",
        "    model = res2net50_v1b_26w_4s(pretrained=False)\n",
        "    model = model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVSgFX16KrRU"
      },
      "source": [
        "## Salient Object Detection Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBFBDRavJhIf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.nn import functional as F\n",
        "\n",
        "def maxpool():\n",
        "    pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "    return pool\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicConv2d(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1):\n",
        "        super(BasicConv2d, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_planes, out_planes,\n",
        "                              kernel_size=kernel_size, stride=stride,\n",
        "                              padding=padding, dilation=dilation, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "#Global Contextual module\n",
        "class GCM(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel):\n",
        "        super(GCM, self).__init__()\n",
        "        self.relu = nn.ReLU(True)\n",
        "        self.branch0 = nn.Sequential(\n",
        "            BasicConv2d(in_channel, out_channel, 1),\n",
        "        )\n",
        "        self.branch1 = nn.Sequential(\n",
        "            BasicConv2d(in_channel, out_channel, 1),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(1, 3), padding=(0, 1)),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(3, 1), padding=(1, 0)),\n",
        "            BasicConv2d(out_channel, out_channel, 3, padding=3, dilation=3)\n",
        "        )\n",
        "        self.branch2 = nn.Sequential(\n",
        "            BasicConv2d(in_channel, out_channel, 1),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(1, 5), padding=(0, 2)),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(5, 1), padding=(2, 0)),\n",
        "            BasicConv2d(out_channel, out_channel, 3, padding=5, dilation=5)\n",
        "        )\n",
        "        self.branch3 = nn.Sequential(\n",
        "            BasicConv2d(in_channel, out_channel, 1),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(1, 7), padding=(0, 3)),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(7, 1), padding=(3, 0)),\n",
        "            BasicConv2d(out_channel, out_channel, 3, padding=7, dilation=7)\n",
        "        )\n",
        "        self.conv_cat = BasicConv2d(4*out_channel, out_channel, 3, padding=1)\n",
        "        self.conv_res = BasicConv2d(in_channel, out_channel, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x0 = self.branch0(x)\n",
        "        x1 = self.branch1(x)\n",
        "        x2 = self.branch2(x)\n",
        "        x3 = self.branch3(x)\n",
        "\n",
        "        x_cat = self.conv_cat(torch.cat((x0, x1, x2, x3), 1))\n",
        "\n",
        "        x = self.relu(x_cat + self.conv_res(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "class CIM0(nn.Module):    \n",
        "    def __init__(self,in_dim, out_dim):\n",
        "        super(CIM0, self).__init__()\n",
        "        \n",
        "        act_fn = nn.ReLU(inplace=True)\n",
        "        \n",
        "\n",
        "        self.layer_10 = nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer_20 = nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1)   \n",
        "        \n",
        "        self.layer_11 = nn.Sequential(nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)        \n",
        "        self.layer_21 = nn.Sequential(nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "        \n",
        "        self.gamma1 = nn.Parameter(torch.zeros(1))\n",
        "        self.gamma2 = nn.Parameter(torch.zeros(1))\n",
        "        \n",
        "\n",
        "        self.layer_ful1 = nn.Sequential(nn.Conv2d(out_dim*2, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "        \n",
        "\n",
        "    def forward(self, rgb, depth):\n",
        "        \n",
        "        ################################\n",
        "        \n",
        "        x_rgb = self.layer_10(rgb)\n",
        "        x_dep = self.layer_20(depth)\n",
        "        \n",
        "        rgb_w = nn.Sigmoid()(x_rgb)\n",
        "        dep_w = nn.Sigmoid()(x_dep)\n",
        "        \n",
        "        ##\n",
        "        x_rgb_w = rgb.mul(dep_w)\n",
        "        x_dep_w = depth.mul(rgb_w)\n",
        "        \n",
        "        x_rgb_r = x_rgb_w + rgb\n",
        "        x_dep_r = x_dep_w + depth\n",
        "        \n",
        "        ## fusion \n",
        "        x_rgb_r = self.layer_11(x_rgb_r)\n",
        "        x_dep_r = self.layer_21(x_dep_r)\n",
        "        \n",
        "        \n",
        "        ful_mul = torch.mul(x_rgb_r, x_dep_r)         \n",
        "        x_in1   = torch.reshape(x_rgb_r,[x_rgb_r.shape[0],1,x_rgb_r.shape[1],x_rgb_r.shape[2],x_rgb_r.shape[3]])\n",
        "        x_in2   = torch.reshape(x_dep_r,[x_dep_r.shape[0],1,x_dep_r.shape[1],x_dep_r.shape[2],x_dep_r.shape[3]])\n",
        "        x_cat   = torch.cat((x_in1, x_in2),dim=1)\n",
        "        ful_max = x_cat.max(dim=1)[0]\n",
        "        ful_out = torch.cat((ful_mul,ful_max),dim=1)\n",
        "        \n",
        "        out1 = self.layer_ful1(ful_out)\n",
        "         \n",
        "        return out1\n",
        "\n",
        "\n",
        "class CIM(nn.Module):    \n",
        "    def __init__(self,in_dim, out_dim):\n",
        "        super(CIM, self).__init__()\n",
        "        \n",
        "        act_fn = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.reduc_1 = nn.Sequential(nn.Conv2d(in_dim, out_dim, kernel_size=1), act_fn)\n",
        "        self.reduc_2 = nn.Sequential(nn.Conv2d(in_dim, out_dim, kernel_size=1), act_fn)\n",
        "        \n",
        "        self.layer_10 = nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer_20 = nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1)   \n",
        "        \n",
        "        self.layer_11 = nn.Sequential(nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)        \n",
        "        self.layer_21 = nn.Sequential(nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "        \n",
        "        self.gamma1 = nn.Parameter(torch.zeros(1))\n",
        "        self.gamma2 = nn.Parameter(torch.zeros(1))\n",
        "        \n",
        "\n",
        "        self.layer_ful1 = nn.Sequential(nn.Conv2d(out_dim*2, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "        self.layer_ful2 = nn.Sequential(nn.Conv2d(out_dim+out_dim//2, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "\n",
        "    def forward(self, rgb, depth, xx):\n",
        "        \n",
        "        ################################\n",
        "        x_rgb = self.reduc_1(rgb)\n",
        "        x_dep = self.reduc_2(depth)\n",
        "        \n",
        "        x_rgb1 = self.layer_10(x_rgb)\n",
        "        x_dep1 = self.layer_20(x_dep)\n",
        "        \n",
        "        rgb_w = nn.Sigmoid()(x_rgb1)\n",
        "        dep_w = nn.Sigmoid()(x_dep1)\n",
        "        \n",
        "        ##\n",
        "        x_rgb_w = x_rgb.mul(dep_w)\n",
        "        x_dep_w = x_dep.mul(rgb_w)\n",
        "        \n",
        "        x_rgb_r = x_rgb_w + x_rgb\n",
        "        x_dep_r = x_dep_w + x_dep\n",
        "        \n",
        "        ## fusion \n",
        "        x_rgb_r = self.layer_11(x_rgb_r)\n",
        "        x_dep_r = self.layer_21(x_dep_r)\n",
        "        \n",
        "        \n",
        "        ful_mul = torch.mul(x_rgb_r, x_dep_r)         \n",
        "        x_in1   = torch.reshape(x_rgb_r,[x_rgb_r.shape[0],1,x_rgb_r.shape[1],x_rgb_r.shape[2],x_rgb_r.shape[3]])\n",
        "        x_in2   = torch.reshape(x_dep_r,[x_dep_r.shape[0],1,x_dep_r.shape[1],x_dep_r.shape[2],x_dep_r.shape[3]])\n",
        "        x_cat   = torch.cat((x_in1, x_in2),dim=1)\n",
        "        ful_max = x_cat.max(dim=1)[0]\n",
        "        ful_out = torch.cat((ful_mul,ful_max),dim=1)\n",
        "        \n",
        "        out1 = self.layer_ful1(ful_out)\n",
        "        out2 = self.layer_ful2(torch.cat([out1,xx],dim=1))\n",
        "         \n",
        "        return out2\n",
        "\n",
        "\n",
        "\n",
        "class MFA(nn.Module):    \n",
        "    def __init__(self,in_dim):\n",
        "        super(MFA, self).__init__()\n",
        "         \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.layer_10 = nn.Conv2d(in_dim, in_dim, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer_20 = nn.Conv2d(in_dim, in_dim, kernel_size=3, stride=1, padding=1)   \n",
        "        self.layer_cat1 = nn.Sequential(nn.Conv2d(in_dim*2, in_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(in_dim),)        \n",
        "        \n",
        "    def forward(self, x_ful, x1, x2):\n",
        "        \n",
        "        ################################\n",
        "    \n",
        "        x_ful_1 = x_ful.mul(x1)\n",
        "        x_ful_2 = x_ful.mul(x2)\n",
        "        \n",
        "     \n",
        "        x_ful_w = self.layer_cat1(torch.cat([x_ful_1, x_ful_2],dim=1))\n",
        "        out     = self.relu(x_ful + x_ful_w)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "    \n",
        "\n",
        "  \n",
        "   \n",
        "###############################################################################\n",
        "\n",
        "class SPNet(nn.Module):\n",
        "    def __init__(self, channel=32,ind=50):\n",
        "        super(SPNet, self).__init__()\n",
        "        \n",
        "       \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.upsample_2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.upsample_4 = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)\n",
        "        self.upsample_8 = nn.Upsample(scale_factor=8, mode='bilinear', align_corners=True)\n",
        "        \n",
        "        #Backbone model\n",
        "        #Backbone model\n",
        "        self.layer_rgb  = Res2Net_model(ind)\n",
        "        self.layer_dep  = Res2Net_model(ind)\n",
        "        \n",
        "        self.layer_dep0 = nn.Conv2d(1, 3, kernel_size=1)\n",
        "        \n",
        "        ###############################################\n",
        "        # funsion encoders #\n",
        "        ###############################################\n",
        "        self.fu_0 = CIM0(64, 64)#\n",
        "        \n",
        "        self.fu_1 = CIM(256, 128) #MixedFusion_Block_IMfusion\n",
        "        self.pool_fu_1 = maxpool()\n",
        "        \n",
        "        self.fu_2 = CIM(512, 256)\n",
        "        self.pool_fu_2 = maxpool()\n",
        "        \n",
        "        self.fu_3 = CIM(1024, 512)\n",
        "        self.pool_fu_3 = maxpool()\n",
        "\n",
        "        self.fu_4 = CIM(2048, 1024)\n",
        "        self.pool_fu_4 = maxpool()\n",
        "        \n",
        "        \n",
        "        ###############################################\n",
        "        # decoders #\n",
        "        ###############################################\n",
        "        \n",
        "        ## rgb\n",
        "        self.rgb_conv_4   = nn.Sequential(BasicConv2d(2048,    256, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_4    = GCM(2048,  channel)\n",
        "        \n",
        "        self.rgb_conv_3   = nn.Sequential(BasicConv2d(1024+32, 256, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_3    = GCM(1024+32,  channel)\n",
        "\n",
        "        self.rgb_conv_2   = nn.Sequential(BasicConv2d(512+32, 128, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_2    = GCM(512+32,  channel)\n",
        "\n",
        "        self.rgb_conv_1   = nn.Sequential(BasicConv2d(256+32, 128, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_1    = GCM(256+32,  channel)\n",
        "\n",
        "        self.rgb_conv_0   = nn.Sequential(BasicConv2d(64+32, 64, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_0    = GCM(64+32,  channel)        \n",
        "        self.rgb_conv_out = nn.Conv2d(channel, 1, 1)\n",
        "        \n",
        "        ## depth\n",
        "        self.dep_conv_4   = nn.Sequential(BasicConv2d(2048, 256, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_4    = GCM(2048,  channel)\n",
        "        \n",
        "        self.dep_conv_3   = nn.Sequential(BasicConv2d(1024+32, 256, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_3    = GCM(1024+32,  channel)\n",
        "\n",
        "        self.dep_conv_2   = nn.Sequential(BasicConv2d(512+32, 128, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_2    = GCM(512+32,  channel)\n",
        "\n",
        "        self.dep_conv_1   = nn.Sequential(BasicConv2d(256+32, 128, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_1    = GCM(256+32,  channel)\n",
        "\n",
        "        self.dep_conv_0   = nn.Sequential(BasicConv2d(64+32, 64, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_0    = GCM(64+32,  channel)        \n",
        "        self.dep_conv_out = nn.Conv2d(channel, 1, 1)\n",
        "        \n",
        "        ## fusion\n",
        "        self.ful_conv_4   = nn.Sequential(BasicConv2d(2048, 256, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_4    = GCM(1024,  channel)\n",
        "        \n",
        "        self.ful_conv_3   = nn.Sequential(BasicConv2d(1024+32*3, 256, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_3    = GCM(512+32,  channel)\n",
        "\n",
        "        self.ful_conv_2   = nn.Sequential(BasicConv2d(512+32*3, 128, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_2    = GCM(256+32,  channel)\n",
        "\n",
        "        self.ful_conv_1   = nn.Sequential(BasicConv2d(256+32*3, 128, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_1    = GCM(128+32,  channel)\n",
        "\n",
        "        self.ful_conv_0   = nn.Sequential(BasicConv2d(128+32*3, 64, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_0    = GCM(64+32,  channel)        \n",
        "        self.ful_conv_out = nn.Conv2d(channel, 1, 1)\n",
        "        \n",
        "        self.ful_layer4   = MFA(channel)\n",
        "        self.ful_layer3   = MFA(channel)\n",
        "        self.ful_layer2   = MFA(channel)\n",
        "        self.ful_layer1   = MFA(channel)\n",
        "        self.ful_layer0   = MFA(channel)\n",
        "        \n",
        "                \n",
        "\n",
        "    def forward(self, imgs, depths):\n",
        "        \n",
        "        img_0, img_1, img_2, img_3, img_4 = self.layer_rgb(imgs)\n",
        "        dep_0, dep_1, dep_2, dep_3, dep_4 = self.layer_dep(self.layer_dep0(depths))\n",
        "        \n",
        "    \n",
        "      \n",
        "        ####################################################\n",
        "        ## fusion\n",
        "        ####################################################\n",
        "        ful_0    = self.fu_0(img_0, dep_0)\n",
        "        ful_1    = self.fu_1(img_1, dep_1, ful_0)\n",
        "        ful_2    = self.fu_2(img_2, dep_2, self.pool_fu_1(ful_1))\n",
        "        ful_3    = self.fu_3(img_3, dep_3, self.pool_fu_2(ful_2))\n",
        "        ful_4    = self.fu_4(img_4, dep_4, self.pool_fu_3(ful_3))\n",
        "        \n",
        "        ####################################################\n",
        "        ## decoder rgb\n",
        "        ####################################################        \n",
        "        #\n",
        "        x_rgb_42    = self.rgb_gcm_4(img_4)\n",
        "        \n",
        "        x_rgb_3_cat = torch.cat([img_3, self.upsample_2(x_rgb_42)], dim=1)\n",
        "        x_rgb_32    = self.rgb_gcm_3(x_rgb_3_cat)\n",
        "        \n",
        "        x_rgb_2_cat = torch.cat([img_2, self.upsample_2(x_rgb_32)], dim=1)\n",
        "        x_rgb_22    = self.rgb_gcm_2(x_rgb_2_cat)        \n",
        "\n",
        "        x_rgb_1_cat = torch.cat([img_1, self.upsample_2(x_rgb_22)], dim=1)\n",
        "        x_rgb_12    = self.rgb_gcm_1(x_rgb_1_cat)     \n",
        "\n",
        "        x_rgb_0_cat = torch.cat([img_0, x_rgb_12], dim=1)\n",
        "        x_rgb_02    = self.rgb_gcm_0(x_rgb_0_cat)     \n",
        "        rgb_out     = self.upsample_4(self.rgb_conv_out(x_rgb_02))\n",
        "        \n",
        "        \n",
        "        ####################################################\n",
        "        ## decoder depth\n",
        "        ####################################################        \n",
        "        #\n",
        "        x_dep_42    = self.dep_gcm_4(dep_4)\n",
        "        \n",
        "        x_dep_3_cat = torch.cat([dep_3, self.upsample_2(x_dep_42)], dim=1)\n",
        "        x_dep_32    = self.dep_gcm_3(x_dep_3_cat)\n",
        "        \n",
        "        x_dep_2_cat = torch.cat([dep_2, self.upsample_2(x_dep_32)], dim=1)\n",
        "        x_dep_22    = self.dep_gcm_2(x_dep_2_cat)        \n",
        "\n",
        "        x_dep_1_cat = torch.cat([dep_1, self.upsample_2(x_dep_22)], dim=1)\n",
        "        x_dep_12    = self.dep_gcm_1(x_dep_1_cat)     \n",
        "\n",
        "        x_dep_0_cat = torch.cat([dep_0, x_dep_12], dim=1)\n",
        "        x_dep_02    = self.dep_gcm_0(x_dep_0_cat)     \n",
        "        dep_out     = self.upsample_4(self.dep_conv_out(x_dep_02))\n",
        "        \n",
        "\n",
        "        ####################################################\n",
        "        ## decoder fusion\n",
        "        ####################################################        \n",
        "        #\n",
        "        x_ful_42    = self.ful_gcm_4(ful_4)\n",
        "        \n",
        "        x_ful_3_cat = torch.cat([ful_3, self.ful_layer3(self.upsample_2(x_ful_42),self.upsample_2(x_rgb_42),self.upsample_2(x_dep_42))], dim=1)\n",
        "        x_ful_32    = self.ful_gcm_3(x_ful_3_cat)\n",
        "        \n",
        "        x_ful_2_cat = torch.cat([ful_2, self.ful_layer2(self.upsample_2(x_ful_32),self.upsample_2(x_rgb_32),self.upsample_2(x_dep_32))], dim=1)\n",
        "        x_ful_22    = self.ful_gcm_2(x_ful_2_cat)        \n",
        "\n",
        "        x_ful_1_cat = torch.cat([ful_1, self.ful_layer1(self.upsample_2(x_ful_22),self.upsample_2(x_rgb_22),self.upsample_2(x_dep_22))], dim=1)\n",
        "        x_ful_12    = self.ful_gcm_1(x_ful_1_cat)     \n",
        "\n",
        "        x_ful_0_cat = torch.cat([ful_0, self.ful_layer0(x_ful_12, x_rgb_12, x_dep_12)], dim=1)\n",
        "        x_ful_02    = self.ful_gcm_0(x_ful_0_cat)     \n",
        "        ful_out     = self.upsample_4(self.ful_conv_out(x_ful_02))\n",
        "\n",
        "\n",
        "        return rgb_out, dep_out, ful_out\n",
        "    \n",
        "    \n",
        "\n",
        "    def _make_agant_layer(self, inplanes, planes):\n",
        "        layers = nn.Sequential(\n",
        "            nn.Conv2d(inplanes, planes, kernel_size=1,\n",
        "                      stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(planes),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        return layers\n",
        "\n",
        "    def _make_transpose(self, block, planes, blocks, stride=1):\n",
        "        upsample = None\n",
        "        if stride != 1:\n",
        "            upsample = nn.Sequential(\n",
        "                nn.ConvTranspose2d(self.inplanes, planes,\n",
        "                                   kernel_size=2, stride=stride,\n",
        "                                   padding=0, bias=False),\n",
        "                nn.BatchNorm2d(planes),\n",
        "            )\n",
        "        elif self.inplanes != planes:\n",
        "            upsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, self.inplanes))\n",
        "\n",
        "        layers.append(block(self.inplanes, planes, stride, upsample))\n",
        "        self.inplanes = planes\n",
        "\n",
        "        return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-uZRV-GLXGz"
      },
      "source": [
        "## Data Preprocessing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbveAVtDLglO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import ImageEnhance\n",
        "\n",
        "#several data augumentation strategies\n",
        "def cv_random_flip(img, label,depth):\n",
        "    flip_flag = random.randint(0, 1)\n",
        "    # flip_flag2= random.randint(0,1)\n",
        "    #left right flip\n",
        "    if flip_flag == 1:\n",
        "        img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        label = label.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        depth = depth.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "    #top bottom flip\n",
        "    # if flip_flag2==1:\n",
        "    #     img = img.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "    #     label = label.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "    #     depth = depth.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "    return img, label, depth\n",
        "def randomCrop(image, label,depth):\n",
        "    border=30\n",
        "    image_width = image.size[0]\n",
        "    image_height = image.size[1]\n",
        "    crop_win_width = np.random.randint(image_width-border , image_width)\n",
        "    crop_win_height = np.random.randint(image_height-border , image_height)\n",
        "    random_region = (\n",
        "        (image_width - crop_win_width) >> 1, (image_height - crop_win_height) >> 1, (image_width + crop_win_width) >> 1,\n",
        "        (image_height + crop_win_height) >> 1)\n",
        "    return image.crop(random_region), label.crop(random_region),depth.crop(random_region)\n",
        "def randomRotation(image,label,depth):\n",
        "    mode=Image.BICUBIC\n",
        "    if random.random()>0.8:\n",
        "        random_angle = np.random.randint(-15, 15)\n",
        "        image=image.rotate(random_angle, mode)\n",
        "        label=label.rotate(random_angle, mode)\n",
        "        depth=depth.rotate(random_angle, mode)\n",
        "    return image,label,depth\n",
        "def colorEnhance(image):\n",
        "    bright_intensity=random.randint(5,15)/10.0\n",
        "    image=ImageEnhance.Brightness(image).enhance(bright_intensity)\n",
        "    contrast_intensity=random.randint(5,15)/10.0\n",
        "    image=ImageEnhance.Contrast(image).enhance(contrast_intensity)\n",
        "    color_intensity=random.randint(0,20)/10.0\n",
        "    image=ImageEnhance.Color(image).enhance(color_intensity)\n",
        "    sharp_intensity=random.randint(0,30)/10.0\n",
        "    image=ImageEnhance.Sharpness(image).enhance(sharp_intensity)\n",
        "    return image\n",
        "def randomGaussian(image, mean=0.1, sigma=0.35):\n",
        "    def gaussianNoisy(im, mean=mean, sigma=sigma):\n",
        "        for _i in range(len(im)):\n",
        "            im[_i] += random.gauss(mean, sigma)\n",
        "        return im\n",
        "    img = np.asarray(image)\n",
        "    width, height = img.shape\n",
        "    img = gaussianNoisy(img[:].flatten(), mean, sigma)\n",
        "    img = img.reshape([width, height])\n",
        "    return Image.fromarray(np.uint8(img))\n",
        "def randomPeper(img):\n",
        "\n",
        "    img=np.array(img)\n",
        "    noiseNum=int(0.0015*img.shape[0]*img.shape[1])\n",
        "    for i in range(noiseNum):\n",
        "\n",
        "        randX=random.randint(0,img.shape[0]-1)  \n",
        "\n",
        "        randY=random.randint(0,img.shape[1]-1)  \n",
        "\n",
        "        if random.randint(0,1)==0:  \n",
        "\n",
        "            img[randX,randY]=0  \n",
        "\n",
        "        else:  \n",
        "\n",
        "            img[randX,randY]=255 \n",
        "    return Image.fromarray(img)  \n",
        "\n",
        "# dataset for training\n",
        "#The current loader is not using the normalized depth maps for training and test. If you use the normalized depth maps\n",
        "#(e.g., 0 represents background and 1 represents foreground.), the performance will be further improved.\n",
        "\n",
        "class SalObjDataset(data.Dataset):\n",
        "    def __init__(self, image_root, gt_root,depth_root, trainsize):\n",
        "        self.trainsize = trainsize\n",
        "        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "        self.gts = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.jpg')\n",
        "                    or f.endswith('.png')]\n",
        "        self.depths=[depth_root + f for f in os.listdir(depth_root) if f.endswith('.bmp')\n",
        "                    or f.endswith('.png')]\n",
        "        self.images = sorted(self.images)\n",
        "        self.gts = sorted(self.gts)\n",
        "        self.depths=sorted(self.depths)\n",
        "        print('SalObjDat', )\n",
        "        self.filter_files()\n",
        "        self.size = len(self.images)\n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        self.gt_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor()])\n",
        "        self.depths_transform = transforms.Compose([transforms.Resize((self.trainsize, self.trainsize)),transforms.ToTensor()])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.rgb_loader(self.images[index])\n",
        "        gt = self.binary_loader(self.gts[index])\n",
        "        depth=self.binary_loader(self.depths[index])\n",
        "        image,gt,depth =cv_random_flip(image,gt,depth)\n",
        "        image,gt,depth=randomCrop(image, gt,depth)\n",
        "        image,gt,depth=randomRotation(image, gt,depth)\n",
        "        image=colorEnhance(image)\n",
        "        # gt=randomGaussian(gt)\n",
        "        gt=randomPeper(gt)\n",
        "        image = self.img_transform(image)\n",
        "        gt = self.gt_transform(gt)\n",
        "        depth=self.depths_transform(depth)\n",
        "        \n",
        "        return image, gt, depth\n",
        "\n",
        "    def filter_files(self):\n",
        "        print('SalObjDataset', self.images, self.gts)\n",
        "        assert len(self.images) == len(self.gts) and len(self.gts)==len(self.images)\n",
        "        images = []\n",
        "        gts = []\n",
        "        depths=[]\n",
        "        for img_path, gt_path,depth_path in zip(self.images, self.gts, self.depths):\n",
        "            img = Image.open(img_path)\n",
        "            gt = Image.open(gt_path)\n",
        "            depth= Image.open(depth_path)\n",
        "            if img.size == gt.size and gt.size==depth.size:\n",
        "                images.append(img_path)\n",
        "                gts.append(gt_path)\n",
        "                depths.append(depth_path)\n",
        "        self.images = images\n",
        "        self.gts = gts\n",
        "        self.depths=depths\n",
        "\n",
        "    def rgb_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def binary_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('L')\n",
        "\n",
        "    def resize(self, img, gt, depth):\n",
        "        assert img.size == gt.size and gt.size==depth.size\n",
        "        w, h = img.size\n",
        "        if h < self.trainsize or w < self.trainsize:\n",
        "            h = max(h, self.trainsize)\n",
        "            w = max(w, self.trainsize)\n",
        "            return img.resize((w, h), Image.BILINEAR), gt.resize((w, h), Image.NEAREST),depth.resize((w, h), Image.NEAREST)\n",
        "        else:\n",
        "            return img, gt, depth\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 0919\n",
        "#\n",
        "\n",
        "class SalObjDataset_var(data.Dataset):\n",
        "    def __init__(self, image_root, gt_root,depth_root, trainsize):\n",
        "        \n",
        "        self.trainsize = trainsize\n",
        "        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.jpg')]\n",
        "        self.gts    = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "        self.depths = [depth_root + f for f in os.listdir(depth_root) if f.endswith('.bmp') or f.endswith('.png')]\n",
        "        self.images = sorted(self.images)\n",
        "        self.gts    = sorted(self.gts)\n",
        "        self.depths = sorted(self.depths)\n",
        "        self.filter_files()\n",
        "        self.size   = len(self.images)\n",
        "        \n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        self.gt_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor()])\n",
        "        self.depths_transform = transforms.Compose([transforms.Resize((self.trainsize, self.trainsize)),transforms.ToTensor()])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        ## read imag, gt, depth\n",
        "        image0 = self.rgb_loader(self.images[index])\n",
        "        gt0    = self.binary_loader(self.gts[index])\n",
        "        depth0 = self.binary_loader(self.depths[index])\n",
        "        \n",
        "        \n",
        "        ##################################################\n",
        "        ## out1\n",
        "        ##################################################\n",
        "        image,gt,depth = cv_random_flip(image0,gt0,depth0)\n",
        "        image,gt,depth = randomCrop(image, gt,depth)\n",
        "        image,gt,depth = randomRotation(image, gt,depth)\n",
        "        image          = colorEnhance(image)\n",
        "        gt             = randomPeper(gt)\n",
        "        image          = self.img_transform(image)\n",
        "        gt             = self.gt_transform(gt)\n",
        "        depth          = self.depths_transform(depth)\n",
        "\n",
        "        ##################################################\n",
        "        ## out1\n",
        "        ##################################################\n",
        "        image2,gt2,depth2 = cv_random_flip(image0,gt0,depth0)\n",
        "        image2,gt2,depth2 = randomCrop(image2, gt2,depth2)\n",
        "        image2,gt2,depth2 = randomRotation(image2, gt2,depth2)\n",
        "        image2          = colorEnhance(image2)\n",
        "        gt2             = randomPeper(gt2)\n",
        "        image2          = self.img_transform(image2)\n",
        "        gt2             = self.gt_transform(gt2)\n",
        "        depth2          = self.depths_transform(depth2)\n",
        "\n",
        "        \n",
        "        return image, gt, depth, image2, gt2, depth2\n",
        "\n",
        "    def filter_files(self):\n",
        "\n",
        "        \n",
        "        assert len(self.images) == len(self.gts) and len(self.gts)==len(self.images)\n",
        "        images = []\n",
        "        gts = []\n",
        "        depths=[]\n",
        "        for img_path, gt_path,depth_path in zip(self.images, self.gts, self.depths):\n",
        "            img = Image.open(img_path)\n",
        "            gt = Image.open(gt_path)\n",
        "            depth= Image.open(depth_path)\n",
        "            if img.size == gt.size and gt.size==depth.size:\n",
        "                images.append(img_path)\n",
        "                gts.append(gt_path)\n",
        "                depths.append(depth_path)\n",
        "        self.images = images\n",
        "        self.gts = gts\n",
        "        self.depths=depths\n",
        "\n",
        "    def rgb_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def binary_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('L')\n",
        "\n",
        "    def resize(self, img, gt, depth):\n",
        "        assert img.size == gt.size and gt.size==depth.size\n",
        "        w, h = img.size\n",
        "        if h < self.trainsize or w < self.trainsize:\n",
        "            h = max(h, self.trainsize)\n",
        "            w = max(w, self.trainsize)\n",
        "            return img.resize((w, h), Image.BILINEAR), gt.resize((w, h), Image.NEAREST),depth.resize((w, h), Image.NEAREST)\n",
        "        else:\n",
        "            return img, gt, depth\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "\n",
        "\n",
        "class SalObjDataset_var_unlabel(data.Dataset):\n",
        "    def __init__(self, image_root, gt_root,depth_root, trainsize):\n",
        "        \n",
        "        self.trainsize = trainsize\n",
        "        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.png')]\n",
        "        self.gts    = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "        self.depths = [depth_root + f for f in os.listdir(depth_root) if f.endswith('.bmp') or f.endswith('.png')]\n",
        "        self.images = sorted(self.images)\n",
        "        self.gts    = sorted(self.gts)\n",
        "        self.depths = sorted(self.depths)\n",
        "        self.filter_files()\n",
        "        self.size   = len(self.images)\n",
        "        \n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        self.gt_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor()])\n",
        "        self.depths_transform = transforms.Compose([transforms.Resize((self.trainsize, self.trainsize)),transforms.ToTensor()])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        ## read imag, gt, depth\n",
        "        image0 = self.rgb_loader(self.images[index])\n",
        "        gt0    = self.binary_loader(self.gts[index])\n",
        "        depth0 = self.binary_loader(self.depths[index])\n",
        "        \n",
        "        \n",
        "        ##################################################\n",
        "        ## out1\n",
        "        ##################################################\n",
        "        image,gt,depth = cv_random_flip(image0,gt0,depth0)\n",
        "        image,gt,depth = randomCrop(image, gt,depth)\n",
        "        image,gt,depth = randomRotation(image, gt,depth)\n",
        "        image          = colorEnhance(image)\n",
        "        gt             = randomPeper(gt)\n",
        "        image          = self.img_transform(image)\n",
        "        gt             = self.gt_transform(gt)\n",
        "        depth          = self.depths_transform(depth)\n",
        "\n",
        "        ##################################################\n",
        "        ## out1\n",
        "        ##################################################\n",
        "        image2,gt2,depth2 = cv_random_flip(image0,gt0,depth0)\n",
        "        image2,gt2,depth2 = randomCrop(image2, gt2,depth2)\n",
        "        image2,gt2,depth2 = randomRotation(image2, gt2,depth2)\n",
        "        image2          = colorEnhance(image2)\n",
        "        gt2             = randomPeper(gt2)\n",
        "        image2          = self.img_transform(image2)\n",
        "        gt2             = self.gt_transform(gt2)\n",
        "        depth2          = self.depths_transform(depth2)\n",
        "\n",
        "        \n",
        "        return image, gt, depth, image2, gt2, depth2\n",
        "\n",
        "    def filter_files(self):\n",
        "\n",
        "        assert len(self.images) == len(self.gts) and len(self.gts)==len(self.images)\n",
        "        images = []\n",
        "        gts = []\n",
        "        depths=[]\n",
        "        for img_path, gt_path,depth_path in zip(self.images, self.gts, self.depths):\n",
        "            img = Image.open(img_path)\n",
        "            gt = Image.open(gt_path)\n",
        "            depth= Image.open(depth_path)\n",
        "            if img.size == gt.size and gt.size==depth.size:\n",
        "                images.append(img_path)\n",
        "                gts.append(gt_path)\n",
        "                depths.append(depth_path)\n",
        "        self.images = images\n",
        "        self.gts = gts\n",
        "        self.depths=depths\n",
        "\n",
        "    def rgb_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def binary_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('L')\n",
        "\n",
        "    def resize(self, img, gt, depth):\n",
        "        assert img.size == gt.size and gt.size==depth.size\n",
        "        w, h = img.size\n",
        "        if h < self.trainsize or w < self.trainsize:\n",
        "            h = max(h, self.trainsize)\n",
        "            w = max(w, self.trainsize)\n",
        "            return img.resize((w, h), Image.BILINEAR), gt.resize((w, h), Image.NEAREST),depth.resize((w, h), Image.NEAREST)\n",
        "        else:\n",
        "            return img, gt, depth\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "#dataloader for training\n",
        "def get_loader(image_root, gt_root,depth_root, batchsize, trainsize, shuffle=True, num_workers=12, pin_memory=False):\n",
        "    print(image_root, gt_root, depth_root)\n",
        "    dataset = SalObjDataset(image_root, gt_root, depth_root,trainsize)\n",
        "    print(dataset)\n",
        "    data_loader = data.DataLoader(dataset=dataset,\n",
        "                                  batch_size=batchsize,\n",
        "                                  shuffle=shuffle,\n",
        "                                  num_workers=num_workers,\n",
        "                                  pin_memory=pin_memory)\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "#dataloader for training2\n",
        "## 09-19-2020\n",
        "def get_loader_var(image_root, gt_root,depth_root, batchsize, trainsize, shuffle=True, num_workers=12, pin_memory=False):\n",
        "\n",
        "    dataset = SalObjDataset_var(image_root, gt_root, depth_root,trainsize)\n",
        "    data_loader = data.DataLoader(dataset=dataset,\n",
        "                                  batch_size=batchsize,\n",
        "                                  shuffle=shuffle,\n",
        "                                  num_workers=num_workers,\n",
        "                                  pin_memory=pin_memory)\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "def get_loader_var_unlabel(image_root, gt_root,depth_root, batchsize, trainsize, shuffle=True, num_workers=12, pin_memory=False):\n",
        "\n",
        "    dataset = SalObjDataset_var_unlabel(image_root, gt_root, depth_root,trainsize)\n",
        "    data_loader = data.DataLoader(dataset=dataset,\n",
        "                                  batch_size=batchsize,\n",
        "                                  shuffle=shuffle,\n",
        "                                  num_workers=num_workers,\n",
        "                                  pin_memory=pin_memory)\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "#test dataset and loader\n",
        "class test_dataset:\n",
        "    def __init__(self, image_root, gt_root,depth_root, testsize):\n",
        "        self.testsize = testsize\n",
        "        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "        self.gts = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.jpg')\n",
        "                       or f.endswith('.png')]\n",
        "        self.depths=[depth_root + f for f in os.listdir(depth_root) if f.endswith('.bmp')\n",
        "                    or f.endswith('.png')]\n",
        "        self.images = sorted(self.images)\n",
        "        self.gts = sorted(self.gts)\n",
        "        self.depths=sorted(self.depths)\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((self.testsize, self.testsize)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        self.gt_transform = transforms.ToTensor()\n",
        "        # self.gt_transform = transforms.Compose([\n",
        "        #     transforms.Resize((self.trainsize, self.trainsize)),\n",
        "        #     transforms.ToTensor()])\n",
        "        self.depths_transform = transforms.Compose([transforms.Resize((self.testsize, self.testsize)),transforms.ToTensor()])\n",
        "        self.size = len(self.images)\n",
        "        self.index = 0\n",
        "\n",
        "    def load_data(self):\n",
        "        image = self.rgb_loader(self.images[self.index])\n",
        "        image = self.transform(image).unsqueeze(0)\n",
        "        gt = self.binary_loader(self.gts[self.index])\n",
        "        depth=self.binary_loader(self.depths[self.index])\n",
        "        depth=self.depths_transform(depth).unsqueeze(0)\n",
        "        name = self.images[self.index].split('/')[-1]\n",
        "        image_for_post=self.rgb_loader(self.images[self.index])\n",
        "        image_for_post=image_for_post.resize(gt.size)\n",
        "        if name.endswith('.jpg'):\n",
        "            name = name.split('.jpg')[0] + '.png'\n",
        "        self.index += 1\n",
        "        self.index = self.index % self.size\n",
        "        return image, gt,depth, name,np.array(image_for_post)\n",
        "\n",
        "    def rgb_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def binary_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('L')\n",
        "    def __len__(self):\n",
        "        return self.size\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTNA4QgLL_Fp"
      },
      "source": [
        "##Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9CzuKgEMD60"
      },
      "outputs": [],
      "source": [
        "def clip_gradient(optimizer, grad_clip):\n",
        "    for group in optimizer.param_groups:\n",
        "        for param in group['params']:\n",
        "            if param.grad is not None:\n",
        "                param.grad.data.clamp_(-grad_clip, grad_clip)\n",
        "\n",
        "\n",
        "def adjust_lr(optimizer, init_lr, epoch, decay_rate=0.1, decay_epoch=30):\n",
        "    decay = decay_rate ** (epoch // decay_epoch)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = decay*init_lr\n",
        "        lr=param_group['lr']\n",
        "    return lr\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuvpBxP8qObG"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Sep 29 17:21:18 2020\n",
        "\n",
        "@author: taozhou\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "## basic funcs\n",
        "###############################################################################\n",
        "\n",
        "def fun_eval_e(y_pred, y, num, cuda=True):\n",
        "    \n",
        "    if cuda:\n",
        "        score = torch.zeros(num).cuda()\n",
        "    else:\n",
        "        score = torch.zeros(num)\n",
        "    \n",
        "    for i in range(num):\n",
        "        \n",
        "        fm = y_pred - y_pred.mean()\n",
        "        gt = y - y.mean()\n",
        "        align_matrix = 2 * gt * fm / (gt * gt + fm * fm + 1e-20)\n",
        "        enhanced = ((align_matrix + 1) * (align_matrix + 1)) / 4\n",
        "        score[i] = torch.sum(enhanced) / (y.numel() - 1 + 1e-20)        \n",
        "    return score.max()\n",
        "\n",
        "\n",
        "def fun_eval_pr(y_pred, y, num, cuda=True):\n",
        "    \n",
        "    if cuda:\n",
        "        prec, recall = torch.zeros(num).cuda(), torch.zeros(num).cuda()\n",
        "        thlist = torch.linspace(0, 1 - 1e-10, num).cuda()\n",
        "    else:\n",
        "        prec, recall = torch.zeros(num), torch.zeros(num)\n",
        "        thlist = torch.linspace(0, 1 - 1e-10, num)\n",
        "    \n",
        "    for i in range(num):\n",
        "        y_temp = (y_pred >= thlist[i]).float()\n",
        "        tp = (y_temp * y).sum()\n",
        "        prec[i], recall[i] = tp / (y_temp.sum() + 1e-20), tp / (y.sum() + 1e-20)\n",
        "    return prec, recall\n",
        "    \n",
        "\n",
        "def fun_S_object(pred, gt):\n",
        "        \n",
        "    fg = torch.where(gt==0, torch.zeros_like(pred), pred)\n",
        "    bg = torch.where(gt==1, torch.zeros_like(pred), 1-pred)\n",
        "    o_fg = fun_object(fg, gt)\n",
        "    o_bg = fun_object(bg, 1-gt)\n",
        "    u = gt.mean()\n",
        "    Q = u * o_fg + (1-u) * o_bg\n",
        "    return Q\n",
        "\n",
        "\n",
        "def fun_object(pred, gt):\n",
        "    \n",
        "    temp = pred[gt == 1]\n",
        "    x = temp.mean()\n",
        "    sigma_x = temp.std()\n",
        "    score = 2.0 * x / (x * x + 1.0 + sigma_x + 1e-20)\n",
        "        \n",
        "    return score\n",
        "\n",
        "\n",
        "def fun_S_region(pred, gt):\n",
        "    \n",
        "    X, Y = fun_centroid(gt)\n",
        "    gt1, gt2, gt3, gt4, w1, w2, w3, w4 = fun_divideGT(gt, X, Y)\n",
        "    p1, p2, p3, p4 = fun_dividePrediction(pred, X, Y)\n",
        "    Q1 = fun_ssim(p1, gt1)\n",
        "    Q2 = fun_ssim(p2, gt2)\n",
        "    Q3 = fun_ssim(p3, gt3)\n",
        "    Q4 = fun_ssim(p4, gt4)\n",
        "    Q = w1*Q1 + w2*Q2 + w3*Q3 + w4*Q4\n",
        "    \n",
        "    return Q\n",
        "    \n",
        "def fun_centroid(gt, cuda=True):\n",
        "    \n",
        "    rows, cols = gt.size()[-2:]\n",
        "    gt = gt.view(rows, cols)\n",
        "    \n",
        "    if gt.sum() == 0:\n",
        "        \n",
        "        if cuda:\n",
        "            X = torch.eye(1).cuda() * round(cols / 2)\n",
        "            Y = torch.eye(1).cuda() * round(rows / 2)\n",
        "        else:\n",
        "            X = torch.eye(1) * round(cols / 2)\n",
        "            Y = torch.eye(1) * round(rows / 2)\n",
        "    \n",
        "    else:\n",
        "        total = gt.sum()\n",
        "        \n",
        "        if cuda:\n",
        "            i = torch.from_numpy(np.arange(0,cols)).cuda().float()\n",
        "            j = torch.from_numpy(np.arange(0,rows)).cuda().float()\n",
        "        else:\n",
        "            i = torch.from_numpy(np.arange(0,cols)).float()\n",
        "            j = torch.from_numpy(np.arange(0,rows)).float()\n",
        "            \n",
        "        X = torch.round((gt.sum(dim=0)*i).sum() / total)\n",
        "        Y = torch.round((gt.sum(dim=1)*j).sum() / total)\n",
        "        \n",
        "    return X.long(), Y.long()\n",
        "  \n",
        "    \n",
        "def fun_divideGT(gt, X, Y):\n",
        "    \n",
        "    h, w = gt.size()[-2:]\n",
        "    area = h*w\n",
        "    gt   = gt.view(h, w)\n",
        "    LT   = gt[:Y, :X]\n",
        "    RT   = gt[:Y, X:w]\n",
        "    LB   = gt[Y:h, :X]\n",
        "    RB   = gt[Y:h, X:w]\n",
        "    X    = X.float()\n",
        "    Y    = Y.float()\n",
        "    w1   = X * Y / area\n",
        "    w2   = (w - X) * Y / area\n",
        "    w3   = X * (h - Y) / area\n",
        "    w4   = 1 - w1 - w2 - w3\n",
        "    \n",
        "    return LT, RT, LB, RB, w1, w2, w3, w4\n",
        "\n",
        "def fun_dividePrediction(pred, X, Y):\n",
        "    \n",
        "    h, w = pred.size()[-2:]\n",
        "    pred = pred.view(h, w)\n",
        "    LT = pred[:Y, :X]\n",
        "    RT = pred[:Y, X:w]\n",
        "    LB = pred[Y:h, :X]\n",
        "    RB = pred[Y:h, X:w]\n",
        "        \n",
        "    return LT, RT, LB, RB\n",
        "\n",
        "\n",
        "def fun_ssim(pred, gt):\n",
        "    \n",
        "    gt       = gt.float()\n",
        "    h, w     = pred.size()[-2:]\n",
        "    N        = h*w\n",
        "    x        = pred.mean()\n",
        "    y        = gt.mean()\n",
        "    sigma_x2 = ((pred - x)*(pred - x)).sum() / (N - 1 + 1e-20)\n",
        "    sigma_y2 = ((gt - y)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "    sigma_xy = ((pred - x)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "        \n",
        "    aplha = 4 * x * y *sigma_xy\n",
        "    beta = (x*x + y*y) * (sigma_x2 + sigma_y2)\n",
        "    \n",
        "    if aplha != 0:\n",
        "        Q = aplha / (beta + 1e-20)\n",
        "    elif aplha == 0 and beta == 0:\n",
        "        Q = 1.0\n",
        "    else:\n",
        "        Q = 0\n",
        "    \n",
        "    return Q\n",
        "\n",
        "###############################################################################\n",
        "## metric funcs\n",
        "###############################################################################\n",
        "def eval_mae(pred,gt,cuda=True):\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        trans = transforms.Compose([transforms.ToTensor()])\n",
        "        \n",
        "        if cuda:\n",
        "            pred = pred.cuda()\n",
        "            gt   = gt.cuda()\n",
        "#        else:\n",
        "#            pred = trans(pred)\n",
        "#            gt = trans(gt)\n",
        "                \n",
        "        mae = torch.abs(pred - gt).mean()\n",
        "        \n",
        "    return mae.cpu().detach().numpy()\n",
        "                \n",
        "\n",
        "def eval_Smeasure(pred,gt,cuda=True):\n",
        "    \n",
        "    alpha, avg_q, img_num = 0.5, 0.0, 0.0\n",
        "   \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        trans = transforms.Compose([transforms.ToTensor()])\n",
        "        \n",
        "        if cuda:\n",
        "            pred = pred.cuda()\n",
        "            gt   = gt.cuda()\n",
        "\n",
        "        \n",
        "        y = gt.mean()\n",
        "        \n",
        "        ##\n",
        "        if y == 0:\n",
        "            x = pred.mean()\n",
        "            Q = 1.0 - x\n",
        "        elif y == 1:\n",
        "            x = pred.mean()\n",
        "            Q = x\n",
        "        else:\n",
        "            Q = alpha * fun_S_object(pred, gt) + (1-alpha) * fun_S_region(pred, gt)\n",
        "            if Q.item() < 0:\n",
        "                Q = torch.FLoatTensor([0.0])\n",
        "                \n",
        "    return Q.item()\n",
        "\n",
        "                \n",
        "def eval_fmeasure(pred, gt, cuda=True):\n",
        "    print('eval[FMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "    \n",
        "    beta2 = 0.3\n",
        "    avg_p, avg_r, img_num = 0.0, 0.0, 0.0\n",
        "    \n",
        "    ##    \n",
        "    with torch.no_grad():\n",
        "        trans = transforms.Compose([transforms.ToTensor()])\n",
        "        if cuda:\n",
        "            pred = trans(pred).cuda()\n",
        "            gt = trans(gt).cuda()\n",
        "        else:\n",
        "            pred = trans(pred)\n",
        "            gt = trans(gt)\n",
        "                \n",
        "        prec, recall = fun_eval_pr(pred, gt, 255)\n",
        "\n",
        "    return prec, recall\n",
        "              \n",
        "\n",
        "class Eval_thread():\n",
        "    def __init__(self, loader, method, dataset, output_dir, cuda):\n",
        "        self.loader = loader\n",
        "        self.method = method\n",
        "        self.dataset = dataset\n",
        "        self.cuda = cuda\n",
        "        self.logfile = os.path.join(output_dir, 'result.txt')\n",
        "    def run(self):\n",
        "        start_time = time.time()\n",
        "        mae = self.Eval_mae()\n",
        "        s = self.Eval_Smeasure()\n",
        "        \n",
        "        return mae,s\n",
        "        \n",
        "        #max_f = self.Eval_fmeasure()\n",
        "        #max_e = self.Eval_Emeasure()\n",
        "        \n",
        "        #self.LOG('{} dataset with {} method get {:.4f} mae, {:.4f} max-fmeasure, {:.4f} max-Emeasure, {:.4f} S-measure..\\n'.format(self.dataset, self.method, mae, max_f, max_e, s))\n",
        "        #return '[cost:{:.4f}s]{} dataset with {} method get {:.4f} mae, {:.4f} max-fmeasure, {:.4f} max-Emeasure, {:.4f} S-measure..'.format(time.time()-start_time, self.dataset, self.method, mae, max_f, max_e, s)\n",
        "    \n",
        "    def Eval_mae(self):\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    \n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                mea = torch.abs(pred - gt).mean()\n",
        "                if mea == mea: # for Nan\n",
        "                    avg_mae += mea\n",
        "                    img_num += 1.0\n",
        "            avg_mae /= img_num\n",
        "            \n",
        "            return avg_mae.item()\n",
        "    \n",
        "    def Eval_fmeasure(self):\n",
        "        print('eval[FMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        beta2 = 0.3\n",
        "        avg_p, avg_r, img_num = 0.0, 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                prec, recall = self._eval_pr(pred, gt, 255)\n",
        "                avg_p += prec\n",
        "                avg_r += recall\n",
        "                img_num += 1.0\n",
        "            avg_p /= img_num\n",
        "            avg_r /= img_num\n",
        "            score = (1 + beta2) * avg_p * avg_r / (beta2 * avg_p + avg_r)\n",
        "            score[score != score] = 0 # for Nan\n",
        "            \n",
        "            return score.max().item()\n",
        "    def Eval_Emeasure(self):\n",
        "        print('eval[EMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        avg_e, img_num = 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                max_e = self._eval_e(pred, gt, 255)\n",
        "                if max_e == max_e:\n",
        "                    avg_e += max_e\n",
        "                    img_num += 1.0\n",
        "                \n",
        "            avg_e /= img_num\n",
        "            return avg_e\n",
        "    def Eval_Smeasure(self):\n",
        "        #print('eval[SMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        alpha, avg_q, img_num = 0.5, 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                y = gt.mean()\n",
        "                if y == 0:\n",
        "                    x = pred.mean()\n",
        "                    Q = 1.0 - x\n",
        "                elif y == 1:\n",
        "                    x = pred.mean()\n",
        "                    Q = x\n",
        "                else:\n",
        "                    Q = alpha * self._S_object(pred, gt) + (1-alpha) * self._S_region(pred, gt)\n",
        "                    if Q.item() < 0:\n",
        "                        Q = torch.FLoatTensor([0.0])\n",
        "                img_num += 1.0\n",
        "                avg_q += Q.item()\n",
        "            avg_q /= img_num\n",
        "            \n",
        "            return avg_q\n",
        "    def LOG(self, output):\n",
        "        with open(self.logfile, 'a') as f:\n",
        "            f.write(output)\n",
        "\n",
        "    def _eval_e(self, y_pred, y, num):\n",
        "        if self.cuda:\n",
        "            score = torch.zeros(num).cuda()\n",
        "        else:\n",
        "            score = torch.zeros(num)\n",
        "        for i in range(num):\n",
        "            fm = y_pred - y_pred.mean()\n",
        "            gt = y - y.mean()\n",
        "            align_matrix = 2 * gt * fm / (gt * gt + fm * fm + 1e-20)\n",
        "            enhanced = ((align_matrix + 1) * (align_matrix + 1)) / 4\n",
        "            score[i] = torch.sum(enhanced) / (y.numel() - 1 + 1e-20)\n",
        "        return score.max()\n",
        "\n",
        "    def _eval_pr(self, y_pred, y, num):\n",
        "        if self.cuda:\n",
        "            prec, recall = torch.zeros(num).cuda(), torch.zeros(num).cuda()\n",
        "            thlist = torch.linspace(0, 1 - 1e-10, num).cuda()\n",
        "        else:\n",
        "            prec, recall = torch.zeros(num), torch.zeros(num)\n",
        "            thlist = torch.linspace(0, 1 - 1e-10, num)\n",
        "        for i in range(num):\n",
        "            y_temp = (y_pred >= thlist[i]).float()\n",
        "            tp = (y_temp * y).sum()\n",
        "            prec[i], recall[i] = tp / (y_temp.sum() + 1e-20), tp / (y.sum() + 1e-20)\n",
        "        return prec, recall\n",
        "    \n",
        "    def _S_object(self, pred, gt):\n",
        "        fg = torch.where(gt==0, torch.zeros_like(pred), pred)\n",
        "        bg = torch.where(gt==1, torch.zeros_like(pred), 1-pred)\n",
        "        o_fg = self._object(fg, gt)\n",
        "        o_bg = self._object(bg, 1-gt)\n",
        "        u = gt.mean()\n",
        "        Q = u * o_fg + (1-u) * o_bg\n",
        "        return Q\n",
        "\n",
        "    def _object(self, pred, gt):\n",
        "        temp = pred[gt == 1]\n",
        "        x = temp.mean()\n",
        "        sigma_x = temp.std()\n",
        "        score = 2.0 * x / (x * x + 1.0 + sigma_x + 1e-20)\n",
        "        \n",
        "        return score\n",
        "\n",
        "    def _S_region(self, pred, gt):\n",
        "        X, Y = self._centroid(gt)\n",
        "        gt1, gt2, gt3, gt4, w1, w2, w3, w4 = self._divideGT(gt, X, Y)\n",
        "        p1, p2, p3, p4 = self._dividePrediction(pred, X, Y)\n",
        "        Q1 = self._ssim(p1, gt1)\n",
        "        Q2 = self._ssim(p2, gt2)\n",
        "        Q3 = self._ssim(p3, gt3)\n",
        "        Q4 = self._ssim(p4, gt4)\n",
        "        Q = w1*Q1 + w2*Q2 + w3*Q3 + w4*Q4\n",
        "        # print(Q)\n",
        "        return Q\n",
        "    \n",
        "    def _centroid(self, gt):\n",
        "        rows, cols = gt.size()[-2:]\n",
        "        gt = gt.view(rows, cols)\n",
        "        if gt.sum() == 0:\n",
        "            if self.cuda:\n",
        "                X = torch.eye(1).cuda() * round(cols / 2)\n",
        "                Y = torch.eye(1).cuda() * round(rows / 2)\n",
        "            else:\n",
        "                X = torch.eye(1) * round(cols / 2)\n",
        "                Y = torch.eye(1) * round(rows / 2)\n",
        "        else:\n",
        "            total = gt.sum()\n",
        "            if self.cuda:\n",
        "                i = torch.from_numpy(np.arange(0,cols)).cuda().float()\n",
        "                j = torch.from_numpy(np.arange(0,rows)).cuda().float()\n",
        "            else:\n",
        "                i = torch.from_numpy(np.arange(0,cols)).float()\n",
        "                j = torch.from_numpy(np.arange(0,rows)).float()\n",
        "            X = torch.round((gt.sum(dim=0)*i).sum() / total)\n",
        "            Y = torch.round((gt.sum(dim=1)*j).sum() / total)\n",
        "        return X.long(), Y.long()\n",
        "    \n",
        "    def _divideGT(self, gt, X, Y):\n",
        "        h, w = gt.size()[-2:]\n",
        "        area = h*w\n",
        "        gt = gt.view(h, w)\n",
        "        LT = gt[:Y, :X]\n",
        "        RT = gt[:Y, X:w]\n",
        "        LB = gt[Y:h, :X]\n",
        "        RB = gt[Y:h, X:w]\n",
        "        X = X.float()\n",
        "        Y = Y.float()\n",
        "        w1 = X * Y / area\n",
        "        w2 = (w - X) * Y / area\n",
        "        w3 = X * (h - Y) / area\n",
        "        w4 = 1 - w1 - w2 - w3\n",
        "        return LT, RT, LB, RB, w1, w2, w3, w4\n",
        "\n",
        "    def _dividePrediction(self, pred, X, Y):\n",
        "        h, w = pred.size()[-2:]\n",
        "        pred = pred.view(h, w)\n",
        "        LT = pred[:Y, :X]\n",
        "        RT = pred[:Y, X:w]\n",
        "        LB = pred[Y:h, :X]\n",
        "        RB = pred[Y:h, X:w]\n",
        "        return LT, RT, LB, RB\n",
        "\n",
        "    def _ssim(self, pred, gt):\n",
        "        gt = gt.float()\n",
        "        h, w = pred.size()[-2:]\n",
        "        N = h*w\n",
        "        x = pred.mean()\n",
        "        y = gt.mean()\n",
        "        sigma_x2 = ((pred - x)*(pred - x)).sum() / (N - 1 + 1e-20)\n",
        "        sigma_y2 = ((gt - y)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "        sigma_xy = ((pred - x)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "        \n",
        "        aplha = 4 * x * y *sigma_xy\n",
        "        beta = (x*x + y*y) * (sigma_x2 + sigma_y2)\n",
        "\n",
        "        if aplha != 0:\n",
        "            Q = aplha / (beta + 1e-20)\n",
        "        elif aplha == 0 and beta == 0:\n",
        "            Q = 1.0\n",
        "        else:\n",
        "            Q = 0\n",
        "        return Q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOyfjL14LqZN"
      },
      "source": [
        "##Training Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmU0hbGlLzt-"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "def arguments():\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument('--epoch',       type=int,   default=250,   help='epoch number')\n",
        "  parser.add_argument('--lr',          type=float, default=1e-4,  help='learning rate')\n",
        "  parser.add_argument('--batchsize',   type=int,   default=4,    help='training batch size')\n",
        "  parser.add_argument('--trainsize',   type=int,   default=352,   help='training dataset size')\n",
        "  parser.add_argument('--clip',        type=float, default=0.5,   help='gradient clipping margin')\n",
        "  parser.add_argument('--lw',          type=float, default=0.001, help='weight')\n",
        "  parser.add_argument('--decay_rate',  type=float, default=0.1,   help='decay rate of learning rate')\n",
        "  parser.add_argument('--decay_epoch', type=int,   default=60,    help='every n epochs decay learning rate')\n",
        "  parser.add_argument('--load',        type=str,   default=None,  help='train from checkpoints')\n",
        "  parser.add_argument('--gpu_id',      type=str,   default='0',   help='train use gpu')\n",
        "\n",
        "  parser.add_argument('--rgb_label_root',      type=str, default='/content/tmp/traindataset_only_depth/RGB/',           help='the training rgb images root')\n",
        "  parser.add_argument('--depth_label_root',    type=str, default='/content/tmp/traindataset_only_depth/depth/',         help='the training depth images root')\n",
        "  parser.add_argument('--gt_label_root',       type=str, default='/content/tmp/traindataset_only_depth/GT/',            help='the training gt images root')\n",
        "\n",
        "  parser.add_argument('--val_rgb_root',        type=str, default='/content/tmp/testdataset_only_depth/NJU2K/RGB/',      help='the test rgb images root')\n",
        "  parser.add_argument('--val_depth_root',      type=str, default='/content/tmp/testdataset_only_depth/NJU2K/depth/',    help='the test depth images root')\n",
        "  parser.add_argument('--val_gt_root',         type=str, default='/content/tmp/testdataset_only_depth/NJU2K/GT/',       help='the test gt images root')\n",
        "\n",
        "  parser.add_argument('--save_path',           type=str, default='/content/drive/MyDrive/Checkpoint/path_with_same_input/',    help='the path to save models and logs')\n",
        "  return parser.parse_args(\"\")\n",
        "\n",
        "opt = arguments()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu1gTl-yM9Kv"
      },
      "source": [
        "##Model Training With DIfferent Loss Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK3RZTqaNF6w"
      },
      "source": [
        "### Training with Perceptual Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8749833372c34712944b35ab0fa2a15b",
            "068e6e83d28b43ae856e8fecb89d4b9d",
            "641b4f6ccb7e4990a995898ad31c23be",
            "7ab5f00d782d48bebcc25eee1e1e9e38",
            "653c429900a54f46a0495f6d8548260f",
            "7a99a99da932477e84d1a2e7943c0427",
            "664c0c86ffd74162989a3345327b1e57",
            "65bcef97a60a472ca515aebaacad69a3",
            "710076496e4f4dd4a4c0e38e6b8aa53d",
            "617f158750ad4178b5359ae4b5bb6b2e",
            "09fb191651614417a0fc3521e708b834"
          ]
        },
        "id": "bo9erSOBNNOo",
        "outputId": "b57d47d4-2135-41c6-b2cd-b79f31e40cdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USE GPU 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://shanghuagao.oss-cn-beijing.aliyuncs.com/res2net/res2net50_v1b_26w_4s-3cf99910.pth\" to /root/.cache/torch/hub/checkpoints/res2net50_v1b_26w_4s-3cf99910.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8749833372c34712944b35ab0fa2a15b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/98.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load data...\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/traindataset_only_depth/RGB/depth_00.png', '/content/tmp/traindataset_only_depth/RGB/depth_01.png', '/content/tmp/traindataset_only_depth/RGB/depth_02.png', '/content/tmp/traindataset_only_depth/RGB/depth_10.png', '/content/tmp/traindataset_only_depth/RGB/depth_100.png', '/content/tmp/traindataset_only_depth/RGB/depth_101.png', '/content/tmp/traindataset_only_depth/RGB/depth_102.png', '/content/tmp/traindataset_only_depth/RGB/depth_11.png', '/content/tmp/traindataset_only_depth/RGB/depth_110.png', '/content/tmp/traindataset_only_depth/RGB/depth_111.png', '/content/tmp/traindataset_only_depth/RGB/depth_112.png', '/content/tmp/traindataset_only_depth/RGB/depth_12.png', '/content/tmp/traindataset_only_depth/RGB/depth_120.png', '/content/tmp/traindataset_only_depth/RGB/depth_121.png', '/content/tmp/traindataset_only_depth/RGB/depth_122.png', '/content/tmp/traindataset_only_depth/RGB/depth_130.png', '/content/tmp/traindataset_only_depth/RGB/depth_131.png', '/content/tmp/traindataset_only_depth/RGB/depth_132.png', '/content/tmp/traindataset_only_depth/RGB/depth_140.png', '/content/tmp/traindataset_only_depth/RGB/depth_141.png', '/content/tmp/traindataset_only_depth/RGB/depth_142.png', '/content/tmp/traindataset_only_depth/RGB/depth_150.png', '/content/tmp/traindataset_only_depth/RGB/depth_151.png', '/content/tmp/traindataset_only_depth/RGB/depth_152.png', '/content/tmp/traindataset_only_depth/RGB/depth_160.png', '/content/tmp/traindataset_only_depth/RGB/depth_161.png', '/content/tmp/traindataset_only_depth/RGB/depth_162.png', '/content/tmp/traindataset_only_depth/RGB/depth_170.png', '/content/tmp/traindataset_only_depth/RGB/depth_171.png', '/content/tmp/traindataset_only_depth/RGB/depth_172.png', '/content/tmp/traindataset_only_depth/RGB/depth_180.png', '/content/tmp/traindataset_only_depth/RGB/depth_181.png', '/content/tmp/traindataset_only_depth/RGB/depth_182.png', '/content/tmp/traindataset_only_depth/RGB/depth_190.png', '/content/tmp/traindataset_only_depth/RGB/depth_191.png', '/content/tmp/traindataset_only_depth/RGB/depth_192.png', '/content/tmp/traindataset_only_depth/RGB/depth_20.png', '/content/tmp/traindataset_only_depth/RGB/depth_200.png', '/content/tmp/traindataset_only_depth/RGB/depth_201.png', '/content/tmp/traindataset_only_depth/RGB/depth_202.png', '/content/tmp/traindataset_only_depth/RGB/depth_21.png', '/content/tmp/traindataset_only_depth/RGB/depth_210.png', '/content/tmp/traindataset_only_depth/RGB/depth_211.png', '/content/tmp/traindataset_only_depth/RGB/depth_212.png', '/content/tmp/traindataset_only_depth/RGB/depth_22.png', '/content/tmp/traindataset_only_depth/RGB/depth_220.png', '/content/tmp/traindataset_only_depth/RGB/depth_221.png', '/content/tmp/traindataset_only_depth/RGB/depth_222.png', '/content/tmp/traindataset_only_depth/RGB/depth_230.png', '/content/tmp/traindataset_only_depth/RGB/depth_231.png', '/content/tmp/traindataset_only_depth/RGB/depth_232.png', '/content/tmp/traindataset_only_depth/RGB/depth_240.png', '/content/tmp/traindataset_only_depth/RGB/depth_241.png', '/content/tmp/traindataset_only_depth/RGB/depth_242.png', '/content/tmp/traindataset_only_depth/RGB/depth_250.png', '/content/tmp/traindataset_only_depth/RGB/depth_251.png', '/content/tmp/traindataset_only_depth/RGB/depth_252.png', '/content/tmp/traindataset_only_depth/RGB/depth_260.png', '/content/tmp/traindataset_only_depth/RGB/depth_261.png', '/content/tmp/traindataset_only_depth/RGB/depth_262.png', '/content/tmp/traindataset_only_depth/RGB/depth_270.png', '/content/tmp/traindataset_only_depth/RGB/depth_271.png', '/content/tmp/traindataset_only_depth/RGB/depth_272.png', '/content/tmp/traindataset_only_depth/RGB/depth_280.png', '/content/tmp/traindataset_only_depth/RGB/depth_281.png', '/content/tmp/traindataset_only_depth/RGB/depth_282.png', '/content/tmp/traindataset_only_depth/RGB/depth_290.png', '/content/tmp/traindataset_only_depth/RGB/depth_291.png', '/content/tmp/traindataset_only_depth/RGB/depth_292.png', '/content/tmp/traindataset_only_depth/RGB/depth_30.png', '/content/tmp/traindataset_only_depth/RGB/depth_300.png', '/content/tmp/traindataset_only_depth/RGB/depth_301.png', '/content/tmp/traindataset_only_depth/RGB/depth_302.png', '/content/tmp/traindataset_only_depth/RGB/depth_31.png', '/content/tmp/traindataset_only_depth/RGB/depth_310.png', '/content/tmp/traindataset_only_depth/RGB/depth_311.png', '/content/tmp/traindataset_only_depth/RGB/depth_312.png', '/content/tmp/traindataset_only_depth/RGB/depth_32.png', '/content/tmp/traindataset_only_depth/RGB/depth_320.png', '/content/tmp/traindataset_only_depth/RGB/depth_321.png', '/content/tmp/traindataset_only_depth/RGB/depth_322.png', '/content/tmp/traindataset_only_depth/RGB/depth_330.png', '/content/tmp/traindataset_only_depth/RGB/depth_331.png', '/content/tmp/traindataset_only_depth/RGB/depth_332.png', '/content/tmp/traindataset_only_depth/RGB/depth_340.png', '/content/tmp/traindataset_only_depth/RGB/depth_341.png', '/content/tmp/traindataset_only_depth/RGB/depth_342.png', '/content/tmp/traindataset_only_depth/RGB/depth_350.png', '/content/tmp/traindataset_only_depth/RGB/depth_351.png', '/content/tmp/traindataset_only_depth/RGB/depth_352.png', '/content/tmp/traindataset_only_depth/RGB/depth_360.png', '/content/tmp/traindataset_only_depth/RGB/depth_361.png', '/content/tmp/traindataset_only_depth/RGB/depth_362.png', '/content/tmp/traindataset_only_depth/RGB/depth_370.png', '/content/tmp/traindataset_only_depth/RGB/depth_371.png', '/content/tmp/traindataset_only_depth/RGB/depth_372.png', '/content/tmp/traindataset_only_depth/RGB/depth_380.png', '/content/tmp/traindataset_only_depth/RGB/depth_381.png', '/content/tmp/traindataset_only_depth/RGB/depth_382.png', '/content/tmp/traindataset_only_depth/RGB/depth_390.png', '/content/tmp/traindataset_only_depth/RGB/depth_391.png', '/content/tmp/traindataset_only_depth/RGB/depth_392.png', '/content/tmp/traindataset_only_depth/RGB/depth_40.png', '/content/tmp/traindataset_only_depth/RGB/depth_400.png', '/content/tmp/traindataset_only_depth/RGB/depth_401.png', '/content/tmp/traindataset_only_depth/RGB/depth_402.png', '/content/tmp/traindataset_only_depth/RGB/depth_41.png', '/content/tmp/traindataset_only_depth/RGB/depth_410.png', '/content/tmp/traindataset_only_depth/RGB/depth_411.png', '/content/tmp/traindataset_only_depth/RGB/depth_412.png', '/content/tmp/traindataset_only_depth/RGB/depth_42.png', '/content/tmp/traindataset_only_depth/RGB/depth_420.png', '/content/tmp/traindataset_only_depth/RGB/depth_421.png', '/content/tmp/traindataset_only_depth/RGB/depth_422.png', '/content/tmp/traindataset_only_depth/RGB/depth_430.png', '/content/tmp/traindataset_only_depth/RGB/depth_431.png', '/content/tmp/traindataset_only_depth/RGB/depth_432.png', '/content/tmp/traindataset_only_depth/RGB/depth_440.png', '/content/tmp/traindataset_only_depth/RGB/depth_441.png', '/content/tmp/traindataset_only_depth/RGB/depth_442.png', '/content/tmp/traindataset_only_depth/RGB/depth_450.png', '/content/tmp/traindataset_only_depth/RGB/depth_451.png', '/content/tmp/traindataset_only_depth/RGB/depth_452.png', '/content/tmp/traindataset_only_depth/RGB/depth_460.png', '/content/tmp/traindataset_only_depth/RGB/depth_461.png', '/content/tmp/traindataset_only_depth/RGB/depth_462.png', '/content/tmp/traindataset_only_depth/RGB/depth_470.png', '/content/tmp/traindataset_only_depth/RGB/depth_471.png', '/content/tmp/traindataset_only_depth/RGB/depth_472.png', '/content/tmp/traindataset_only_depth/RGB/depth_480.png', '/content/tmp/traindataset_only_depth/RGB/depth_481.png', '/content/tmp/traindataset_only_depth/RGB/depth_482.png', '/content/tmp/traindataset_only_depth/RGB/depth_490.png', '/content/tmp/traindataset_only_depth/RGB/depth_491.png', '/content/tmp/traindataset_only_depth/RGB/depth_492.png', '/content/tmp/traindataset_only_depth/RGB/depth_50.png', '/content/tmp/traindataset_only_depth/RGB/depth_500.png', '/content/tmp/traindataset_only_depth/RGB/depth_501.png', '/content/tmp/traindataset_only_depth/RGB/depth_502.png', '/content/tmp/traindataset_only_depth/RGB/depth_51.png', '/content/tmp/traindataset_only_depth/RGB/depth_510.png', '/content/tmp/traindataset_only_depth/RGB/depth_511.png', '/content/tmp/traindataset_only_depth/RGB/depth_512.png', '/content/tmp/traindataset_only_depth/RGB/depth_52.png', '/content/tmp/traindataset_only_depth/RGB/depth_520.png', '/content/tmp/traindataset_only_depth/RGB/depth_521.png', '/content/tmp/traindataset_only_depth/RGB/depth_522.png', '/content/tmp/traindataset_only_depth/RGB/depth_530.png', '/content/tmp/traindataset_only_depth/RGB/depth_531.png', '/content/tmp/traindataset_only_depth/RGB/depth_532.png', '/content/tmp/traindataset_only_depth/RGB/depth_540.png', '/content/tmp/traindataset_only_depth/RGB/depth_541.png', '/content/tmp/traindataset_only_depth/RGB/depth_542.png', '/content/tmp/traindataset_only_depth/RGB/depth_550.png', '/content/tmp/traindataset_only_depth/RGB/depth_551.png', '/content/tmp/traindataset_only_depth/RGB/depth_552.png', '/content/tmp/traindataset_only_depth/RGB/depth_560.png', '/content/tmp/traindataset_only_depth/RGB/depth_561.png', '/content/tmp/traindataset_only_depth/RGB/depth_562.png', '/content/tmp/traindataset_only_depth/RGB/depth_570.png', '/content/tmp/traindataset_only_depth/RGB/depth_571.png', '/content/tmp/traindataset_only_depth/RGB/depth_572.png', '/content/tmp/traindataset_only_depth/RGB/depth_580.png', '/content/tmp/traindataset_only_depth/RGB/depth_581.png', '/content/tmp/traindataset_only_depth/RGB/depth_582.png', '/content/tmp/traindataset_only_depth/RGB/depth_590.png', '/content/tmp/traindataset_only_depth/RGB/depth_591.png', '/content/tmp/traindataset_only_depth/RGB/depth_592.png', '/content/tmp/traindataset_only_depth/RGB/depth_60.png', '/content/tmp/traindataset_only_depth/RGB/depth_600.png', '/content/tmp/traindataset_only_depth/RGB/depth_601.png', '/content/tmp/traindataset_only_depth/RGB/depth_602.png', '/content/tmp/traindataset_only_depth/RGB/depth_61.png', '/content/tmp/traindataset_only_depth/RGB/depth_610.png', '/content/tmp/traindataset_only_depth/RGB/depth_611.png', '/content/tmp/traindataset_only_depth/RGB/depth_612.png', '/content/tmp/traindataset_only_depth/RGB/depth_62.png', '/content/tmp/traindataset_only_depth/RGB/depth_620.png', '/content/tmp/traindataset_only_depth/RGB/depth_621.png', '/content/tmp/traindataset_only_depth/RGB/depth_622.png', '/content/tmp/traindataset_only_depth/RGB/depth_630.png', '/content/tmp/traindataset_only_depth/RGB/depth_631.png', '/content/tmp/traindataset_only_depth/RGB/depth_632.png', '/content/tmp/traindataset_only_depth/RGB/depth_640.png', '/content/tmp/traindataset_only_depth/RGB/depth_641.png', '/content/tmp/traindataset_only_depth/RGB/depth_642.png', '/content/tmp/traindataset_only_depth/RGB/depth_650.png', '/content/tmp/traindataset_only_depth/RGB/depth_651.png', '/content/tmp/traindataset_only_depth/RGB/depth_652.png', '/content/tmp/traindataset_only_depth/RGB/depth_660.png', '/content/tmp/traindataset_only_depth/RGB/depth_661.png', '/content/tmp/traindataset_only_depth/RGB/depth_662.png', '/content/tmp/traindataset_only_depth/RGB/depth_670.png', '/content/tmp/traindataset_only_depth/RGB/depth_671.png', '/content/tmp/traindataset_only_depth/RGB/depth_672.png', '/content/tmp/traindataset_only_depth/RGB/depth_680.png', '/content/tmp/traindataset_only_depth/RGB/depth_681.png', '/content/tmp/traindataset_only_depth/RGB/depth_682.png', '/content/tmp/traindataset_only_depth/RGB/depth_690.png', '/content/tmp/traindataset_only_depth/RGB/depth_691.png', '/content/tmp/traindataset_only_depth/RGB/depth_692.png', '/content/tmp/traindataset_only_depth/RGB/depth_70.png', '/content/tmp/traindataset_only_depth/RGB/depth_700.png', '/content/tmp/traindataset_only_depth/RGB/depth_701.png', '/content/tmp/traindataset_only_depth/RGB/depth_702.png', '/content/tmp/traindataset_only_depth/RGB/depth_71.png', '/content/tmp/traindataset_only_depth/RGB/depth_710.png', '/content/tmp/traindataset_only_depth/RGB/depth_711.png', '/content/tmp/traindataset_only_depth/RGB/depth_712.png', '/content/tmp/traindataset_only_depth/RGB/depth_72.png', '/content/tmp/traindataset_only_depth/RGB/depth_720.png', '/content/tmp/traindataset_only_depth/RGB/depth_721.png', '/content/tmp/traindataset_only_depth/RGB/depth_722.png', '/content/tmp/traindataset_only_depth/RGB/depth_730.png', '/content/tmp/traindataset_only_depth/RGB/depth_731.png', '/content/tmp/traindataset_only_depth/RGB/depth_732.png', '/content/tmp/traindataset_only_depth/RGB/depth_740.png', '/content/tmp/traindataset_only_depth/RGB/depth_741.png', '/content/tmp/traindataset_only_depth/RGB/depth_742.png', '/content/tmp/traindataset_only_depth/RGB/depth_750.png', '/content/tmp/traindataset_only_depth/RGB/depth_751.png', '/content/tmp/traindataset_only_depth/RGB/depth_752.png', '/content/tmp/traindataset_only_depth/RGB/depth_760.png', '/content/tmp/traindataset_only_depth/RGB/depth_761.png', '/content/tmp/traindataset_only_depth/RGB/depth_762.png', '/content/tmp/traindataset_only_depth/RGB/depth_770.png', '/content/tmp/traindataset_only_depth/RGB/depth_771.png', '/content/tmp/traindataset_only_depth/RGB/depth_772.png', '/content/tmp/traindataset_only_depth/RGB/depth_780.png', '/content/tmp/traindataset_only_depth/RGB/depth_781.png', '/content/tmp/traindataset_only_depth/RGB/depth_782.png', '/content/tmp/traindataset_only_depth/RGB/depth_790.png', '/content/tmp/traindataset_only_depth/RGB/depth_791.png', '/content/tmp/traindataset_only_depth/RGB/depth_792.png', '/content/tmp/traindataset_only_depth/RGB/depth_80.png', '/content/tmp/traindataset_only_depth/RGB/depth_81.png', '/content/tmp/traindataset_only_depth/RGB/depth_82.png', '/content/tmp/traindataset_only_depth/RGB/depth_90.png', '/content/tmp/traindataset_only_depth/RGB/depth_91.png', '/content/tmp/traindataset_only_depth/RGB/depth_92.png'] ['/content/tmp/traindataset_only_depth/GT/GT_00.png', '/content/tmp/traindataset_only_depth/GT/GT_01.png', '/content/tmp/traindataset_only_depth/GT/GT_02.png', '/content/tmp/traindataset_only_depth/GT/GT_10.png', '/content/tmp/traindataset_only_depth/GT/GT_100.png', '/content/tmp/traindataset_only_depth/GT/GT_101.png', '/content/tmp/traindataset_only_depth/GT/GT_102.png', '/content/tmp/traindataset_only_depth/GT/GT_11.png', '/content/tmp/traindataset_only_depth/GT/GT_110.png', '/content/tmp/traindataset_only_depth/GT/GT_111.png', '/content/tmp/traindataset_only_depth/GT/GT_112.png', '/content/tmp/traindataset_only_depth/GT/GT_12.png', '/content/tmp/traindataset_only_depth/GT/GT_120.png', '/content/tmp/traindataset_only_depth/GT/GT_121.png', '/content/tmp/traindataset_only_depth/GT/GT_122.png', '/content/tmp/traindataset_only_depth/GT/GT_130.png', '/content/tmp/traindataset_only_depth/GT/GT_131.png', '/content/tmp/traindataset_only_depth/GT/GT_132.png', '/content/tmp/traindataset_only_depth/GT/GT_140.png', '/content/tmp/traindataset_only_depth/GT/GT_141.png', '/content/tmp/traindataset_only_depth/GT/GT_142.png', '/content/tmp/traindataset_only_depth/GT/GT_150.png', '/content/tmp/traindataset_only_depth/GT/GT_151.png', '/content/tmp/traindataset_only_depth/GT/GT_152.png', '/content/tmp/traindataset_only_depth/GT/GT_160.png', '/content/tmp/traindataset_only_depth/GT/GT_161.png', '/content/tmp/traindataset_only_depth/GT/GT_162.png', '/content/tmp/traindataset_only_depth/GT/GT_170.png', '/content/tmp/traindataset_only_depth/GT/GT_171.png', '/content/tmp/traindataset_only_depth/GT/GT_172.png', '/content/tmp/traindataset_only_depth/GT/GT_180.png', '/content/tmp/traindataset_only_depth/GT/GT_181.png', '/content/tmp/traindataset_only_depth/GT/GT_182.png', '/content/tmp/traindataset_only_depth/GT/GT_190.png', '/content/tmp/traindataset_only_depth/GT/GT_191.png', '/content/tmp/traindataset_only_depth/GT/GT_192.png', '/content/tmp/traindataset_only_depth/GT/GT_20.png', '/content/tmp/traindataset_only_depth/GT/GT_200.png', '/content/tmp/traindataset_only_depth/GT/GT_201.png', '/content/tmp/traindataset_only_depth/GT/GT_202.png', '/content/tmp/traindataset_only_depth/GT/GT_21.png', '/content/tmp/traindataset_only_depth/GT/GT_210.png', '/content/tmp/traindataset_only_depth/GT/GT_211.png', '/content/tmp/traindataset_only_depth/GT/GT_212.png', '/content/tmp/traindataset_only_depth/GT/GT_22.png', '/content/tmp/traindataset_only_depth/GT/GT_220.png', '/content/tmp/traindataset_only_depth/GT/GT_221.png', '/content/tmp/traindataset_only_depth/GT/GT_222.png', '/content/tmp/traindataset_only_depth/GT/GT_230.png', '/content/tmp/traindataset_only_depth/GT/GT_231.png', '/content/tmp/traindataset_only_depth/GT/GT_232.png', '/content/tmp/traindataset_only_depth/GT/GT_240.png', '/content/tmp/traindataset_only_depth/GT/GT_241.png', '/content/tmp/traindataset_only_depth/GT/GT_242.png', '/content/tmp/traindataset_only_depth/GT/GT_250.png', '/content/tmp/traindataset_only_depth/GT/GT_251.png', '/content/tmp/traindataset_only_depth/GT/GT_252.png', '/content/tmp/traindataset_only_depth/GT/GT_260.png', '/content/tmp/traindataset_only_depth/GT/GT_261.png', '/content/tmp/traindataset_only_depth/GT/GT_262.png', '/content/tmp/traindataset_only_depth/GT/GT_270.png', '/content/tmp/traindataset_only_depth/GT/GT_271.png', '/content/tmp/traindataset_only_depth/GT/GT_272.png', '/content/tmp/traindataset_only_depth/GT/GT_280.png', '/content/tmp/traindataset_only_depth/GT/GT_281.png', '/content/tmp/traindataset_only_depth/GT/GT_282.png', '/content/tmp/traindataset_only_depth/GT/GT_290.png', '/content/tmp/traindataset_only_depth/GT/GT_291.png', '/content/tmp/traindataset_only_depth/GT/GT_292.png', '/content/tmp/traindataset_only_depth/GT/GT_30.png', '/content/tmp/traindataset_only_depth/GT/GT_300.png', '/content/tmp/traindataset_only_depth/GT/GT_301.png', '/content/tmp/traindataset_only_depth/GT/GT_302.png', '/content/tmp/traindataset_only_depth/GT/GT_31.png', '/content/tmp/traindataset_only_depth/GT/GT_310.png', '/content/tmp/traindataset_only_depth/GT/GT_311.png', '/content/tmp/traindataset_only_depth/GT/GT_312.png', '/content/tmp/traindataset_only_depth/GT/GT_32.png', '/content/tmp/traindataset_only_depth/GT/GT_320.png', '/content/tmp/traindataset_only_depth/GT/GT_321.png', '/content/tmp/traindataset_only_depth/GT/GT_322.png', '/content/tmp/traindataset_only_depth/GT/GT_330.png', '/content/tmp/traindataset_only_depth/GT/GT_331.png', '/content/tmp/traindataset_only_depth/GT/GT_332.png', '/content/tmp/traindataset_only_depth/GT/GT_340.png', '/content/tmp/traindataset_only_depth/GT/GT_341.png', '/content/tmp/traindataset_only_depth/GT/GT_342.png', '/content/tmp/traindataset_only_depth/GT/GT_350.png', '/content/tmp/traindataset_only_depth/GT/GT_351.png', '/content/tmp/traindataset_only_depth/GT/GT_352.png', '/content/tmp/traindataset_only_depth/GT/GT_360.png', '/content/tmp/traindataset_only_depth/GT/GT_361.png', '/content/tmp/traindataset_only_depth/GT/GT_362.png', '/content/tmp/traindataset_only_depth/GT/GT_370.png', '/content/tmp/traindataset_only_depth/GT/GT_371.png', '/content/tmp/traindataset_only_depth/GT/GT_372.png', '/content/tmp/traindataset_only_depth/GT/GT_380.png', '/content/tmp/traindataset_only_depth/GT/GT_381.png', '/content/tmp/traindataset_only_depth/GT/GT_382.png', '/content/tmp/traindataset_only_depth/GT/GT_390.png', '/content/tmp/traindataset_only_depth/GT/GT_391.png', '/content/tmp/traindataset_only_depth/GT/GT_392.png', '/content/tmp/traindataset_only_depth/GT/GT_40.png', '/content/tmp/traindataset_only_depth/GT/GT_400.png', '/content/tmp/traindataset_only_depth/GT/GT_401.png', '/content/tmp/traindataset_only_depth/GT/GT_402.png', '/content/tmp/traindataset_only_depth/GT/GT_41.png', '/content/tmp/traindataset_only_depth/GT/GT_410.png', '/content/tmp/traindataset_only_depth/GT/GT_411.png', '/content/tmp/traindataset_only_depth/GT/GT_412.png', '/content/tmp/traindataset_only_depth/GT/GT_42.png', '/content/tmp/traindataset_only_depth/GT/GT_420.png', '/content/tmp/traindataset_only_depth/GT/GT_421.png', '/content/tmp/traindataset_only_depth/GT/GT_422.png', '/content/tmp/traindataset_only_depth/GT/GT_430.png', '/content/tmp/traindataset_only_depth/GT/GT_431.png', '/content/tmp/traindataset_only_depth/GT/GT_432.png', '/content/tmp/traindataset_only_depth/GT/GT_440.png', '/content/tmp/traindataset_only_depth/GT/GT_441.png', '/content/tmp/traindataset_only_depth/GT/GT_442.png', '/content/tmp/traindataset_only_depth/GT/GT_450.png', '/content/tmp/traindataset_only_depth/GT/GT_451.png', '/content/tmp/traindataset_only_depth/GT/GT_452.png', '/content/tmp/traindataset_only_depth/GT/GT_460.png', '/content/tmp/traindataset_only_depth/GT/GT_461.png', '/content/tmp/traindataset_only_depth/GT/GT_462.png', '/content/tmp/traindataset_only_depth/GT/GT_470.png', '/content/tmp/traindataset_only_depth/GT/GT_471.png', '/content/tmp/traindataset_only_depth/GT/GT_472.png', '/content/tmp/traindataset_only_depth/GT/GT_480.png', '/content/tmp/traindataset_only_depth/GT/GT_481.png', '/content/tmp/traindataset_only_depth/GT/GT_482.png', '/content/tmp/traindataset_only_depth/GT/GT_490.png', '/content/tmp/traindataset_only_depth/GT/GT_491.png', '/content/tmp/traindataset_only_depth/GT/GT_492.png', '/content/tmp/traindataset_only_depth/GT/GT_50.png', '/content/tmp/traindataset_only_depth/GT/GT_500.png', '/content/tmp/traindataset_only_depth/GT/GT_501.png', '/content/tmp/traindataset_only_depth/GT/GT_502.png', '/content/tmp/traindataset_only_depth/GT/GT_51.png', '/content/tmp/traindataset_only_depth/GT/GT_510.png', '/content/tmp/traindataset_only_depth/GT/GT_511.png', '/content/tmp/traindataset_only_depth/GT/GT_512.png', '/content/tmp/traindataset_only_depth/GT/GT_52.png', '/content/tmp/traindataset_only_depth/GT/GT_520.png', '/content/tmp/traindataset_only_depth/GT/GT_521.png', '/content/tmp/traindataset_only_depth/GT/GT_522.png', '/content/tmp/traindataset_only_depth/GT/GT_530.png', '/content/tmp/traindataset_only_depth/GT/GT_531.png', '/content/tmp/traindataset_only_depth/GT/GT_532.png', '/content/tmp/traindataset_only_depth/GT/GT_540.png', '/content/tmp/traindataset_only_depth/GT/GT_541.png', '/content/tmp/traindataset_only_depth/GT/GT_542.png', '/content/tmp/traindataset_only_depth/GT/GT_550.png', '/content/tmp/traindataset_only_depth/GT/GT_551.png', '/content/tmp/traindataset_only_depth/GT/GT_552.png', '/content/tmp/traindataset_only_depth/GT/GT_560.png', '/content/tmp/traindataset_only_depth/GT/GT_561.png', '/content/tmp/traindataset_only_depth/GT/GT_562.png', '/content/tmp/traindataset_only_depth/GT/GT_570.png', '/content/tmp/traindataset_only_depth/GT/GT_571.png', '/content/tmp/traindataset_only_depth/GT/GT_572.png', '/content/tmp/traindataset_only_depth/GT/GT_580.png', '/content/tmp/traindataset_only_depth/GT/GT_581.png', '/content/tmp/traindataset_only_depth/GT/GT_582.png', '/content/tmp/traindataset_only_depth/GT/GT_590.png', '/content/tmp/traindataset_only_depth/GT/GT_591.png', '/content/tmp/traindataset_only_depth/GT/GT_592.png', '/content/tmp/traindataset_only_depth/GT/GT_60.png', '/content/tmp/traindataset_only_depth/GT/GT_600.png', '/content/tmp/traindataset_only_depth/GT/GT_601.png', '/content/tmp/traindataset_only_depth/GT/GT_602.png', '/content/tmp/traindataset_only_depth/GT/GT_61.png', '/content/tmp/traindataset_only_depth/GT/GT_610.png', '/content/tmp/traindataset_only_depth/GT/GT_611.png', '/content/tmp/traindataset_only_depth/GT/GT_612.png', '/content/tmp/traindataset_only_depth/GT/GT_62.png', '/content/tmp/traindataset_only_depth/GT/GT_620.png', '/content/tmp/traindataset_only_depth/GT/GT_621.png', '/content/tmp/traindataset_only_depth/GT/GT_622.png', '/content/tmp/traindataset_only_depth/GT/GT_630.png', '/content/tmp/traindataset_only_depth/GT/GT_631.png', '/content/tmp/traindataset_only_depth/GT/GT_632.png', '/content/tmp/traindataset_only_depth/GT/GT_640.png', '/content/tmp/traindataset_only_depth/GT/GT_641.png', '/content/tmp/traindataset_only_depth/GT/GT_642.png', '/content/tmp/traindataset_only_depth/GT/GT_650.png', '/content/tmp/traindataset_only_depth/GT/GT_651.png', '/content/tmp/traindataset_only_depth/GT/GT_652.png', '/content/tmp/traindataset_only_depth/GT/GT_660.png', '/content/tmp/traindataset_only_depth/GT/GT_661.png', '/content/tmp/traindataset_only_depth/GT/GT_662.png', '/content/tmp/traindataset_only_depth/GT/GT_670.png', '/content/tmp/traindataset_only_depth/GT/GT_671.png', '/content/tmp/traindataset_only_depth/GT/GT_672.png', '/content/tmp/traindataset_only_depth/GT/GT_680.png', '/content/tmp/traindataset_only_depth/GT/GT_681.png', '/content/tmp/traindataset_only_depth/GT/GT_682.png', '/content/tmp/traindataset_only_depth/GT/GT_690.png', '/content/tmp/traindataset_only_depth/GT/GT_691.png', '/content/tmp/traindataset_only_depth/GT/GT_692.png', '/content/tmp/traindataset_only_depth/GT/GT_70.png', '/content/tmp/traindataset_only_depth/GT/GT_700.png', '/content/tmp/traindataset_only_depth/GT/GT_701.png', '/content/tmp/traindataset_only_depth/GT/GT_702.png', '/content/tmp/traindataset_only_depth/GT/GT_71.png', '/content/tmp/traindataset_only_depth/GT/GT_710.png', '/content/tmp/traindataset_only_depth/GT/GT_711.png', '/content/tmp/traindataset_only_depth/GT/GT_712.png', '/content/tmp/traindataset_only_depth/GT/GT_72.png', '/content/tmp/traindataset_only_depth/GT/GT_720.png', '/content/tmp/traindataset_only_depth/GT/GT_721.png', '/content/tmp/traindataset_only_depth/GT/GT_722.png', '/content/tmp/traindataset_only_depth/GT/GT_730.png', '/content/tmp/traindataset_only_depth/GT/GT_731.png', '/content/tmp/traindataset_only_depth/GT/GT_732.png', '/content/tmp/traindataset_only_depth/GT/GT_740.png', '/content/tmp/traindataset_only_depth/GT/GT_741.png', '/content/tmp/traindataset_only_depth/GT/GT_742.png', '/content/tmp/traindataset_only_depth/GT/GT_750.png', '/content/tmp/traindataset_only_depth/GT/GT_751.png', '/content/tmp/traindataset_only_depth/GT/GT_752.png', '/content/tmp/traindataset_only_depth/GT/GT_760.png', '/content/tmp/traindataset_only_depth/GT/GT_761.png', '/content/tmp/traindataset_only_depth/GT/GT_762.png', '/content/tmp/traindataset_only_depth/GT/GT_770.png', '/content/tmp/traindataset_only_depth/GT/GT_771.png', '/content/tmp/traindataset_only_depth/GT/GT_772.png', '/content/tmp/traindataset_only_depth/GT/GT_780.png', '/content/tmp/traindataset_only_depth/GT/GT_781.png', '/content/tmp/traindataset_only_depth/GT/GT_782.png', '/content/tmp/traindataset_only_depth/GT/GT_790.png', '/content/tmp/traindataset_only_depth/GT/GT_791.png', '/content/tmp/traindataset_only_depth/GT/GT_792.png', '/content/tmp/traindataset_only_depth/GT/GT_80.png', '/content/tmp/traindataset_only_depth/GT/GT_81.png', '/content/tmp/traindataset_only_depth/GT/GT_82.png', '/content/tmp/traindataset_only_depth/GT/GT_90.png', '/content/tmp/traindataset_only_depth/GT/GT_91.png', '/content/tmp/traindataset_only_depth/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7f822d4bde50>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/photosynthesis-team/photosynthesis.metrics/releases/download/v0.4.0/lpips_weights.pt\" to /root/.cache/torch/hub/checkpoints/lpips_weights.pt\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start train...\n",
            "2022-07-30 10:05:56.032225 Epoch [001/250], Step [0001/0060], Loss1: 0.6937 Loss2: 0.6839 Loss3: 0.6641\n",
            "2022-07-30 10:06:36.603186 Epoch [001/250], Step [0050/0060], Loss1: 0.4764 Loss2: 0.4859 Loss3: 0.4503\n",
            "2022-07-30 10:06:44.854657 Epoch [001/250], Step [0060/0060], Loss1: 0.4681 Loss2: 0.4761 Loss3: 0.4395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 MAE: 0.21945147135901066 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-07-30 10:06:54.467166 Epoch [002/250], Step [0001/0060], Loss1: 0.4448 Loss2: 0.4828 Loss3: 0.4267\n",
            "2022-07-30 10:07:34.967480 Epoch [002/250], Step [0050/0060], Loss1: 0.3852 Loss2: 0.4301 Loss3: 0.3607\n",
            "2022-07-30 10:07:43.232599 Epoch [002/250], Step [0060/0060], Loss1: 0.3727 Loss2: 0.4125 Loss3: 0.3427\n",
            "Epoch: 2 MAE: 0.15204927474733382 ####  bestMAE: 0.21945147135901066 bestEpoch: 0\n",
            "best epoch:2\n",
            "2022-07-30 10:07:51.445137 Epoch [003/250], Step [0001/0060], Loss1: 0.3671 Loss2: 0.4115 Loss3: 0.3422\n",
            "2022-07-30 10:08:32.259561 Epoch [003/250], Step [0050/0060], Loss1: 0.3406 Loss2: 0.3891 Loss3: 0.2995\n",
            "2022-07-30 10:08:40.514043 Epoch [003/250], Step [0060/0060], Loss1: 0.3286 Loss2: 0.3840 Loss3: 0.2940\n",
            "Epoch: 3 MAE: 0.09258307815228818 ####  bestMAE: 0.15204927474733382 bestEpoch: 2\n",
            "best epoch:3\n",
            "2022-07-30 10:08:48.564219 Epoch [004/250], Step [0001/0060], Loss1: 0.3331 Loss2: 0.3700 Loss3: 0.2972\n",
            "2022-07-30 10:09:29.323016 Epoch [004/250], Step [0050/0060], Loss1: 0.3130 Loss2: 0.3686 Loss3: 0.2829\n",
            "2022-07-30 10:09:37.574175 Epoch [004/250], Step [0060/0060], Loss1: 0.3005 Loss2: 0.3624 Loss3: 0.2725\n",
            "Epoch: 4 MAE: 0.07943808076242925 ####  bestMAE: 0.09258307815228818 bestEpoch: 3\n",
            "best epoch:4\n",
            "2022-07-30 10:09:46.110367 Epoch [005/250], Step [0001/0060], Loss1: 0.2817 Loss2: 0.3412 Loss3: 0.2484\n",
            "2022-07-30 10:10:27.103242 Epoch [005/250], Step [0050/0060], Loss1: 0.2943 Loss2: 0.3450 Loss3: 0.2715\n",
            "2022-07-30 10:10:35.351001 Epoch [005/250], Step [0060/0060], Loss1: 0.2863 Loss2: 0.3274 Loss3: 0.2614\n",
            "Epoch: 5 MAE: 0.0804469849823644 ####  bestMAE: 0.07943808076242925 bestEpoch: 4\n",
            "2022-07-30 10:10:43.331180 Epoch [006/250], Step [0001/0060], Loss1: 0.2802 Loss2: 0.3324 Loss3: 0.2621\n",
            "2022-07-30 10:11:24.308370 Epoch [006/250], Step [0050/0060], Loss1: 0.2633 Loss2: 0.3035 Loss3: 0.2428\n",
            "2022-07-30 10:11:32.563448 Epoch [006/250], Step [0060/0060], Loss1: 0.2703 Loss2: 0.3189 Loss3: 0.2512\n",
            "Epoch: 6 MAE: 0.08621464007745974 ####  bestMAE: 0.07943808076242925 bestEpoch: 4\n",
            "2022-07-30 10:11:38.366398 Epoch [007/250], Step [0001/0060], Loss1: 0.2841 Loss2: 0.3184 Loss3: 0.2598\n",
            "2022-07-30 10:12:18.875028 Epoch [007/250], Step [0050/0060], Loss1: 0.2560 Loss2: 0.2925 Loss3: 0.2348\n",
            "2022-07-30 10:12:27.130754 Epoch [007/250], Step [0060/0060], Loss1: 0.2694 Loss2: 0.2991 Loss3: 0.2481\n",
            "Epoch: 7 MAE: 0.08459893746350808 ####  bestMAE: 0.07943808076242925 bestEpoch: 4\n",
            "2022-07-30 10:12:32.895651 Epoch [008/250], Step [0001/0060], Loss1: 0.2551 Loss2: 0.2909 Loss3: 0.2365\n",
            "2022-07-30 10:13:13.402370 Epoch [008/250], Step [0050/0060], Loss1: 0.2590 Loss2: 0.2935 Loss3: 0.2383\n",
            "2022-07-30 10:13:21.661386 Epoch [008/250], Step [0060/0060], Loss1: 0.2549 Loss2: 0.3070 Loss3: 0.2367\n",
            "Epoch: 8 MAE: 0.0796548069343365 ####  bestMAE: 0.07943808076242925 bestEpoch: 4\n",
            "2022-07-30 10:13:27.458238 Epoch [009/250], Step [0001/0060], Loss1: 0.2584 Loss2: 0.2830 Loss3: 0.2397\n",
            "2022-07-30 10:14:07.960632 Epoch [009/250], Step [0050/0060], Loss1: 0.2625 Loss2: 0.2969 Loss3: 0.2465\n",
            "2022-07-30 10:14:16.222938 Epoch [009/250], Step [0060/0060], Loss1: 0.2765 Loss2: 0.3062 Loss3: 0.2600\n",
            "Epoch: 9 MAE: 0.08371729689300375 ####  bestMAE: 0.07943808076242925 bestEpoch: 4\n",
            "2022-07-30 10:14:22.045346 Epoch [010/250], Step [0001/0060], Loss1: 0.2617 Loss2: 0.3004 Loss3: 0.2458\n",
            "2022-07-30 10:15:02.545034 Epoch [010/250], Step [0050/0060], Loss1: 0.2404 Loss2: 0.2714 Loss3: 0.2249\n",
            "2022-07-30 10:15:10.853774 Epoch [010/250], Step [0060/0060], Loss1: 0.2440 Loss2: 0.2855 Loss3: 0.2267\n",
            "Epoch: 10 MAE: 0.08857162445310564 ####  bestMAE: 0.07943808076242925 bestEpoch: 4\n",
            "2022-07-30 10:15:19.014049 Epoch [011/250], Step [0001/0060], Loss1: 0.2607 Loss2: 0.3072 Loss3: 0.2453\n",
            "2022-07-30 10:15:59.783859 Epoch [011/250], Step [0050/0060], Loss1: 0.2409 Loss2: 0.2750 Loss3: 0.2275\n",
            "2022-07-30 10:16:08.044810 Epoch [011/250], Step [0060/0060], Loss1: 0.2463 Loss2: 0.2836 Loss3: 0.2322\n",
            "Epoch: 11 MAE: 0.08499919477593962 ####  bestMAE: 0.07943808076242925 bestEpoch: 4\n",
            "2022-07-30 10:16:13.938821 Epoch [012/250], Step [0001/0060], Loss1: 0.2567 Loss2: 0.2969 Loss3: 0.2408\n",
            "2022-07-30 10:16:54.469750 Epoch [012/250], Step [0050/0060], Loss1: 0.2605 Loss2: 0.3065 Loss3: 0.2452\n",
            "2022-07-30 10:17:02.750148 Epoch [012/250], Step [0060/0060], Loss1: 0.2456 Loss2: 0.2739 Loss3: 0.2257\n",
            "Epoch: 12 MAE: 0.08631029018018611 ####  bestMAE: 0.07943808076242925 bestEpoch: 4\n",
            "2022-07-30 10:17:08.640558 Epoch [013/250], Step [0001/0060], Loss1: 0.2425 Loss2: 0.2897 Loss3: 0.2301\n",
            "2022-07-30 10:17:49.163775 Epoch [013/250], Step [0050/0060], Loss1: 0.2418 Loss2: 0.2710 Loss3: 0.2272\n",
            "2022-07-30 10:17:57.422950 Epoch [013/250], Step [0060/0060], Loss1: 0.2364 Loss2: 0.2668 Loss3: 0.2220\n",
            "Epoch: 13 MAE: 0.08531795602626902 ####  bestMAE: 0.07943808076242925 bestEpoch: 4\n",
            "2022-07-30 10:18:03.316908 Epoch [014/250], Step [0001/0060], Loss1: 0.2263 Loss2: 0.2617 Loss3: 0.2096\n",
            "2022-07-30 10:18:43.859533 Epoch [014/250], Step [0050/0060], Loss1: 0.2361 Loss2: 0.2631 Loss3: 0.2190\n",
            "2022-07-30 10:18:52.114429 Epoch [014/250], Step [0060/0060], Loss1: 0.2364 Loss2: 0.2722 Loss3: 0.2209\n",
            "Epoch: 14 MAE: 0.07470111796464868 ####  bestMAE: 0.07943808076242925 bestEpoch: 4\n",
            "best epoch:14\n",
            "2022-07-30 10:19:00.369727 Epoch [015/250], Step [0001/0060], Loss1: 0.2482 Loss2: 0.2756 Loss3: 0.2287\n",
            "2022-07-30 10:19:41.226157 Epoch [015/250], Step [0050/0060], Loss1: 0.2526 Loss2: 0.2742 Loss3: 0.2305\n",
            "2022-07-30 10:19:49.490344 Epoch [015/250], Step [0060/0060], Loss1: 0.2540 Loss2: 0.2929 Loss3: 0.2393\n",
            "Epoch: 15 MAE: 0.0873788691323901 ####  bestMAE: 0.07470111796464868 bestEpoch: 14\n",
            "2022-07-30 10:19:57.965885 Epoch [016/250], Step [0001/0060], Loss1: 0.2481 Loss2: 0.2700 Loss3: 0.2309\n",
            "2022-07-30 10:20:38.707343 Epoch [016/250], Step [0050/0060], Loss1: 0.2399 Loss2: 0.2604 Loss3: 0.2235\n",
            "2022-07-30 10:20:46.955476 Epoch [016/250], Step [0060/0060], Loss1: 0.2446 Loss2: 0.2739 Loss3: 0.2276\n",
            "Epoch: 16 MAE: 0.08369760331653413 ####  bestMAE: 0.07470111796464868 bestEpoch: 14\n",
            "2022-07-30 10:20:52.817577 Epoch [017/250], Step [0001/0060], Loss1: 0.2417 Loss2: 0.2650 Loss3: 0.2255\n",
            "2022-07-30 10:21:33.351340 Epoch [017/250], Step [0050/0060], Loss1: 0.2507 Loss2: 0.2732 Loss3: 0.2341\n",
            "2022-07-30 10:21:41.611996 Epoch [017/250], Step [0060/0060], Loss1: 0.2364 Loss2: 0.2748 Loss3: 0.2220\n",
            "Epoch: 17 MAE: 0.08379128047398153 ####  bestMAE: 0.07470111796464868 bestEpoch: 14\n",
            "2022-07-30 10:21:47.520320 Epoch [018/250], Step [0001/0060], Loss1: 0.2424 Loss2: 0.2611 Loss3: 0.2235\n",
            "2022-07-30 10:22:28.054565 Epoch [018/250], Step [0050/0060], Loss1: 0.2477 Loss2: 0.2692 Loss3: 0.2265\n",
            "2022-07-30 10:22:36.307427 Epoch [018/250], Step [0060/0060], Loss1: 0.2448 Loss2: 0.2693 Loss3: 0.2299\n",
            "Epoch: 18 MAE: 0.09092233698204082 ####  bestMAE: 0.07470111796464868 bestEpoch: 14\n",
            "2022-07-30 10:22:42.169629 Epoch [019/250], Step [0001/0060], Loss1: 0.2298 Loss2: 0.2570 Loss3: 0.2104\n",
            "2022-07-30 10:23:22.701483 Epoch [019/250], Step [0050/0060], Loss1: 0.2190 Loss2: 0.2492 Loss3: 0.2053\n",
            "2022-07-30 10:23:30.952286 Epoch [019/250], Step [0060/0060], Loss1: 0.2364 Loss2: 0.2661 Loss3: 0.2208\n",
            "Epoch: 19 MAE: 0.08239057672086844 ####  bestMAE: 0.07470111796464868 bestEpoch: 14\n",
            "2022-07-30 10:23:36.840191 Epoch [020/250], Step [0001/0060], Loss1: 0.2417 Loss2: 0.2704 Loss3: 0.2234\n",
            "2022-07-30 10:24:17.347148 Epoch [020/250], Step [0050/0060], Loss1: 0.2363 Loss2: 0.2646 Loss3: 0.2195\n",
            "2022-07-30 10:24:25.611427 Epoch [020/250], Step [0060/0060], Loss1: 0.2330 Loss2: 0.2689 Loss3: 0.2177\n",
            "Epoch: 20 MAE: 0.08134704155896705 ####  bestMAE: 0.07470111796464868 bestEpoch: 14\n",
            "2022-07-30 10:24:33.828850 Epoch [021/250], Step [0001/0060], Loss1: 0.2249 Loss2: 0.2416 Loss3: 0.2074\n",
            "2022-07-30 10:25:14.644929 Epoch [021/250], Step [0050/0060], Loss1: 0.2484 Loss2: 0.2755 Loss3: 0.2311\n",
            "2022-07-30 10:25:22.893413 Epoch [021/250], Step [0060/0060], Loss1: 0.2456 Loss2: 0.2878 Loss3: 0.2283\n",
            "Epoch: 21 MAE: 0.07438739514224746 ####  bestMAE: 0.07470111796464868 bestEpoch: 14\n",
            "best epoch:21\n",
            "2022-07-30 10:25:31.261303 Epoch [022/250], Step [0001/0060], Loss1: 0.2449 Loss2: 0.2730 Loss3: 0.2251\n",
            "2022-07-30 10:26:12.141300 Epoch [022/250], Step [0050/0060], Loss1: 0.2356 Loss2: 0.2725 Loss3: 0.2169\n",
            "2022-07-30 10:26:20.381830 Epoch [022/250], Step [0060/0060], Loss1: 0.2218 Loss2: 0.2474 Loss3: 0.2050\n",
            "Epoch: 22 MAE: 0.08651197181176891 ####  bestMAE: 0.07438739514224746 bestEpoch: 21\n",
            "2022-07-30 10:26:26.221935 Epoch [023/250], Step [0001/0060], Loss1: 0.2249 Loss2: 0.2558 Loss3: 0.2077\n",
            "2022-07-30 10:27:06.711562 Epoch [023/250], Step [0050/0060], Loss1: 0.2372 Loss2: 0.2647 Loss3: 0.2216\n",
            "2022-07-30 10:27:14.976342 Epoch [023/250], Step [0060/0060], Loss1: 0.2355 Loss2: 0.2663 Loss3: 0.2180\n",
            "Epoch: 23 MAE: 0.06771096290103974 ####  bestMAE: 0.07438739514224746 bestEpoch: 21\n",
            "best epoch:23\n",
            "2022-07-30 10:27:23.152353 Epoch [024/250], Step [0001/0060], Loss1: 0.2294 Loss2: 0.2465 Loss3: 0.2114\n",
            "2022-07-30 10:28:04.141917 Epoch [024/250], Step [0050/0060], Loss1: 0.2265 Loss2: 0.2531 Loss3: 0.2118\n",
            "2022-07-30 10:28:12.384028 Epoch [024/250], Step [0060/0060], Loss1: 0.2340 Loss2: 0.2734 Loss3: 0.2166\n",
            "Epoch: 24 MAE: 0.07847418956655672 ####  bestMAE: 0.06771096290103974 bestEpoch: 23\n",
            "2022-07-30 10:28:18.210854 Epoch [025/250], Step [0001/0060], Loss1: 0.2290 Loss2: 0.2657 Loss3: 0.2161\n",
            "2022-07-30 10:28:58.768337 Epoch [025/250], Step [0050/0060], Loss1: 0.2340 Loss2: 0.2576 Loss3: 0.2146\n",
            "2022-07-30 10:29:07.021913 Epoch [025/250], Step [0060/0060], Loss1: 0.2226 Loss2: 0.2421 Loss3: 0.2060\n",
            "Epoch: 25 MAE: 0.08189730578629428 ####  bestMAE: 0.06771096290103974 bestEpoch: 23\n",
            "2022-07-30 10:29:15.282188 Epoch [026/250], Step [0001/0060], Loss1: 0.2133 Loss2: 0.2463 Loss3: 0.1978\n",
            "2022-07-30 10:29:55.803528 Epoch [026/250], Step [0050/0060], Loss1: 0.2232 Loss2: 0.2561 Loss3: 0.2067\n",
            "2022-07-30 10:30:04.044422 Epoch [026/250], Step [0060/0060], Loss1: 0.2219 Loss2: 0.2382 Loss3: 0.2037\n",
            "Epoch: 26 MAE: 0.08670323972348813 ####  bestMAE: 0.06771096290103974 bestEpoch: 23\n",
            "2022-07-30 10:30:09.972928 Epoch [027/250], Step [0001/0060], Loss1: 0.2385 Loss2: 0.2681 Loss3: 0.2206\n",
            "2022-07-30 10:30:50.459297 Epoch [027/250], Step [0050/0060], Loss1: 0.2225 Loss2: 0.2452 Loss3: 0.2051\n",
            "2022-07-30 10:30:58.700872 Epoch [027/250], Step [0060/0060], Loss1: 0.2324 Loss2: 0.2717 Loss3: 0.2146\n",
            "Epoch: 27 MAE: 0.07731933896503751 ####  bestMAE: 0.06771096290103974 bestEpoch: 23\n",
            "2022-07-30 10:31:04.592966 Epoch [028/250], Step [0001/0060], Loss1: 0.2294 Loss2: 0.2640 Loss3: 0.2132\n",
            "2022-07-30 10:31:45.089584 Epoch [028/250], Step [0050/0060], Loss1: 0.2272 Loss2: 0.2510 Loss3: 0.2090\n",
            "2022-07-30 10:31:53.346461 Epoch [028/250], Step [0060/0060], Loss1: 0.2350 Loss2: 0.2594 Loss3: 0.2168\n",
            "Epoch: 28 MAE: 0.0832749548412505 ####  bestMAE: 0.06771096290103974 bestEpoch: 23\n",
            "2022-07-30 10:31:59.299643 Epoch [029/250], Step [0001/0060], Loss1: 0.2297 Loss2: 0.2551 Loss3: 0.2104\n",
            "2022-07-30 10:32:39.853978 Epoch [029/250], Step [0050/0060], Loss1: 0.2261 Loss2: 0.2586 Loss3: 0.2091\n",
            "2022-07-30 10:32:48.097746 Epoch [029/250], Step [0060/0060], Loss1: 0.2238 Loss2: 0.2558 Loss3: 0.2076\n",
            "Epoch: 29 MAE: 0.07608183048389576 ####  bestMAE: 0.06771096290103974 bestEpoch: 23\n",
            "2022-07-30 10:32:53.890112 Epoch [030/250], Step [0001/0060], Loss1: 0.2250 Loss2: 0.2493 Loss3: 0.2053\n",
            "2022-07-30 10:33:34.381910 Epoch [030/250], Step [0050/0060], Loss1: 0.2259 Loss2: 0.2549 Loss3: 0.2090\n",
            "2022-07-30 10:33:42.622766 Epoch [030/250], Step [0060/0060], Loss1: 0.2176 Loss2: 0.2494 Loss3: 0.2030\n",
            "Epoch: 30 MAE: 0.06873663841731964 ####  bestMAE: 0.06771096290103974 bestEpoch: 23\n",
            "2022-07-30 10:33:50.756151 Epoch [031/250], Step [0001/0060], Loss1: 0.2216 Loss2: 0.2414 Loss3: 0.2036\n",
            "2022-07-30 10:34:31.525827 Epoch [031/250], Step [0050/0060], Loss1: 0.2186 Loss2: 0.2471 Loss3: 0.2023\n",
            "2022-07-30 10:34:39.780470 Epoch [031/250], Step [0060/0060], Loss1: 0.2232 Loss2: 0.2389 Loss3: 0.2056\n",
            "Epoch: 31 MAE: 0.07131472380703721 ####  bestMAE: 0.06771096290103974 bestEpoch: 23\n",
            "2022-07-30 10:34:45.683815 Epoch [032/250], Step [0001/0060], Loss1: 0.2264 Loss2: 0.2505 Loss3: 0.2096\n",
            "2022-07-30 10:35:26.109880 Epoch [032/250], Step [0050/0060], Loss1: 0.2224 Loss2: 0.2508 Loss3: 0.2066\n",
            "2022-07-30 10:35:34.351784 Epoch [032/250], Step [0060/0060], Loss1: 0.2251 Loss2: 0.2509 Loss3: 0.2100\n",
            "Epoch: 32 MAE: 0.06470456824731576 ####  bestMAE: 0.06771096290103974 bestEpoch: 23\n",
            "best epoch:32\n",
            "2022-07-30 10:35:42.586573 Epoch [033/250], Step [0001/0060], Loss1: 0.2216 Loss2: 0.2485 Loss3: 0.2058\n",
            "2022-07-30 10:36:23.372851 Epoch [033/250], Step [0050/0060], Loss1: 0.2339 Loss2: 0.2702 Loss3: 0.2148\n",
            "2022-07-30 10:36:31.616197 Epoch [033/250], Step [0060/0060], Loss1: 0.2190 Loss2: 0.2464 Loss3: 0.1996\n",
            "Epoch: 33 MAE: 0.06895091354531586 ####  bestMAE: 0.06470456824731576 bestEpoch: 32\n",
            "2022-07-30 10:36:37.461784 Epoch [034/250], Step [0001/0060], Loss1: 0.2258 Loss2: 0.2591 Loss3: 0.2074\n",
            "2022-07-30 10:37:17.925433 Epoch [034/250], Step [0050/0060], Loss1: 0.2016 Loss2: 0.2246 Loss3: 0.1851\n",
            "2022-07-30 10:37:26.184510 Epoch [034/250], Step [0060/0060], Loss1: 0.2255 Loss2: 0.2559 Loss3: 0.2077\n",
            "Epoch: 34 MAE: 0.06327015018967723 ####  bestMAE: 0.06470456824731576 bestEpoch: 32\n",
            "best epoch:34\n",
            "2022-07-30 10:37:34.601656 Epoch [035/250], Step [0001/0060], Loss1: 0.2268 Loss2: 0.2489 Loss3: 0.2099\n",
            "2022-07-30 10:38:15.379941 Epoch [035/250], Step [0050/0060], Loss1: 0.2249 Loss2: 0.2492 Loss3: 0.2055\n",
            "2022-07-30 10:38:23.648656 Epoch [035/250], Step [0060/0060], Loss1: 0.2242 Loss2: 0.2475 Loss3: 0.2036\n",
            "Epoch: 35 MAE: 0.06761570885067895 ####  bestMAE: 0.06327015018967723 bestEpoch: 34\n",
            "2022-07-30 10:38:31.915135 Epoch [036/250], Step [0001/0060], Loss1: 0.2286 Loss2: 0.2624 Loss3: 0.2070\n",
            "2022-07-30 10:39:12.433525 Epoch [036/250], Step [0050/0060], Loss1: 0.2207 Loss2: 0.2366 Loss3: 0.2022\n",
            "2022-07-30 10:39:20.676692 Epoch [036/250], Step [0060/0060], Loss1: 0.2279 Loss2: 0.2519 Loss3: 0.2075\n",
            "Epoch: 36 MAE: 0.0737800596126173 ####  bestMAE: 0.06327015018967723 bestEpoch: 34\n",
            "2022-07-30 10:39:26.477832 Epoch [037/250], Step [0001/0060], Loss1: 0.2147 Loss2: 0.2431 Loss3: 0.1984\n",
            "2022-07-30 10:40:06.941047 Epoch [037/250], Step [0050/0060], Loss1: 0.2273 Loss2: 0.2722 Loss3: 0.2075\n",
            "2022-07-30 10:40:15.198822 Epoch [037/250], Step [0060/0060], Loss1: 0.2189 Loss2: 0.2480 Loss3: 0.1991\n",
            "Epoch: 37 MAE: 0.06345485096886046 ####  bestMAE: 0.06327015018967723 bestEpoch: 34\n",
            "2022-07-30 10:40:21.194969 Epoch [038/250], Step [0001/0060], Loss1: 0.2241 Loss2: 0.2525 Loss3: 0.2028\n",
            "2022-07-30 10:41:02.414287 Epoch [038/250], Step [0050/0060], Loss1: 0.2324 Loss2: 0.2649 Loss3: 0.2132\n",
            "2022-07-30 10:41:10.667258 Epoch [038/250], Step [0060/0060], Loss1: 0.2172 Loss2: 0.2478 Loss3: 0.2024\n",
            "Epoch: 38 MAE: 0.06841046358542469 ####  bestMAE: 0.06327015018967723 bestEpoch: 34\n",
            "2022-07-30 10:41:16.559266 Epoch [039/250], Step [0001/0060], Loss1: 0.2206 Loss2: 0.2497 Loss3: 0.2050\n",
            "2022-07-30 10:41:56.986540 Epoch [039/250], Step [0050/0060], Loss1: 0.2339 Loss2: 0.2636 Loss3: 0.2158\n",
            "2022-07-30 10:42:05.234052 Epoch [039/250], Step [0060/0060], Loss1: 0.2317 Loss2: 0.2644 Loss3: 0.2116\n",
            "Epoch: 39 MAE: 0.07716096307865528 ####  bestMAE: 0.06327015018967723 bestEpoch: 34\n",
            "2022-07-30 10:42:11.041398 Epoch [040/250], Step [0001/0060], Loss1: 0.2307 Loss2: 0.2605 Loss3: 0.2090\n",
            "2022-07-30 10:42:51.813952 Epoch [040/250], Step [0050/0060], Loss1: 0.2185 Loss2: 0.2398 Loss3: 0.2011\n",
            "2022-07-30 10:43:00.052085 Epoch [040/250], Step [0060/0060], Loss1: 0.2285 Loss2: 0.2462 Loss3: 0.2051\n",
            "Epoch: 40 MAE: 0.07087766051923156 ####  bestMAE: 0.06327015018967723 bestEpoch: 34\n",
            "2022-07-30 10:43:08.446177 Epoch [041/250], Step [0001/0060], Loss1: 0.2313 Loss2: 0.2675 Loss3: 0.2112\n",
            "2022-07-30 10:43:48.890787 Epoch [041/250], Step [0050/0060], Loss1: 0.2218 Loss2: 0.2536 Loss3: 0.2050\n",
            "2022-07-30 10:43:57.141390 Epoch [041/250], Step [0060/0060], Loss1: 0.2118 Loss2: 0.2361 Loss3: 0.1928\n",
            "Epoch: 41 MAE: 0.06628647112972522 ####  bestMAE: 0.06327015018967723 bestEpoch: 34\n",
            "2022-07-30 10:44:02.994868 Epoch [042/250], Step [0001/0060], Loss1: 0.2042 Loss2: 0.2399 Loss3: 0.1855\n",
            "2022-07-30 10:44:43.497053 Epoch [042/250], Step [0050/0060], Loss1: 0.2297 Loss2: 0.2498 Loss3: 0.2117\n",
            "2022-07-30 10:44:52.304630 Epoch [042/250], Step [0060/0060], Loss1: 0.2163 Loss2: 0.2321 Loss3: 0.1991\n",
            "Epoch: 42 MAE: 0.06429944719587052 ####  bestMAE: 0.06327015018967723 bestEpoch: 34\n",
            "2022-07-30 10:44:59.528602 Epoch [043/250], Step [0001/0060], Loss1: 0.2102 Loss2: 0.2359 Loss3: 0.1882\n",
            "2022-07-30 10:45:39.996284 Epoch [043/250], Step [0050/0060], Loss1: 0.2125 Loss2: 0.2327 Loss3: 0.1935\n",
            "2022-07-30 10:45:48.242231 Epoch [043/250], Step [0060/0060], Loss1: 0.2183 Loss2: 0.2478 Loss3: 0.2004\n",
            "Epoch: 43 MAE: 0.07169373032907958 ####  bestMAE: 0.06327015018967723 bestEpoch: 34\n",
            "2022-07-30 10:45:54.089137 Epoch [044/250], Step [0001/0060], Loss1: 0.2259 Loss2: 0.2510 Loss3: 0.2054\n",
            "2022-07-30 10:46:34.626796 Epoch [044/250], Step [0050/0060], Loss1: 0.2298 Loss2: 0.2503 Loss3: 0.2062\n",
            "2022-07-30 10:46:42.882507 Epoch [044/250], Step [0060/0060], Loss1: 0.2172 Loss2: 0.2326 Loss3: 0.1998\n",
            "Epoch: 44 MAE: 0.15668086173042417 ####  bestMAE: 0.06327015018967723 bestEpoch: 34\n",
            "2022-07-30 10:46:48.751937 Epoch [045/250], Step [0001/0060], Loss1: 0.2172 Loss2: 0.2387 Loss3: 0.1959\n",
            "2022-07-30 10:47:29.623072 Epoch [045/250], Step [0050/0060], Loss1: 0.2028 Loss2: 0.2252 Loss3: 0.1865\n",
            "2022-07-30 10:47:37.884133 Epoch [045/250], Step [0060/0060], Loss1: 0.2087 Loss2: 0.2275 Loss3: 0.1880\n",
            "Epoch: 45 MAE: 0.23215677180618208 ####  bestMAE: 0.06327015018967723 bestEpoch: 34\n",
            "2022-07-30 10:47:46.928301 Epoch [046/250], Step [0001/0060], Loss1: 0.2117 Loss2: 0.2419 Loss3: 0.1958\n",
            "2022-07-30 10:48:27.355584 Epoch [046/250], Step [0050/0060], Loss1: 0.2106 Loss2: 0.2399 Loss3: 0.1919\n",
            "2022-07-30 10:48:35.597508 Epoch [046/250], Step [0060/0060], Loss1: 0.2125 Loss2: 0.2343 Loss3: 0.1938\n",
            "Epoch: 46 MAE: 0.06034647966818834 ####  bestMAE: 0.06327015018967723 bestEpoch: 34\n",
            "best epoch:46\n",
            "2022-07-30 10:48:45.145227 Epoch [047/250], Step [0001/0060], Loss1: 0.2153 Loss2: 0.2370 Loss3: 0.1957\n",
            "2022-07-30 10:49:26.568839 Epoch [047/250], Step [0050/0060], Loss1: 0.2115 Loss2: 0.2285 Loss3: 0.1935\n",
            "2022-07-30 10:49:34.825319 Epoch [047/250], Step [0060/0060], Loss1: 0.2293 Loss2: 0.2579 Loss3: 0.2088\n",
            "Epoch: 47 MAE: 0.07475163696934936 ####  bestMAE: 0.06034647966818834 bestEpoch: 46\n",
            "2022-07-30 10:49:40.682557 Epoch [048/250], Step [0001/0060], Loss1: 0.2121 Loss2: 0.2278 Loss3: 0.1919\n",
            "2022-07-30 10:50:21.157123 Epoch [048/250], Step [0050/0060], Loss1: 0.2175 Loss2: 0.2395 Loss3: 0.1993\n",
            "2022-07-30 10:50:29.403669 Epoch [048/250], Step [0060/0060], Loss1: 0.2231 Loss2: 0.2438 Loss3: 0.2021\n",
            "Epoch: 48 MAE: 0.06969681028335813 ####  bestMAE: 0.06034647966818834 bestEpoch: 46\n",
            "2022-07-30 10:50:35.186987 Epoch [049/250], Step [0001/0060], Loss1: 0.2176 Loss2: 0.2477 Loss3: 0.1980\n",
            "2022-07-30 10:51:15.658220 Epoch [049/250], Step [0050/0060], Loss1: 0.2242 Loss2: 0.2424 Loss3: 0.2042\n",
            "2022-07-30 10:51:23.942506 Epoch [049/250], Step [0060/0060], Loss1: 0.2024 Loss2: 0.2302 Loss3: 0.1872\n",
            "Epoch: 49 MAE: 0.06141318623981778 ####  bestMAE: 0.06034647966818834 bestEpoch: 46\n",
            "2022-07-30 10:51:30.964842 Epoch [050/250], Step [0001/0060], Loss1: 0.2109 Loss2: 0.2272 Loss3: 0.1907\n",
            "2022-07-30 10:52:11.532908 Epoch [050/250], Step [0050/0060], Loss1: 0.2195 Loss2: 0.2510 Loss3: 0.2025\n",
            "2022-07-30 10:52:19.778583 Epoch [050/250], Step [0060/0060], Loss1: 0.2209 Loss2: 0.2502 Loss3: 0.2028\n",
            "Epoch: 50 MAE: 0.06175416285398777 ####  bestMAE: 0.06034647966818834 bestEpoch: 46\n",
            "2022-07-30 10:52:27.933111 Epoch [051/250], Step [0001/0060], Loss1: 0.2241 Loss2: 0.2442 Loss3: 0.2034\n",
            "2022-07-30 10:53:08.505972 Epoch [051/250], Step [0050/0060], Loss1: 0.2130 Loss2: 0.2349 Loss3: 0.1922\n",
            "2022-07-30 10:53:16.746370 Epoch [051/250], Step [0060/0060], Loss1: 0.2031 Loss2: 0.2326 Loss3: 0.1842\n",
            "Epoch: 51 MAE: 0.05835259871508081 ####  bestMAE: 0.06034647966818834 bestEpoch: 46\n",
            "best epoch:51\n",
            "2022-07-30 10:53:24.978064 Epoch [052/250], Step [0001/0060], Loss1: 0.2183 Loss2: 0.2438 Loss3: 0.1995\n",
            "2022-07-30 10:54:06.368344 Epoch [052/250], Step [0050/0060], Loss1: 0.2171 Loss2: 0.2447 Loss3: 0.1994\n",
            "2022-07-30 10:54:14.610154 Epoch [052/250], Step [0060/0060], Loss1: 0.2247 Loss2: 0.2555 Loss3: 0.2033\n",
            "Epoch: 52 MAE: 0.07137560708182197 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 10:54:20.350042 Epoch [053/250], Step [0001/0060], Loss1: 0.2087 Loss2: 0.2388 Loss3: 0.1921\n",
            "2022-07-30 10:55:00.895676 Epoch [053/250], Step [0050/0060], Loss1: 0.2201 Loss2: 0.2526 Loss3: 0.2015\n",
            "2022-07-30 10:55:09.142424 Epoch [053/250], Step [0060/0060], Loss1: 0.2038 Loss2: 0.2154 Loss3: 0.1875\n",
            "Epoch: 53 MAE: 0.0642486187768361 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 10:55:14.887734 Epoch [054/250], Step [0001/0060], Loss1: 0.2202 Loss2: 0.2313 Loss3: 0.1998\n",
            "2022-07-30 10:55:55.875446 Epoch [054/250], Step [0050/0060], Loss1: 0.2137 Loss2: 0.2315 Loss3: 0.1958\n",
            "2022-07-30 10:56:04.150565 Epoch [054/250], Step [0060/0060], Loss1: 0.2102 Loss2: 0.2308 Loss3: 0.1911\n",
            "Epoch: 54 MAE: 0.07382269011603461 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 10:56:09.889993 Epoch [055/250], Step [0001/0060], Loss1: 0.2175 Loss2: 0.2368 Loss3: 0.1967\n",
            "2022-07-30 10:56:50.389805 Epoch [055/250], Step [0050/0060], Loss1: 0.2120 Loss2: 0.2328 Loss3: 0.1925\n",
            "2022-07-30 10:56:58.643996 Epoch [055/250], Step [0060/0060], Loss1: 0.2224 Loss2: 0.2511 Loss3: 0.2041\n",
            "Epoch: 55 MAE: 0.3251598743156151 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 10:57:06.724117 Epoch [056/250], Step [0001/0060], Loss1: 0.2099 Loss2: 0.2265 Loss3: 0.1907\n",
            "2022-07-30 10:57:47.243406 Epoch [056/250], Step [0050/0060], Loss1: 0.2103 Loss2: 0.2322 Loss3: 0.1931\n",
            "2022-07-30 10:57:55.483389 Epoch [056/250], Step [0060/0060], Loss1: 0.2085 Loss2: 0.2307 Loss3: 0.1906\n",
            "Epoch: 56 MAE: 0.06470974362085735 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 10:58:01.682760 Epoch [057/250], Step [0001/0060], Loss1: 0.2122 Loss2: 0.2313 Loss3: 0.1931\n",
            "2022-07-30 10:58:42.658132 Epoch [057/250], Step [0050/0060], Loss1: 0.2067 Loss2: 0.2366 Loss3: 0.1877\n",
            "2022-07-30 10:58:50.942699 Epoch [057/250], Step [0060/0060], Loss1: 0.2152 Loss2: 0.2513 Loss3: 0.1976\n",
            "Epoch: 57 MAE: 0.06860369102033988 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 10:58:56.748515 Epoch [058/250], Step [0001/0060], Loss1: 0.2163 Loss2: 0.2391 Loss3: 0.1975\n",
            "2022-07-30 10:59:37.228623 Epoch [058/250], Step [0050/0060], Loss1: 0.2233 Loss2: 0.2445 Loss3: 0.2031\n",
            "2022-07-30 10:59:45.479469 Epoch [058/250], Step [0060/0060], Loss1: 0.2101 Loss2: 0.2242 Loss3: 0.1913\n",
            "Epoch: 58 MAE: 0.06001041921988996 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 10:59:51.208785 Epoch [059/250], Step [0001/0060], Loss1: 0.2044 Loss2: 0.2178 Loss3: 0.1833\n",
            "2022-07-30 11:00:31.957664 Epoch [059/250], Step [0050/0060], Loss1: 0.2172 Loss2: 0.2318 Loss3: 0.1952\n",
            "2022-07-30 11:00:40.206555 Epoch [059/250], Step [0060/0060], Loss1: 0.2087 Loss2: 0.2306 Loss3: 0.1914\n",
            "Epoch: 59 MAE: 0.06626762324540074 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:00:45.943140 Epoch [060/250], Step [0001/0060], Loss1: 0.2247 Loss2: 0.2361 Loss3: 0.2021\n",
            "2022-07-30 11:01:26.482892 Epoch [060/250], Step [0050/0060], Loss1: 0.1961 Loss2: 0.2223 Loss3: 0.1796\n",
            "2022-07-30 11:01:34.737316 Epoch [060/250], Step [0060/0060], Loss1: 0.2139 Loss2: 0.2283 Loss3: 0.1917\n",
            "Epoch: 60 MAE: 0.06580302717824463 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:01:42.757035 Epoch [061/250], Step [0001/0060], Loss1: 0.2121 Loss2: 0.2224 Loss3: 0.1929\n",
            "2022-07-30 11:02:23.266815 Epoch [061/250], Step [0050/0060], Loss1: 0.2046 Loss2: 0.2277 Loss3: 0.1845\n",
            "2022-07-30 11:02:31.995145 Epoch [061/250], Step [0060/0060], Loss1: 0.2106 Loss2: 0.2217 Loss3: 0.1898\n",
            "Epoch: 61 MAE: 0.06561678765312075 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:02:38.880876 Epoch [062/250], Step [0001/0060], Loss1: 0.2092 Loss2: 0.2268 Loss3: 0.1878\n",
            "2022-07-30 11:03:19.368463 Epoch [062/250], Step [0050/0060], Loss1: 0.2075 Loss2: 0.2217 Loss3: 0.1845\n",
            "2022-07-30 11:03:27.611288 Epoch [062/250], Step [0060/0060], Loss1: 0.2149 Loss2: 0.2324 Loss3: 0.1916\n",
            "Epoch: 62 MAE: 0.06869544796212007 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:03:33.360573 Epoch [063/250], Step [0001/0060], Loss1: 0.2346 Loss2: 0.2513 Loss3: 0.2060\n",
            "2022-07-30 11:04:13.832966 Epoch [063/250], Step [0050/0060], Loss1: 0.2135 Loss2: 0.2275 Loss3: 0.1944\n",
            "2022-07-30 11:04:22.100608 Epoch [063/250], Step [0060/0060], Loss1: 0.2049 Loss2: 0.2251 Loss3: 0.1860\n",
            "Epoch: 63 MAE: 0.06853920810437077 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:04:27.868809 Epoch [064/250], Step [0001/0060], Loss1: 0.2166 Loss2: 0.2304 Loss3: 0.1941\n",
            "2022-07-30 11:05:08.593170 Epoch [064/250], Step [0050/0060], Loss1: 0.2006 Loss2: 0.2383 Loss3: 0.1825\n",
            "2022-07-30 11:05:16.837504 Epoch [064/250], Step [0060/0060], Loss1: 0.1952 Loss2: 0.2163 Loss3: 0.1775\n",
            "Epoch: 64 MAE: 0.06524545578729538 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:05:22.602234 Epoch [065/250], Step [0001/0060], Loss1: 0.2223 Loss2: 0.2301 Loss3: 0.1971\n",
            "2022-07-30 11:06:03.036562 Epoch [065/250], Step [0050/0060], Loss1: 0.2170 Loss2: 0.2354 Loss3: 0.1967\n",
            "2022-07-30 11:06:11.274956 Epoch [065/250], Step [0060/0060], Loss1: 0.2103 Loss2: 0.2240 Loss3: 0.1888\n",
            "Epoch: 65 MAE: 0.06723916129460411 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:06:19.333900 Epoch [066/250], Step [0001/0060], Loss1: 0.2043 Loss2: 0.2297 Loss3: 0.1878\n",
            "2022-07-30 11:07:00.389313 Epoch [066/250], Step [0050/0060], Loss1: 0.2027 Loss2: 0.2200 Loss3: 0.1833\n",
            "2022-07-30 11:07:08.634125 Epoch [066/250], Step [0060/0060], Loss1: 0.2070 Loss2: 0.2273 Loss3: 0.1876\n",
            "Epoch: 66 MAE: 0.06590991701398574 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:07:14.405305 Epoch [067/250], Step [0001/0060], Loss1: 0.1945 Loss2: 0.2096 Loss3: 0.1766\n",
            "2022-07-30 11:07:54.899132 Epoch [067/250], Step [0050/0060], Loss1: 0.2214 Loss2: 0.2347 Loss3: 0.1961\n",
            "2022-07-30 11:08:03.159874 Epoch [067/250], Step [0060/0060], Loss1: 0.2073 Loss2: 0.2285 Loss3: 0.1876\n",
            "Epoch: 67 MAE: 0.06364231836228144 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:08:08.894086 Epoch [068/250], Step [0001/0060], Loss1: 0.2061 Loss2: 0.2220 Loss3: 0.1867\n",
            "2022-07-30 11:08:49.372528 Epoch [068/250], Step [0050/0060], Loss1: 0.2163 Loss2: 0.2381 Loss3: 0.1948\n",
            "2022-07-30 11:08:57.609923 Epoch [068/250], Step [0060/0060], Loss1: 0.2087 Loss2: 0.2210 Loss3: 0.1883\n",
            "Epoch: 68 MAE: 0.06528113738569634 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:09:04.245190 Epoch [069/250], Step [0001/0060], Loss1: 0.2116 Loss2: 0.2374 Loss3: 0.1899\n",
            "2022-07-30 11:09:44.849472 Epoch [069/250], Step [0050/0060], Loss1: 0.2065 Loss2: 0.2232 Loss3: 0.1874\n",
            "2022-07-30 11:09:53.102130 Epoch [069/250], Step [0060/0060], Loss1: 0.2145 Loss2: 0.2437 Loss3: 0.1945\n",
            "Epoch: 69 MAE: 0.06295978263572412 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:09:58.751360 Epoch [070/250], Step [0001/0060], Loss1: 0.2087 Loss2: 0.2232 Loss3: 0.1874\n",
            "2022-07-30 11:10:39.204726 Epoch [070/250], Step [0050/0060], Loss1: 0.2199 Loss2: 0.2464 Loss3: 0.1967\n",
            "2022-07-30 11:10:47.449022 Epoch [070/250], Step [0060/0060], Loss1: 0.2199 Loss2: 0.2315 Loss3: 0.1960\n",
            "Epoch: 70 MAE: 0.0659944834532561 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:10:56.462502 Epoch [071/250], Step [0001/0060], Loss1: 0.2054 Loss2: 0.2209 Loss3: 0.1850\n",
            "2022-07-30 11:11:37.429629 Epoch [071/250], Step [0050/0060], Loss1: 0.2181 Loss2: 0.2334 Loss3: 0.1933\n",
            "2022-07-30 11:11:45.669847 Epoch [071/250], Step [0060/0060], Loss1: 0.2035 Loss2: 0.2190 Loss3: 0.1857\n",
            "Epoch: 71 MAE: 0.06387324605669295 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:11:51.352086 Epoch [072/250], Step [0001/0060], Loss1: 0.2006 Loss2: 0.2209 Loss3: 0.1803\n",
            "2022-07-30 11:12:31.797322 Epoch [072/250], Step [0050/0060], Loss1: 0.2146 Loss2: 0.2356 Loss3: 0.1925\n",
            "2022-07-30 11:12:40.033785 Epoch [072/250], Step [0060/0060], Loss1: 0.2084 Loss2: 0.2236 Loss3: 0.1861\n",
            "Epoch: 72 MAE: 0.0644183408141767 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:12:45.720660 Epoch [073/250], Step [0001/0060], Loss1: 0.2154 Loss2: 0.2264 Loss3: 0.1930\n",
            "2022-07-30 11:13:26.321341 Epoch [073/250], Step [0050/0060], Loss1: 0.2161 Loss2: 0.2382 Loss3: 0.1981\n",
            "2022-07-30 11:13:34.674334 Epoch [073/250], Step [0060/0060], Loss1: 0.2075 Loss2: 0.2309 Loss3: 0.1856\n",
            "Epoch: 73 MAE: 0.06621564774286177 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:13:40.367454 Epoch [074/250], Step [0001/0060], Loss1: 0.2063 Loss2: 0.2309 Loss3: 0.1860\n",
            "2022-07-30 11:14:20.864505 Epoch [074/250], Step [0050/0060], Loss1: 0.2128 Loss2: 0.2353 Loss3: 0.1899\n",
            "2022-07-30 11:14:29.136558 Epoch [074/250], Step [0060/0060], Loss1: 0.2046 Loss2: 0.2180 Loss3: 0.1834\n",
            "Epoch: 74 MAE: 0.06798601256476507 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:14:34.812230 Epoch [075/250], Step [0001/0060], Loss1: 0.2093 Loss2: 0.2227 Loss3: 0.1864\n",
            "2022-07-30 11:15:15.229865 Epoch [075/250], Step [0050/0060], Loss1: 0.2015 Loss2: 0.2211 Loss3: 0.1794\n",
            "2022-07-30 11:15:23.466615 Epoch [075/250], Step [0060/0060], Loss1: 0.2046 Loss2: 0.2194 Loss3: 0.1849\n",
            "Epoch: 75 MAE: 0.06920677825887367 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:15:31.347443 Epoch [076/250], Step [0001/0060], Loss1: 0.2108 Loss2: 0.2352 Loss3: 0.1909\n",
            "2022-07-30 11:16:12.438652 Epoch [076/250], Step [0050/0060], Loss1: 0.2086 Loss2: 0.2243 Loss3: 0.1868\n",
            "2022-07-30 11:16:20.673739 Epoch [076/250], Step [0060/0060], Loss1: 0.2000 Loss2: 0.2222 Loss3: 0.1826\n",
            "Epoch: 76 MAE: 0.06775746961119315 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:16:26.357089 Epoch [077/250], Step [0001/0060], Loss1: 0.2168 Loss2: 0.2410 Loss3: 0.1956\n",
            "2022-07-30 11:17:06.742677 Epoch [077/250], Step [0050/0060], Loss1: 0.2041 Loss2: 0.2177 Loss3: 0.1849\n",
            "2022-07-30 11:17:14.982064 Epoch [077/250], Step [0060/0060], Loss1: 0.2006 Loss2: 0.2204 Loss3: 0.1793\n",
            "Epoch: 77 MAE: 0.0648701528518919 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:17:20.818479 Epoch [078/250], Step [0001/0060], Loss1: 0.2150 Loss2: 0.2440 Loss3: 0.1942\n",
            "2022-07-30 11:18:01.602228 Epoch [078/250], Step [0050/0060], Loss1: 0.2277 Loss2: 0.2416 Loss3: 0.2028\n",
            "2022-07-30 11:18:09.846857 Epoch [078/250], Step [0060/0060], Loss1: 0.2079 Loss2: 0.2295 Loss3: 0.1855\n",
            "Epoch: 78 MAE: 0.06755830971652238 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:18:15.487336 Epoch [079/250], Step [0001/0060], Loss1: 0.1986 Loss2: 0.2134 Loss3: 0.1783\n",
            "2022-07-30 11:18:55.979202 Epoch [079/250], Step [0050/0060], Loss1: 0.2150 Loss2: 0.2401 Loss3: 0.1938\n",
            "2022-07-30 11:19:04.229617 Epoch [079/250], Step [0060/0060], Loss1: 0.2108 Loss2: 0.2316 Loss3: 0.1909\n",
            "Epoch: 79 MAE: 0.0633911953275166 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:19:09.932244 Epoch [080/250], Step [0001/0060], Loss1: 0.2115 Loss2: 0.2275 Loss3: 0.1902\n",
            "2022-07-30 11:19:50.403131 Epoch [080/250], Step [0050/0060], Loss1: 0.2092 Loss2: 0.2257 Loss3: 0.1895\n",
            "2022-07-30 11:19:58.641158 Epoch [080/250], Step [0060/0060], Loss1: 0.2057 Loss2: 0.2300 Loss3: 0.1843\n",
            "Epoch: 80 MAE: 0.067196339450816 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:20:07.663881 Epoch [081/250], Step [0001/0060], Loss1: 0.2061 Loss2: 0.2222 Loss3: 0.1854\n",
            "2022-07-30 11:20:48.553945 Epoch [081/250], Step [0050/0060], Loss1: 0.1971 Loss2: 0.2148 Loss3: 0.1762\n",
            "2022-07-30 11:20:56.793291 Epoch [081/250], Step [0060/0060], Loss1: 0.2073 Loss2: 0.2186 Loss3: 0.1866\n",
            "Epoch: 81 MAE: 0.06717583156767346 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:21:02.505794 Epoch [082/250], Step [0001/0060], Loss1: 0.2164 Loss2: 0.2332 Loss3: 0.1941\n",
            "2022-07-30 11:21:42.902551 Epoch [082/250], Step [0050/0060], Loss1: 0.2112 Loss2: 0.2270 Loss3: 0.1893\n",
            "2022-07-30 11:21:51.147504 Epoch [082/250], Step [0060/0060], Loss1: 0.2011 Loss2: 0.2236 Loss3: 0.1793\n",
            "Epoch: 82 MAE: 0.0664805873991951 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:21:56.850309 Epoch [083/250], Step [0001/0060], Loss1: 0.2077 Loss2: 0.2233 Loss3: 0.1854\n",
            "2022-07-30 11:22:37.532396 Epoch [083/250], Step [0050/0060], Loss1: 0.2030 Loss2: 0.2244 Loss3: 0.1870\n",
            "2022-07-30 11:22:45.772580 Epoch [083/250], Step [0060/0060], Loss1: 0.2163 Loss2: 0.2387 Loss3: 0.1965\n",
            "Epoch: 83 MAE: 0.06614134541264287 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:22:51.411485 Epoch [084/250], Step [0001/0060], Loss1: 0.2124 Loss2: 0.2269 Loss3: 0.1901\n",
            "2022-07-30 11:23:31.874099 Epoch [084/250], Step [0050/0060], Loss1: 0.2071 Loss2: 0.2241 Loss3: 0.1850\n",
            "2022-07-30 11:23:40.112175 Epoch [084/250], Step [0060/0060], Loss1: 0.2017 Loss2: 0.2187 Loss3: 0.1804\n",
            "Epoch: 84 MAE: 0.0678199027328895 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:23:45.748253 Epoch [085/250], Step [0001/0060], Loss1: 0.2038 Loss2: 0.2183 Loss3: 0.1818\n",
            "2022-07-30 11:24:26.329181 Epoch [085/250], Step [0050/0060], Loss1: 0.1892 Loss2: 0.2044 Loss3: 0.1684\n",
            "2022-07-30 11:24:34.851928 Epoch [085/250], Step [0060/0060], Loss1: 0.2051 Loss2: 0.2251 Loss3: 0.1872\n",
            "Epoch: 85 MAE: 0.07253143663759586 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:24:42.802752 Epoch [086/250], Step [0001/0060], Loss1: 0.2181 Loss2: 0.2284 Loss3: 0.1908\n",
            "2022-07-30 11:25:23.251071 Epoch [086/250], Step [0050/0060], Loss1: 0.1968 Loss2: 0.2132 Loss3: 0.1729\n",
            "2022-07-30 11:25:31.483773 Epoch [086/250], Step [0060/0060], Loss1: 0.2221 Loss2: 0.2468 Loss3: 0.2001\n",
            "Epoch: 86 MAE: 0.0689066515019331 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:25:37.216161 Epoch [087/250], Step [0001/0060], Loss1: 0.2073 Loss2: 0.2238 Loss3: 0.1872\n",
            "2022-07-30 11:26:17.671196 Epoch [087/250], Step [0050/0060], Loss1: 0.2009 Loss2: 0.2246 Loss3: 0.1804\n",
            "2022-07-30 11:26:25.910245 Epoch [087/250], Step [0060/0060], Loss1: 0.2021 Loss2: 0.2164 Loss3: 0.1799\n",
            "Epoch: 87 MAE: 0.06767422534801341 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:26:31.633137 Epoch [088/250], Step [0001/0060], Loss1: 0.2062 Loss2: 0.2265 Loss3: 0.1880\n",
            "2022-07-30 11:27:12.641039 Epoch [088/250], Step [0050/0060], Loss1: 0.2117 Loss2: 0.2378 Loss3: 0.1904\n",
            "2022-07-30 11:27:20.895325 Epoch [088/250], Step [0060/0060], Loss1: 0.2131 Loss2: 0.2305 Loss3: 0.1898\n",
            "Epoch: 88 MAE: 0.06405838290219583 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:27:26.616403 Epoch [089/250], Step [0001/0060], Loss1: 0.2069 Loss2: 0.2202 Loss3: 0.1882\n",
            "2022-07-30 11:28:07.002066 Epoch [089/250], Step [0050/0060], Loss1: 0.1941 Loss2: 0.2064 Loss3: 0.1759\n",
            "2022-07-30 11:28:15.230790 Epoch [089/250], Step [0060/0060], Loss1: 0.1967 Loss2: 0.2180 Loss3: 0.1773\n",
            "Epoch: 89 MAE: 0.06847895551610876 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:28:20.894144 Epoch [090/250], Step [0001/0060], Loss1: 0.1981 Loss2: 0.2113 Loss3: 0.1783\n",
            "2022-07-30 11:29:01.810253 Epoch [090/250], Step [0050/0060], Loss1: 0.2090 Loss2: 0.2248 Loss3: 0.1858\n",
            "2022-07-30 11:29:10.042324 Epoch [090/250], Step [0060/0060], Loss1: 0.2174 Loss2: 0.2392 Loss3: 0.1934\n",
            "Epoch: 90 MAE: 0.06904837845494509 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:29:17.988305 Epoch [091/250], Step [0001/0060], Loss1: 0.2055 Loss2: 0.2285 Loss3: 0.1858\n",
            "2022-07-30 11:29:58.414052 Epoch [091/250], Step [0050/0060], Loss1: 0.2056 Loss2: 0.2263 Loss3: 0.1821\n",
            "2022-07-30 11:30:06.668314 Epoch [091/250], Step [0060/0060], Loss1: 0.1989 Loss2: 0.2115 Loss3: 0.1788\n",
            "Epoch: 91 MAE: 0.06864563805716375 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:30:12.218877 Epoch [092/250], Step [0001/0060], Loss1: 0.2134 Loss2: 0.2276 Loss3: 0.1910\n",
            "2022-07-30 11:30:52.588593 Epoch [092/250], Step [0050/0060], Loss1: 0.2034 Loss2: 0.2260 Loss3: 0.1801\n",
            "2022-07-30 11:31:00.879665 Epoch [092/250], Step [0060/0060], Loss1: 0.2050 Loss2: 0.2199 Loss3: 0.1845\n",
            "Epoch: 92 MAE: 0.06945919203379798 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:31:08.231285 Epoch [093/250], Step [0001/0060], Loss1: 0.2133 Loss2: 0.2362 Loss3: 0.1900\n",
            "2022-07-30 11:31:48.923797 Epoch [093/250], Step [0050/0060], Loss1: 0.2018 Loss2: 0.2101 Loss3: 0.1808\n",
            "2022-07-30 11:31:57.156541 Epoch [093/250], Step [0060/0060], Loss1: 0.2304 Loss2: 0.2578 Loss3: 0.2021\n",
            "Epoch: 93 MAE: 0.07036338089635134 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:32:02.727791 Epoch [094/250], Step [0001/0060], Loss1: 0.1995 Loss2: 0.2094 Loss3: 0.1803\n",
            "2022-07-30 11:32:43.163461 Epoch [094/250], Step [0050/0060], Loss1: 0.2105 Loss2: 0.2228 Loss3: 0.1912\n",
            "2022-07-30 11:32:51.397733 Epoch [094/250], Step [0060/0060], Loss1: 0.2111 Loss2: 0.2309 Loss3: 0.1886\n",
            "Epoch: 94 MAE: 0.0686941974377506 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:32:57.106921 Epoch [095/250], Step [0001/0060], Loss1: 0.2124 Loss2: 0.2264 Loss3: 0.1879\n",
            "2022-07-30 11:33:37.798823 Epoch [095/250], Step [0050/0060], Loss1: 0.2073 Loss2: 0.2151 Loss3: 0.1853\n",
            "2022-07-30 11:33:46.035737 Epoch [095/250], Step [0060/0060], Loss1: 0.2029 Loss2: 0.2154 Loss3: 0.1811\n",
            "Epoch: 95 MAE: 0.06740969859733782 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:33:54.207014 Epoch [096/250], Step [0001/0060], Loss1: 0.2078 Loss2: 0.2197 Loss3: 0.1857\n",
            "2022-07-30 11:34:34.667969 Epoch [096/250], Step [0050/0060], Loss1: 0.2108 Loss2: 0.2252 Loss3: 0.1885\n",
            "2022-07-30 11:34:42.906966 Epoch [096/250], Step [0060/0060], Loss1: 0.2141 Loss2: 0.2173 Loss3: 0.1897\n",
            "Epoch: 96 MAE: 0.06408838716133562 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:34:48.679247 Epoch [097/250], Step [0001/0060], Loss1: 0.2051 Loss2: 0.2181 Loss3: 0.1839\n",
            "2022-07-30 11:35:29.518918 Epoch [097/250], Step [0050/0060], Loss1: 0.2072 Loss2: 0.2186 Loss3: 0.1834\n",
            "2022-07-30 11:35:38.004922 Epoch [097/250], Step [0060/0060], Loss1: 0.2095 Loss2: 0.2263 Loss3: 0.1881\n",
            "Epoch: 97 MAE: 0.06832435850113155 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:35:43.999823 Epoch [098/250], Step [0001/0060], Loss1: 0.2085 Loss2: 0.2315 Loss3: 0.1873\n",
            "2022-07-30 11:36:24.407161 Epoch [098/250], Step [0050/0060], Loss1: 0.2048 Loss2: 0.2246 Loss3: 0.1843\n",
            "2022-07-30 11:36:32.641676 Epoch [098/250], Step [0060/0060], Loss1: 0.2076 Loss2: 0.2307 Loss3: 0.1893\n",
            "Epoch: 98 MAE: 0.07051324107659555 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:36:38.432688 Epoch [099/250], Step [0001/0060], Loss1: 0.2222 Loss2: 0.2369 Loss3: 0.1949\n",
            "2022-07-30 11:37:18.811479 Epoch [099/250], Step [0050/0060], Loss1: 0.2093 Loss2: 0.2317 Loss3: 0.1899\n",
            "2022-07-30 11:37:27.046666 Epoch [099/250], Step [0060/0060], Loss1: 0.2064 Loss2: 0.2174 Loss3: 0.1830\n",
            "Epoch: 99 MAE: 0.06905896736831264 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:37:32.846827 Epoch [100/250], Step [0001/0060], Loss1: 0.2094 Loss2: 0.2254 Loss3: 0.1860\n",
            "2022-07-30 11:38:13.574864 Epoch [100/250], Step [0050/0060], Loss1: 0.2056 Loss2: 0.2227 Loss3: 0.1840\n",
            "2022-07-30 11:38:21.815603 Epoch [100/250], Step [0060/0060], Loss1: 0.2129 Loss2: 0.2317 Loss3: 0.1876\n",
            "Epoch: 100 MAE: 0.067792318838614 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:38:30.563824 Epoch [101/250], Step [0001/0060], Loss1: 0.1979 Loss2: 0.2148 Loss3: 0.1773\n",
            "2022-07-30 11:39:11.011309 Epoch [101/250], Step [0050/0060], Loss1: 0.1967 Loss2: 0.2147 Loss3: 0.1770\n",
            "2022-07-30 11:39:19.268155 Epoch [101/250], Step [0060/0060], Loss1: 0.2005 Loss2: 0.2176 Loss3: 0.1771\n",
            "Epoch: 101 MAE: 0.06805554102337551 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:39:25.047655 Epoch [102/250], Step [0001/0060], Loss1: 0.2076 Loss2: 0.2234 Loss3: 0.1845\n",
            "2022-07-30 11:40:06.185236 Epoch [102/250], Step [0050/0060], Loss1: 0.2066 Loss2: 0.2178 Loss3: 0.1843\n",
            "2022-07-30 11:40:14.416707 Epoch [102/250], Step [0060/0060], Loss1: 0.2093 Loss2: 0.2272 Loss3: 0.1859\n",
            "Epoch: 102 MAE: 0.06872525850931802 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:40:20.208455 Epoch [103/250], Step [0001/0060], Loss1: 0.1970 Loss2: 0.2105 Loss3: 0.1747\n",
            "2022-07-30 11:41:00.596554 Epoch [103/250], Step [0050/0060], Loss1: 0.1971 Loss2: 0.2193 Loss3: 0.1802\n",
            "2022-07-30 11:41:08.833900 Epoch [103/250], Step [0060/0060], Loss1: 0.2091 Loss2: 0.2226 Loss3: 0.1875\n",
            "Epoch: 103 MAE: 0.06945604324340822 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:41:14.475329 Epoch [104/250], Step [0001/0060], Loss1: 0.2058 Loss2: 0.2292 Loss3: 0.1835\n",
            "2022-07-30 11:41:54.894088 Epoch [104/250], Step [0050/0060], Loss1: 0.2114 Loss2: 0.2357 Loss3: 0.1886\n",
            "2022-07-30 11:42:03.258847 Epoch [104/250], Step [0060/0060], Loss1: 0.1977 Loss2: 0.2142 Loss3: 0.1785\n",
            "Epoch: 104 MAE: 0.06676663010208694 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:42:10.130503 Epoch [105/250], Step [0001/0060], Loss1: 0.2015 Loss2: 0.2226 Loss3: 0.1820\n",
            "2022-07-30 11:42:50.571170 Epoch [105/250], Step [0050/0060], Loss1: 0.2117 Loss2: 0.2314 Loss3: 0.1912\n",
            "2022-07-30 11:42:58.808897 Epoch [105/250], Step [0060/0060], Loss1: 0.1904 Loss2: 0.2140 Loss3: 0.1723\n",
            "Epoch: 105 MAE: 0.06877424699288828 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:43:08.322402 Epoch [106/250], Step [0001/0060], Loss1: 0.1991 Loss2: 0.2312 Loss3: 0.1804\n",
            "2022-07-30 11:43:48.830865 Epoch [106/250], Step [0050/0060], Loss1: 0.1930 Loss2: 0.2134 Loss3: 0.1761\n",
            "2022-07-30 11:43:57.063975 Epoch [106/250], Step [0060/0060], Loss1: 0.2033 Loss2: 0.2212 Loss3: 0.1837\n",
            "Epoch: 106 MAE: 0.0677155640011742 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:44:02.803513 Epoch [107/250], Step [0001/0060], Loss1: 0.1965 Loss2: 0.2150 Loss3: 0.1751\n",
            "2022-07-30 11:44:44.060653 Epoch [107/250], Step [0050/0060], Loss1: 0.1993 Loss2: 0.2176 Loss3: 0.1816\n",
            "2022-07-30 11:44:52.291577 Epoch [107/250], Step [0060/0060], Loss1: 0.2233 Loss2: 0.2451 Loss3: 0.2002\n",
            "Epoch: 107 MAE: 0.07216161223315687 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:44:58.028848 Epoch [108/250], Step [0001/0060], Loss1: 0.2011 Loss2: 0.2118 Loss3: 0.1796\n",
            "2022-07-30 11:45:38.446184 Epoch [108/250], Step [0050/0060], Loss1: 0.1995 Loss2: 0.2096 Loss3: 0.1772\n",
            "2022-07-30 11:45:46.677723 Epoch [108/250], Step [0060/0060], Loss1: 0.2029 Loss2: 0.2319 Loss3: 0.1795\n",
            "Epoch: 108 MAE: 0.0719261848106586 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:45:52.371690 Epoch [109/250], Step [0001/0060], Loss1: 0.2081 Loss2: 0.2299 Loss3: 0.1888\n",
            "2022-07-30 11:46:33.279527 Epoch [109/250], Step [0050/0060], Loss1: 0.2015 Loss2: 0.2119 Loss3: 0.1790\n",
            "2022-07-30 11:46:41.508803 Epoch [109/250], Step [0060/0060], Loss1: 0.1991 Loss2: 0.2131 Loss3: 0.1764\n",
            "Epoch: 109 MAE: 0.07192069951819363 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:46:47.233811 Epoch [110/250], Step [0001/0060], Loss1: 0.2019 Loss2: 0.2165 Loss3: 0.1804\n",
            "2022-07-30 11:47:27.697562 Epoch [110/250], Step [0050/0060], Loss1: 0.2029 Loss2: 0.2195 Loss3: 0.1803\n",
            "2022-07-30 11:47:35.950900 Epoch [110/250], Step [0060/0060], Loss1: 0.2130 Loss2: 0.2342 Loss3: 0.1860\n",
            "Epoch: 110 MAE: 0.06692197976288973 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:47:43.882955 Epoch [111/250], Step [0001/0060], Loss1: 0.1929 Loss2: 0.2053 Loss3: 0.1721\n",
            "2022-07-30 11:48:24.331539 Epoch [111/250], Step [0050/0060], Loss1: 0.2137 Loss2: 0.2346 Loss3: 0.1963\n",
            "2022-07-30 11:48:32.584706 Epoch [111/250], Step [0060/0060], Loss1: 0.2029 Loss2: 0.2180 Loss3: 0.1833\n",
            "Epoch: 111 MAE: 0.06946543870148836 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:48:38.595448 Epoch [112/250], Step [0001/0060], Loss1: 0.2013 Loss2: 0.2179 Loss3: 0.1801\n",
            "2022-07-30 11:49:19.778732 Epoch [112/250], Step [0050/0060], Loss1: 0.2070 Loss2: 0.2230 Loss3: 0.1838\n",
            "2022-07-30 11:49:28.020331 Epoch [112/250], Step [0060/0060], Loss1: 0.2178 Loss2: 0.2334 Loss3: 0.1942\n",
            "Epoch: 112 MAE: 0.06896315998501247 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:49:33.742109 Epoch [113/250], Step [0001/0060], Loss1: 0.2035 Loss2: 0.2125 Loss3: 0.1814\n",
            "2022-07-30 11:50:14.200459 Epoch [113/250], Step [0050/0060], Loss1: 0.2036 Loss2: 0.2176 Loss3: 0.1808\n",
            "2022-07-30 11:50:22.490097 Epoch [113/250], Step [0060/0060], Loss1: 0.2053 Loss2: 0.2228 Loss3: 0.1829\n",
            "Epoch: 113 MAE: 0.06764171337955213 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:50:28.232476 Epoch [114/250], Step [0001/0060], Loss1: 0.2022 Loss2: 0.2175 Loss3: 0.1826\n",
            "2022-07-30 11:51:08.984191 Epoch [114/250], Step [0050/0060], Loss1: 0.2141 Loss2: 0.2319 Loss3: 0.1907\n",
            "2022-07-30 11:51:17.232249 Epoch [114/250], Step [0060/0060], Loss1: 0.2028 Loss2: 0.2198 Loss3: 0.1799\n",
            "Epoch: 114 MAE: 0.06564131474368787 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:51:22.990904 Epoch [115/250], Step [0001/0060], Loss1: 0.2249 Loss2: 0.2374 Loss3: 0.1963\n",
            "2022-07-30 11:52:03.441153 Epoch [115/250], Step [0050/0060], Loss1: 0.2040 Loss2: 0.2216 Loss3: 0.1811\n",
            "2022-07-30 11:52:11.671833 Epoch [115/250], Step [0060/0060], Loss1: 0.1974 Loss2: 0.2147 Loss3: 0.1761\n",
            "Epoch: 115 MAE: 0.07026125660649052 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:52:19.827326 Epoch [116/250], Step [0001/0060], Loss1: 0.2096 Loss2: 0.2270 Loss3: 0.1848\n",
            "2022-07-30 11:53:00.223718 Epoch [116/250], Step [0050/0060], Loss1: 0.2018 Loss2: 0.2145 Loss3: 0.1820\n",
            "2022-07-30 11:53:08.630321 Epoch [116/250], Step [0060/0060], Loss1: 0.2086 Loss2: 0.2268 Loss3: 0.1846\n",
            "Epoch: 116 MAE: 0.06488448198510226 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:53:15.968288 Epoch [117/250], Step [0001/0060], Loss1: 0.1994 Loss2: 0.2141 Loss3: 0.1771\n",
            "2022-07-30 11:53:56.484862 Epoch [117/250], Step [0050/0060], Loss1: 0.2049 Loss2: 0.2197 Loss3: 0.1831\n",
            "2022-07-30 11:54:04.721210 Epoch [117/250], Step [0060/0060], Loss1: 0.1970 Loss2: 0.2167 Loss3: 0.1786\n",
            "Epoch: 117 MAE: 0.06515344483511788 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:54:10.566883 Epoch [118/250], Step [0001/0060], Loss1: 0.2016 Loss2: 0.2154 Loss3: 0.1795\n",
            "2022-07-30 11:54:50.996982 Epoch [118/250], Step [0050/0060], Loss1: 0.2066 Loss2: 0.2235 Loss3: 0.1873\n",
            "2022-07-30 11:54:59.238703 Epoch [118/250], Step [0060/0060], Loss1: 0.2151 Loss2: 0.2215 Loss3: 0.1906\n",
            "Epoch: 118 MAE: 0.06814806751473239 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:55:05.004495 Epoch [119/250], Step [0001/0060], Loss1: 0.2051 Loss2: 0.2196 Loss3: 0.1823\n",
            "2022-07-30 11:55:45.882703 Epoch [119/250], Step [0050/0060], Loss1: 0.1989 Loss2: 0.2151 Loss3: 0.1772\n",
            "2022-07-30 11:55:54.121687 Epoch [119/250], Step [0060/0060], Loss1: 0.2107 Loss2: 0.2271 Loss3: 0.1889\n",
            "Epoch: 119 MAE: 0.0658126673622737 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:55:59.844724 Epoch [120/250], Step [0001/0060], Loss1: 0.2035 Loss2: 0.2244 Loss3: 0.1820\n",
            "2022-07-30 11:56:40.243506 Epoch [120/250], Step [0050/0060], Loss1: 0.2044 Loss2: 0.2237 Loss3: 0.1831\n",
            "2022-07-30 11:56:48.491637 Epoch [120/250], Step [0060/0060], Loss1: 0.2109 Loss2: 0.2314 Loss3: 0.1870\n",
            "Epoch: 120 MAE: 0.06838952735618309 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:56:57.126280 Epoch [121/250], Step [0001/0060], Loss1: 0.1999 Loss2: 0.2196 Loss3: 0.1771\n",
            "2022-07-30 11:57:38.109398 Epoch [121/250], Step [0050/0060], Loss1: 0.2122 Loss2: 0.2326 Loss3: 0.1872\n",
            "2022-07-30 11:57:46.681644 Epoch [121/250], Step [0060/0060], Loss1: 0.2057 Loss2: 0.2265 Loss3: 0.1886\n",
            "Epoch: 121 MAE: 0.06934804078763122 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:57:52.466642 Epoch [122/250], Step [0001/0060], Loss1: 0.2031 Loss2: 0.2174 Loss3: 0.1797\n",
            "2022-07-30 11:58:32.982157 Epoch [122/250], Step [0050/0060], Loss1: 0.2173 Loss2: 0.2358 Loss3: 0.1910\n",
            "2022-07-30 11:58:41.234229 Epoch [122/250], Step [0060/0060], Loss1: 0.2085 Loss2: 0.2272 Loss3: 0.1874\n",
            "Epoch: 122 MAE: 0.06613400529932092 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:58:47.059023 Epoch [123/250], Step [0001/0060], Loss1: 0.2131 Loss2: 0.2276 Loss3: 0.1885\n",
            "2022-07-30 11:59:27.526601 Epoch [123/250], Step [0050/0060], Loss1: 0.2089 Loss2: 0.2263 Loss3: 0.1853\n",
            "2022-07-30 11:59:35.788313 Epoch [123/250], Step [0060/0060], Loss1: 0.2142 Loss2: 0.2327 Loss3: 0.1915\n",
            "Epoch: 123 MAE: 0.06752229993305506 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 11:59:41.615550 Epoch [124/250], Step [0001/0060], Loss1: 0.2093 Loss2: 0.2254 Loss3: 0.1836\n",
            "2022-07-30 12:00:22.435976 Epoch [124/250], Step [0050/0060], Loss1: 0.2003 Loss2: 0.2174 Loss3: 0.1793\n",
            "2022-07-30 12:00:30.697631 Epoch [124/250], Step [0060/0060], Loss1: 0.2178 Loss2: 0.2357 Loss3: 0.1931\n",
            "Epoch: 124 MAE: 0.06465022415080399 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:00:36.605279 Epoch [125/250], Step [0001/0060], Loss1: 0.2035 Loss2: 0.2214 Loss3: 0.1819\n",
            "2022-07-30 12:01:17.141872 Epoch [125/250], Step [0050/0060], Loss1: 0.1916 Loss2: 0.2066 Loss3: 0.1706\n",
            "2022-07-30 12:01:25.384638 Epoch [125/250], Step [0060/0060], Loss1: 0.2138 Loss2: 0.2327 Loss3: 0.1894\n",
            "Epoch: 125 MAE: 0.0683669875412391 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:01:33.630838 Epoch [126/250], Step [0001/0060], Loss1: 0.1946 Loss2: 0.2092 Loss3: 0.1745\n",
            "2022-07-30 12:02:15.195926 Epoch [126/250], Step [0050/0060], Loss1: 0.1968 Loss2: 0.2106 Loss3: 0.1759\n",
            "2022-07-30 12:02:23.454323 Epoch [126/250], Step [0060/0060], Loss1: 0.2008 Loss2: 0.2130 Loss3: 0.1809\n",
            "Epoch: 126 MAE: 0.0666689694116986 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:02:29.370851 Epoch [127/250], Step [0001/0060], Loss1: 0.2085 Loss2: 0.2303 Loss3: 0.1856\n",
            "2022-07-30 12:03:09.851454 Epoch [127/250], Step [0050/0060], Loss1: 0.1921 Loss2: 0.2244 Loss3: 0.1727\n",
            "2022-07-30 12:03:18.087707 Epoch [127/250], Step [0060/0060], Loss1: 0.1910 Loss2: 0.2020 Loss3: 0.1684\n",
            "Epoch: 127 MAE: 0.06544920512608121 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:03:23.886039 Epoch [128/250], Step [0001/0060], Loss1: 0.2089 Loss2: 0.2224 Loss3: 0.1872\n",
            "2022-07-30 12:04:04.379312 Epoch [128/250], Step [0050/0060], Loss1: 0.2077 Loss2: 0.2248 Loss3: 0.1832\n",
            "2022-07-30 12:04:12.617806 Epoch [128/250], Step [0060/0060], Loss1: 0.2154 Loss2: 0.2286 Loss3: 0.1928\n",
            "Epoch: 128 MAE: 0.06802752010406006 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:04:19.207528 Epoch [129/250], Step [0001/0060], Loss1: 0.1932 Loss2: 0.2154 Loss3: 0.1744\n",
            "2022-07-30 12:04:59.715347 Epoch [129/250], Step [0050/0060], Loss1: 0.2081 Loss2: 0.2344 Loss3: 0.1881\n",
            "2022-07-30 12:05:07.961402 Epoch [129/250], Step [0060/0060], Loss1: 0.2039 Loss2: 0.2218 Loss3: 0.1805\n",
            "Epoch: 129 MAE: 0.0671771645419812 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:05:13.807615 Epoch [130/250], Step [0001/0060], Loss1: 0.1976 Loss2: 0.2174 Loss3: 0.1783\n",
            "2022-07-30 12:05:54.308131 Epoch [130/250], Step [0050/0060], Loss1: 0.2142 Loss2: 0.2256 Loss3: 0.1912\n",
            "2022-07-30 12:06:02.555265 Epoch [130/250], Step [0060/0060], Loss1: 0.2146 Loss2: 0.2393 Loss3: 0.1905\n",
            "Epoch: 130 MAE: 0.06835115457968739 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:06:10.708636 Epoch [131/250], Step [0001/0060], Loss1: 0.2105 Loss2: 0.2275 Loss3: 0.1851\n",
            "2022-07-30 12:06:52.064322 Epoch [131/250], Step [0050/0060], Loss1: 0.2037 Loss2: 0.2279 Loss3: 0.1827\n",
            "2022-07-30 12:07:00.332934 Epoch [131/250], Step [0060/0060], Loss1: 0.2109 Loss2: 0.2213 Loss3: 0.1866\n",
            "Epoch: 131 MAE: 0.06822092061320308 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:07:06.159470 Epoch [132/250], Step [0001/0060], Loss1: 0.2033 Loss2: 0.2176 Loss3: 0.1812\n",
            "2022-07-30 12:07:46.624500 Epoch [132/250], Step [0050/0060], Loss1: 0.2192 Loss2: 0.2413 Loss3: 0.1938\n",
            "2022-07-30 12:07:54.863130 Epoch [132/250], Step [0060/0060], Loss1: 0.1931 Loss2: 0.2018 Loss3: 0.1725\n",
            "Epoch: 132 MAE: 0.06957723329937647 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:08:00.705037 Epoch [133/250], Step [0001/0060], Loss1: 0.2030 Loss2: 0.2188 Loss3: 0.1823\n",
            "2022-07-30 12:08:41.366051 Epoch [133/250], Step [0050/0060], Loss1: 0.2170 Loss2: 0.2346 Loss3: 0.1912\n",
            "2022-07-30 12:08:49.816256 Epoch [133/250], Step [0060/0060], Loss1: 0.1899 Loss2: 0.1996 Loss3: 0.1661\n",
            "Epoch: 133 MAE: 0.0679792133714787 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:08:55.655789 Epoch [134/250], Step [0001/0060], Loss1: 0.1935 Loss2: 0.2094 Loss3: 0.1713\n",
            "2022-07-30 12:09:36.190976 Epoch [134/250], Step [0050/0060], Loss1: 0.2031 Loss2: 0.2149 Loss3: 0.1796\n",
            "2022-07-30 12:09:44.446625 Epoch [134/250], Step [0060/0060], Loss1: 0.2164 Loss2: 0.2306 Loss3: 0.1962\n",
            "Epoch: 134 MAE: 0.06504769976176915 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:09:50.339560 Epoch [135/250], Step [0001/0060], Loss1: 0.2038 Loss2: 0.2169 Loss3: 0.1810\n",
            "2022-07-30 12:10:30.822435 Epoch [135/250], Step [0050/0060], Loss1: 0.2024 Loss2: 0.2236 Loss3: 0.1767\n",
            "2022-07-30 12:10:39.072037 Epoch [135/250], Step [0060/0060], Loss1: 0.2034 Loss2: 0.2218 Loss3: 0.1832\n",
            "Epoch: 135 MAE: 0.06767944679058417 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:10:47.259025 Epoch [136/250], Step [0001/0060], Loss1: 0.2025 Loss2: 0.2190 Loss3: 0.1817\n",
            "2022-07-30 12:11:28.388076 Epoch [136/250], Step [0050/0060], Loss1: 0.2069 Loss2: 0.2207 Loss3: 0.1853\n",
            "2022-07-30 12:11:36.635302 Epoch [136/250], Step [0060/0060], Loss1: 0.2119 Loss2: 0.2405 Loss3: 0.1909\n",
            "Epoch: 136 MAE: 0.0671466895512172 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:11:42.522836 Epoch [137/250], Step [0001/0060], Loss1: 0.2027 Loss2: 0.2159 Loss3: 0.1809\n",
            "2022-07-30 12:12:23.025089 Epoch [137/250], Step [0050/0060], Loss1: 0.1968 Loss2: 0.2060 Loss3: 0.1766\n",
            "2022-07-30 12:12:31.271021 Epoch [137/250], Step [0060/0060], Loss1: 0.2105 Loss2: 0.2258 Loss3: 0.1860\n",
            "Epoch: 137 MAE: 0.0662157548167718 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:12:37.376126 Epoch [138/250], Step [0001/0060], Loss1: 0.2027 Loss2: 0.2117 Loss3: 0.1785\n",
            "2022-07-30 12:13:18.060825 Epoch [138/250], Step [0050/0060], Loss1: 0.2070 Loss2: 0.2294 Loss3: 0.1846\n",
            "2022-07-30 12:13:26.317961 Epoch [138/250], Step [0060/0060], Loss1: 0.2005 Loss2: 0.2265 Loss3: 0.1800\n",
            "Epoch: 138 MAE: 0.067889466361394 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:13:32.153813 Epoch [139/250], Step [0001/0060], Loss1: 0.2058 Loss2: 0.2281 Loss3: 0.1849\n",
            "2022-07-30 12:14:12.620297 Epoch [139/250], Step [0050/0060], Loss1: 0.2046 Loss2: 0.2224 Loss3: 0.1844\n",
            "2022-07-30 12:14:20.871420 Epoch [139/250], Step [0060/0060], Loss1: 0.1931 Loss2: 0.2123 Loss3: 0.1720\n",
            "Epoch: 139 MAE: 0.06861688795543852 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:14:26.777448 Epoch [140/250], Step [0001/0060], Loss1: 0.2022 Loss2: 0.2178 Loss3: 0.1796\n",
            "2022-07-30 12:15:07.242598 Epoch [140/250], Step [0050/0060], Loss1: 0.1953 Loss2: 0.2079 Loss3: 0.1725\n",
            "2022-07-30 12:15:15.886009 Epoch [140/250], Step [0060/0060], Loss1: 0.2041 Loss2: 0.2175 Loss3: 0.1814\n",
            "Epoch: 140 MAE: 0.06631200058750374 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:15:25.479643 Epoch [141/250], Step [0001/0060], Loss1: 0.2064 Loss2: 0.2252 Loss3: 0.1843\n",
            "2022-07-30 12:16:05.973244 Epoch [141/250], Step [0050/0060], Loss1: 0.2106 Loss2: 0.2349 Loss3: 0.1886\n",
            "2022-07-30 12:16:14.216339 Epoch [141/250], Step [0060/0060], Loss1: 0.2061 Loss2: 0.2279 Loss3: 0.1838\n",
            "Epoch: 141 MAE: 0.06739215447158409 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:16:19.915080 Epoch [142/250], Step [0001/0060], Loss1: 0.2034 Loss2: 0.2219 Loss3: 0.1808\n",
            "2022-07-30 12:17:00.379446 Epoch [142/250], Step [0050/0060], Loss1: 0.1992 Loss2: 0.2189 Loss3: 0.1736\n",
            "2022-07-30 12:17:08.629434 Epoch [142/250], Step [0060/0060], Loss1: 0.1999 Loss2: 0.2132 Loss3: 0.1789\n",
            "Epoch: 142 MAE: 0.06777229097154407 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:17:14.355437 Epoch [143/250], Step [0001/0060], Loss1: 0.2121 Loss2: 0.2180 Loss3: 0.1831\n",
            "2022-07-30 12:17:55.944522 Epoch [143/250], Step [0050/0060], Loss1: 0.1971 Loss2: 0.2164 Loss3: 0.1737\n",
            "2022-07-30 12:18:04.184921 Epoch [143/250], Step [0060/0060], Loss1: 0.2055 Loss2: 0.2261 Loss3: 0.1835\n",
            "Epoch: 143 MAE: 0.06860583855361538 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:18:09.841424 Epoch [144/250], Step [0001/0060], Loss1: 0.2103 Loss2: 0.2282 Loss3: 0.1893\n",
            "2022-07-30 12:18:50.313291 Epoch [144/250], Step [0050/0060], Loss1: 0.2176 Loss2: 0.2442 Loss3: 0.1961\n",
            "2022-07-30 12:18:58.579783 Epoch [144/250], Step [0060/0060], Loss1: 0.2049 Loss2: 0.2223 Loss3: 0.1824\n",
            "Epoch: 144 MAE: 0.06834654782814956 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:19:04.427187 Epoch [145/250], Step [0001/0060], Loss1: 0.2065 Loss2: 0.2235 Loss3: 0.1851\n",
            "2022-07-30 12:19:44.990205 Epoch [145/250], Step [0050/0060], Loss1: 0.2018 Loss2: 0.2236 Loss3: 0.1807\n",
            "2022-07-30 12:19:53.245959 Epoch [145/250], Step [0060/0060], Loss1: 0.1987 Loss2: 0.2063 Loss3: 0.1764\n",
            "Epoch: 145 MAE: 0.06531055102272638 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:20:01.289723 Epoch [146/250], Step [0001/0060], Loss1: 0.1885 Loss2: 0.2073 Loss3: 0.1658\n",
            "2022-07-30 12:20:41.698024 Epoch [146/250], Step [0050/0060], Loss1: 0.2066 Loss2: 0.2261 Loss3: 0.1854\n",
            "2022-07-30 12:20:49.934854 Epoch [146/250], Step [0060/0060], Loss1: 0.2043 Loss2: 0.2205 Loss3: 0.1827\n",
            "Epoch: 146 MAE: 0.06715099773709735 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:20:55.757947 Epoch [147/250], Step [0001/0060], Loss1: 0.2194 Loss2: 0.2425 Loss3: 0.1971\n",
            "2022-07-30 12:21:36.273131 Epoch [147/250], Step [0050/0060], Loss1: 0.2107 Loss2: 0.2374 Loss3: 0.1861\n",
            "2022-07-30 12:21:44.510918 Epoch [147/250], Step [0060/0060], Loss1: 0.2044 Loss2: 0.2140 Loss3: 0.1815\n",
            "Epoch: 147 MAE: 0.06797652315210413 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:21:52.003693 Epoch [148/250], Step [0001/0060], Loss1: 0.2078 Loss2: 0.2279 Loss3: 0.1827\n",
            "2022-07-30 12:22:32.848227 Epoch [148/250], Step [0050/0060], Loss1: 0.2047 Loss2: 0.2208 Loss3: 0.1798\n",
            "2022-07-30 12:22:41.118360 Epoch [148/250], Step [0060/0060], Loss1: 0.2038 Loss2: 0.2243 Loss3: 0.1815\n",
            "Epoch: 148 MAE: 0.06863265178821706 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:22:46.929833 Epoch [149/250], Step [0001/0060], Loss1: 0.2078 Loss2: 0.2289 Loss3: 0.1893\n",
            "2022-07-30 12:23:27.383113 Epoch [149/250], Step [0050/0060], Loss1: 0.1969 Loss2: 0.2090 Loss3: 0.1731\n",
            "2022-07-30 12:23:35.624290 Epoch [149/250], Step [0060/0060], Loss1: 0.2026 Loss2: 0.2157 Loss3: 0.1815\n",
            "Epoch: 149 MAE: 0.06841346241178967 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:23:41.441919 Epoch [150/250], Step [0001/0060], Loss1: 0.2063 Loss2: 0.2256 Loss3: 0.1842\n",
            "2022-07-30 12:24:22.498505 Epoch [150/250], Step [0050/0060], Loss1: 0.2090 Loss2: 0.2288 Loss3: 0.1877\n",
            "2022-07-30 12:24:30.751344 Epoch [150/250], Step [0060/0060], Loss1: 0.2040 Loss2: 0.2262 Loss3: 0.1835\n",
            "Epoch: 150 MAE: 0.06958236129195604 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:24:38.945202 Epoch [151/250], Step [0001/0060], Loss1: 0.2124 Loss2: 0.2213 Loss3: 0.1877\n",
            "2022-07-30 12:25:19.479691 Epoch [151/250], Step [0050/0060], Loss1: 0.2128 Loss2: 0.2368 Loss3: 0.1868\n",
            "2022-07-30 12:25:27.724025 Epoch [151/250], Step [0060/0060], Loss1: 0.2139 Loss2: 0.2219 Loss3: 0.1888\n",
            "Epoch: 151 MAE: 0.06552838047976216 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:25:33.713647 Epoch [152/250], Step [0001/0060], Loss1: 0.2114 Loss2: 0.2301 Loss3: 0.1881\n",
            "2022-07-30 12:26:14.502404 Epoch [152/250], Step [0050/0060], Loss1: 0.1977 Loss2: 0.2135 Loss3: 0.1759\n",
            "2022-07-30 12:26:23.268633 Epoch [152/250], Step [0060/0060], Loss1: 0.2003 Loss2: 0.2148 Loss3: 0.1794\n",
            "Epoch: 152 MAE: 0.06984165105870162 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:26:29.151744 Epoch [153/250], Step [0001/0060], Loss1: 0.2145 Loss2: 0.2360 Loss3: 0.1913\n",
            "2022-07-30 12:27:09.582663 Epoch [153/250], Step [0050/0060], Loss1: 0.2093 Loss2: 0.2310 Loss3: 0.1886\n",
            "2022-07-30 12:27:17.821964 Epoch [153/250], Step [0060/0060], Loss1: 0.2151 Loss2: 0.2330 Loss3: 0.1922\n",
            "Epoch: 153 MAE: 0.06631064051673527 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:27:23.677297 Epoch [154/250], Step [0001/0060], Loss1: 0.1989 Loss2: 0.2128 Loss3: 0.1754\n",
            "2022-07-30 12:28:04.134887 Epoch [154/250], Step [0050/0060], Loss1: 0.2057 Loss2: 0.2187 Loss3: 0.1815\n",
            "2022-07-30 12:28:12.380499 Epoch [154/250], Step [0060/0060], Loss1: 0.2041 Loss2: 0.2188 Loss3: 0.1813\n",
            "Epoch: 154 MAE: 0.06997802996761586 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:28:18.332866 Epoch [155/250], Step [0001/0060], Loss1: 0.1973 Loss2: 0.2098 Loss3: 0.1745\n",
            "2022-07-30 12:28:59.453539 Epoch [155/250], Step [0050/0060], Loss1: 0.2056 Loss2: 0.2189 Loss3: 0.1805\n",
            "2022-07-30 12:29:07.768518 Epoch [155/250], Step [0060/0060], Loss1: 0.2088 Loss2: 0.2303 Loss3: 0.1843\n",
            "Epoch: 155 MAE: 0.06699745314461843 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:29:16.187647 Epoch [156/250], Step [0001/0060], Loss1: 0.2128 Loss2: 0.2350 Loss3: 0.1877\n",
            "2022-07-30 12:29:56.658966 Epoch [156/250], Step [0050/0060], Loss1: 0.2028 Loss2: 0.2313 Loss3: 0.1858\n",
            "2022-07-30 12:30:04.898308 Epoch [156/250], Step [0060/0060], Loss1: 0.1934 Loss2: 0.2077 Loss3: 0.1732\n",
            "Epoch: 156 MAE: 0.06736381389476635 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:30:10.724293 Epoch [157/250], Step [0001/0060], Loss1: 0.2132 Loss2: 0.2209 Loss3: 0.1877\n",
            "2022-07-30 12:30:52.131475 Epoch [157/250], Step [0050/0060], Loss1: 0.1937 Loss2: 0.2119 Loss3: 0.1747\n",
            "2022-07-30 12:31:00.384967 Epoch [157/250], Step [0060/0060], Loss1: 0.2055 Loss2: 0.2243 Loss3: 0.1827\n",
            "Epoch: 157 MAE: 0.06845346168235497 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:31:06.238672 Epoch [158/250], Step [0001/0060], Loss1: 0.2146 Loss2: 0.2425 Loss3: 0.1916\n",
            "2022-07-30 12:31:46.704356 Epoch [158/250], Step [0050/0060], Loss1: 0.2015 Loss2: 0.2178 Loss3: 0.1805\n",
            "2022-07-30 12:31:54.951745 Epoch [158/250], Step [0060/0060], Loss1: 0.2062 Loss2: 0.2217 Loss3: 0.1841\n",
            "Epoch: 158 MAE: 0.06845381595470287 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:32:00.960536 Epoch [159/250], Step [0001/0060], Loss1: 0.1959 Loss2: 0.2157 Loss3: 0.1777\n",
            "2022-07-30 12:32:41.423833 Epoch [159/250], Step [0050/0060], Loss1: 0.2080 Loss2: 0.2279 Loss3: 0.1828\n",
            "2022-07-30 12:32:49.980140 Epoch [159/250], Step [0060/0060], Loss1: 0.1954 Loss2: 0.2014 Loss3: 0.1749\n",
            "Epoch: 159 MAE: 0.06805222269088504 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:32:56.427032 Epoch [160/250], Step [0001/0060], Loss1: 0.2011 Loss2: 0.2160 Loss3: 0.1825\n",
            "2022-07-30 12:33:36.897238 Epoch [160/250], Step [0050/0060], Loss1: 0.2058 Loss2: 0.2149 Loss3: 0.1813\n",
            "2022-07-30 12:33:45.131696 Epoch [160/250], Step [0060/0060], Loss1: 0.2063 Loss2: 0.2222 Loss3: 0.1847\n",
            "Epoch: 160 MAE: 0.068182477698755 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:33:53.474941 Epoch [161/250], Step [0001/0060], Loss1: 0.2047 Loss2: 0.2251 Loss3: 0.1843\n",
            "2022-07-30 12:34:34.000310 Epoch [161/250], Step [0050/0060], Loss1: 0.1956 Loss2: 0.2119 Loss3: 0.1777\n",
            "2022-07-30 12:34:42.247855 Epoch [161/250], Step [0060/0060], Loss1: 0.2039 Loss2: 0.2176 Loss3: 0.1800\n",
            "Epoch: 161 MAE: 0.06792985371180944 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:34:48.070738 Epoch [162/250], Step [0001/0060], Loss1: 0.2089 Loss2: 0.2319 Loss3: 0.1891\n",
            "2022-07-30 12:35:29.156422 Epoch [162/250], Step [0050/0060], Loss1: 0.1939 Loss2: 0.2160 Loss3: 0.1710\n",
            "2022-07-30 12:35:37.406205 Epoch [162/250], Step [0060/0060], Loss1: 0.2008 Loss2: 0.2154 Loss3: 0.1799\n",
            "Epoch: 162 MAE: 0.07025487864459003 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:35:43.508194 Epoch [163/250], Step [0001/0060], Loss1: 0.2182 Loss2: 0.2417 Loss3: 0.1954\n",
            "2022-07-30 12:36:23.978576 Epoch [163/250], Step [0050/0060], Loss1: 0.2000 Loss2: 0.2201 Loss3: 0.1780\n",
            "2022-07-30 12:36:32.226717 Epoch [163/250], Step [0060/0060], Loss1: 0.2062 Loss2: 0.2257 Loss3: 0.1846\n",
            "Epoch: 163 MAE: 0.06860758266751729 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:36:38.079927 Epoch [164/250], Step [0001/0060], Loss1: 0.2009 Loss2: 0.2218 Loss3: 0.1793\n",
            "2022-07-30 12:37:19.135614 Epoch [164/250], Step [0050/0060], Loss1: 0.2165 Loss2: 0.2408 Loss3: 0.1915\n",
            "2022-07-30 12:37:27.391401 Epoch [164/250], Step [0060/0060], Loss1: 0.2073 Loss2: 0.2205 Loss3: 0.1850\n",
            "Epoch: 164 MAE: 0.06836591387551931 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:37:33.190950 Epoch [165/250], Step [0001/0060], Loss1: 0.1987 Loss2: 0.2182 Loss3: 0.1789\n",
            "2022-07-30 12:38:13.611722 Epoch [165/250], Step [0050/0060], Loss1: 0.2067 Loss2: 0.2239 Loss3: 0.1878\n",
            "2022-07-30 12:38:21.855599 Epoch [165/250], Step [0060/0060], Loss1: 0.2149 Loss2: 0.2360 Loss3: 0.1923\n",
            "Epoch: 165 MAE: 0.06665578347665294 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:38:29.929366 Epoch [166/250], Step [0001/0060], Loss1: 0.2021 Loss2: 0.2279 Loss3: 0.1806\n",
            "2022-07-30 12:39:10.405448 Epoch [166/250], Step [0050/0060], Loss1: 0.2034 Loss2: 0.2126 Loss3: 0.1802\n",
            "2022-07-30 12:39:18.920867 Epoch [166/250], Step [0060/0060], Loss1: 0.1952 Loss2: 0.2074 Loss3: 0.1748\n",
            "Epoch: 166 MAE: 0.06886282063035108 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:39:26.952973 Epoch [167/250], Step [0001/0060], Loss1: 0.2098 Loss2: 0.2234 Loss3: 0.1859\n",
            "2022-07-30 12:40:07.536241 Epoch [167/250], Step [0050/0060], Loss1: 0.2011 Loss2: 0.2118 Loss3: 0.1778\n",
            "2022-07-30 12:40:15.778909 Epoch [167/250], Step [0060/0060], Loss1: 0.1985 Loss2: 0.2205 Loss3: 0.1761\n",
            "Epoch: 167 MAE: 0.06851370629810152 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:40:21.611243 Epoch [168/250], Step [0001/0060], Loss1: 0.2000 Loss2: 0.2190 Loss3: 0.1795\n",
            "2022-07-30 12:41:02.043469 Epoch [168/250], Step [0050/0060], Loss1: 0.1971 Loss2: 0.2213 Loss3: 0.1764\n",
            "2022-07-30 12:41:10.298810 Epoch [168/250], Step [0060/0060], Loss1: 0.1999 Loss2: 0.2200 Loss3: 0.1791\n",
            "Epoch: 168 MAE: 0.0685722663415172 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:41:16.139620 Epoch [169/250], Step [0001/0060], Loss1: 0.1884 Loss2: 0.2018 Loss3: 0.1699\n",
            "2022-07-30 12:41:56.961959 Epoch [169/250], Step [0050/0060], Loss1: 0.2169 Loss2: 0.2380 Loss3: 0.1949\n",
            "2022-07-30 12:42:05.209527 Epoch [169/250], Step [0060/0060], Loss1: 0.1944 Loss2: 0.2083 Loss3: 0.1725\n",
            "Epoch: 169 MAE: 0.06858648900632504 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:42:11.015670 Epoch [170/250], Step [0001/0060], Loss1: 0.2078 Loss2: 0.2218 Loss3: 0.1842\n",
            "2022-07-30 12:42:51.497070 Epoch [170/250], Step [0050/0060], Loss1: 0.1988 Loss2: 0.2211 Loss3: 0.1768\n",
            "2022-07-30 12:42:59.772231 Epoch [170/250], Step [0060/0060], Loss1: 0.2189 Loss2: 0.2340 Loss3: 0.1931\n",
            "Epoch: 170 MAE: 0.06798229550558425 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:43:07.655288 Epoch [171/250], Step [0001/0060], Loss1: 0.2043 Loss2: 0.2243 Loss3: 0.1820\n",
            "2022-07-30 12:43:48.748467 Epoch [171/250], Step [0050/0060], Loss1: 0.2209 Loss2: 0.2326 Loss3: 0.1952\n",
            "2022-07-30 12:43:57.277533 Epoch [171/250], Step [0060/0060], Loss1: 0.2090 Loss2: 0.2293 Loss3: 0.1895\n",
            "Epoch: 171 MAE: 0.06857398295528674 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:44:03.208487 Epoch [172/250], Step [0001/0060], Loss1: 0.2014 Loss2: 0.2159 Loss3: 0.1774\n",
            "2022-07-30 12:44:43.700442 Epoch [172/250], Step [0050/0060], Loss1: 0.2026 Loss2: 0.2234 Loss3: 0.1799\n",
            "2022-07-30 12:44:51.941043 Epoch [172/250], Step [0060/0060], Loss1: 0.2067 Loss2: 0.2222 Loss3: 0.1867\n",
            "Epoch: 172 MAE: 0.06864632217972366 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:44:57.774396 Epoch [173/250], Step [0001/0060], Loss1: 0.2094 Loss2: 0.2248 Loss3: 0.1861\n",
            "2022-07-30 12:45:38.268144 Epoch [173/250], Step [0050/0060], Loss1: 0.1958 Loss2: 0.2146 Loss3: 0.1746\n",
            "2022-07-30 12:45:46.514830 Epoch [173/250], Step [0060/0060], Loss1: 0.2097 Loss2: 0.2206 Loss3: 0.1845\n",
            "Epoch: 173 MAE: 0.06833725621460608 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:45:52.548886 Epoch [174/250], Step [0001/0060], Loss1: 0.2057 Loss2: 0.2212 Loss3: 0.1813\n",
            "2022-07-30 12:46:33.309944 Epoch [174/250], Step [0050/0060], Loss1: 0.2123 Loss2: 0.2210 Loss3: 0.1851\n",
            "2022-07-30 12:46:41.559311 Epoch [174/250], Step [0060/0060], Loss1: 0.2037 Loss2: 0.2201 Loss3: 0.1818\n",
            "Epoch: 174 MAE: 0.06737268790996893 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:46:47.430816 Epoch [175/250], Step [0001/0060], Loss1: 0.1994 Loss2: 0.2197 Loss3: 0.1803\n",
            "2022-07-30 12:47:27.884436 Epoch [175/250], Step [0050/0060], Loss1: 0.2105 Loss2: 0.2237 Loss3: 0.1866\n",
            "2022-07-30 12:47:36.130396 Epoch [175/250], Step [0060/0060], Loss1: 0.2249 Loss2: 0.2537 Loss3: 0.1988\n",
            "Epoch: 175 MAE: 0.0684497631416119 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:47:44.213011 Epoch [176/250], Step [0001/0060], Loss1: 0.2128 Loss2: 0.2262 Loss3: 0.1908\n",
            "2022-07-30 12:48:25.269208 Epoch [176/250], Step [0050/0060], Loss1: 0.2071 Loss2: 0.2194 Loss3: 0.1837\n",
            "2022-07-30 12:48:33.514759 Epoch [176/250], Step [0060/0060], Loss1: 0.2209 Loss2: 0.2328 Loss3: 0.1927\n",
            "Epoch: 176 MAE: 0.06867959133531683 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:48:39.327599 Epoch [177/250], Step [0001/0060], Loss1: 0.1964 Loss2: 0.2184 Loss3: 0.1752\n",
            "2022-07-30 12:49:19.774539 Epoch [177/250], Step [0050/0060], Loss1: 0.1987 Loss2: 0.2228 Loss3: 0.1776\n",
            "2022-07-30 12:49:28.030854 Epoch [177/250], Step [0060/0060], Loss1: 0.2039 Loss2: 0.2221 Loss3: 0.1824\n",
            "Epoch: 177 MAE: 0.06774390543579423 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:49:33.861482 Epoch [178/250], Step [0001/0060], Loss1: 0.2069 Loss2: 0.2208 Loss3: 0.1836\n",
            "2022-07-30 12:50:14.284557 Epoch [178/250], Step [0050/0060], Loss1: 0.2003 Loss2: 0.2214 Loss3: 0.1801\n",
            "2022-07-30 12:50:22.517644 Epoch [178/250], Step [0060/0060], Loss1: 0.2032 Loss2: 0.2132 Loss3: 0.1798\n",
            "Epoch: 178 MAE: 0.06615329086465178 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:50:28.484853 Epoch [179/250], Step [0001/0060], Loss1: 0.2014 Loss2: 0.2129 Loss3: 0.1802\n",
            "2022-07-30 12:51:09.090395 Epoch [179/250], Step [0050/0060], Loss1: 0.1960 Loss2: 0.2160 Loss3: 0.1784\n",
            "2022-07-30 12:51:17.338112 Epoch [179/250], Step [0060/0060], Loss1: 0.2016 Loss2: 0.2257 Loss3: 0.1833\n",
            "Epoch: 179 MAE: 0.06700827760040445 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:51:23.287894 Epoch [180/250], Step [0001/0060], Loss1: 0.2172 Loss2: 0.2312 Loss3: 0.1910\n",
            "2022-07-30 12:52:03.762970 Epoch [180/250], Step [0050/0060], Loss1: 0.1954 Loss2: 0.2101 Loss3: 0.1725\n",
            "2022-07-30 12:52:12.008198 Epoch [180/250], Step [0060/0060], Loss1: 0.2028 Loss2: 0.2211 Loss3: 0.1822\n",
            "Epoch: 180 MAE: 0.06956213380924609 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:52:20.215361 Epoch [181/250], Step [0001/0060], Loss1: 0.1881 Loss2: 0.2091 Loss3: 0.1685\n",
            "2022-07-30 12:53:01.399014 Epoch [181/250], Step [0050/0060], Loss1: 0.1976 Loss2: 0.2125 Loss3: 0.1793\n",
            "2022-07-30 12:53:09.644025 Epoch [181/250], Step [0060/0060], Loss1: 0.2081 Loss2: 0.2362 Loss3: 0.1849\n",
            "Epoch: 181 MAE: 0.06683814119409633 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:53:15.462884 Epoch [182/250], Step [0001/0060], Loss1: 0.2102 Loss2: 0.2286 Loss3: 0.1867\n",
            "2022-07-30 12:53:55.893837 Epoch [182/250], Step [0050/0060], Loss1: 0.2056 Loss2: 0.2246 Loss3: 0.1815\n",
            "2022-07-30 12:54:04.146579 Epoch [182/250], Step [0060/0060], Loss1: 0.2040 Loss2: 0.2120 Loss3: 0.1788\n",
            "Epoch: 182 MAE: 0.0670233585216381 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:54:10.049043 Epoch [183/250], Step [0001/0060], Loss1: 0.1995 Loss2: 0.2130 Loss3: 0.1769\n",
            "2022-07-30 12:54:50.546950 Epoch [183/250], Step [0050/0060], Loss1: 0.2105 Loss2: 0.2272 Loss3: 0.1907\n",
            "2022-07-30 12:54:58.921472 Epoch [183/250], Step [0060/0060], Loss1: 0.2044 Loss2: 0.2167 Loss3: 0.1804\n",
            "Epoch: 183 MAE: 0.06797270043186408 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:55:05.776240 Epoch [184/250], Step [0001/0060], Loss1: 0.2028 Loss2: 0.2152 Loss3: 0.1810\n",
            "2022-07-30 12:55:46.203196 Epoch [184/250], Step [0050/0060], Loss1: 0.1989 Loss2: 0.2071 Loss3: 0.1773\n",
            "2022-07-30 12:55:54.446263 Epoch [184/250], Step [0060/0060], Loss1: 0.2116 Loss2: 0.2508 Loss3: 0.1927\n",
            "Epoch: 184 MAE: 0.06915622009802115 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:56:00.263647 Epoch [185/250], Step [0001/0060], Loss1: 0.2037 Loss2: 0.2245 Loss3: 0.1809\n",
            "2022-07-30 12:56:40.870362 Epoch [185/250], Step [0050/0060], Loss1: 0.2027 Loss2: 0.2156 Loss3: 0.1818\n",
            "2022-07-30 12:56:49.130660 Epoch [185/250], Step [0060/0060], Loss1: 0.1917 Loss2: 0.2182 Loss3: 0.1694\n",
            "Epoch: 185 MAE: 0.0671839500608898 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:56:57.488426 Epoch [186/250], Step [0001/0060], Loss1: 0.1991 Loss2: 0.2181 Loss3: 0.1791\n",
            "2022-07-30 12:57:38.648634 Epoch [186/250], Step [0050/0060], Loss1: 0.2098 Loss2: 0.2230 Loss3: 0.1867\n",
            "2022-07-30 12:57:46.883579 Epoch [186/250], Step [0060/0060], Loss1: 0.2022 Loss2: 0.2139 Loss3: 0.1830\n",
            "Epoch: 186 MAE: 0.06857600403841212 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:57:52.688294 Epoch [187/250], Step [0001/0060], Loss1: 0.2008 Loss2: 0.2086 Loss3: 0.1777\n",
            "2022-07-30 12:58:33.090824 Epoch [187/250], Step [0050/0060], Loss1: 0.2090 Loss2: 0.2223 Loss3: 0.1835\n",
            "2022-07-30 12:58:41.324476 Epoch [187/250], Step [0060/0060], Loss1: 0.2061 Loss2: 0.2180 Loss3: 0.1855\n",
            "Epoch: 187 MAE: 0.06864696810485191 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:58:47.091402 Epoch [188/250], Step [0001/0060], Loss1: 0.1937 Loss2: 0.2042 Loss3: 0.1722\n",
            "2022-07-30 12:59:27.590293 Epoch [188/250], Step [0050/0060], Loss1: 0.2117 Loss2: 0.2345 Loss3: 0.1875\n",
            "2022-07-30 12:59:36.292587 Epoch [188/250], Step [0060/0060], Loss1: 0.2156 Loss2: 0.2431 Loss3: 0.1937\n",
            "Epoch: 188 MAE: 0.06827600771787937 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 12:59:42.051307 Epoch [189/250], Step [0001/0060], Loss1: 0.2027 Loss2: 0.2271 Loss3: 0.1811\n",
            "2022-07-30 13:00:22.528956 Epoch [189/250], Step [0050/0060], Loss1: 0.1948 Loss2: 0.2037 Loss3: 0.1731\n",
            "2022-07-30 13:00:30.785350 Epoch [189/250], Step [0060/0060], Loss1: 0.2018 Loss2: 0.2251 Loss3: 0.1835\n",
            "Epoch: 189 MAE: 0.06935066450209847 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:00:36.580302 Epoch [190/250], Step [0001/0060], Loss1: 0.2226 Loss2: 0.2328 Loss3: 0.1958\n",
            "2022-07-30 13:01:17.005191 Epoch [190/250], Step [0050/0060], Loss1: 0.2092 Loss2: 0.2247 Loss3: 0.1841\n",
            "2022-07-30 13:01:25.238429 Epoch [190/250], Step [0060/0060], Loss1: 0.2048 Loss2: 0.2158 Loss3: 0.1808\n",
            "Epoch: 190 MAE: 0.0668769232936637 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:01:33.407449 Epoch [191/250], Step [0001/0060], Loss1: 0.2098 Loss2: 0.2417 Loss3: 0.1888\n",
            "2022-07-30 13:02:14.687326 Epoch [191/250], Step [0050/0060], Loss1: 0.2046 Loss2: 0.2140 Loss3: 0.1799\n",
            "2022-07-30 13:02:22.932971 Epoch [191/250], Step [0060/0060], Loss1: 0.1920 Loss2: 0.2010 Loss3: 0.1684\n",
            "Epoch: 191 MAE: 0.06613622039714187 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:02:28.696046 Epoch [192/250], Step [0001/0060], Loss1: 0.2058 Loss2: 0.2174 Loss3: 0.1840\n",
            "2022-07-30 13:03:09.177115 Epoch [192/250], Step [0050/0060], Loss1: 0.1956 Loss2: 0.2232 Loss3: 0.1752\n",
            "2022-07-30 13:03:17.419227 Epoch [192/250], Step [0060/0060], Loss1: 0.1983 Loss2: 0.2162 Loss3: 0.1775\n",
            "Epoch: 192 MAE: 0.06851129466263706 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:03:23.405316 Epoch [193/250], Step [0001/0060], Loss1: 0.2191 Loss2: 0.2342 Loss3: 0.1941\n",
            "2022-07-30 13:04:04.091291 Epoch [193/250], Step [0050/0060], Loss1: 0.1975 Loss2: 0.2233 Loss3: 0.1790\n",
            "2022-07-30 13:04:12.352767 Epoch [193/250], Step [0060/0060], Loss1: 0.2127 Loss2: 0.2203 Loss3: 0.1889\n",
            "Epoch: 193 MAE: 0.06825071582087766 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:04:18.498584 Epoch [194/250], Step [0001/0060], Loss1: 0.2019 Loss2: 0.2147 Loss3: 0.1794\n",
            "2022-07-30 13:04:59.159051 Epoch [194/250], Step [0050/0060], Loss1: 0.2006 Loss2: 0.2215 Loss3: 0.1775\n",
            "2022-07-30 13:05:07.431035 Epoch [194/250], Step [0060/0060], Loss1: 0.1953 Loss2: 0.2172 Loss3: 0.1744\n",
            "Epoch: 194 MAE: 0.06954393366657237 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:05:13.340766 Epoch [195/250], Step [0001/0060], Loss1: 0.2059 Loss2: 0.2186 Loss3: 0.1816\n",
            "2022-07-30 13:05:53.917262 Epoch [195/250], Step [0050/0060], Loss1: 0.1948 Loss2: 0.2130 Loss3: 0.1748\n",
            "2022-07-30 13:06:02.180744 Epoch [195/250], Step [0060/0060], Loss1: 0.2033 Loss2: 0.2122 Loss3: 0.1795\n",
            "Epoch: 195 MAE: 0.06910501439735373 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:06:10.874401 Epoch [196/250], Step [0001/0060], Loss1: 0.2179 Loss2: 0.2246 Loss3: 0.1910\n",
            "2022-07-30 13:06:51.949689 Epoch [196/250], Step [0050/0060], Loss1: 0.2177 Loss2: 0.2413 Loss3: 0.1911\n",
            "2022-07-30 13:07:00.220923 Epoch [196/250], Step [0060/0060], Loss1: 0.1975 Loss2: 0.2099 Loss3: 0.1765\n",
            "Epoch: 196 MAE: 0.0672225768982418 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:07:06.064678 Epoch [197/250], Step [0001/0060], Loss1: 0.2054 Loss2: 0.2224 Loss3: 0.1852\n",
            "2022-07-30 13:07:46.577873 Epoch [197/250], Step [0050/0060], Loss1: 0.1945 Loss2: 0.2098 Loss3: 0.1733\n",
            "2022-07-30 13:07:54.826814 Epoch [197/250], Step [0060/0060], Loss1: 0.2068 Loss2: 0.2250 Loss3: 0.1836\n",
            "Epoch: 197 MAE: 0.0690453111053144 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:08:00.677111 Epoch [198/250], Step [0001/0060], Loss1: 0.2027 Loss2: 0.2190 Loss3: 0.1821\n",
            "2022-07-30 13:08:41.388579 Epoch [198/250], Step [0050/0060], Loss1: 0.2132 Loss2: 0.2183 Loss3: 0.1884\n",
            "2022-07-30 13:08:49.626021 Epoch [198/250], Step [0060/0060], Loss1: 0.2000 Loss2: 0.2170 Loss3: 0.1779\n",
            "Epoch: 198 MAE: 0.06667100437103755 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:08:55.383831 Epoch [199/250], Step [0001/0060], Loss1: 0.2071 Loss2: 0.2287 Loss3: 0.1845\n",
            "2022-07-30 13:09:35.888085 Epoch [199/250], Step [0050/0060], Loss1: 0.1936 Loss2: 0.2136 Loss3: 0.1744\n",
            "2022-07-30 13:09:44.146455 Epoch [199/250], Step [0060/0060], Loss1: 0.2080 Loss2: 0.2178 Loss3: 0.1845\n",
            "Epoch: 199 MAE: 0.0684422485916703 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:09:49.956047 Epoch [200/250], Step [0001/0060], Loss1: 0.2000 Loss2: 0.2150 Loss3: 0.1778\n",
            "2022-07-30 13:10:30.567051 Epoch [200/250], Step [0050/0060], Loss1: 0.2040 Loss2: 0.2214 Loss3: 0.1820\n",
            "2022-07-30 13:10:38.952241 Epoch [200/250], Step [0060/0060], Loss1: 0.2004 Loss2: 0.2130 Loss3: 0.1781\n",
            "Epoch: 200 MAE: 0.06840559767667577 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:10:48.331063 Epoch [201/250], Step [0001/0060], Loss1: 0.2060 Loss2: 0.2202 Loss3: 0.1835\n",
            "2022-07-30 13:11:28.855836 Epoch [201/250], Step [0050/0060], Loss1: 0.2008 Loss2: 0.2176 Loss3: 0.1788\n",
            "2022-07-30 13:11:37.106384 Epoch [201/250], Step [0060/0060], Loss1: 0.1951 Loss2: 0.2155 Loss3: 0.1752\n",
            "Epoch: 201 MAE: 0.06906335245364559 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:11:42.951001 Epoch [202/250], Step [0001/0060], Loss1: 0.2183 Loss2: 0.2369 Loss3: 0.1946\n",
            "2022-07-30 13:12:23.413196 Epoch [202/250], Step [0050/0060], Loss1: 0.1982 Loss2: 0.2126 Loss3: 0.1745\n",
            "2022-07-30 13:12:31.676261 Epoch [202/250], Step [0060/0060], Loss1: 0.2006 Loss2: 0.2077 Loss3: 0.1782\n",
            "Epoch: 202 MAE: 0.06813008015748685 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:12:37.534594 Epoch [203/250], Step [0001/0060], Loss1: 0.1982 Loss2: 0.2118 Loss3: 0.1777\n",
            "2022-07-30 13:13:18.816287 Epoch [203/250], Step [0050/0060], Loss1: 0.2058 Loss2: 0.2258 Loss3: 0.1833\n",
            "2022-07-30 13:13:27.083390 Epoch [203/250], Step [0060/0060], Loss1: 0.1951 Loss2: 0.2055 Loss3: 0.1721\n",
            "Epoch: 203 MAE: 0.06809102492357688 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:13:32.993959 Epoch [204/250], Step [0001/0060], Loss1: 0.2122 Loss2: 0.2241 Loss3: 0.1885\n",
            "2022-07-30 13:14:13.520179 Epoch [204/250], Step [0050/0060], Loss1: 0.2022 Loss2: 0.2342 Loss3: 0.1812\n",
            "2022-07-30 13:14:21.787617 Epoch [204/250], Step [0060/0060], Loss1: 0.2020 Loss2: 0.2118 Loss3: 0.1802\n",
            "Epoch: 204 MAE: 0.06910408090662074 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:14:27.807552 Epoch [205/250], Step [0001/0060], Loss1: 0.1972 Loss2: 0.2213 Loss3: 0.1768\n",
            "2022-07-30 13:15:08.622909 Epoch [205/250], Step [0050/0060], Loss1: 0.2074 Loss2: 0.2231 Loss3: 0.1846\n",
            "2022-07-30 13:15:16.872329 Epoch [205/250], Step [0060/0060], Loss1: 0.2103 Loss2: 0.2288 Loss3: 0.1854\n",
            "Epoch: 205 MAE: 0.06802384987079275 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:15:26.296131 Epoch [206/250], Step [0001/0060], Loss1: 0.2012 Loss2: 0.2114 Loss3: 0.1784\n",
            "2022-07-30 13:16:06.806159 Epoch [206/250], Step [0050/0060], Loss1: 0.1936 Loss2: 0.2129 Loss3: 0.1752\n",
            "2022-07-30 13:16:15.063659 Epoch [206/250], Step [0060/0060], Loss1: 0.2083 Loss2: 0.2210 Loss3: 0.1809\n",
            "Epoch: 206 MAE: 0.0665193392233874 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:16:21.002994 Epoch [207/250], Step [0001/0060], Loss1: 0.2166 Loss2: 0.2292 Loss3: 0.1944\n",
            "2022-07-30 13:17:01.494706 Epoch [207/250], Step [0050/0060], Loss1: 0.2013 Loss2: 0.2270 Loss3: 0.1810\n",
            "2022-07-30 13:17:10.244595 Epoch [207/250], Step [0060/0060], Loss1: 0.2076 Loss2: 0.2348 Loss3: 0.1850\n",
            "Epoch: 207 MAE: 0.06981498592114321 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:17:17.458712 Epoch [208/250], Step [0001/0060], Loss1: 0.2218 Loss2: 0.2391 Loss3: 0.1945\n",
            "2022-07-30 13:17:57.922299 Epoch [208/250], Step [0050/0060], Loss1: 0.1956 Loss2: 0.2143 Loss3: 0.1765\n",
            "2022-07-30 13:18:06.167598 Epoch [208/250], Step [0060/0060], Loss1: 0.1943 Loss2: 0.2076 Loss3: 0.1750\n",
            "Epoch: 208 MAE: 0.06871114478540169 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:18:12.076158 Epoch [209/250], Step [0001/0060], Loss1: 0.2051 Loss2: 0.2216 Loss3: 0.1833\n",
            "2022-07-30 13:18:52.483081 Epoch [209/250], Step [0050/0060], Loss1: 0.1933 Loss2: 0.2087 Loss3: 0.1720\n",
            "2022-07-30 13:19:00.737760 Epoch [209/250], Step [0060/0060], Loss1: 0.2108 Loss2: 0.2330 Loss3: 0.1868\n",
            "Epoch: 209 MAE: 0.06906725247701008 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:19:06.643835 Epoch [210/250], Step [0001/0060], Loss1: 0.1954 Loss2: 0.2147 Loss3: 0.1724\n",
            "2022-07-30 13:19:47.577867 Epoch [210/250], Step [0050/0060], Loss1: 0.1946 Loss2: 0.2111 Loss3: 0.1761\n",
            "2022-07-30 13:19:55.820930 Epoch [210/250], Step [0060/0060], Loss1: 0.2000 Loss2: 0.2138 Loss3: 0.1803\n",
            "Epoch: 210 MAE: 0.06871242851176591 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:20:05.419811 Epoch [211/250], Step [0001/0060], Loss1: 0.1993 Loss2: 0.2082 Loss3: 0.1794\n",
            "2022-07-30 13:20:45.869889 Epoch [211/250], Step [0050/0060], Loss1: 0.2104 Loss2: 0.2254 Loss3: 0.1871\n",
            "2022-07-30 13:20:54.116939 Epoch [211/250], Step [0060/0060], Loss1: 0.2171 Loss2: 0.2256 Loss3: 0.1908\n",
            "Epoch: 211 MAE: 0.06856128889416895 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:20:59.988690 Epoch [212/250], Step [0001/0060], Loss1: 0.2037 Loss2: 0.2131 Loss3: 0.1809\n",
            "2022-07-30 13:21:41.281876 Epoch [212/250], Step [0050/0060], Loss1: 0.2084 Loss2: 0.2187 Loss3: 0.1843\n",
            "2022-07-30 13:21:49.537394 Epoch [212/250], Step [0060/0060], Loss1: 0.2011 Loss2: 0.2154 Loss3: 0.1799\n",
            "Epoch: 212 MAE: 0.06909593491327198 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:21:55.411641 Epoch [213/250], Step [0001/0060], Loss1: 0.2080 Loss2: 0.2179 Loss3: 0.1838\n",
            "2022-07-30 13:22:35.923612 Epoch [213/250], Step [0050/0060], Loss1: 0.2026 Loss2: 0.2146 Loss3: 0.1805\n",
            "2022-07-30 13:22:44.159629 Epoch [213/250], Step [0060/0060], Loss1: 0.2061 Loss2: 0.2173 Loss3: 0.1815\n",
            "Epoch: 213 MAE: 0.06737131794924459 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:22:50.051361 Epoch [214/250], Step [0001/0060], Loss1: 0.2128 Loss2: 0.2310 Loss3: 0.1910\n",
            "2022-07-30 13:23:30.534831 Epoch [214/250], Step [0050/0060], Loss1: 0.2101 Loss2: 0.2310 Loss3: 0.1866\n",
            "2022-07-30 13:23:38.776489 Epoch [214/250], Step [0060/0060], Loss1: 0.2056 Loss2: 0.2187 Loss3: 0.1827\n",
            "Epoch: 214 MAE: 0.06941942376434486 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:23:44.689462 Epoch [215/250], Step [0001/0060], Loss1: 0.2059 Loss2: 0.2160 Loss3: 0.1808\n",
            "2022-07-30 13:24:25.378450 Epoch [215/250], Step [0050/0060], Loss1: 0.2023 Loss2: 0.2165 Loss3: 0.1795\n",
            "2022-07-30 13:24:33.634216 Epoch [215/250], Step [0060/0060], Loss1: 0.2029 Loss2: 0.2272 Loss3: 0.1800\n",
            "Epoch: 215 MAE: 0.07050812463911756 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:24:41.935495 Epoch [216/250], Step [0001/0060], Loss1: 0.2064 Loss2: 0.2172 Loss3: 0.1839\n",
            "2022-07-30 13:25:22.364869 Epoch [216/250], Step [0050/0060], Loss1: 0.1967 Loss2: 0.2243 Loss3: 0.1770\n",
            "2022-07-30 13:25:30.614286 Epoch [216/250], Step [0060/0060], Loss1: 0.2050 Loss2: 0.2213 Loss3: 0.1801\n",
            "Epoch: 216 MAE: 0.07029428845360167 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:25:36.639553 Epoch [217/250], Step [0001/0060], Loss1: 0.2119 Loss2: 0.2323 Loss3: 0.1860\n",
            "2022-07-30 13:26:18.232682 Epoch [217/250], Step [0050/0060], Loss1: 0.2088 Loss2: 0.2268 Loss3: 0.1857\n",
            "2022-07-30 13:26:26.481146 Epoch [217/250], Step [0060/0060], Loss1: 0.2077 Loss2: 0.2284 Loss3: 0.1843\n",
            "Epoch: 217 MAE: 0.06739461974492146 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:26:32.400341 Epoch [218/250], Step [0001/0060], Loss1: 0.2035 Loss2: 0.2145 Loss3: 0.1821\n",
            "2022-07-30 13:27:12.894023 Epoch [218/250], Step [0050/0060], Loss1: 0.1975 Loss2: 0.2137 Loss3: 0.1761\n",
            "2022-07-30 13:27:21.135837 Epoch [218/250], Step [0060/0060], Loss1: 0.1997 Loss2: 0.2158 Loss3: 0.1755\n",
            "Epoch: 218 MAE: 0.06872284086923751 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:27:27.064514 Epoch [219/250], Step [0001/0060], Loss1: 0.1993 Loss2: 0.2136 Loss3: 0.1755\n",
            "2022-07-30 13:28:07.521303 Epoch [219/250], Step [0050/0060], Loss1: 0.2124 Loss2: 0.2329 Loss3: 0.1921\n",
            "2022-07-30 13:28:16.000248 Epoch [219/250], Step [0060/0060], Loss1: 0.2151 Loss2: 0.2387 Loss3: 0.1950\n",
            "Epoch: 219 MAE: 0.07105567679834114 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:28:22.054315 Epoch [220/250], Step [0001/0060], Loss1: 0.2063 Loss2: 0.2299 Loss3: 0.1848\n",
            "2022-07-30 13:29:02.528058 Epoch [220/250], Step [0050/0060], Loss1: 0.2125 Loss2: 0.2287 Loss3: 0.1884\n",
            "2022-07-30 13:29:10.765866 Epoch [220/250], Step [0060/0060], Loss1: 0.2070 Loss2: 0.2273 Loss3: 0.1839\n",
            "Epoch: 220 MAE: 0.0693309523062731 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:29:19.138712 Epoch [221/250], Step [0001/0060], Loss1: 0.2092 Loss2: 0.2217 Loss3: 0.1902\n",
            "2022-07-30 13:29:59.598726 Epoch [221/250], Step [0050/0060], Loss1: 0.2010 Loss2: 0.2184 Loss3: 0.1786\n",
            "2022-07-30 13:30:07.871996 Epoch [221/250], Step [0060/0060], Loss1: 0.2038 Loss2: 0.2218 Loss3: 0.1829\n",
            "Epoch: 221 MAE: 0.06974876181789175 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:30:13.748051 Epoch [222/250], Step [0001/0060], Loss1: 0.1953 Loss2: 0.2111 Loss3: 0.1752\n",
            "2022-07-30 13:30:55.200135 Epoch [222/250], Step [0050/0060], Loss1: 0.1942 Loss2: 0.2087 Loss3: 0.1716\n",
            "2022-07-30 13:31:03.447688 Epoch [222/250], Step [0060/0060], Loss1: 0.2137 Loss2: 0.2354 Loss3: 0.1907\n",
            "Epoch: 222 MAE: 0.06842451998796414 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:31:09.318186 Epoch [223/250], Step [0001/0060], Loss1: 0.2003 Loss2: 0.2122 Loss3: 0.1778\n",
            "2022-07-30 13:31:49.767475 Epoch [223/250], Step [0050/0060], Loss1: 0.2074 Loss2: 0.2264 Loss3: 0.1848\n",
            "2022-07-30 13:31:58.012022 Epoch [223/250], Step [0060/0060], Loss1: 0.2026 Loss2: 0.2216 Loss3: 0.1794\n",
            "Epoch: 223 MAE: 0.06870442269340396 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:32:03.840249 Epoch [224/250], Step [0001/0060], Loss1: 0.1975 Loss2: 0.2160 Loss3: 0.1764\n",
            "2022-07-30 13:32:44.515095 Epoch [224/250], Step [0050/0060], Loss1: 0.2033 Loss2: 0.2167 Loss3: 0.1776\n",
            "2022-07-30 13:32:52.760348 Epoch [224/250], Step [0060/0060], Loss1: 0.2090 Loss2: 0.2212 Loss3: 0.1858\n",
            "Epoch: 224 MAE: 0.06516322796937649 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:32:58.570024 Epoch [225/250], Step [0001/0060], Loss1: 0.2041 Loss2: 0.2135 Loss3: 0.1813\n",
            "2022-07-30 13:33:39.011926 Epoch [225/250], Step [0050/0060], Loss1: 0.2101 Loss2: 0.2186 Loss3: 0.1864\n",
            "2022-07-30 13:33:47.251330 Epoch [225/250], Step [0060/0060], Loss1: 0.2008 Loss2: 0.2139 Loss3: 0.1794\n",
            "Epoch: 225 MAE: 0.06944324185608558 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:33:56.336699 Epoch [226/250], Step [0001/0060], Loss1: 0.2033 Loss2: 0.2166 Loss3: 0.1789\n",
            "2022-07-30 13:34:36.791689 Epoch [226/250], Step [0050/0060], Loss1: 0.1981 Loss2: 0.2132 Loss3: 0.1748\n",
            "2022-07-30 13:34:45.046105 Epoch [226/250], Step [0060/0060], Loss1: 0.2100 Loss2: 0.2311 Loss3: 0.1835\n",
            "Epoch: 226 MAE: 0.06727904551874392 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:34:51.187735 Epoch [227/250], Step [0001/0060], Loss1: 0.2006 Loss2: 0.2131 Loss3: 0.1799\n",
            "2022-07-30 13:35:32.452711 Epoch [227/250], Step [0050/0060], Loss1: 0.2037 Loss2: 0.2127 Loss3: 0.1808\n",
            "2022-07-30 13:35:40.694751 Epoch [227/250], Step [0060/0060], Loss1: 0.2024 Loss2: 0.2141 Loss3: 0.1795\n",
            "Epoch: 227 MAE: 0.06662215424593164 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:35:46.607231 Epoch [228/250], Step [0001/0060], Loss1: 0.2061 Loss2: 0.2154 Loss3: 0.1825\n",
            "2022-07-30 13:36:27.045062 Epoch [228/250], Step [0050/0060], Loss1: 0.2014 Loss2: 0.2241 Loss3: 0.1781\n",
            "2022-07-30 13:36:35.289424 Epoch [228/250], Step [0060/0060], Loss1: 0.2060 Loss2: 0.2189 Loss3: 0.1846\n",
            "Epoch: 228 MAE: 0.07038969791755474 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:36:41.163548 Epoch [229/250], Step [0001/0060], Loss1: 0.2026 Loss2: 0.2163 Loss3: 0.1793\n",
            "2022-07-30 13:37:21.847607 Epoch [229/250], Step [0050/0060], Loss1: 0.2040 Loss2: 0.2273 Loss3: 0.1851\n",
            "2022-07-30 13:37:30.091605 Epoch [229/250], Step [0060/0060], Loss1: 0.1912 Loss2: 0.2101 Loss3: 0.1681\n",
            "Epoch: 229 MAE: 0.06715015850369896 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:37:35.953552 Epoch [230/250], Step [0001/0060], Loss1: 0.2004 Loss2: 0.2228 Loss3: 0.1784\n",
            "2022-07-30 13:38:16.422384 Epoch [230/250], Step [0050/0060], Loss1: 0.1974 Loss2: 0.2188 Loss3: 0.1737\n",
            "2022-07-30 13:38:24.661705 Epoch [230/250], Step [0060/0060], Loss1: 0.1945 Loss2: 0.2187 Loss3: 0.1742\n",
            "Epoch: 230 MAE: 0.06996838599916487 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:38:32.930328 Epoch [231/250], Step [0001/0060], Loss1: 0.2119 Loss2: 0.2353 Loss3: 0.1915\n",
            "2022-07-30 13:39:13.393459 Epoch [231/250], Step [0050/0060], Loss1: 0.2167 Loss2: 0.2330 Loss3: 0.1922\n",
            "2022-07-30 13:39:22.265258 Epoch [231/250], Step [0060/0060], Loss1: 0.2171 Loss2: 0.2396 Loss3: 0.1917\n",
            "Epoch: 231 MAE: 0.07133926477381791 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:39:29.428484 Epoch [232/250], Step [0001/0060], Loss1: 0.2100 Loss2: 0.2255 Loss3: 0.1855\n",
            "2022-07-30 13:40:09.883997 Epoch [232/250], Step [0050/0060], Loss1: 0.2055 Loss2: 0.2221 Loss3: 0.1851\n",
            "2022-07-30 13:40:18.123169 Epoch [232/250], Step [0060/0060], Loss1: 0.1928 Loss2: 0.2056 Loss3: 0.1724\n",
            "Epoch: 232 MAE: 0.06843563100017568 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:40:23.990861 Epoch [233/250], Step [0001/0060], Loss1: 0.2035 Loss2: 0.2216 Loss3: 0.1800\n",
            "2022-07-30 13:41:04.471890 Epoch [233/250], Step [0050/0060], Loss1: 0.2053 Loss2: 0.2202 Loss3: 0.1841\n",
            "2022-07-30 13:41:12.714229 Epoch [233/250], Step [0060/0060], Loss1: 0.2061 Loss2: 0.2312 Loss3: 0.1828\n",
            "Epoch: 233 MAE: 0.06871509208881037 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:41:18.605406 Epoch [234/250], Step [0001/0060], Loss1: 0.2050 Loss2: 0.2293 Loss3: 0.1831\n",
            "2022-07-30 13:41:59.433388 Epoch [234/250], Step [0050/0060], Loss1: 0.2046 Loss2: 0.2236 Loss3: 0.1848\n",
            "2022-07-30 13:42:07.686158 Epoch [234/250], Step [0060/0060], Loss1: 0.2107 Loss2: 0.2298 Loss3: 0.1887\n",
            "Epoch: 234 MAE: 0.06879215467543827 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:42:13.490941 Epoch [235/250], Step [0001/0060], Loss1: 0.1948 Loss2: 0.2108 Loss3: 0.1729\n",
            "2022-07-30 13:42:53.932861 Epoch [235/250], Step [0050/0060], Loss1: 0.2017 Loss2: 0.2152 Loss3: 0.1771\n",
            "2022-07-30 13:43:02.173612 Epoch [235/250], Step [0060/0060], Loss1: 0.1981 Loss2: 0.2090 Loss3: 0.1789\n",
            "Epoch: 235 MAE: 0.06796024085352662 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:43:10.473157 Epoch [236/250], Step [0001/0060], Loss1: 0.2091 Loss2: 0.2255 Loss3: 0.1841\n",
            "2022-07-30 13:43:51.881202 Epoch [236/250], Step [0050/0060], Loss1: 0.2070 Loss2: 0.2220 Loss3: 0.1842\n",
            "2022-07-30 13:44:00.126338 Epoch [236/250], Step [0060/0060], Loss1: 0.1981 Loss2: 0.2093 Loss3: 0.1757\n",
            "Epoch: 236 MAE: 0.06753113988846068 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:44:05.959659 Epoch [237/250], Step [0001/0060], Loss1: 0.2067 Loss2: 0.2258 Loss3: 0.1835\n",
            "2022-07-30 13:44:46.405078 Epoch [237/250], Step [0050/0060], Loss1: 0.2026 Loss2: 0.2232 Loss3: 0.1814\n",
            "2022-07-30 13:44:54.640590 Epoch [237/250], Step [0060/0060], Loss1: 0.2106 Loss2: 0.2306 Loss3: 0.1841\n",
            "Epoch: 237 MAE: 0.06687493753180931 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:45:00.535084 Epoch [238/250], Step [0001/0060], Loss1: 0.2039 Loss2: 0.2200 Loss3: 0.1824\n",
            "2022-07-30 13:45:40.995581 Epoch [238/250], Step [0050/0060], Loss1: 0.2027 Loss2: 0.2158 Loss3: 0.1792\n",
            "2022-07-30 13:45:49.238506 Epoch [238/250], Step [0060/0060], Loss1: 0.2152 Loss2: 0.2339 Loss3: 0.1892\n",
            "Epoch: 238 MAE: 0.06794066393816915 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:45:55.187845 Epoch [239/250], Step [0001/0060], Loss1: 0.2039 Loss2: 0.2176 Loss3: 0.1836\n",
            "2022-07-30 13:46:35.809629 Epoch [239/250], Step [0050/0060], Loss1: 0.2118 Loss2: 0.2223 Loss3: 0.1891\n",
            "2022-07-30 13:46:44.045835 Epoch [239/250], Step [0060/0060], Loss1: 0.2109 Loss2: 0.2221 Loss3: 0.1835\n",
            "Epoch: 239 MAE: 0.06740071624675122 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:46:49.958829 Epoch [240/250], Step [0001/0060], Loss1: 0.1987 Loss2: 0.2278 Loss3: 0.1792\n",
            "2022-07-30 13:47:30.483149 Epoch [240/250], Step [0050/0060], Loss1: 0.1937 Loss2: 0.2112 Loss3: 0.1716\n",
            "2022-07-30 13:47:38.740187 Epoch [240/250], Step [0060/0060], Loss1: 0.2154 Loss2: 0.2365 Loss3: 0.1918\n",
            "Epoch: 240 MAE: 0.0690116372184148 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:47:47.061852 Epoch [241/250], Step [0001/0060], Loss1: 0.1927 Loss2: 0.2054 Loss3: 0.1720\n",
            "2022-07-30 13:48:28.436118 Epoch [241/250], Step [0050/0060], Loss1: 0.1954 Loss2: 0.2116 Loss3: 0.1746\n",
            "2022-07-30 13:48:36.703527 Epoch [241/250], Step [0060/0060], Loss1: 0.2118 Loss2: 0.2232 Loss3: 0.1894\n",
            "Epoch: 241 MAE: 0.06761271789591147 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:48:42.624845 Epoch [242/250], Step [0001/0060], Loss1: 0.1958 Loss2: 0.2171 Loss3: 0.1754\n",
            "2022-07-30 13:49:23.114405 Epoch [242/250], Step [0050/0060], Loss1: 0.2113 Loss2: 0.2339 Loss3: 0.1896\n",
            "2022-07-30 13:49:31.369910 Epoch [242/250], Step [0060/0060], Loss1: 0.1927 Loss2: 0.2173 Loss3: 0.1742\n",
            "Epoch: 242 MAE: 0.07198872672186957 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:49:37.296932 Epoch [243/250], Step [0001/0060], Loss1: 0.1982 Loss2: 0.2135 Loss3: 0.1778\n",
            "2022-07-30 13:50:17.841484 Epoch [243/250], Step [0050/0060], Loss1: 0.2019 Loss2: 0.2258 Loss3: 0.1802\n",
            "2022-07-30 13:50:26.379098 Epoch [243/250], Step [0060/0060], Loss1: 0.2017 Loss2: 0.2124 Loss3: 0.1810\n",
            "Epoch: 243 MAE: 0.06853539603097102 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:50:32.676322 Epoch [244/250], Step [0001/0060], Loss1: 0.2076 Loss2: 0.2289 Loss3: 0.1857\n",
            "2022-07-30 13:51:13.139165 Epoch [244/250], Step [0050/0060], Loss1: 0.1985 Loss2: 0.2128 Loss3: 0.1777\n",
            "2022-07-30 13:51:21.406182 Epoch [244/250], Step [0060/0060], Loss1: 0.2026 Loss2: 0.2222 Loss3: 0.1812\n",
            "Epoch: 244 MAE: 0.06868103486520276 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:51:27.375222 Epoch [245/250], Step [0001/0060], Loss1: 0.2006 Loss2: 0.2218 Loss3: 0.1833\n",
            "2022-07-30 13:52:07.858344 Epoch [245/250], Step [0050/0060], Loss1: 0.1952 Loss2: 0.2072 Loss3: 0.1728\n",
            "2022-07-30 13:52:16.098965 Epoch [245/250], Step [0060/0060], Loss1: 0.2082 Loss2: 0.2314 Loss3: 0.1845\n",
            "Epoch: 245 MAE: 0.0695454264948608 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:52:24.312921 Epoch [246/250], Step [0001/0060], Loss1: 0.2242 Loss2: 0.2396 Loss3: 0.1972\n",
            "2022-07-30 13:53:05.573644 Epoch [246/250], Step [0050/0060], Loss1: 0.2014 Loss2: 0.2104 Loss3: 0.1766\n",
            "2022-07-30 13:53:13.848691 Epoch [246/250], Step [0060/0060], Loss1: 0.2113 Loss2: 0.2206 Loss3: 0.1848\n",
            "Epoch: 246 MAE: 0.06595936876125438 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:53:19.655164 Epoch [247/250], Step [0001/0060], Loss1: 0.2067 Loss2: 0.2260 Loss3: 0.1837\n",
            "2022-07-30 13:54:00.102049 Epoch [247/250], Step [0050/0060], Loss1: 0.2081 Loss2: 0.2212 Loss3: 0.1856\n",
            "2022-07-30 13:54:08.359128 Epoch [247/250], Step [0060/0060], Loss1: 0.1897 Loss2: 0.2107 Loss3: 0.1726\n",
            "Epoch: 247 MAE: 0.0700841807814502 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:54:14.179165 Epoch [248/250], Step [0001/0060], Loss1: 0.2145 Loss2: 0.2189 Loss3: 0.1880\n",
            "2022-07-30 13:54:54.967814 Epoch [248/250], Step [0050/0060], Loss1: 0.2192 Loss2: 0.2424 Loss3: 0.1967\n",
            "2022-07-30 13:55:03.228000 Epoch [248/250], Step [0060/0060], Loss1: 0.2001 Loss2: 0.2141 Loss3: 0.1806\n",
            "Epoch: 248 MAE: 0.06914398647490003 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n",
            "2022-07-30 13:55:09.208139 Epoch [249/250], Step [0001/0060], Loss1: 0.2181 Loss2: 0.2395 Loss3: 0.1941\n",
            "2022-07-30 13:55:49.666299 Epoch [249/250], Step [0050/0060], Loss1: 0.1957 Loss2: 0.2195 Loss3: 0.1769\n",
            "2022-07-30 13:55:57.904693 Epoch [249/250], Step [0060/0060], Loss1: 0.2063 Loss2: 0.2221 Loss3: 0.1820\n",
            "Epoch: 249 MAE: 0.06993892392153461 ####  bestMAE: 0.05835259871508081 bestEpoch: 51\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeZwdRbn3v3X6bLNPkskeYhLWkA1C2JIoESEIQ7jIJossghIBNSAqioARUPB6ZRG9CoqICwkYuXBDEHIh5lWCEFYJYV8lyYRszEwymbN0d71/dFef7j59tlkyk6F/+eQz5/Tp7nqquurpp5566vkJKSUhQoQIEWLgIdLXAoQIESJEiN5BqOBDhAgRYoAiVPAhQoQIMUARKvgQIUKEGKAIFXyIECFCDFCECj5EiBAhBihCBR9it4cQ4q9CiHP7Wo4QIfobRBgHH6IvIITY4fpaDaQBw/4+X0r5p10sz0pgGjBCSpnelWWHCNFbCC34EH0CKWWt+g/8G5jnOuYodyFEtLdlEUKMAz4JSOCE3i7PV3av1y/Exxehgg/RryCEmCOEWCeEuEIIsRG4SwgxSAjxkBBisxDiI/vzGNc1K4UQX7I/nyeEeEII8V/2ue8KIY4tUew5wFPA7wCPq0cIsYcQ4n677K1CiJ+7fvuyEOJVIcR2IcQrQojp9nEphNjLdd7vhBDXd6N+g4UQdwkhNti/P2Aff1kIMc91XkwIsUUIcWCFzR5igCJU8CH6I0YAg4FPABdi9dO77O9jgU7g5wWvhkOB14Em4D+BO4UQosj55wB/sv8fI4QYDiCE0ICHgPeBccBoYLH926nAQvvaeizLf2sv1e8PWG6sScAw4Gb7+O+BL7jOOw5okVK+UKYcIQY6pJTh//B/n/4H3gOOsj/PATJAssj5BwAfub6vBL5kfz4PeMv1WzWW62VEgXvNBrJAk/39NeAy+/PhwGYgGnDdo8CCAveUwF6u778Dru9K/YCRgAkMCjhvFLAdqLe/LwG+3dfPM/zff/6HFnyI/ojNUsqU+iKEqBZC3C6EeF8I0Q78HWi0LewgbFQfpJQ77Y+1Bc49F1gupdxif7+HnJtmD+B9KaUecN0ewNvlVScPldRvD2CblPIj/02klBuAVcDJQohG4FisWUiIEACECzwh+iP8oV2XA/sCh0opNwohDgBeAIq5XUpCCFEFnAZotj8cIIGlXKcBHwBjhRDRACX/AbBngVvvxJo5KIwA1rm+V1K/D4DBQohGKWVrQFl3A1/CGsv/lFKuL1zjEB83hBZ8iN0BdVh+6VYhxGDg+z103xOxQjP3x3KLHABMBP6B5VtfDbQANwohaoQQSSHELPva3wDfFEIcJCzsJYT4hP3bi8CZQghNCPFZ4Iiu1k9K2QL8FfhvezE2JoT4lOvaB4DpwAIsn3yIEA5CBR9id8AtQBWwBSva5ZEeuu+5wF1Syn9LKTeq/1gLnGdhWdDzgL2wQjnXAZ8HkFL+GfghlktnO5aiHWzfd4F9Xat9nwe6Wb+zsdYJXgM2AZeqH6SUncBfgPHA/ZVVP8RAR7jRKUSI3RxCiGuAfaSUXyh5coiPFUIffIgQuzFsl84FWFZ+iBAehC6aECF2Uwghvoy1CPtXKeXf+1qeEP0PoYsmRIgQIQYoQgs+RIgQIQYo+pUPvqmpSY4bN66vxQgRIkSI3QbPPffcFinl0KDf+pWCHzduHM8++2xfixEiRIgQuw2EEO8X+i100YQIESLEAEWo4EOECBFigCJU8CFChAgxQNGvfPBByGazrFu3jlQqVfrkEHlIJpOMGTOGWCzW16KECBFiF6PfK/h169ZRV1fHuHHjKM7ZEMIPKSVbt25l3bp1jB8/vq/FCREixC5Gv3fRpFIphgwZEir3LkAIwZAhQz42s59l7yxj7pK5TL17KnOXzGXZO8v6WqQQIfoU/d6CB0Ll3g18XNpu2TvLWPjkQlKG9TJr6Whh4ZMLAWie0NyHkoUI0Xfo9xZ8iBDl4Nbnb3WUu0LKSHHr87f2kUQhQvQ9QgVfJh544AGEELz22mt9LUqIAGzs2FjR8RAhPg4YcAr+gRfWM+vGFYz/zjJm3biCB17oGQazRYsWMXv2bBYtWtQj9wuCYRi9du+BjhE1Iyo6HiLExwEDSsE/8MJ6vnv/Gta3diKB9a2dfPf+Nd1W8jt27OCJJ57gzjvvZPHixYCljL/5zW8yefJkpk6dym233QbAM888w8yZM5k2bRqHHHII27dv53e/+x1f/epXnfsdf/zxrFy5EoDa2louv/xypk2bxj//+U+uvfZaDj74YCZPnsyFF16Iyvb51ltvcdRRRzFt2jSmT5/O22+/zTnnnMMDD+TIgs466ywefPDBbtV1d8WC6QtIaknPsaSWZMH0BX0kUYgQfY/dYpFV4QdL1/LKhvaCv7/w71Yyhuk51pk1+PaSl1i0+t+B1+w/qp7vz5tUtNwHH3yQz372s+yzzz4MGTKE5557jtWrV/Pee+/x4osvEo1G2bZtG5lMhs9//vPce++9HHzwwbS3t1NVVVX03h0dHRx66KH89Kc/teTZf3+uueYaAM4++2weeugh5s2bx1lnncV3vvMdPve5z5FKpTBNkwsuuICbb76ZE088kba2Np588knuvvvuouUNVKiFVLXQOrJmJAumLwgXWEN8rDGgLHi/ci91vFwsWrSI008/HYDTTz+dRYsW8dhjjzF//nyiUesdOXjwYF5//XVGjhzJwQcfDEB9fb3zeyFomsbJJ5/sfP/b3/7GoYceypQpU1ixYgVr165l+/btrF+/ns997nOAtXmpurqaI444gjfffJPNmzezaNEiTj755JLlDWQ0T2hm9ujZVEWrWH7K8lC5h/jYY7fSBqUs7Vk3rmB9a2fe8dGNVdw7//Aulblt2zZWrFjBmjVrEEJgGAZCCEeJl4NoNIpp5l4y7rj0ZDKJpmnO8Ysvvphnn32WPfbYg4ULF5aMYT/nnHP44x//yOLFi7nrrrsqrN3AgylNsma2r8UIEaJfYEBZ8N86Zl+qYprnWFVM41vH7Nvley5ZsoSzzz6b999/n/fee48PPviA8ePHM23aNG6//XZ0XQesF8G+++5LS0sLzzzzDADbt29H13XGjRvHiy++iGmafPDBB6xevTqwLKXMm5qa2LFjB0uWLAGgrq6OMWPGOP72dDrNzp07ATjvvPO45ZZbAMu983GHiYlu6oRMZSFCDDAFf+KBo7nhpCmMbqxCYFnuN5w0hRMPHN3ley5atMhxjSicfPLJtLS0MHbsWKZOncq0adO45557iMfj3HvvvXzta19j2rRpHH300aRSKWbNmsX48ePZf//9+frXv8706dMDy2psbOTLX/4ykydP5phjjvHMEv7whz/ws5/9jKlTpzJz5kw2brTC/4YPH87EiRP54he/2OU6DiQoxa6beh9LEiJE36NfcbLOmDFD+gk/Xn31VSZOnNhHEvV/7Ny5kylTpvD888/T0NAQeM7HqQ0veuwinlj/BE+f+TTVseq+FidEiF6HEOI5KeWMoN8GlAX/ccNjjz3GxIkT+drXvlZQuX/coAyW0A8fIsRutsgawoujjjqK998vyNb1sYQprcXsUMGHCBFa8CEGGEwsBR/64EOECBV8iAEGx0VjhBZ8iBChgg8xoGBIK59P6KIJESJU8CEGGMJF1hAhcggVfJnoTrrgrVu38ulPf5ra2lpP0rEQPY9wkTVEiBwGnoJ/6T64eTIsbLT+vnRfj9y2O+mCk8kk1113Hf/1X//VI7KEKAy1yBoq+BAhBpqCf+k+WPp1aPsAkNbfpV/vtpLvbrrgmpoaZs+eTTKZLFZMiB5AuMgaIkQOu1cc/F+/AxvXFP593TNgpL3Hsp3w4FfhuQJpdEdMgWNvLFpsb6YLDtGzUIusYZhkiBC7m4IvBb9yL3W8TCxatIgFCyziCJUu+N133+UrX/mKJ13wmjVr8tIFh9i1CBdZQ4TIYfdS8CUsbW6ebLtnfGjYA764rEtF9kS64BC7DuEia4gQOQwsH/xnroGYzyUSq7KOdxE9kS44xK5DuMgaIkQOva7ghRCaEOIFIcRDvV0WU0+DeT+zLHaE9Xfez6zjXURPpAsGGDduHN/4xjf43e9+x5gxY3jllVe6U9MQBRC6aEKEyGFXuGgWAK8Cu8YhPfW0bil0P/72t7/lHfv617/ufL7ppps8vx188ME89dRTede89957PSZTiMJwdrKGUTQhQvSuBS+EGAM0A7/pzXJChFAICT9ChMiht100twDfBgqyXgshLhRCPCuEeHbz5s29LE6IgY5wkTVEiBx6TcELIY4HNkkpnyt2npTyDinlDCnljKFDh/aWOCE+JggVfIgQOfSmBT8LOEEI8R6wGDhSCPHHXiwvRAgk4SJriBAKvabgpZTflVKOkVKOA04HVkgpv9Bb5YUIAaEFHyKEGwMrDj7Exx5hFE2IEDnsEgUvpVwppTx+V5TVW+hOuuD/+7//46CDDmLKlCkcdNBBrFixohckDAFhHHyIEG4MOAt+2TvLmLtkLlPvnsrcJXNZ9k7XUhT40Z10wU1NTSxdupQ1a9Zw9913c/bZZ/eITCHyoVw0YZhkiBADTMEve2cZC59cSEtHCxJJS0cLC59c2G0l3910wQceeCCjRo0CYNKkSXR2dpJOdy8BWohghIusIULksFslG/vx6h/z2rbCLpJ/bf5X3sBOGSmuWXUNS95YEnjNfoP344pDrihabrnpgjdt38RJp57ET379E6YfNJ2kkcxLF/yXv/yF6dOnk0gkyqz1wMGyd5Zx6/O3srFjIyNqRrBg+gKaJzQHntu2dCmbbr4FvaWF6MiRDLvsUhrmzStZRrjIGiJEDruVgi8G3dQLDuqMmenWvctJFxypifDk6idpGtbElAOnkDWz6BGdHcYOGqONAKxdu5YrrriC5cuXd0ue3RFqdpUyrNw8anYF5Cn5tqVLabn6GqSdx0ffsIGWq62EcaWUfEi6HSJEDruVgi9mab+x7Q3mPzafLZ1b8n4bWTOSuz57V5fKLDdd8KaOTc4Cn4KUkk0dm2hMNLJu3To+97nP8fvf/54999yzS7Lszrj1+Vsd5a6QMlLc+vyteQp+0823OMpdQaZSbLr5lpIKPmR0ChEihwHjg8+aWU7f93TiWtxzPK7FWTB9QZfvW2664C1btzB+r/Fs2bSFNS9YrFMdOzrozHTS2tpKc3MzN954I7Nmzep6JXdjbOzYWPZxvaUl8NxCx90IXTQhQuQwYBR8LBJj9ujZXDjlQpqqmhAImqqauGjqRQX9vOWg3HTBj9z/CLF4jJ/8+ifc8N0bOGnOSXz5lC9jZkx+/vOf89Zbb3HttddywAEHcMABB7Bp06buVnm3woiaEWUfj44cGXhuoeNuqEXWMIomRAgQfrdCX2LGjBny2Wef9Rx79dVXmThxYslrW9OtbNixweMmEUIwqnYUjYnGHpe1v5VfDOW2YW9i2TvLuGbVNZ71kKSWZOHMhcE++KuuRroijUQyycjrri3popnxxxmkjTSHjTyMX8/9dc9WIkSIfgghxHNSyhlBvw0YC74x0cio2lFoEQ2AaCS6S5WrU77om/L7O5onNHP+5POd7yNrRgYqd7AWUodccrHzPTpqVFnKHcJF1hAh3BgwCh5sJVtjxZuPrh29y5VrY6KRIVVDAPhE/SdC5e7DISMPAeBHs3/E8lOWF3Wd1c2eDcCI71/D3iseL0u5Q7iTNUQINwaUgoecD/bjWn5/hloALaeNpGF6/lZaRhhFEyLEAFTwfQ2lvEJFnw/DNDx/i8JW1JjlK3gpZbiTNUQIFwasgu8rBesssob6PQ/KP16eBW+fW87LQF3jum8YRRMixABU8H0dFRRa8IWhFLz6WxTKcq/ARaPcMxBa8CFCwABU8Ao9rejLTRccVO7q1aud+Pdp06bxP//zPz0q2+4Cx4Iv49l0xYIPFXyIEF4MOAXf8fAjiJO/wvoDDuPNIz9D29KlPXLfStMFuy34yZMn8+yzz/Liiy/yyCOPMH/+fGcH7McJjg9+F1jwoYsmRIgBpuDbli6l/dobER9uASmdJFXdVfKVpAt+4dkXOOu4szjsoMOcdMHV1dVOUrJUKoUQonsV3U2hFLBbERdCty34MIomRIjdK9nYxh/9iPSrhV0knf/6F2S8mSNlKkXL966i9b4/B16TmLgfI668smi55aYLzmQyXPzFi/nxHT9m3hHzMFKGky746aef5vzzz+f999/nD3/4g6PwP07QpWVVl6Pgu2LBq1mTQIQumhAhGGAWvMwEpwUudLxcLFq0iNNPPx3IpQt+7LHHmD9/vqOoBw8ezOuvv87Q4UOZcuAUJJL6+nrn90MPPZS1a9fyzDPPcMMNN5DyZUv8OGBXWfAJLREq+BAh2M0s+FKW9ptHfgZ9w4a849FRo/jEH37fpTLLTRdcLiZOnEhtbS0vv/wyM2YEpo8YsFA++N6y4B0FH02QSqcwpUlEDCgbJkSIijCgev+wyy6FpJcpSSST1vEuotx0wdu2bWPfffdl08ZNrHlhDRLJ9u3b0XWdd9991znvpTde4uVXXiZVl+KNbW/Qmm7teoV3EXqK51YtrgYp+GXvLGP2otlMuXsKU+6ewpX/7zvWD12w4LdntgNwzF+O6bKsbUuX8uaRn+HVifv36GJ9b6K3+Ij7A8qpW3+q/8o7r2XVoZNZu99EVh06md/ddEGfyDagFHzDvHnUXX0FcngTCFFRkqpCKDdd8D333EM8Hue2u27jhu/ewMwZMzn66KNJpVI88cQTTJs2jSnTpnD6Kadz1X9exaAhg8iaWTbs2NCvlXxP8twqC96/R2DZO8u46omraMu0Occ6Mx0AvL3trbLv/+h7jwI5Rb+xY2OXZFWMUvqGDT26WN+b6C0+4v6AcurWn+q/8s5rabxlEYPbDCLA4DaDab99kgmr1+1y2QZMumCFLZ1b+LDjQyvZWHLXJ/t6t+1ddmZ3MrZ+LHXxOs9vb2x7I9A3HIvE2GfwPr0mU3fSBc9dMpeWjnyijZE1I1l+SmXUg/e8eg83rL6Brx7wVeZPm1+0jMNfMbnsQZOVM2u56LfPlHX/o/58FB/u/LDbshZz9e294vGy77Mr0ZPPqb+hnLr1p/qvOnQyg9vyZ56b6+GSS3Je8Z6S7WORLtiPvk5VEPTiLLTw158XBCthYioFx0WD10UTdK+I3Xyd6Z1l33/TzmASlUpl7Q6jVF+hJ59Tf0M5detP9W8MUO4AQ9q933eFbANOwff1jKTYiyUWiVV0vD+gEiamUigURRN0L6Xga6PVZd9/aPXQwOOVytodRqm+Qk8+p/6GcurWn+rf2qAFHt9a7/2+K2TbLRR8V5R2n1vwAeUPqxmWt8lJCMGwmmG9Lk9XsWD6ApJa0nMsqSW7xHOrdpf6FfyC6QuICm9AV8Q+ZdqQKWXf/4uTvph3rCuyDrvsUkTcy+3b3cX63kZPPqf+hnLqtmD6AhJaoug5uwrZC08j7bPZUlG4Z05u7O8q2fq9gk8mk2zdurXPLfNyUezFolifFGKRWK+yPkkp2bp1K8lksvTJBdA8oZmFMxdSH7fMj6aqpoJMTKVQKIqmeUIz18++3nOsVrMs97E1Y8q+/5w95gBQE60BYFBiUJdkbZg3j0HnnON874nF+t6Gek4qLLQYY9buBlU3pcCD6tY8oZlvHfwt53tf1n/OBdfQeukZ7LTfN611Ef51/kxWT0nuctn6fRz8mDFjWLduHZs3by7r/O2Z7WzPbKcz0cmHsfwFt97Ghzs/xDAN0sk0VdGqwHM279yMJjSaqpposf/1FpLJJGPGlK8kg9A8oZnWdCs3rr6Rm+bcxIHDDuzSfYqFSTZPaObqVVeTNbNUR6u5YsblbPzf71eWLtg2As6fcj63vXAblx50aZcHUc0hB7PtN79h9M9upX7u3C7dY1ejeUIzN66+kbH1Y/nTcX/qa3F6FM0TmvnLm3/hmY3PcP8J91Mbr807Z86YOVzP9Zy6z6lcc/g1fSClS5YLruGeZ/7OgSvXM/SOn3P4gZ9m2dJT2Z7ZziMnP7LL5Oj3Cj4WizF+/Piyz//Fi7/gV6/8iu8e8l3OnHhmL0oWjIvvu5gtnVv40ewfMW/PYIvvkvsuYWj1UO49/t5dLF3XoUIcu5PjpdhGJ8M0nMVmiezaRid78VbNiNrSbcVOLwq1k7YSwpH+gKyZHbB5eNK6RcKeMlLUkq/gVf/pL0ELMmXJq2etnfS6qe9y2fq9gq8UFe2W7AUU8jO7kTWz5bEa9SP0BJl1sVQFaSOdK8s0kHQ9VUFtrJaoiNKeaS9xRREol+DupuCNbL9RcD2NlGGl93D3FTf6nYJPW3KauiWPIY1dnuW03/vgK4XygfeVgledq6SCLydlbj+Ckrc7HbRYsrGMYVk5VdEqyxI3umDB2/eNRCLUJ+p7xIKvlBO2r6FLfcCmSlZ9pJCCV/XuLzMYmbbkNTK2Jd8HFvyAU/CV0ML1BlTnKqbgdVPf/RS82QMWvFnYglfWWVW0ClOajuXeFQs+QoT6eH33LHil2HejmZZhGpjS7DcWbE/DseD1/m/BSykRGdtyt3WCYYYWfLehFtr6woKXUuYseIpb8H01w+gqlLzdGTzFKPuUVaYUfLcseNF9C14p9t3Jgu9PCq43oBR7KRdNf5jBdGQ7iOm2Lsq4fPC7eHYx4BR8sUiNXVG24yIq4LtVVlZ/6ISVQLlXekLBB4W8pnTLOquOWeGRpmGV1xXSbSFEty14uRta8P1JwfUGSvrgjf7zgmvPtBPPWv3R0G0FL3V0qe9S3dRrCl4IkRRCrBZC/EsIsVYI8YPeKsuNvrTg3R2rkAVfjo++P8Kx4HsgiibIgnf74MEVxdIVC54IDYmGj68F30980D2NUj74/jSDaUu3EVeBWHYm2Z5Yx6oUvWnBp4EjpZTTgAOAzwohDuvF8oC+teDdD65Q+arz7XZRND3ggy+2PuL2wUPXLHjV5lpE+3ha8P3Igu1puAMT1GzPD2eRtR/U37Lgrc+GK0wSdq18vabgpYUd9teY/b/XVz6dULwiPvDegseCL6Xgd7dF1h6wPhwffIDSdPvgAWQ3CD8EgoZEA9sz27v+It0NLXjlRhuILhr3wmpJC74fzGDa0m3E7ccglQVvDiwLHiGEJoR4EdgE/J+U8uneLA9yg7wvUhu4O1YhBa8e7u6q4HsiDj7IglcDuNpOLiZtC74rhB8REXFSK+zI7ih2SUHszhb8rvbz7gq4lfru4KJpz7Q7Ct7Qc88Fdq18vbrRSUppAAcIIRqB/xFCTJZSvuw+RwhxIXAhwNixY7tdZiW8n21Ll/L+T35EdFMrW+rhr3MHM/v8K4tub1/2zjJuff5WNnZsZETNCBZMX+Cc3xsWfNvSpWy6+Rb0lhaiI0cy7LJLPTlR3PI0v1nHGX83iW1uc859YlIkUN6gegAF61bIRVOsPfxwv9z8131qzKcAt4tGhUmW/6J2L7K+2/YuAJ9c/Enq4/UIIWhLtwXKGNTGvW3BV9Ju5cL9bHRTJ67F885Z9s4ybnj6BodcpTHRyHcO+U6v5EXpTh39156zfy43UFejaEqNpWKyPP6b73PiYx0MabeyQj54VC2DTvgP/r7u74Fj66Znb+Jnthjvbn2DT0oZGKffG/3AjV2yk1VK2SqE+BvwWeBl3293AHeARfjR3bLKVfBtS5ey7qrvEUtbjT20HU57YBt36d+DCwlsZMUao/zFipkFrPPdA6yQAs8a5fvgFbOQtAm6FbMQWAmx3PLMWmtw2sPbiNmdSt+wgXVXfY9Hj43QMtHwyPvCphd48K0HPfW46omrEEI4dfDXLciCL9Uefqhn8kH7Byx833vd/W/eD7gXWZX5U7kFv7plNQ+89YB1H6SHKcovY6E2rvvsZ+2b9rwFX2m7lQv3s8ma2TwFr5izlCUJ0Jpu5epVV3e7bD+6U8ega295/hbn90I++GJrEKXGUjFZHv7Vd/jSwzpJu9mGtsMX/ncHt+v30DJJ89TPPbaUBf/chmcY/PZDOTlt+XqrH7jRm1E0Q23LHSFEFXA08FpvladQroLfdPMtRNLejpDU4ZQVaW59/tbAa259/lbnYSikjJRzvrtjFXIRVRJFs+nmW5wO6dw3lWLTzbfkyXPmSul0QIVIOsspK7zWTspI8ec3/pxXD13m77Jz1y0oiqZUe/ihXhJvfPRG3nWqbH8UjawgVYCS8YG3Hig6DXbLWKiNd6xYYcvR8xZ8pe1WLjwKPsAPfevzt3qUu/u67pYdVFZX6xh0bTkummIukFJjqZgsn1+p542tpG6NOTfcY0uYkpiyDQyDn734M+c8JV9v9QM3etOCHwncLYTQsF4k90kpHypxTbdR7iJrIXaeIe2Vs8Oo4+6pYUEL3vT647oiozrulsfPFlPseCX+WX/d3IOn0nZSsxZ/p3YjFwevwiQrt+C3praWPNepV4E2NtvthuuFXDS9xT7kVupBSq7Y/XuaXag7dSx1Tqk4+CAXTVdZujZ2bOzS2Iq7RNBM+LAjl9lWPZtdwULVm1E0L0kpD5RSTpVSTpZSXttbZbmhFHupRdZC7Dxb6ytnh1HHe9qCL8Us5JbHzxZT7LjKGV4OVBlKXvfgqbSd1EvPT97ghpNi2ey6BT8kOaTkuUrGQm0cqa+3y+95F01vsQ+5jYYgJVfs/j3NLtSdOpY6pytRNF1l6RpRM6JLYyvmU/DDqnOkPurZ7AoWqgG3k7VYvhM3hl12KWbMO4FJRWHJkYmCTCulmGXcHauQBe/ONlnqJTTssksRPrION7OQm8XmnjmClG8+ZiZiLDkyn+Xm1H1OzatHVETzqAPddQua/i6YvoB4JF7wGj9Um4xvGB9YPuD4jc0u+OBVe566z6l57D6FZBx22aWIhPdckUxSM3uWXX7PW/C9xb5UyoJfMH0BkYAhH4vEepxdqNK+4b/W3z7uvlnQB18kiqbUWComy71zonljy8/QBN6x5bbgYzLCl6d+OU/OXcHCNfAUPOUp+IZ582g651zACs7fXA/3nTiYYy78YcEFDsUsozqbn5mlkigaKB1J0zBvHr7GzkUAACAASURBVCOvu5ZIteW20JqaPMxCzROauWjaRQCsmqRx34mDMaotZRUdOpQx1/+QYy78oRN6OKJmBAtnLuSqw65i4cyF1MXqAIv56PrZ13PdrOucc4ckh3jqFpSLpnlCM1+Y+AXneymmGuWiGVY9jIUzFzrMS0OSQzh05KFURavQhLVopXzfFVnw9rOfPWY2Xz/w67l2jDc4Cn949XCPjA3z5jHkkoudcxV7U3Kffe3ye96CV/1IKcCeYvjxL7IGlTv3E17yksZEI9fNuq7Ho2gq7Rv+axfOXEhtrNaR8dR9TnV+70qYpDOW7JlZdNiwsli6mic0c9xXbuT24wSmrc+31MEfTqhhzElnOoaJqp8aW9Vm7o0wsX4fjtzjyJyc9otY1VPNWnuD6WngKfgKwiSrD54BwE2fi/DUL77IDdevKtm4zROamThkIuPqx7H8lOWe88tS8GVY+W40zJtHffNxAIEdcvbo2QBceeiV3HD9Koae+nkA9rj9VzTMm0fzhGY+O96KCHngPx5w5G2e0Mw5k6zQM8V81DyhmWPHHwvAD2b+wFO3QmGSM0ZYbfjTI36a1x5+uJ9N84Rmjt/zeKes0bWjSWpJBNYokmbXo2giRJg7zlJkCw9fyBNnPMGJe50IwOLjF+fJWDfbakMRj7P3isdpmDcvp9h7KUyyeUIzk5smk9ASJdutXJRS8ACj6kYRi8SYPXo2+w/Zn3+c/o9eo45TfePKQ6+suI7NE5o5foLVPy6fcTmTmyYDEI1ES/rgDWkEjr+GefMY8uUvATD27t+VTcHYPKGZ1ZMTYPMpX32OxpVXP8JVh13F2PqxTGma4qlf84Rm9q76hHP90MRgz1j3G0lHjDkiUJ/0BD7WCl4pD82sLHWAlDJQOVeSiwbKL1PaaUedhT8XVD3VvWTWPjeVGwSF8mSrOrhztij53KGF7nP993DKL+Nl5c8H75SfaSNtpElEE2gRZcF3I11wJEI0EvWUUUh+qyx7tmBn/bMu6P2NTrrUSRvpHtuUVyqKBqxnXR+v736unjKgnkeh9L6loFJNZIyMo9Qb4g0lo2igyG5RJ0tpZc81njaI2Hsyaju9eZWCypKZnIxS14u+fA1pODPXnsaAU/CV5INXSiRiVraztNBD9eSiKeBaqMRF48hpK22jLX9A+pWlOlemU3nn+DuWkteds0Uphva092VSKFVBJQre//J1yk+3WwpeS+Qs+G4mG1MDxr/5JdCyDVDichekKlAyFVJYXb0fFI7Sas+005BooCHe0L18+WXAyR1TJGqqGJSRkdJTOQWfaCicD77EGgR07blKKanemTu/JiU9hlWQMSldBhaG4THm/GPIMA0ikd5RxQNOwVeUTdJtwVeg4KWUgdZ3pRZ8ueGKOQVfxIJXCl5Z+66Y30LuFXW8IgveLGDBl2Hp+ukUnfIzbaSMFAkt4fLBV27Bq2cfERFnJuBYWkWSpQUO9l1gwSuZekrBl2PBt6fbqY/XU5+o716unjKgnkdX67c9vd25Xi2s1sfrS/rgoUg+GrUz2ihg4QfAkAY1rndUbSo3vg1pBOuOdG42KHUvy1bQGFK+/J7GgFPwlWSTVAM7IiuLDTekEbxhpIJcNP7PReVUyYoCLHh/fdW50tXBClnfqg5uS85tVXvKKfSSqKC9nXPtweGUn24nradJaslcCGc3SLeFEM6AcepeLA9IkOy7wIJXsvWYgi/DgnVb8ND1XD3loLv1cyx4I+WkCq6L15Wk7IMi+V668FxNaVKbynkEalK5GXo5Ch7de07eTFrqFYUuV4IBp+CV1VAWZZ/9Fo+YlWV4K0TYUWkUTcUWfHu+glf1VPIEuWgKWd/qmnIs+EJuHsfdUsbGLX82Sad8lw9edXQVPdNVyj7lg1dl+P+6IV3+2Dwu1t70wSsXTRd91H6Us8iqfPD1iXrne2+h2z74dM4HnzJSxCIxqqJVBV0+5dTfea4VWPC6qXst+E5vXw4ax4quzyrTaxAGrWOpGWdPY8Ap+GIpaf3oqgVvSrPoIqtA9FgUDRT3wfvdHkGLrIUUvLrW44M3g33whXzYjlVeRjijf33EKd/2wce1eE7Bd8cH71pkVQOraD57l+zm9u32h13ng++qj9qPchSc34LvTT98d3zwUkpHNuWDT2pJktFkSU5W/2cPuriBrrYz973W5YMPMvbcfKwAlHDRGGa4yFo2KrHgVUKrSqNoTGkGnq8eYkJL9EgcvCOnUtoBPvjCFrxLwSvl1o0omkKMThVZ8D5GJ38UjcdFoxR8F3ayRogQEREEIi89c3AUTe45GHakkpPFshdSFThl2TIp90N3UcoHrZs6O7I7dr0F3wUXTUe2w+PiSekp4lqcuBYvy0VTaEbuREzplfnga+13lFmVoDbldf35x3rGzHg2OvkXWcMomm6gIkYnZcFXuMhaykUT1+LlKfhywySLWfB+H7x6GZQRReNY65VE0fgUeSXt7c/V7/b3p3RrkTXnoul6qgJ1Dy2i5bmDSlnwTht3YZG3UvS0BV8qimZ7xpqd1Cfqd6kF3xUF7zYwlA8+GU2S1JIl4+ChiAXfBcPBUvASM6phDGmwfPAuC94/jlN6LpNkKi7A8M7486JoQgVfPiqJg3cseNkFBS/1vPhl1al6y4I3isXB+8Mk3XHwBRYY1TXuaIogpe8+t2AcfBmK0G9Nuxd51QDOuWgqj1d254MHa3t7OYusHgu+TVnwvbvRCVwKsDd88AEWvLLWdwcfvNvASOtpJ8oqoSXK88EXiKJx1nb0CsKiTSuKxqirQtbV5Png/eM4Y2ScXDSpRATKiYPvLz54IcQgIcTU3hCmJ1ARo1M3LHjIvyZrZImIiEex+OHJOFmuBa/nLHh/vfIUvBNFk2/B50XRuL6raAq3Ve0uq1QUTSVx8IEWvJEiHom7omh6wIIXWlmLrF4LvtX+UPkib6VQbdljPvgSFqx6aTckGhzGq93Bgk+baWefRCKaQDf1kmHKpS34yva91HaCWWspeE8cfEAUjZULXiIjEfSYbcEXc9GYRq9F0ZQVfCmEWAmcYJ//HLBJCLFKSvmNXpGqAjzwwnp+8ujrbGjtZFRjFQ17WoOlmMJRLCoHPb2ec7AVfCU+eFcMbJRoHktOS0cLH7R/EHiteriz1hpkf3s+r27aUpKp6Y6WLA0Aus4/D5vCG58/lHvGfsDGjo00JhstWXw7We9fey//fffvGVEzwsl5UmiRFSzmoxE1I2hPWQNelzqzF83msJcz/MdjO/iBzWSzbG4bbfEcM84+TfXMOtzAONDbfn62rHvmCFomeUMXN+/c7JTVnmln8euLWf7+cqsetoI1UynePPIzDgvP+rOO4EcNTwQy4Dik2/Z0V4vkFHzxOPic7Osv/yYvX3sFyT0+QTWwoW0dX1wy11Pe7LWmhxmomEzFGJSUTE9teIobV99YFuuWuq+fnaj2iE/xmeX/y/FbdXYkQYhrWdv5A7Y1RHjgM9Us3zflJBq7ZtU1HPWJowC47YXbuO2F26jSrHwonUZnnpwr77yW2B330dhm0Nqgkb3wNDo+fVCgbG65VN/4aEjhF5i7jop5qzXd6sgqELy+9XVrlmdmeG2bRSnx2b981kmxoaCbOp9cKzl9pUHyhrP4ewBLm3phP7P+KW5Ycn1ZTEqph5cz/S1JzNgMH2xmAsDJF9Fy5FHcsqyTpvZOVt08mdV7GhzytsagNgMrMYZkUKuJsWm7d5E1YBbcW3Hw5d61QUrZLoT4EvB7KeX3hRAv9YpEFeCBF9bz3fvX0Jm1Htr61k7atnUgkoUXWd0sKsI23CKyshzMTgysabDs/XyWHInkxc0vsuydZXmdJmtkmbXWYP7DEnRbwZVgaqrvyF0/qM1g2m+f5KnjBC2TND5KfQTAO63vALC9YxtxINvZgUSjpaPF2R3qV27rd6z3yNzS4c2NPeXFj/jCw9LDZHPW/a20PPg950US39zG/IfhnbGvgD2vC2LLmv+wBHRWTdJoTbWy7J1lfLA9/yW4LbXNukfnNgYDZDLoGzY47dR4yyImHGvV3c+A4ybdBitDZV6qggAF/8r/3Wu9QAEBDG4zMNqt9ly7eQ0tdvu3dLTw6B3fY9xfTYcspphMQFEGJSXTkjeX5DFpBbFuqfvOXmvmsRO1LlpMjV1GfQqw+39Tm8kX/ncHHccJVk2yft+a2sq9r9/raQOl2P1ybn7gfg6460kSdrMNbjNI37yIJW8soWV/6ZGt5m/PMeK2/3HkUn3jwarNcHxes+cxGrmtdiftN5ItqS3OcTWuN+7cmMd+tM8zH9L8sEHC1V/zWNpsw2HxK4to2UvPa1v/eG1bupTOH95E3G//fbiF1kWLGUquXY55HgTWiSrPpGbC0PfaaH38Kcdf0h/j4KNCiJHAaUCvk3aUi588+rqj3BVK+eDdLCqafYpmSt5vf7/sclXnU0w4QQtaEhnIzJI1s4HsS8WYmoTvHkFsMi9tsd63bR0W2UXc1YfUoPBbDu+0vVOklsEsUTEzN0twyzN+8SrneyG2LCXzttQ2bn3+1qKRTls6NgUeT2S9dQ9inXIvsvpdM0G+We2xf+Yfs4uQvjWAU1ak8+pWSKZSDEqFFn4LsW6p+waxExVDUH8pB1kzy4TFOeWukNDhtL/lyxy74748uZI6HP1o8LMMYjSqBH72oyMf3uAod3f5bpY2ZcEbujdyqRCT0qabb4FUeS4m/zhViEiov2up8z1vL4nZe3Hw5Vrw1wKPAquklM8IISYAb/aKRBVgQ2tn/kFRXMG7LfWIzP3NmOWHqrn9b5Wy5OimXpAhpjtMTTv1ndaHrNXD4wGuZn/HKuUbLVR2EJJbczsii7FlgWWxlJoxKSb6cuRS91K+fbXI6rbgiy2y1uws7OeP+PRiuc+jVP02dmws+oIr1n/1lvJD/ArJ193rgo43tgW7OQe1Bh/vCeYi9z0aWoP7jIelzQ5/jQQ0b+B4LcH4VC60zR+h1G2/i6KRUv7ZZma6yP7+jpTy5F6RqAKMaqwKOGrHwRdYZHWzpWj2w9ZM8sguisEdOVIpS07WzBZkiOkOU5PKKR038xll3GW74SdkKFVGMaSG1Dqfi7FlgeUjL8VaEy/ik/TL5bBO4bXgo5FoWT74jqrCw8CvCMp9HiNqRnSLQanQlH1EzYiSLETlyNfd64KOtzYEK6mtDYXr0l247/FRY3Cf8bC02f1AC1DwQfJ0pa2DoDc1Op/7XRSNEGIfIcTjQoiX7e9ThRBX9YpEFeBbx+xLVczbMBFhJxsrkOzLzaKiBm/ErKyzuaNSFkxfELhAIhCBzCxZMxvIvuRnalIy3jNH5Nl5QWwy+w6yCCpqI9Z1bgte+aT9lsPImuKdN0jOjABi3pdhKgqvnXKQ833YZZdixvPZspTM9fF6Fkxf4MgVhCHxQYHH0zFv3d0MOMUWWYtF0RhHHJJ/zC4i6hsiS45MYCa89U9Hg2Uq1DdikZhD1BIExQyk2K389w1iJyqGoP5SDmKRGO+cPpO0z/ZJR+G+T+ezf2UvPC1PrlQU7vt0sOINYjSqBH72o4eOqicT89bTz9KmFu/9BkQhJqVhl10KicLsYG4Umo+ZAjadczRgtWl/3Mn6a+C7QBZASvkScHqvSFQBTjxwNDecNIVE1KrG6MYqhtVbD6NQFI1iUamOVudcNCbOxo9y4N692TyhmetnX+/5PSIi7Dd4v8BVed20FhpvP05g1tpMTUOG5DE1fevgbwGwav8IEsjY/bG9WvCv82fy7FTr2saEZRkoZR2zNVNcl85xxVHq71gNyQYGJXKKVN1DMS09O6Wa24/LKfnN9fDLeYJh1/8AEbeUT6qpjtuPE3wwc3zuvvPmMeyrFqOSYsu6/TjBqklWJ66KVtE8oZmGRIMz81AWa1OyyZJBq3buJ+wXSnTUKDZ+9STnPn4GHGeRVbloIuUtsu43275eWPJua9DI7jkGgH0a9nIG38iakRxz4Q8Zc/0PHfKH6KhRvDn/6ECZgvpGfbye62Zd5xCS+OFmBvrS5C/lHW+e0OywE+Fql7oT5jnt3V6F88w+qhVO26sX6siakXx+3897+rx/NqeYns77xp20XnoGWVv/bGvQaL3sDI6df4PnfgtnLmTOBdcw8rpr8/rGyonB9JRqLColr/od5IwS9zHAia5pSjblsR89PTXBijP3wxC5frf4xEYvS5ttwR85ak5g2/rRMG8e5hXzkXbbSvu5G0MaqDr1JPSIdXxLQ4QX7SGgzgXQo4KPhiTY9imLsCQZTQbuKO9rBV8tpVztO1a5I7AXcOKBozlq4nAmNNWw6jtHUpOwN8oUiYNvntDMMeOOyVnwXdjoBLlpf/OEZoZWDeXkvU9mzblr2G/wfgytHhp4rXq4qyZppE47BoBRN96Yxy7zqTGfAmBC7TgiQHbmAQBsX3Am533jTqY0TaEqWsW3D/62JYtvo1Nch//81H+y/JTlVMcsZRlkOQxODgbgulnX8fBJDwNw3uTziIooR449klWTNN6ebL0EvnmBxqpJGsnj5pKcMgURj/P0L85n1SQtr/1qZ80E4H8/leCSS6IeBaNmV3EtzjHjjmHNuWv41zn/Ys25a/j5Z35uN3JuBhbfc0+iw4ez94rHOfAL1ovj7P3PzmPAcacqAMsH71/IDAyTtMva3ABvTIgz6+mXaRq7DwBDE0MYXj2cUTWjnPIa5s0jUl1NcupU9l7xOONOPRuAH87+YZ5MzROaaUw0MqpmFAC/OupXNE9oDpxJnLHfGZ7rFSPSV6Z9Je++DfPmkdhrL2JjxrD3iscZepFN3Th3FFd8Zzh/mW21QeKW61g1SePQEYdy4l4nMqxqGMtPWc5Vh13FE2c8wdWHWRE91826zrn3YSMP8zA9zbngGj4caSnhQx/5B3MuuIbmCc1oEQ1NaDx68qMeCsSqAw4gOny40zeg8HpP84RmDhpuzf6uOfwa59hJe5/EsKphnDnxTOfca2deyy+P/iUAN336pvwINTPLusPH05mAD4bCJZdE+cZ3H/Ccpyz4MfbzOHGvE0syKelHz0TXIHXGsZg//CYAbdddQv33LmdbHbw7Av79uytZva/V5ltPOJy3R0Bs1qGs36uRzppcP6zSqgJdNH0dRbNFCLEn9otJCHEK0DOrDz2AhuoYbZ32Fv0yd7KmjbRjwVeaDz5o45AhDSfBVYRIWTtZFYOQPypFyQfQ0WmtZim3gGEzxWSMDIZp5BJ3SQMppXOvmJ6/c9RvOeim7rgBDNNwZItFYtQn6nNhjHYkiQoV000ddB2ZyWD6kp3lKmrdK6LnjitZ3WGmqs0U8tIFY0UYqWgWJWPQvgV3PniwNzr5k40F7XC0y0rFIJLxUgVK0yRrZvOiPaRhOPl+SiW4y5pZmqqsmYnaWBSk4P2bjlQfKJjbXNdzO5ftv1EixLQYUVuUdNYKREgZKSdjpxvJaNJTdkJLBL4EhdqXYO+mNkyL9MaQRm6B34Y0DKThzbJYbEFfla3+Zo0sWTNLTIs58oGVYkGtlQW1SdbMUh2rJqbj1D8vz4/9jFKZDqcepWBK0/LZRyJEklb7mem0Fb9uWB6AjJHJ5atJWakKtGQVUhMIV6qCZDQZSJrjHwc9hXIV/CXA7cB+Qoj1wKVAYSfiLkZDVYzWzqyHSq/UTta0kXYWWrqSTRK8L4WsmXWmWZFIcQXv+B3t8KsgBa8IDjptBW8kLUWsZ6zjKSPlyYNhSMNSSna940EKPsByUGTUhvQp+Hg963assyts1aXOTDj3cXbM2i+pvIx6LgVfE/NOs90bxfxT01yyMVeGx3TaeWE4Cj7ghezOBw+2i8aX4KzYRqdUHLSsScbI5HbQGla7+BWF1HUnJFC9sIplEB1cZc2UVGqAIPn9aQPUFv+CqW8DFLwmBbFIjKhh9YNUxlK+aSO3G9QN9V2VXROrCVbwdkCCytXjVth56Q4MA7JZTx3LUfDqPlnTVvCRmEfehnhDTsEHyJg1slRrVSRcCj7/xWy/zNNWu5STJlw3skQkRKIxIgk7sCOdRjd1ooZVVtpIOznjZTpNXIdoshqpRYgY0iknGU0Gpu3uUwvejpo5ChgK7CelnC2lfK9XJOoCGqtiGKakI2PkGJ0KLLIqpIyU46LRzMrzwUN+2gG1El7KgnesknRpC17lyzES9i5Q24JPG2nLanel3nVnyItn8y3LoI7lVvCqPjEtRkOigda0tW1fWW+10t4Ra2Rz8eF2Hfz1dRS8Yeb5Ud3tV5YFn07nW/BBCr6cOPggZWnXLx0TxHVb4RSx4KWUoOvWiwcX12xAn5NSkjWzzjpIJRa8KrNwbnMj13eUBS8jtoK3DqcztgWvp0gZqbxFTUfB25uMamO1gdaxULMuO1ePW2H75Q604Ivko1GKXcmQNbNO33DLW5+oJ6YVUfBmlhq7jzr1979Y7Oeatl985WRBNe0xKDSNSKKwBa9yxisFb1nwGhHTa8EHcSr0qQ9eCLFACFEP7ARuFkI8L4QIXiXqAzRUWQ+9rTNnNZR00ehpZzNLxKzQgvcxEoHPRSMKK3i3Ui3HRaM6qpH0umhSegpJzjIwpem5T9wgz3oNykWjXDSmNJ2BrSz4XIWtutSYrsGlCBPsOvgVruMyMHDWAJzbuWZA/iiTchV8UPv6FXzQTtZAwg8zZ8HHdUvheCx4I+vNf6ISVikLXrkFA/LmqJfwkCpLwTsWfIBrwJ/BU80aCuZVCbLg8Sl420WTMTJkjExeZI7qi6rs2nhtcQu+Pd+C98uNreDdfaLQhiZTmjkXjX2frJkla1gWvFvehniD01+C1pMkkmrT+r2QglfPVc1syqKaVMZKNEokmbPgDdMgalib4tJG2skZLzJZ4jpEkknQNCKGdOStigb74Pt6kfV8KWU7MBcYApwN3NgrEnUBjdWW4mndmSmbkzVjZDxhkmVndpRewl0F3dSdzldMwWfNrBM5krPg8zdZ+RW8nrTubdrnqsHvWKgyN9iNqgTxrIvsogwXjW7qHhdNQyIXYSHs6b5jwZtZpL2hKpL2lqHgVvC1sVrPb25l64//LeSiUbOTYuGOeYusLhdNORZ8KmbNfIIseHDNqmxZTPVy871I3VDXVkerqYpW5Sz4AMuxkAVfMLd5ARdNNBIlajdfRs+59NJ62uPThnwffF2sLrC8SDEXjY87QBrWbNL9wivkounIdjjPzT27US6aPB+8FuyDd1J121Fkyv2aN3Own2vGfvGVxWNgb7oTEc1S2oBMZxwXjWa7aBzWp7Sl4EUygdQiCDPH4ZzQEvlRNGbfZ5NUwaXHYeWiWUvhnbm7HPVdsODdLppKomjcuw8dkg3b968seE1oRf2xjl9RKfgA8gHVMR0F71tk9Q9+twVvVCeImqDbLwM10IJcNB4L3gy24NX0vNrIWU9+F43fElJ1iprk+eDd2STLcdGgW4u6kBvYgUz2/kXWiObUqZiCVxZ8Om7NfNwWvDR055k7SkqtP6RSnnWfIJkct5fdpsqCD3TR+DJ4lvTBG9a6izRNp71zPnj7HraLJm3kUu664ffBF7bgrb9qkVWtESm5PTAN0PWyfPDul5rfBx+NRB354pE4SS3p+OD9itlJ1W2LXtAHbz/XjL2WVdYiq93nRCyGlswZZ4aeJYL1MrEWWe3+l7YIPyKJhGPBq9lqPBLvlxb8c0KI5VgK/lEhRB2UcHLvQjRWWUqqbWfWGYzlLLJ6omjKzCbpSdwvdc9f9ZCEKELZZ2adSAZhW4AELbLaHTOn4K17m1lrMVkNGHeUSE7B20pbJaOSXuXorosTReNaZI1Goh4LXlm4avqrm7qjUBQ1WTELviqW23GsUimb0kQiy3LRWDeUSCMnY9DzyltktV00qqygNnDXL9CCN/KVlPNCNk3PYmIxC16tayiFps5VoaPV0Wp0qXsiUhwffKHc5upF47LkNSl8UTTWPdJ68UVWJVfQIquUMmfBt5ZhwevWYr/p4j0t5IN3L9AGRtHYPvj6hJVpslAUTc6Ct74X9MErBZ8tPjtyQ1nwkUjOB086jZG17q2ZXgs+utMa1yKRhKhGxJSOMePeXQ0547CvLfgLgO8AB0spdwIx4Iu9IlEX0FDdBQteT3miaCpx0Sg4U3O1/dl+SEUteHcUTcY7vXYjz0UTsx6VmbWmhv6FXl3qSPt+erXXx1+I0cmzyOoPkwzwwbsteGXFkg5WuEoWv4smFolZndrXZgoeBS+8k0SPgi+wyOqORlCLrMX4MMHlg49ZM462nR+5LHiXH9m2Wt3HzHS6aJ9TiigaiXoseFV/tT4xtn4s4LWGy/HBg9XW+VE0dvnZ3Et+Z3ZnYQWfbkcTGlXRqsBcKWq2q0hnivngnRz6LlKNQj54twXv9sErhagMELUpq1AUjbN+ZB/WpLVukO+Dt100mfJdNKbdzpFoDK3KMlZEOouZySn4jJFxfPDxDuu5RZIJa2HWVvBaRMvbyepfN+pplHvXw4HXpZStQogvAFcBvUcFUyEabRdNa2c2t+BVYoKRMTJdioMPot5Sx1TnK2XBK7+iSJeh4NXAikas3YTZrKfTOouOpukQg+j2jEaFYRaLonFb8P4oGgVlvSXtPDfuKJpIJthl4igcw+uiiWmxvNmCG04ecNN0drDmBNYrUvDKgi+l4J0omrj1Quno2OZY8B4r1G/BYy0Al+ODV+sajpVqH1cRRnvU7QHkU9UVlJnci0ZmM65FVlvBKx98NqdYt2e2F/XBJ7SEpYACrGNlDJXjg1eK3f0iLMQ7G2TBB/ngFQNVoSgapajdOZiiZpAP3jZ2st6xUQzSbo+IFiWSUMZZxlmD0UzQsymq7SrGd9ounUQSGdXQjFwQRkwLVvC9lQ++XAX/S2CnEGIacDnwNvD7XpGoC6iOa0Qjgja3gi/DB686rTCDIyCC4LHgfZEZTg4Ukb+zU8FtNYtiFrzPir/PGgAAIABJREFUB29oAl2zznVbQ+6XjLqPbr/wFC9roQgS1ekEwlK6BaJolPWWNGwF74qDV7MQvyXkuGhMbxSNY8HbMhWOg5d5Cl6Wo+BdXVpNh4vxYYJl1UkhSNtjbMeOAha8aneXgjdT6aJ9zj8rUlaqkkm1zZhaKzWCn6rOfY88uZUFn806MyZN4rHgM9mcgivmg08ZKZLRZGCulKyZdYwhUyl4vZgFb7edKyNoORa8+4WmomiUfMqCLxRFk7Pgc88gagT54G1jx26XcuPgwYqiiUZjZDQgnUW37xExge0515qSQSgfvLLghWXBB3Hn9imjE6BLKaUQ4j+An0sp7xRCXNArEnUBD764AVNKfrnyber2zULEGmwr77wW7Y57Gdxm2iw3gtqUJDZyJDNm7PTEwc94aSev/exwZKsV+601NjL8e1fmpRAIUhbq75B/vMKbX/0MF2/YQFtjjJWbruWq6uWOhVOlVTH9pR2cuPKvXNAORKw82SoixQ3VMWN2cUv//Ve+GrEGs8eCtzvfR6mP+Pryi/kGsHnD2wwFZl6+iDd/upKZM6z8N1kz62HQkUjea30vR069/O/84hc6dTeeR2xIHbNmGqyapDnhpOkOi7T5K499hbtTOlVA5z+f4hdv6DS1r+RVbTIYBtFRo6iaPh2AqCEZ988P+MXvrTTJUmwkImHDXfOYdbBB9JBgH7wwTbJaBLf6X/72IxgNlkKc8PR6Xlp4uMMY9de5g2mfc0DZLhp3O3xpbZLPCMjaojz06v1M3QZ7AOvbP0ANkwUrFrAttY1J6Sause8n0yl0qTNrrcGht/03r+642VmG314FS46rh33gpc0vsfy95XToHVz87cmcvtJgcTtsrX+Le+YIFmuLAbhg+QVOFJaKtnLL7zBEpVu5z7aUj158JIe8F+WLwNtb3+Sxf7/DIXa/2dqxCQZZDGJnrpQ0tf+WN0c94jCIuRV+XIvn+YhV+cr10fHss/z9kIk8fFQt7GutISx/fznfuHIGJz3eyaA2E4RlOUrdQCCQSK5edTVXr7ra+X78m/Wc/LcUk7bu5Bf1sGhOhCcm5QwIpQz/ucHK1b9y3UrmLpnLJQdcAsDLm19m9qLZebOH37/4G65Qz9+Ae15eyp9e/ZPD3PTjnZIkYBgZQOO1j14LJOZx948x26v5KfDj5W+xZuOT3BYFMhnHBRo14OwfvwBY+YzUy/BHL/4XU40a9rA9BFkjy9K3l7JT38ncJXNZMH0Bc/aYY92jl3aylnvX7UKI72KFR35SCBHB8sP3ORSrk6kIGjARwNgn19H40CsOAYCb5Ubf0MKXH4YN1uZCBm2XfOl/00gzpziN1lZarvwegEfJu600dxjirLUGYx99CD2dRQCNrVnSNy9isivJ1vSXdjDfxZCkhE699lpevdZuWQuAZocotstOdA0yqQ6P9aRk+HDnhwzaYcm2zwdqAc+q6/yHAQxaGlo8DDoA/1j/DySS4U+8QfVvV1Fj37pqy3bnOvUi3NS6HhU8pWY/n35Bd15Cyq2hb9jA9k2b7LaFYb9+DE2JrCzBlg+Z/zBs2vMVmJirt1LQhqnTIQzcOSV/+vSPmT11HrPWGhz519eIZa2bKeaeX2f+H8bkXNy0mkn5dxz7mYR2ZnagC0kmaidqy+Ysd+Faq9+asshUtu7IEVjIdJr6f7zIRUslcZl22h2gvhPOfqCd7c2Ce8W9Tj/5so8la/7DktvZ4fQT1cc6dcupu2mnVd6yd3LsYW65ooa1+A455aJcNFs6NjFrrenpd24Gsfrjj3eUblJLEtNi6FL3uLt2PPSws3gpbJlzLFEas9YanP1wR65fK9lWrEJO8gY7SCSz1hqc9vA2Txtc+LC1EL5qkvVSzoosGzs28vi/H3eubelo4fqnrORtj/37scB8+m6im6gJ6ztfd5ZyWjpaaGk3GE+u/+qmnsfm5O8fGd3iOpBVG2lpTZOJQuu2DmoyaRJYL7O6dm/7A2wyPuKDjlammfBe23vsyO5wZFYsUiqXVF/74D8PpLHi4TcCY4Cf9IpEFSKf1clqwM+taM9jd3EjqcMYix2OEa0WU5EfMpt1WJYU3AreHWN95kqZz/Sje5l0ghiSADqfey7v2DMbnwFcPvgI6Bqk052BFrxEOtvTo766KEaff2//d96UVQ3mfe5bjUhnAq9TgyHmyiuj2U0eC/ZEOW6MpnbQ0sEPIqnDiD8+7jmmOrqp62Q17wDWs2kee/8xzlwpiWe9vyV1OH2l4XEVqTh4Px+mn0koYoIZgYxtssR1LxmMH+5c4mYqzfA/Pk68QNBWzLDaUL1kgvpAKcYlRaXoZohyP+OomfuuXsaqLwhTFmUQE0I4fm7lgwfvrGHnz39dlFWsUL+es2JrYH1KtYGKonlt22t5i6TquRUiS3GnyY4aeev0CBVK62o/P5tTUP8AiNS/BkTIxGDT1h0eF1QQMlHICpOoCa9sWZsnc8pIcftLtwP5rsqeQrmpCjYCfwIahBDHAykpZVEfvBBiDyHE34QQrwgh1goh8pMt9wDyWJ1s06YcBhu1IFNQSZHP6OKx4F1kEuUw3xQ6x9y5M+9Yh24lQ3KiaDRLyWuG6en0HoVWpB5D2ov4cpFUbe0I/G1Ie07JOYNHSrTC+sgD/8vGj9gW7xRbKfiIBN3XOyOmtaBXrK3dg0i5G/wuGj9zj5DW1FqlZI7pXq4AP9wKXqZTxLcUjzcopw8U669Kfg8bmVvBG7ln71jwru+lGMSUmyYRTQRGqcgPNxeVudD9B+8IPl6qDVQcvD+JWTnwK3g/Cj1Xd9v6+4ez/hDtBCnIRK3gAjMdvHCskIkKDM16w2T04DUINTvr61QFpwGrgVOxeFmftjNKFoMOXC6l3B84DLhECLF/d4QNQj6rk/U0ymGwUTmu9SJt62d08VjwaoeoLMzS5D5e6BxRlc9MpfyvmkvB6xpEDeGxLtwRD0EsNe6yC/n5BIKdQ6oDf9tanxsMavpbrBw/jBI9zM10Ay4Fb+Y/l6hh5VMv1tZuEhGVTdK/buInd4lIy4JXPvi4Lota8BGPBZ8iM6R4ZyunDxTrr2rwe9nIcr+7FbzwK3iz8L1V31aRVAkt4fQRTyTNsKaiMhe6/0e1wcdLtYEKk/TnMCoHJRV8gefqblt//3AiiGQ1ECEbhWppOrvKCyETzfX/aoJJQ1Ra8b6Og/8eVgz8uVLKc4BDgKuLXSClbJFSPm9/3g68CozujrBB8LI6SYTdw+8/ssaJighCKgqb7EjArTU2U5EPIhZzWJYUClnw98wRJZl+ghiSABL77pt3bK/GvRAIxwJWCj5uRrw+eDPfgs/6+opi9BmcGJyXbCoaiVIdrWbNydPy5FfXORa8vQ3creAKGvKaJURHAmQimBowFYXW87yLW05GTgmm5u2eVSLB4SMP5545IpC5Z/EcjSot97J0omjMXBhr1szmMQlFTGXBK7IUPGQwfkQ9FnyG98+cTbbAvu6sZrWhiv4I6gOlGJfq4nWAxYCk2cvO+Qredj24Qn/V91IMYqot3C4aTyjfhZ/Pk8kt8z1zhBVZ4sMTsxrzD1K6DQxpkDbSzBgxI6+/JrUkiUiiIBuYX8H79ztq0ruGpO7pZnMK6h8A6e3THAt+aDxSWsHHgIhNRlQ1Mk/mpJbki5Os7UR9vZM1IqV0U6NvreBahBDjgAOBp8uWrEwoVqeqWAS3unnt4CZaLzuDTNQ6usPWMRJg+FBuP06ww9YFnVUWU5F6GACR2lpG/uiHeVE0gQpeWtEmbZeeSaTOGozttRFaLzuDf07KKU3FkOR3PcRG5NMFDqmyiCaq7ARfsXiVZcH7Nm+ogVgXqyMhrU7y+EExp66RkcMdRp/qWDULZy70dLTm8c3UxGp477A9WHfJPHba7aQPaeC+EwdbUTR2lccnrfeze3CoO7nHUXTUKKoPsWjw9CjsvPxcOhO5MiUghzdx+3GC9FGHeuothABpWdBNdcM9v3116lfYc9CerJqksfSUPTDtFMpb6uCPJ9SR+cxhJGO5gakWWVUbqUx+iklIKd3aaDURLUqy2jIh4zpopv0yC3iDNWh1ubqkU3w4e1/umuutH8COJPxmXoJVkzQumnYRI2tGWmxexwqH9WdLQ4Q7jovw8oGDCyst28JuntDMeZPPs+rm8cFLEtLOg2RasyC3i0YxiHXaXTE6dKiHQUztrPakAnCH8s2xnpFS4h/VWAxd/5wUoy5WZz2PTyacuqv6pw6ayPDq4R7mKIHVF/94Qp1z7uZ6+O3xcWeRWZW/3+D9WDhzISNrLOWomJcGVQ1iStOUvHYSCGJ67oFphvD44EfWjKQpPthpF7D2XfjZnFT/ULPohLRfeqkJjGqsIRMV1ArpUfAdtoGeqsq9uRrrhrH3UCuCoCFaw+ia0U748YjqESycuZAj9jjCkrWPLfhHhBCPCiHOE0KcBywDHi7nQiFELfAX4FI7YZn/9wuFEM8KIZ7dvDnY11cKJx44mmMnj2T0oNw0SErJnAuu4b0xcQTwX6fYVF8XfYX0n3/mUVwR0xoE0TGjiY22lNjom2/KU+7g3UDljy/PHnU4g844A4C7Tm9izgXXsP+QnFfql0f/0mI/GjHEc89CcfDDaoaxX/1eABy15zHompVf3eODd21O2iNpTbkTsw4D4P99aTqDlt3nDByl3Kpj1QyvtpTntGHTiEQiGKbBlk/uzz8mWyNinz8u4obrV3HLp29xLJghEUuxfWNa/nLKvWeOIv6JTxAbNYq9VzxOfIzVjlED5NxPsnp6jTOzuGdOhB2Lf2o9A5/lognNcTNUV3vn8rOHz3RcBy9Nb6DxyKMA+N65GnMvvI496vfwRCPEIjFMaXrYdNTn5gnNDEpaMTrH7HE0QtOorrW+VxlR6u3dt/GAQLNz9zvL+WymrJ2sL+xllTvi2h8w+if/acl1joZ+lMVsdeTYI1l+ynJeOuclntpfQwDP7i2Y8Phyfvmfa3nijCcYWz+WY8cf67B5KbiV7fThVvjpL474mXMsasDc0UcCsP+gffnXOf9ijyqrL6i2XDVJ458TrWc75le/9PRtx4KPJgI3EqmY8ef2tq6/49gIqyZpNCYbmT9tPgCHn2D9feOcWU6qCGEYDEoO4okznuCEPU9gVM0ovnbg1wCYe+F1RGIx/r1PA3f+4BCqjjsmr51jkRjNE5qtdjv3JYd5yZ0M79sHf5s1565hzblreOncl7hw39wG+33rcjSSs0fPttjNIpaO0Ew4dZ9TqUvUBbI5NU9oZvbo2QBMa7Lo9g4cN5RVV3zG9sHrTpgkwOPTrX78xmkznGN/OHExoxqs/Q16Js2Q6iFcfMDFACw5YQnNE5qd2WVf54P/FnAHMNX+f4eU8oriV4EQIoal3P8kpby/wL3vkFLOkFLOGDo0mOauHMS0CLo7A6GtiBVDT9KeQ8tU2vFh+6ezRlsbWpOlfINi08G7ISpvo1NEQ9qbi1QOdfciqAp7E4Z33l8om2RCSzjugKwGuibQDMmObG71yrPxx5ZZLRZKPeeeEAhHORqmwc6stYAVFVHH0tVN3VHmiq0oFok57RPNWB8MPV9eYVgJr1SOdHeqAk1oJPUIHbZxHc9KMqYdQ+xbFxAi5xLyz3QwdM+sSW30iWet9pJS5sXBq7YEKyeO27fspA3Qs5gCNHuXYiSrOzseRcAGON21O1SmUxim4axPRJJJa4ML1kxAPStVTyEENcIqRzO8U/O4Fndyxrjhltl5oZs50zRqgGEnz1JJwZx8/C7xlftCPVt3ueDzwQco+HZ7xqtyrsS1uLNA25GymccymZxfxMhR0SW0hMMqBZDWU0hdRxgmMS2WtwELcrtW845HYk67+q9TKZwBZ0YLuc1YaqNiDCuRWbGdrE5iODslgU4EIQRZpeBdOiJmj41UwuUFSCYRUTt/UzaNJnIGjT/tdW/tZC37rlLKv2Ap67IgrNf4ncCrUsqbuiBbRYhFBVmXpWNKk5SeImqH9jXKJNCBTKccH7bbTymkRG7fQbTJeskEWdXgteD9uyr/P3tvHm5ZUV8Nrxr23me659weoZspMtMIyCjSgIADSNuIvFFMUOIclbwvQyZR4xCNosknmC8gGqN+UVETo0EkigxBBATEBhroBoGWsRt6vOfc4eypqt4/atznnHu7UfiS8FDP0093n3vuHmpXrb1q/X71W5xyB3DWqq4QhfYGNbVAAG2CEbaRjk4ixfxofiWLpqRAowA2Bdu7wziABfjMSt5BTe7QaKCUZQVgQymDDwA8p9wvZ83GGjkiPYyUEkr43wuLjVHKkQiKLAJKThEL5bauDw5sRpgDpZIphOr9YLEx5z8rvAFKBeDNZLIv9BrzfZCWqesDIQpIokDrGnjjAs7azdZBD1sR7A61xg82E4skNVdSNgT4EKya5q64rL7gaqymnZcGttdXwNaWeFDUmSJz4UHIAXo+nJcdzQLw29PgS3M9PROHtzVXaqwWAPzk0LGVEG5nccIS5yoFmDr1SoGWYsi5ybbZQC8E+MHSC3b3NgDUle9zt2PW7G9IwCum7KOaKythCE1p4h9FREDzEjIgOvbl2a/5Fy+p1UC56c8iRZ1GjnS4FOvneSfrnEclhEwSQnoj/kwSQraXiLgcemPUSYSQu82fU5+zKx9oEaMowiJQSqKbdR2zGhd6IMjMD7IwkFbLAEgJvsAy+NEAHw6IwVrjjDAoU//FgnhY/92mfdn66raNOlcuctRYDdwwtYJICKZBIdzeXXnJCMvgzWpF+AyShCW6CqRSLvfdXrPdyVrIwgGETD2Ddzt+zWpIjuobKaBEwOADgGeUIREmqyBmiAs4cB3UHgk8gy/oYD9VSxU4gC+0pDWqVIHtS6D6kgtroDgGb0rBxiWctRsZUZW0DEEszVCqMmDwia4iCCAqFabyKdePtjUswItqNc1BlmvbKIAfDLLawlfUXO9cDF6m1ZQ9C66hBl9ZNZgX2lSdQBGgacriJixxANvPzGagQLYgpQA1ca0aryErM1ewLU/1W4KWUtecGQimAtth8PksDD5IXawweDNnbBmFhERghM2aOgwEDN7WrTFjq+AUNPeECvBliqfNhghFdJKGY/B5DkaZe96DBeqeLw1+TgavlBqb6+fb+d2b8f9jzfiIURRSuO211inGDuqO8RNVaQDwAYO3hrl84dwAH9aiqbBnWAZv5J+yCvCTxaRj8CR4EYGQWT1ZE56AlwqCAoIokyZZrf0RlgsmhR6AM4b2k0JUAL5bdofqpVgGbx2dmpIAUE5q0rVjTD9ZgJ+FwaNQQFFUrOSYAoiiiAu9tJURQ1yWlSqLleMQAq4oAIF8MIVFlCgwAuBLzdKVUk7/DY9tGXyd11354PAlKUQBEUg0cQlXQdNKHna3JwAUAcNWWQopdWoloOuPUJM1FJcYCfD1wFYunNgJT9DLepU0WFsnyO4sdf2mCOxVaIkmq1yvla+o8tdur3GQwdsga8zikfXWHYNlQNGI0UoL93sWYPuWwQcAD+Gt6GIWV8oh55ned0FLbTjtSmgH/Rz2WdgiNhfAp5AgoFAVgO9mXT13rYE8WMUQZlQbZPCFgbPSMPhw3iaFzsSaNnNPRlzLjYbBCyPR2DE5iB3/1Vk0/+1bxAiKQPpQSmkGb8bpmPAFuJwGH9SisQDPHIMfnQJVYfCquszihDsGwQIGbwtKWQ0+dCuizWaFCdhmNXgmFUqqB0JJ9WQO629UDDCMhDJNTREqIdwAslZhg0XBGGUuX7yUJbhJI7MsL2JegyeZlptGMXgipK9umKaViotcEsSl8gy+9Kx61MDWAA9kZEDKKr0GHxqcxKXOLJKQIyUaK3lYlljKssLgZVlCUoUk1ibJcan8jkfzcgsrYopgbNggqx1nJElARkk0IYMnkemX6gsuoZrBh5UX7XkHDUt4oMEz6VdVRCkopTyDV6bGDOFOopmVwfPRDN7GXCQF8kbs5krCAoA3gI1wN3egwdu+d6CZGQYvVEWiqVQenQXgOeWzavAyzZBGZuNWAPBCCcyUM47Bx+A6ZgY1a5G46WLa3L8p+qYswFOwYhjgSwZME7Oz3KQcEwfwuasHD1TLnAAvAvx2W8QoZAC+ElUGbwFepV7jDD1ZW32zzX87GvwoBl8JsqajGTwQBln9ddJWa1YNPmGJZmfMlPOdg8GXqgQtBQQBpokBiMD4OGEJhBJDZVs54a64ldbg9ZCwL6pQoiG5rtE9isFDyIqVXXhPrJSISi0dyUgDzWzlgoEA4GmVXanSV7wsZemANir1C3HQvNge267YrJxQyKLC4KUoIYhCwhOoJKoweKoAKDUA8CGD1wBvwbMSZC38ztpQbmgEDL4i0fCkImMAHvBsf80m0VhCQqRhqcGW/IhGSHgSBFmrY8DtZGWjs2icMxgBsmaEZt//nv3dzAJ88NxJ6Z2KBr1fSwfw8lkDfEQj16+DGrxKU8yYz2JZBc1u1nUMPlJsZEqobZP55ND9l1aiiQioUK4cN6ATB0oGTFMD8LE+NjMADyndahnAUInpFwF+Oy1iPg+eU641+HTCDepGYYFrWKJh0mcGWIkmLAkbtrnqwVeCrEZnL2XpGLzbeh0weDY2GuCtBs9KPXAqAB9q8OGOw7KEYEBfWWs5X5vFLoHTgS3TllVYDd4yQyvRcMLdi5AYHdFamIW8hwqJipVdcE9caD0654BMeIXBjwJ4ZpbCKRkAeFFWsg9s5khceg0+lGhckLX0Eo3tswqDFwUElAaZONZ+mkFwlSi/2QjwEx6EQNosGsfgfZA1LIERAnnNCImDEk2N1YY0eHve8MUGVBl8pdiYVJW+p6Z8cMISFydQWXUMhEHWUVk09kUqKJA1uLOmq7GaA9gsM/JjHsybkMEPeL8W5tkxoSrOTWE/z6XB2zbE4PMM02YvRGLIijWc6eU9Vy44AnXjYxTAV1d4ui9yeAYPAGTGl0lJSp0EMUVNDMoAPDUlr5k0c4lWzzmb8c1z1V4wAB8z6pJ+bc3xyZkJt8RumJw7mfkJFGbReA1eb8veEQY/mCbJCfcM3ko0okCDG4AvLMAHDL45DPDWki/hiTYToAbgqb7mCoMPB2epXwLTFuCFcGmddgINAjyjDJRQlybpJRqTRRMOkUz7ZNr0sDRIcQklGjkA8EwoRIVEwQEVaYbsgqyjJBpzzpQMPIOBevBWd44DBj8yyCp9kBUYZvCiNAzeALytRWNfYFSNlmhoswk1INHQJK4weEBnSFSA3GxK4qKaPRGzGLnIKxr8DjF4CceciaqOXcfgWRIEWWdPkxydReMZfL/BvUTDE/e7aW4yxEK5UVY1eCAIXJqXDCuVW2GE9wvMnUVj23CaZIYZG1MwK0FnppJ1HbmKlAf4UZk0gzEaINDguQH46SAl00g0U9S6fhiANwyemZe5vfZBm8f/6mqS/+0bZzo4CHgnn6kpX82uZlWLfn8oD54GDJ4tmBvgR2rwoURjbbxKrYUOZtEQpSrskI6NDZ3LvoASloAJqRm89Ay+osHLkClrvX5G+Hz7ME0SGDZACPPgC1k4gHdBVhUCfK4DsobRhABPhXSyhsqyKsiUEryQeldxEiEu1KxBVgBg5px9NfDiK6uWfdZRJy62E2QdZPCyyuCVFCgtwNdiV6rA1sKhUptR2yYDgJdZqgHeXCqp1ZxvpwXUQakhBPjK56yGftmvvLTteQcBngZjiAv4OM4oBm/yzG3JXzWgwbtqkmGxsYoGb/qcAjM16uZKwhJHHPIRDJ6Uc2jwufUcVhVz7bCffysGn6aY4nYFpc+969iu7tyWhHDQoYBn2MLxYfvaavAiNuU0Znw/xhbgYYDGBNqpyaJhCpU8+FGr/+ejvWAAXks0PuVIKYXp6Qn38yTXD0mkfWRlhjqvV7No+gqIY9CmZtuz5sHPUqoAMBJNkCYplNCVGgMNfjAxZJREUwF4I9HkMgciDi4wcicrYPKhGTAjU0iCSh68C4aV1eqbnHKfJil8HryVmiITqEojHTuIJXOTpB8APA+cdAYBngkFVkjkkV66RsKz6lEsjRumNEOqWrEKNzpJ4YA2ElryGfJktUHWAQ2+lOUQQ5NEocZrIEkNiTmtBfgIzK3CAA94tNmEyvR5Xb30pFYJsgJzALysJpklPBlKkRyLxtw1Axp4KaEDAK+cPEakrAS4qVTO+s5JNPlAFs2INMkwGB8GWacbROfBK1XR4K21IQtLdwdZNE6rN/fn/EwFKhq8vd9R/eY+D4B/KA8+zTBjTN4jA8gW4LtZ15EQLokD1e0xeDtniwGJJgT4WqFX2pOqr1HIAnxkd86qapB1QKL5r3Z0+m/fQomGU45CFLjhoZ/g9ebn27pPowVtWnHFA1cA8Ayel8BrVymoIsfDr3o1QCkeu/NGPHro5Wia4GuZMGRMoTEjcWlbF0YqX6IfUuOGX+HSr5ToXfQaV4Cal8qxrTCLZpC1Td74MweYX73oL7H393+EBT19jjv3/jQOWq2B4t0f+yUeXiTd73uHnmeci4yCzkv9zMXbIAEsXt9H7c3n4jvPlNja+QlmXgl848H34NLrtLvSljbA+a1gixie6T+DNVvW4BWGWT309P1YBA+2Noj4iUs24snlehIu9u9P7Pa0B4R3XHkWPjBBsIASUKlw2xM3Y2naR84JHpl5ArsUQRbNCO3RBlkn5UC52ECiycoMUzMpxqGXx796+mFs7jaRYRLLL7oBf37yfmgvqAZZv7HmGwCAFT9YgeX3C1x6o8KCHiD4OjRbwKpvXoKj1ykcZp+R2+lMcPNTNwPQaXzPdJ8CAEw/ug583Tq8/sEYaxdrFFhx9elYnz6Db1GfOhnRCN2rrsLGiy9BuWEDTmwZSSRTeOikV6HcsAF8yRLs+r8OAQyBJSA45v4Sp112Nd7eVZj+2lvR/dM/x6J1D+AfrijwRPePXbcwCZdBRQYJwYQLAAAgAElEQVQY/O4bFU666DeY3/UDb93GB5GY6yk2rMeebYp37CXBLzsHvZ7EVxIAl/wl7u//Jba2CTJj2rHvkxKH3LseTAGXXSrwrRO/ibMev8FfAwAaADwR/oXb+s9VuPRSP+4eWa77kBuA3/iD7+HSb5VY0PsRVpr5FZ1S7Te+ZAkWn38e+ILq3gEA6F51FTb8zaehJiZwPHS532fuvAXLuwLLL/lHnNIHwvqIGyafwuRV/4FL/6XExouOw4Nthm++UuGRo3bB8bsejx//5sfV/oVn8Hs8pft3wS9+7b4TF0DZAg69x2RN3fswHjrpVZhcmqAB4KNXSKgrvguC7+K7ANSl70f3rz6KaMtaXHpZieiiP8BD5v5GlUj5bdsLBuAjTmAZfF7mEBBQgdFENqmXXGG1OfvgmAK4mRPl+vVQAOp3rK0sb6LM59hbF56rm3ej270Ku1x6JXRsRbnshd03eKOJUIM/5v6B1D9TC/7K95yFQ3+xquJyc8oqv5Ggsy3HIV19rcfeK/Den3jTBBcEddencwwOeHAGVOnjL+wqvP8qgNCeC/4t6gH43Jex6+kLcPuem6DgzT1uf/Tn2Lbuahxx+7bKOeZ1BTo/1gM7NEk58FHPKKNSAYVAP9bS19fv/go+XuiNTn1SIi6BX2/Vxxi1NLUMuQxkNwBY/fTdKH7PSBWqcIHsqFTYkD4KqXYGQPHURB8Xfv9evP3V+t4f2vYQAJ8Zsfx+UXE4oqXCzhPAB65WlcBo3YwJKUv0rZE0FBY91q3c//i2HEd29eh7KtXgknM/1l5xb4ENV3/USSP1SRM7EHq8Afrvfb68EctP1oXrjrm/rLp/Pb0J6y/8EA6CBAsKagHA7s8oEHN9kNKViQCAwx8B+ECu9+TNN+PJa24HNe5jC7vSjDV9Q+1AwVnYU2jfof99yiogMhr2wknrRLUezxzIXFlrFqzkqJBglKF71VVI/u6rejMh9Libd+3j+vsKID/5Ofb/1mpn0GPn1+b+RWj8/CHXb9aJ6iVnHwaYXIiEJehedRXWX/ghv4qx9762wKEPAHxEwbh5W0os+frt7pzzuwLv/Q/gS3gS353+buW7buMdCLpXXYXld0xVzgPoZ5nkwLuuLhxulOvXY7F+vCAD3ye9Kaz/yw+iTQlICQCq4rT1XIH8C0uiMQzemmWEYF4zYz78zKX/DRyLYPsdUyuBV/7HE9h48SVDTk4AcPBjnqWGWTRvumV0gd29bl415HIzeF1WPvmDm0Y76Azdw8CpYjXC3CTLcNJPNri0M8/ESnxh1RfQvfwrQ8ce6XIUfBaXmpnZ6oUqy8GlTpPMI/3zezbfo39vRJA1N2msg/Xgf/bo9QMxB38+QhRosgm21/qFwPd/pQ0t7tt8X+U4oxyFKIb7xvb/4P0etm7okoeMTUKAP+26ySHdOzy+bSwr53ZJKkuwcuBEAJY96dNyBxn8KMOVpVsxNGbn2pFo5afB/gldmFy9ovD6pAQB0c5RA6mZPHhJHfKDe4fc12olsOS6e4f6TaUpDvq3e8w1E83+L75kZNYbxWhwB/RLbNQ5RzlrWZzIpb6X2QyC5k9ju3O40qT0L2bTrNPWc9VeUABPDEhZTS0KAd4Gtws4lv1sjCtGtfldNeT4ZFs999JAyOAXTI78+kjQnK0t3AG3qmfT5neDEqumT+JSO9uIjRtn+a3ZW2QAPjMA3zDxj5zrP1HpYwGjGLwt8DUI8NP93qwAr3+xRDiltkyZbJ+BwPKOuH2FbTBu0shGfy+czHnks2jmdWdBhBFtey5Jo1ot9wAPKWeNH426zt+12et0q+EA4EmpNfjZ5oht83ujB/9sc8K6j9V4DYSQ7R7/2bRR/W6vI8fc55rLUe3ZtOfyfl5AAF/NogG8Bgp4Bk9RTY98Frg61LZ2yJDjk21pHFQxDLJots7iciOfxazb8lsXkBjdtnaquyIBDZo7N3cGX7z4WR8vLjVztEXPLCBagI9Ln1UxOovGBLMGRmcnGvMAr9QwwCuui4CYtqBl6nkPZFrsiNtX2AaBZma0OU/lGebcM96J8R1XQrfnkjSqpVFQwE5IYDteoc9ls9cZjhvbiJCglM46R2zb1h49+GebE+lCPYnsc93e8Z9NG9XvToOXc59r0Gjnt23P5f28gACeukIcC+s61TF0WK8FK0TL4qkCyhGDSKG6iWdUSzlw3Sk7YfH550HEwxP44Z2DbBjuM1h++PLRo/Y3Rx8y5HIz+PIxe7Xw768Y7Qw1dA8Dp8rJiEFYS/CzU3dzZhN2MNdKinMPOxfz3/nOoWOLEbcQnisuLIPXH7YLk3rHtUzDJbB3S9fqHiXRtJmewJbBW6OJ43c6xsU1qPKDNy70okzm86HMfdQjhrOO0udY2lxaOf4oRyGJ4b6xY4ANdOSa3YafjSC+2qK9Vzv+rn/dzi6zZq4mk2hulyTOIehw5z+2SGcq6YNUGfyo8b21iSH3rrmITj7wHGwLXZi8Mbv/OTFZNIvPPw+oVd+K4erskde/bOSxN598GEhcdQMjtRp+85blAHxu/eLzz0No1mObBDAbqZ6JMOT4NpuzlnN0AsHi888bchOzbf18bHcOVw9MIflAsb3Aaeu5aC8sgDfduaCuIzBJMLpDLTK0ZMvMuJPmt/nSpeCLF2Nm7yXu4SgAhTHPVdAONF85leOJY16CzsqVeOjs44euZ3OHOICPqS7iVMrSGUPMNLl2XGpryvC6z38Rd731NOeo1K0DPzlM5x4rc7y7j9QWaKv2pvjSqcS5yNjrsn82tXXt7od3oVCMOuegL64k+OppdXevm9pA8yN/ht6Jh2B+bb5OmTT9tH9rL6zYcwXGTjoRgNfTp1ocq47W/bu1ZSYRAZ7xpj3GEQmot7WBxulLXgMAKDgBNxUbF3H9C6MYfNPY7jmAN+fet7O3L3EQBkMFQ0LrUKIFKIpdxuv4zBkH4aT9NROyuyOXNPX/rcNRZty+Cgo8thj44gqKNPZjxt7TwmS+cxVq8AY2LCAoCTBpMLvb5nhsEdBv+2JdoQb/wBGLseSTfw3S0G8AEYCrBX6+aBFmLvgjZ87ywOGLcd3L/JgTi+dj6Wc+jdWv+b1qZ9USbGsTF+RUQRllALh/92GQae6+B3b91N8AjEEB2NphuGV/uHP1av5lN9EE7jxUD4orjybOZ3WqoZ2o1h21K8aTcTCTtjnE4AlFZ+VKLPj4XyE1t715DLj5UP/CW/Dq12L6jBPd+Te1tWPUgZ++BPPeepb7Hl+6FEs++dfY9kptwGFXgZ2VKzF2sjcMsQRt3R4R/u3YYactAEibDGvefQKKYH596VSC1YeO48z9znSrA0qoiy8ViqCzciV+eMZSd6yQCG4a18fY1AZACPjSpeiteIWbb/YPAIhWHUs/exE2nHuG82+w9/dcZtG8sADeMHgLGg01Oo/2hjf8BHf94a8AVJlE//QTsc8N14PPn4/WwiUgAEquue3En+qB9sDRS3DOORx3vWzMscktLx1eUnHpg6wRjdzEtxuHbnjTnrjo4iOx+IILAOi8+3d+8LNYfZhmnfPO+RAuuGIt1PwObjyY4H+fE2Ny2e4AgGtO+xE+/JFr8NPDCATR7Pn7xxA8tQC4bX+Cc87hmK4BWzsUYn4HBMDWr30ctxzIsMfvvw1pDDy8BDjnHI7GilO0IQevYfex3dEgemBb9yabU33jwXqi/Mcf7okndtPf+au3MbzlQo5nxoMa9ABquV4dRU398tov1td90Ws+j9ftf7o+brb9nawO4O07INjoxAKA3zVZjIhTMArMa8S45YMn4fRDdxmqB3/N/7rGuf9c/rk1WHDsCSAAnloIbGkT/O2nbscuZ/sVS29MX8f8eNy5Cp2xzxlgEihi4JsrNGD/4AMHYbJBIOMIe43vZa6ZOILBKUdn5Uq0lmvm2X+pdxpqHHWkvofLvwh6ygnu88tfczneufJjus+PJNjwjY+js3IlntrTvBh30o5cvN2pmG5DVBn8xvkkVK1A4hgdNNBZuRJ8p8WIly7F8tvvw1s/9T0AwKIPvB/n/kUH9++uf+mR95+OqSX64HfvRfHRs/WD3ucjn8IXP3c/fvr7P8WC2oKRDJ5K5Z7BgtNOx6/21sf8xNtreGSpv6hIUhz8au37Ou+8/41zzuG45UC967O2v37z1I84HPvccD06K1e6uWRXxgAQLV0CEseIbroDp57+d3i6uQCHHPha/Nl7vu6+s2kXv0t2p9oi/N6b34YnFwFq50X42Rf+ELccyPCmfd+Ejxz9ERy08CAcvtPh2KW1iw+ymo6878gFyBp6UE6M+fsomSYP55zD0fnlddjnhutx9P/zVcRLlqD9ulNAALC99bN/9O/ej87KlZh45cF4aCnADz3Y3d9z2V4wAB8P1KIBfHnbwaayzJULsEyFApBGaiFRBDGlo6H9uilx0NPRl3jagDaLvFvS1EC+NlDZkBSxyG3OsN6ZhOn6L8TUqrBbzan5W5jzkbzUVRiVAMxyThUFKKV6y3/k2WJcejAUzDhHGYBu9PUo7Zd9cOmZlt3Jaq3t7ER12Qsm4Nk3cykpqat7Yh3jBasyN6u5FzWzFdz0pS7EFZtnkGp7PjL7ktgCfMmgVyKmzHBoRg4AvFDIygwKEipAs7Ae/KhzOUeoElCUoBk1XS13AEBkYjlhHRleA5V61bI5MrsxZzLEpUIREffSzzlQM8Wu3PZ080x53wOwnDR11LOsUhM9YYn7flz6naUWvOW0KbdbryMWJAB4MbDJrBpDYJ2Oe7aqKIL6/bn7jFNfbyabmXAsVVAgNScK69kkPPF1nYJzhXnwjDLnQrWAjlVSOSMZ1K8Psns45RBd4xTV7VU+B1DpL9nrgXU6KM1KoqQMssjddRYRAcvDTVhCj30BoCxd+Q+7wSkTmdv45QHe3CNhSA3AF7GH0DBmFG7SYu02isef0P9etLDSf1LpQnykNktg53dsLxiA13nw1SBruLsybDJN3eaiUHeVkf4P4RxySk+8aQPwqqtBKp4x2+NNfWsAYL3q7lDAAHzpXZFc4Ne4wiim678QU7PC1U83f6uuzrUmeeEZrNn2rIoCjDBToXEWgKem4Jm5z9q0ySgpU9AQ4MOdrLJwZRRsXXtl0rhSozvGpYI0wChM30laZW4O4M2WbgtiJE5cnRaVZrNuz7YM3r5AHMCbYmM1XqtINLyQ5lkIp8EDfhNVKtKR5wrryVOm63fb6wMAYgA+QtVWj0t979PGvSeZzhGXerXndpxyoGYZPDM7Js0zZTOBI5QZZypNnaYMaPASXb2TLC58iQJVVgGe1OtIBHETOSwVDAynNtJO27seFaV/kdtCcUWJiEbOtSnv9yBtfSLidfiwnk1oLVk5l6haKNrV6zhpVlzNIkH87tssd/GgiEWuz+zfgAfPsL/ERBe000ZpYhEF4foFZu4vr3FwswlLQpfSdpJkWbryH7ZEQSpSVx/f58FTSKnvyQJ8qMeHakAF4Dsd5E8YgDdJC9YYqJR6XwhNth+j+W3aCwbgOa3uZAWqrDJsIYMvg3lva0yQKAIMK5+umwdoQCqZNqBAY1+DZnoY4FnI4OkwgwfX9XJIANoAwExNETnZ07VVAoBXBnBUWYKAOEAfBfCSaiZMzKBO+hbgNYO3gGzrwdtaNHbzkCspa1Yptu5MXPrqejbYKhgdzeANu5GOwSeeqeT5rCVSnSdryOApcbVobBll2+zEVSSvZNHYl2pWZiPPFTpC2bKutBYCvL7pEOBrzDB4CkyZOZlMF6bviUvR1c/EAJVj8Bo8wi3uYlqPKznI4HniVo2RCGoOWSC05YBrtUoCAYSo1uIfAHjW7rhnW2XwfoUQ0cjVmynSabuIg6A+HhKahiQsGUolBXS6a8VzVlqAr1efX8DgVZ67+csJd31mVzOA78+wv0SvB9YZrzL4vHD3mtcjR/hKrvuJUaYBvhhm8Laaq/YkNnOCUJRGdkrr1r7PQ6gIhlhIKFin7Z6lzUqz5SKkkogLuAqkz3V7wQB8zKjbiWeZWzyw48+WEVCzMngv0RAzCafMfCeTJvd2xizrWezrSExWJRpFtIRQAXirG5raLoRpULUSjbO4s0Wjej2g0IzaWvBZyUAVBRhlVYAv9B87AQUlYBIgZrLbF5Ot+hcyeFtNUgO8dH0EBAw+AHhVViUaRUkF4OsGcHID8MKwVF2IywxkU5lyVLOlChzAU0Ay6mrPhAxeEYCaiUtoMVKiycTo1ULI4DnXNxhKNNQAfBxs+HY1+imciXgyU+ga95GvMaI3dPlSBQAgJ4YBPpRoQk05YQmE+X5c+OOG0gYAkHrNpQBLAqhgJ6uipLKyAoYlGpQlVFlWAD4GR9NWnE5nPIOn+r4lqXqfamvJoe4dZvCGEXRUowrwwt+XylINqsZKUhrmrtLU10eyZClIfxXdLli7DWH3UFCm78tKNHXuAF4wohk84W6OWAZvgd46qkVMM3grvwjD4PsNA/BxCPBBXCGol0M7PgMhGmDwthJpuHJ8LtsLBuAjTjyDJ57BS85cqhVt6iCLTLORAB8yeNbXD2CypgeFBfFa32yiopF3cpqu7nyR9RhcqJEA7/RcxioavGVd3G6Jn+y5AW1BO2T7lFC9dOf6T1LA7RYFtKTBJdxOORs7yIMa6gCcjZhQutiYl2jMPclqYTEN8KbUqek7xeiARGP028QyeCMnJLpaI6Clp9kA3uXBmwkjGIFkxK0cQkDJE+a8YkHzqkQTFBubC+CjcjSDp/EIBs89g5+p6Zd5MhMweOkZfFR4gFdFAWnKUiBY8VmJRqZpBbCGNPhBBu+uMXF+oEVEKhq8iqNhgG+3IbOsIuWExeFUUaBVMLeKklnqM0YIAEJQRtQBFFDV4CvXFgRZATgNvo3aMMDb2EKa6ZiVXfUE2ruVaUYFWUWvC9bpoLASDWVQee6kpLIWu92zJSdQ1oBDAiiEY+6hBm/r4zMJSEMOS7Mq6deHAV5xP8bCInqsHQC8CY7bFZAFeOsH/Fy3Fw7AB9UknURT6MCpBUY6ZjJD8lCi8YAgIg/w5l2BbmJWBVN9c0yFqNQmBa4O/FR1p6Rs1KpB1hDgLYPn2pRkiMHbolGTPTcI3Eso+G5VgyfOCLmwcg6l4KVy92FlpDy39wFQEF2ZkFBdjliWwwze9JPdlRoVSgdv4Rm8ZNWgp9vYZFIO5aSRaJIENNa0l2SzSzQW4N3xOYVk1NVhDxl8XucumE5oVmHwzsFeidESjXlhMAVEjsF70GCx2UgTTJOYxWDKpK8SAtmsoTajddSC+yqMBQdY6clAKDFUjLytSXaa+Y07xJiwWEALCteRsFpjFIHEsauUWkZUM3gL1kmMaMDgnXbamrXnuTu3HAD4sdzfr8x9n0rLYiNaDbKyZOSucCKUM90GPMCPqdjJHkAV4FWWVeZLqL1bNm/nd/hClBNdsE4bwhxXUAZVFG4OlQ1vPSkY0WUfCNMyppSYTKsavAV4G2S1+w9KoUtSWwYvGXHj1CZB2NWHbSxg8PHOJuPOSEfWLOZFiWY7bdDRCTBsM4kciLKWZfAplDXkCOZ9GQC8bVZnZUFx/2aqNXhXEmE6Qz/xwCIbSTVNkg2nSYIzlLIcAvjITuCpScc+LIOvZNEQ7R2aRwRlRJxm6vR6Tiu1NuxLKLdWafDxAFs/vxS5fiEQApXnFZPiggHg2m7PThTpJJoAEAA0M90XdqNTKNFYDX5OBg8f1NObQSgk9dp/qMHnNQ5ilveDEk0Y6JqLwQMAt6bPAcBza8I9oMEzAYAZGalVQzJTanmMo5JFwwoJolQlG2S2pnIP8JaZWv05zKKB8A+VMAYSRYhzI0tEtJpFE0fDGrwBG7tyAFDx0FVFgbEgpKSKvKLB2/PIAQ2eDZwHAKisGrDYgG9LVWMoTPoVrDQSjSvl2+uBtlru30DA4E1/2dURDbNoCDMxBlOorBGwfa5fhIwyR0yoUGhFLUwVUyhlOQTwdq+b1eBnamZ1asamvjBeuT53fx273ZchWaAtQa13rTBB1hcZ/HbaYLlgQC+9VRx5d5WWYfBp5iZKWZFojFNL5MHAAnw05Qd0q2+yaMxkjqczdDvcgbVs6iCSzb8O60BbBg/D4DEQZI1MLQ86NelYkgVtG/RTuWbwVoMvIupcdlzGDWNu6Q54iako/IuqbjQWSihykbsAq5WyVOalLMI4aJKAFxJMKq332rRD5odRmgQavA34GjChSeKYCsnL7TJ4SaF3KDIGSQckGgMQRT3SJhOWCYcpgcHx5wqyAp7Bh0wqim1dcf+7lq1afT5vxGhMC8QCPp0VXiqLSsPgu0Ft5RFNphkIIdUa6xMBwI9g8BrgueuLMmJAmEWTxENZNFYuCAFeZpnXwMvSjSUAOtMmyKIBtJSpBrJo2EC4CwCoqNY5t8SgKasvHl4GcpHJrgoZfLz77u7fwHCQ1QI/a3dQWuJGdRaNSjOAc2eCDWhQRqn9ha20xIV3ftqWboNU0pmQU1WVaCihmGmEAG9jZFHl+tx9m5cqGxsDNZvdYF6Qsiz0ruwXs2jmbhVHp5DBx57BWyagsoDBB8TOFvJHwOBtIM1q2EDA4K2/43SOfoO7YIqVaCobndiARMM4SlV60HYM3gD8zLTTbB1oB1k0lGjdu+B6yezS2gKAD0s1EAvwuadnFuCtu7yr0WMBPghGK0pAajVEpf6eCEaOYh4A+7GWsXTfKpSMOLmHJAmIkT2oMfAe1Zz+SzSISc50cM/0UcITbXIBoKzHmiXboGvgQBUef3sMPjI+nmGQNUo0wHMyrMFTHqHO6+g3GcYmTQnjAQYPaCksYpHLopit2T6yAB9q9klJAg0+AHjOK2NVmPHr5JMkrpYOiGPQugHFyYDBVySavALwpBQQA5KZ4KwaZOW1YQbPmNbgA6nCPqOG5BWAp0L6PPw0dfNFKQXZ7SJyAF9l8DZN0n4+mAevCh1kpXFc7SdjuccUdQw+BPiNM7rAnmXwTMKBeCkGGDxjTr6x7k2DY83uVmedjovrwL5QU+MO9qJEM3fjlLidrM4HsgQQSjRjGuBlljsGXwmyjpJozMopLIPaSo0GryyDz5E2mHtTK8vgjVVcqCnaDBHCWVWDNw881EzLTZv0NToGX82Dtwy+jKgr6epeWJy67AoAQG8SBGQkg7f9RQcAXgbppOAMNEkQFXIEwPv/ZMFW/5wqCBvj4DoWYpeivJDbDbJaBq8iA/AjGHzZMJkuLntwWIPX3THiXOFmm8hKND63Ok402xqVB08ZRyfpYKZG0e6ZOAVHJcgKaFlCM3ivJY9qFjAtwFfSAkv/4qBheVnOK2PVJgnINAMYA+FRhcGTJHEvMJu6CqBikq6KAo2+H4NxoWuwAIEGP8DgYxYPafAkNv0UMngztuuCVWI2THgGL/PczRfV7+usnt008NpVkCVL1s3Jfs6CPPiSMqDUaaCkVnNxOMAweABcEc/g5SwAzzTAC8PgbRaNxQUdH7IdMRuD1yVGaKfjSlO48skmXfL52ui042Xu/hs36/ryw/XrsaUN9A68HiffVWIsBYCnUJiHU2zWHq2bPv95bL388wCqEs2D07/Ba7/3Wrz2oSexwnw2VfOAMRMBjQL4i+9JTP7oxziTAGs+cQAWAFjwlEIOzYoad6wBlLeli2iEZXduxlk/KLGw9zAAYMt/XovNLyf4xCWn42wAT553HgiADnRRsFgBT37gAwAI9ntC4Z49gcV3PwkA2HDhheB///do9U22RsCg9UtKAYxXGPzMzbfgH1YT/OSoafdZf6aLCz+yHG+8YQbf2Vpiq6lSOf3oY4gA/PKUN+CZY/bD/gD6MsMTxUakM+OgrArwebA8X7zF/2flF+/zAFOW+PXRr4A8/uUAgHdcK4FrH8D9f3mAhg9KQaQEGR/H6/oa3D7xDQGZ9XHg6j5KCqxTvwBewfDTx36KI8zE3GW1Ntj46sXCwNAvcceXlkGedDQad6zFdzaV2NIGrjjhQRzXPw6fnH4NdvnWz1Bu0DXw7dO9a9M92LbuakSbnsFu5rPrn7oRKwFs/Nm1+OUXlqHZV4gALKPA0+PbsNcdE9jpbuWMQc74cRfH3wLcuTewfK3+7DNfF7j91i/jobUETXOfkBIlrdZH+tdbH8EXPv0p1JZuwb5rnsYvP308xqFlsHqq8M9r/hnXPnYtXhOsOrq9Gcx8519hoWHx43r8TXznO/rF/MijaIYEZnISGz6myx88/vZ3uM9l6hn8xOMP4+hVm/XnBNh1s8L6BTq+5SUajk1beviDi27ARnkrakt+iA8OAHwXfSycAJa+8zKsnf57KAC2UMA1a/4NCwVcHzy4cQ1eVuj0wemnn8T/+dQUFvQU1nzocDAAW775TSgAz1z0Wdz7hS/he8fuieV1gf0vvRhrehcDRG+NWv+hD6P+lvfghCcexfL19wIiR/fKH2r7vCgEeENsJCoMft2/fh2X3lBiwWc+gK/UgJh/BgdP5UgjoCAmKcNo97s+qufRkbdsdlsvrGw36CU7c+cvAQDp6tV46KgDIUBQ/GYVPv6pj2F6D2NW/jxJNP/jAb571VXY8FfaLYdCu8Es/MUzbjccACfM9u+8030kTMbawgkPSDdtug0bFsgK6E8H/W4ZMUHV9cZ/qhtNczQBLL3lYWAxkP74Wpz47QcQBRtSfv8mgfkTwKvvqv42ARAphdAD5rTbFZppif3uu839frlhA5oAFnQVpncOLriWAEgBzhyrt21RT+HMG/2a/agHJd5461ZnUrDQkLrIsNB5/S5aN2o7H0GBPi0xObkVvF0F+J7wNxYOqNrA+cXEBNQPr6m427hes4bdExMOsFpB9mkkgd2eUVh+v3Y8OvBR/f3IuHaFS9GxvoK6+heBw5V2CPrPJzdjfPW3XaZhWLigr1J85OaPYFFX4QvmsxmiH/gbbgN4IO5zqU0zBh2gCIC2ypoAACAASURBVIaduOZP2f/7ao8AhgBeqAeQLLkDy9cUxslJf58ohaSEue8NFYOIRtGv3LfNTLHSDi0lmqFEAzgHsbBN/fwmp83z9ZsRm0ulCtj/SWDLmL5Qy+AnZI7JzRN4Rt6K2pLvA7QYyoMnEnjJMwBF6c5t+2TXpxVKTpDGQCsFblj3U3SSl6MDgG2bxCJ7ENvl/b773Z36E3jPdatAaLBL1zwbsXkzdvri53CBBCITC1H9PpCmaK0PTNYNg79x3XVYZj57+QMSZ96Uubmg57ce1/UCSCBxwhO/QimPw953bMDy67f6+zLXufNTfWCfKoPvXnUVNl3yBfd/Ma13HS/YLPEXxWX4k0cO18d5MQ9+dNt48SVDri8VcA+blEMf7RPU1u8bITEE+KkguP1sOosAOPQHawAA2y75fxHl1XMnJfDau4BoRHBq8Ppjob9bqaVhzrHver9BC/BaHmWj393hhqRTfrV9Zyg7iSSxuzOVywO3TfBZHDBGtFmezA41przjznFrnt15aqa/B118bJNEpzjOUP8FOw5GuQJRjHDHmuXco+55yB2JbQShxUgnJwJ/3yGQ7sh43JH+7n7/By5ldLD2PVPAYY/of9tnPklmEJUFkkXXgFDzewNTq57Pfn0HPabvw1aXRFFi9dN37fD1jnQmM40K4cDdNaUw/74n3X8tg//WPV93n628Y+65QAG8fc2PUQqFI//9weFNlAD2Wq0VglAOHI1PwMKnKRokx4Hlo/r4L9aiGd1+V/eTesCqfR2XQJb5Hfq9tTUFJRTl00+P/PmzcXGa1d0mB2Ts30jUBDHBt784G5/e7ldck1RnhsSl0rVYQoB/NjfyOzbruDM2XB1iu22uy7TsNA+6bdBR6rlsQ3aKZnU4m5OT/fy5cg0Km9i2bU4XKLur1Uo0eSQRiwIk8plBYV47gJFZNbbVc30fdnc0l0CePovB+Fu0sP6PMgDfndzkPps3NfQrQ21RfwKlVGhuHT34ama3eMjgZ8Mn6wFdN6tf8mIWzej2u7qfhABuJ3doNCEYGXIW2tHWm6ej8LNd47NxcZrtu9MJIOMgBcykg9Fo+wAfGlTsyPmt3R6VHhABQIwwW3i+mnXcmfot5sNc/e3By3/22z73HWmDx7Zy2mxOTjY+8nwAPO105gR4O0fsSz1nDLEsoIpx953BIOtcfZdGplaT6WsugDHy/OSB2yZafsDYmk5L4oXus4nm0K8MtU31cQgpMT1/9LVmLaPBh/svZpn7wkzPTNj03BcZ/Mi2+PzzhtxyFGahDyOA6K49/b9tueBBowlX3+VZ6gv/ecrOiGikXZ9Y9dwZB356qA6oDrbB67ffHeUcdefe/roBuEg+GQj02BY659x8wPZtxuzPBTUuRaWucRNOYKF2YHaY9rtwfUm8486v9n5250lNHw66+ITH5oSD8shvarG1cEY8I4nZ+27w3KPu+enx6v95vw0lo5FuUwDw70ebypQBwI+ulfrsW+uEE3wWzcDPJIB7dZaiCybWG/ORiBLZppOhpMlQG7iYjR3M2h5fpO8j5/r4NcmwrLPvDl/vSGcye72MoRjc80Apei/f3//fMPiz93qL++i6l41w0AqPC+Dry16HUiisPuMgt4kvbI8v114AoUQzCp8kFCbGFWZUjCfEzgBe1OBnbZ2VK7Hkk3/tJIlNbWDzIdpxyA1WA65jp5zivsdMjZlHlpp8VgBH77YcDd5wE9vVijedf9/uGiAVgG4NzhFIEAPK5plL4wV670EtRDRCZ+VKbDh8t8o1fft1TXztZI4vriTo1asT68mda+HV4yuvJfjayRyPvv9Ud/3W8OHXu1GoCsAbRhCkz1lQm+hwXHm0H5iPLmFYdVDdXddWg9O9WP9jOqrjsaNfpn9OCVitjnHUTV6wP+XCsfnu370EzrlmJkJlIrDxcSS/fzp6NX93g043ZHxc1woBMFUnEO0GlLmHTWNwjkeP7aQvIFsw5hx87HEm6wQzh+/njm8dgn5w2kJMvuM0jGqNZAyfOvZT+OSxn0JhUjtjkwf/08OIc/6x7aGl2gFqUxvO1cqe6z+PiLHN9mWD4JrD9AtRQZf3BYDewuqkj/rjSDecgVv3W4gvnaqdpRQAMaaXWffsSbFTY6eKBv9MYz66Ud3dd5nY3Eyz4S4YF70WhSIAaQ8b+tb23cenKTZrKMwYzziwrQU8tUgby9hifYvnL0aLCIjeoUg3nAFSzhsC+K0DPqth3800TYVMTiAY8Molx2FJvAiDzT5TMt6BjCKdSVMfxz+ecBy+saLjjmtfPHzpUvz67efj84e9GROxJx3JsmXIXrqXvxbTL8ftdLT7bM3uBDcclbhj9mpeq5cANjUT3Ljb4SilwhPHvARXnNbGxLi+JlszaeJg/SYMs2gsPvGlSwEC8IbAlg4wUyf4BPljLJynGf6LEs0crbNyJeI99gAAfPAdDBvfeBwA4LO/TxH94iqMnfQqAEDjkIOR7L03WiedhKV/pN11LIgXEbDn+F541e6vQquh6dWCcd351ORuP74TwS/3JdgwD/g/73wbbjyIgHRa+OgFEl/6+G44YO1aHPDAWqRv064sRZF5C7dFekCm8/SE/cwnb8aqt63CLQcy3PX1czH/7Le5+7lxv73AG56q3XSwfkzdEw5G47DDUD/8cOzxjX/Wx+Wo7NKz+bQ00ODvPEgPni//yZ5Ys4efeJ884q+w4th36XMeRPDZN+vO2PDeC1BQhpmTT8OxJ78RAHDNmdfhNfuuQGIYfKjBt1t+yfqbf74Q+6xZjTMv5Hj7n3F897I34IAHdL/se9sv0Pnwn+Ld53N87TX6AD9fejBIZxzNo45C/YjDsf9tv8ATL12MJxYCf/3RvfDSO36FB6/6NFa/hIC3x5CwBN9e8W3HZO/9h/dh2QNr0b3657hyz+Mww2s47M77sO9Z7wUAjL/xjTj+jrW4/HNr8PO3/BxHvfF9AIDm8cchbG976dlYsecKrNhzBRpN/aw+fOzHAQDv/sO/xYJTTkW8667u+0cesRKHnKXdh95yIccffJDjzAs5zjmHY+nHPo7DrrgSAHDApy/G+VesRTJ/Iea96U3ovP71AICjf+94B5gyihCLAn944OlY/a6bcPnn7sdOr1uJeJddsPsn/0bfB2ngW6d+q8Lgp5sd/Nlb/w7f//pZOPNCjrVnHwMASPbcE7VlyzD2imPcdw/+2nexbO1a7H3NNUP3L4M8+DiuY+yAl+Lupctw686HYgFleO+2HjhRGIvMTvAkAs0zcAq8tHMiVr/rJuzb9gAK+P0YMuaI99gDreB8x84/Ai1aQ0l1wbq9mruPlIg6p5wCPm8e9r/tNix61zshCcXbX/thvOvCz+KiD5v7ePnLMX7GGeA77YR9brgeG458JW7c7XB8+qiz3XGSl7zEbzACAFNYLiy3cNj8g/HON/41AGDtbsC7z+eIjtMvAAqga/ZblCYP/vaDE/zth/bGl794Mjbuql8m3NRZGsyD76xciX1uuB4HrF2LfS48Br020C8bmPfyt2Kh2T3/okSznWYHSKvv64PnkX6bus0gZmOILpOqgxt2IOacoFS6bKjdwWhzU+0GqJxr7beVAkJEesdfswYBUkmjI2YAiTz1pU3NTliemi3nXG/HbvAGenmvUnEOjIKZXDUSx64kACN6M5Xsdb2RAQdUOHjNaoNx/1lmnJXqglWyHVSeuQ04rdTb4GWKYjJqAJM9l3lEKNXlfguhAT5YzpLAOHisMe7uCxixq89sfLHpp0umt0CNjema2eZakpkCU3X/u+2kDUGBssjRiTughDqg4yaoLKTCZFxHs0xR5IWr4zO4wcgx1clqVI0EewncZhQ7bkwBL1qvu63mhEeVeuRhY5RVagzZHZlsvOOW4iSO3XdEcwyxLDAx40FOdHugnbb7ftmfQSrSyo7RglAUQjpAYSZzSmUZEHGQYKOXfUYW6ML7V2kGFL4WjcpSZDRCTiOgVHrzGPUbx1Qc6ZIIZYnCGneU1eCAnVeiVQep1arny1LEkkIwzX5VUVRq2LtjPP44mNkFStttMCXRKDNM9P3zVWkKlWaO2Aiz0Wky8gEmWktcjjoAILb95DMsWqTuyjPbXeGk5wO/0ozb0rhUSSUhTdkCu9HP1i4aBPhKKzMIDsRCotvPQU2a746Ysv827YUD8CbNq5kCUWa3jhNE1AM8ifS/VVm475cBg5dKopf1kJgdjDbl0JYwyDnBVF2fQxTaFEE2aygJEMp3buLmvkxtbCavBXgYQOkkHXSzbqXiHAgFiw2wBg+eUQbaaUNMdL2RAYfeyAHNqnk0LNFYc4K6oFUNN80gTUGrZqpc5kMGiqm4DjLVc6WBwRhoEoPmBZioxiMoD5ak9XnuvoDhGjD2/zZIunR6C1SrDdrpuC3ntZkC0zXiJko71gCvygLtpK1LHAsFQfwO1FIoTJlJnXd7bru+LdhlmwP4YCenvokgE8mBsAFpU8CLRBHouL4vwlilXG1lxyZh/nfL0u3IpO22Y2p2LAIG4EWBbj8EeD0m7BiMS2BrurUi0RSgKIRy/UQMwMss08cO4z5mvNnxVK1FU93JKtMMfcqRMQ4ICUi92HD3aMZbLAoH8CFAK+ITE2SrDpIk1fOlKbgkKE0SgyqKkQw+f/xx19+ypYG+lc+g1y+85V2WQWapI2O2VMFU7FeVJKm5yqAAfP2n3DP4MVpzu4ddqYYpD/DC1aJRziBHKF1T3gJ8ZBj8bDu0AQBF31hcSnT7hS+UF5K057C9cADeMvhUucL+OTdvU2fkETsGP1gPvuAUpdQMPkn0kstuq7dspODapo0pIE4VWn0F2YyHGbzVQHMv0dhaNkRBryTMgGnHbc3gO0H6BGMe4JPY5cUzwsDaHYieB7CC++31JaducIUMPjcMviZoJT1PpWmFtVh2nynNgOjUpKsHTxgDSTSD50MM3lT+I0DbAHs71vczONjtfdsdws0yhWi29H0Zth1PF5iqeS2zk3S05i8k2rEFeH0Ntn9Lw+ABoNw24RieHCwRYM1KpqppeSQAQ8eyrcwlpHbRiiK30iIRr5SrHaxc6Rl87othdTpOayVR5I5fNltIRIGJEOB7elVnvx+XCpv7m10NHgAoQFAIX/KBmf5SaaqPX2Hw9iXAgChyFT4BzWQdwJfaxi8jHAWLAFvHjShX49yOt0QUrjSAnU8AoBhxMRo51gBNkur50hSR2ckq+OwAL6emXH/3a/rlPVb0MTHjrfhUlkFluV/pmBXnZBQCfAwWMHgLpqErVQNJZTULwNl0Ar7YmC1VIJWEUAKUhgzeFKebk8GnEFwhKiUmZgrn4PY/rhYNIeSrhJCNhJD7nq9zVFruGTzPfcGncLI5Bl8UbqI78I6IZ/B1XbOG1nRdkMzJOH7jU22mQCvVdaZLgpEAL0xdDaBqChLKAZ2kg17WqzB4QokDeJrU3NLYSjQqyxxo5BFxjKqIPOsNB7SVaBJBK8EwmaUV1mLBI1MEU1EdbHqqwuDtMriWK82oTV0dq/cL5pm7/XsQ4B2DDzLNyuaYuy+ZpkhmCkzXvGlCO267nZ/tpK3LvAq9+nJlZaV0DL7odr2hwkCZXs/gBxKf6QiJxgK8MjXWI+6fE5sD4AmvSDTOi7Xd8eWSI1/ltKi3EMsSvREM3oJpVAJb+lt07XTLJgnTEo0BdsZnZ/ChjEZDRk1IpRYNhIDs95GxCBmNAKElGkJ8bXcrCcaiQO4YfOFWCaDMM/ixhpZoXH8ryCwDM89PMuoBfoQBu+3vmdgC/Ay6fW/FJ7NU72J3AG/GMIuhrInLAIN3BCyQaJpI3Go2LrXvQVggTpp7L4R0JvVCap8Bz+B3AOCLvpFoFLr9wnsZ/A/Movk6gFOex+NXWkWDDwB+pERTDEs0ZaT9NLt5F7WaBniS1BCzGJnZyphHXjuu9Q3A1zlKEDDlkTOc3K4OfGAKEgK8ZfC24hwAMEpBrQZfSzxoU+aYfrlxo7tHOzhEzEYCfF7XEz8pSUXDVVleYS2ewRNMxg3w6SqDt8vgWm42g0nD6GzMgXrmbv8elGjsaiQsAVE0mu6+xJYtiDKhJZoBBk8lPIM3qZr2fgvhGXwxMeGKd82qwU8NavB+KjiJxj5HIZ1EYzVhwlhFgw8NoAc1eAfw453Kse138karItE4zb7Trkg0W1ID8A0TGyJVicZKZZrBxwMM3r9oQ8mEtloVww8AkNPTyBlHziIABKokAPHP0r6kYlnV4O29IWDwqtUErQXni5Qudy2Ul2iMZaCt9ho2299WU2/lM5iY8RKNSjNXUAzwGjwIgWiaeVyrgcX+WTn5rMLgI7eaBYCFaVQp62A9D4TULzohhTOScQBvVvyDtWgqrcwMg1eYmClAc4GSE5DnaS/J8wbwSqmbAGx9vo4/dD4n0cBZuOlCXAMAzzlgvCiBqkQzleti/426zhYgtQQ1VkPKfIVAKy20+jkaKZA3GMQAg7cBHSY9w2Sh61Ogj3sN3idG00EGT6oMHhgEeB8rsIOLR54RFDUT6DUZMK7PAgYfl35XbyoJpqIGopkBBm8mcD03jkaq+jIRFBiLx9x9ASMYvAGdEODzxpi7r/wJvaV8ql6t+62YXn10kk6Fwbu64VI5EBDdnqt2aFcF7p4tkIWF44HRDN4FWb0Gz8YDiSbQ4AdLE4f2ip7BtwOJxrP8rN4EVxKT06m20jOafSjpxAGDR1MDiaQUQipwYoOsPig8rMEH5SySxN0/bbUqhh+2bzIaITPHkyUBIQAzGrwdB1qD9xKNixexAQYfB+eLJFSWgwlZZfDlLABv+rtnJJexoo/uUJA1dS+dMthRK4z/A60lLgCq+976KniAryOuVPDcpVcdtxbgrQZvJRpGmdtf46qPzinR9CGZltx6/QK0KFHy549n/5dr8ISQ9xJC7iSE3Llp06bt/8KIFvpLtlJVlWhIKNHYLJoSypULNtpaRLAt2wYAqNdM5D7WEk2fGr2eExccXDw1BQogrxGUZLQGz4V+waiiAEv9cnAUgw81eBYAPEmSikRjmX5RAXgDsFHA4AMNvggZvAV4QiBTnUUjW3pgtg1hSRXBZFxHnPW1tZu5ZhsgrOcmD15VGbykxGe+zMLgrcOPYASZeQlltaa7r/yJxwHoIKwLHhICFmmjjVCDL5lnS4WQLrBWTkxU2Fko08y2Y7OqwZu+G2LwsV9pMVaRaGIaMHjiGTzK0i31ddB0BIOvmzS7IsdUVjqgCYOyUQls7m/Wz6+pn1dpyzzDxl2CdFk+OosGGAjct1pQeTbULzmLUNigbUlBiHIAb/daJKJAUfogqyt5SwOXo7FWpRQuixRkXoCUBuA5hSp0DIBZgGcMxGQr2f7eRvU1L1Apuv3cB1nzHCrLXImOMqg3JRqGwcdJVaKxGnzu52Rd8cpcWNqtQqMDeGMkLpSAVFqusaUPoh3R4IsUiul9AFNpDpYL70PxPLT/coBXSn1ZKXWEUuqIRYuGNzvsUAsCPM0UoCZwIaLqcrmqwRtHJ1ueIGLYlmqAb9bNMrxWQ43XMG0LKiU1px0vmdKsLK0TCAAsKHBEA4DnlFeYATAA8EkbmchQNDxARCGDryVOi9YMXjP98hkP8C6LJvJBVh4MaCvRxAIVUw+xbRtQFJBLdb93ZvRLyjJ4ABAT28wvUMcmG5nJolFVYAnrwreT0UHWMNtkpqaBLas33X0Vjz8BoArwgM4OcgzeAjytMnh7zbLXqxhSyCCTZlQ6nr6wUKOeg8Gb6ySDGnywLOeUaz2a6ACiXfrToSCr/p3U9INNlXSMvzPu2XIg0ViAF5ZR2xVe0NfDGnzws9BYfGysUi7YtpxFyMzxpOBaojFwQWpBFo0F1LL0dZAYc/skVLtZKYVrJRpSlLrGP/cavGXwrN32LkimvycERUEZltLCaPCZO6+YmfYSTcDgy6ZfifM4vAaTKhqQgJrSvrlkF72zdOdtle4IJBoD6tA+uaFEk5jNVXNm0ZR9SCP5RlKA5CXK+AUM8M9FCwdnq68lGkkAaoI2LoMgikDi0Vk0ZUSxNdWKUqOuB5cNsjqAr9d8/rYF+ASawcuQwesBxI0+OmT2ENSJsUx3UvVRGiklIiGDD4Kss2jwygJ87K3OQommrBuvz7IK8PYYcqmuxd02iSWphM9I2bpNMypCKsBQUuKDrNEIgJ8li6YC8CZwNpN4DT5/QgN8qMEDehOJZfCUaCeeUKIppYKgDDNcB8tCQ4qw/3eIwddm0eA59xr8QBZNyOA51VlSlkyIXk+nmTablWMTY5pdMAuYJbp9/0JgnbbTtVsichKN8yilczD4gSyaikQTvPxps1kNspqWswjS9IkUDIR6icYCttbghyUawpjPshprVVYMNDLjuhQoGaA48wA/NgrgdX9PpAUmowYWqsxk0fjnK7s9t9IphAKz7ksNmyxRqwK8y6LxDD6RFKLbRbSb3sy2eFtVwrOuZYVh8IA2YaGEutIHSX1HJJrMhq4Qi+KFz+CfixYOzmaqwLLSyDMG4EcGWasafBlRx+BbTcPSkpqWaIwGz2sN5FyXK1gyrV8G/TpQYoDBx4FEMwLgSTDZrFbdy3rIGjFKCsRMjgyyUkKHNfgILhtDBgBvLegEAYTZwh4VPpBKWy13DLVUlz3oGIlmJmTwW7e6ABANIv2SEsAAvJODBrKDgBFB1iBTYtqko2qA198vHjcSTd1n0dj7YUIfl1PusjDsC8R6cU5G9SEGH66gVD4a4EczeHNfUkCVVQ1+UKIJJ7ULRkYRVF5AdCe0/k7IUJCV1GrIDDDbQKvN3WedjpaJKEVLxQ7giTGPdwze7MJgrArws2XRhFo5rdeHgqwAkFPuNnfIkgDEA5sL/IoCQird9yIMsnoGj7FWxSWLBfWxS0agDINH7iUaOt5xL1I7Lrr9Av2k4TR4FTxflefOClJIhcRo2oUNsiaJy1EH4OSaUMbj0xlQFKjt8XsAgIVbB1Z6QZDVPt9CaON4y+5jw+BnBXilgDKFMhtOEqGDrIKz0d9/DhpRg8Gm5+rAhHwbwAkAFgJ4BsDHlFL/NNfvHHHEEerOwJRjR9rV667GP9zwN/j832lwVtDV6hSAcy/gOOrWs/CW2/4FY0Uf5fh8dA5ahuk7fgmKHDJTmEyAsUx/f3NbF7Na0q/hzdf2dV2Tmma+Salrtdy+H3DyKoDqKhlIE4UvnUxxyzKKnUqJ87ZtQ3RPDbvfWavU3yDQNS0ogGfmA9NnMaw47qO4pFiPf7rvn7D8foFzfqT9Tre0gXhRhvYjeiBu7VB845UKZy/YggPWUjx9WwcwFhKTdeDWvefjlHu3Vu6hLoH3/kgh48Dbz6f49t9KXHl0CxPNGfzR9RIlCLi5wpxQxErC2ox8f/mbMb15G9724LX2YWLp5z6L7DePYstll7l+nqnpOjk8XYZzfno/npoPfO6C3XDuYefioW0P4Z/u0497SXMJzj3sXKzYcwWuXnc1PvjzD2L5/QLv+w9tZtFvz0N61HKMX/cj11eTNeCqU18K1liGI574DpbcRp00RJ0hCjDVrGHy7efjNy87Fjdf/k1csOpfwJUGGyWlDqhDgTcEFh08iemyjt6dQYQ3ioCiwJKLPoPx009H99IP4+nLvw9ZQBfrLwhsJZX64gz1RcDW+3WtINoiuPgkglsOZDhs8WFYtXEVAOC7r/8uli1Yhl8f/Qp0d90TfO29SESBjfVxrJu3K16x/j5fewcKhCkoQYfGC2230V5xKrZ9+zuAebadaeDhpcCyJ/RTyJsK/9+r67h2mcARjzfwF9/SL7OfHngSTuhsQXzrPQCA/d9DQV7zMfy7WI70z8/DIU/eh5xQCMpQEwUUIaBKun695qgjsdvERiz79WP6/gnw/TfOw3f2m8IXN52KBV/5YXAPpiv33BPFunVAAkxDlxmW7Ro6x5yAyZ/8RH+XSygTgR1EnniXhSie2hz8hGBbrY17DtkXJ+M25L9kUBKYrDdw384H4hW/8Vix4H1/jMXnnYc/uWIVbnl4Mw558Db86Zorwfsz6NbGcMX+x+D9d+vyBr9+1dHY9/rb4EeRrpmUFApFxMELb1Ji5+xNBxL84+taOG/bBPqsj79foEng8vsF3vtj7eq1uQ186wSCm5cxqHIc2caTsRM9Bn9+8n44/dBdgKKP7ntegnV3j6OWEkxGEeqi0HO+wyDe+2ac8K6P4tk2QsivlFJHjPzZ8wXwv017tgB/9bqr8ZGbP4JX/TLDu64dWFIBuP5lwLH3RqgJz04UISBz3HNOAEow5FATHncwW7dgwGUr9EQ//t4S77t6tEmEbZtbwAXnULxhOsX3xpo4+v7SuPjMfp6UA2SvPpJfJ445z/XdGw4GTl2lywm/43yG73xW4N9fQbBom8Jxa2e/NgAoCYUCqRoncK59bAfuq2DAdYcQvG6VwuMLgT97D3fM23rWAjoT5g17vwFXPnwlDl89vd37BbTG3ts3R/PheFajDn0NDA8ceiL2uetn1Wc9cEzCJMZ2TdF7LNjG3m5D9npY+refAx6/DRsu+zeoWcuGmoJyge9rynUhs/JVx+D2p28HAHxv5few3/z9cN+hR0ClffAghXbUfc7VBr+voCtfhvXW7TVsaxF8/Ap9rlX77oNXqtWYfEhLbfufuR6C1/DB4t3Y9+aHcdz61SOuxX/S3m8Kkw81oYIayzlXuP5ggpPvoaBixARx78KBIzOqd8Ru917VaLMeokAIKtciCAEL5vGi887Fwve9D+//5q+Q3Hgt/ugXV1TGQsY4EpNYkVOKeIT5z1xtza7Ax9/GUZMS++Y5VtdqWH6/GBrH9lncciCDkhHSDWcg6h+Bz5xxEE585OfY8LGPQYnRwknGgYnz/+BZg/xcAP8/WqL5wqovoFQlTv/FMJoSACfeg8pDBjAnuAPaLWY2cLfHHWyR8I47Z940cl99TAAAIABJREFUN7gDwPgMkFKKf23VIaBmdfEJW60E4l/XhsB9tu9aT1BBARDiarkftm7uawMAruSwK045DO6Avvdj1uof2MyJUpUVcAeAVKT41//L3pvHWVaU9//vOss959y9Z3qWHmaYAWWXkW0QBYHECIFBVFBEYxJjiCSaiMZo3BLRqGhI4pbEn0YT/X4To2iMwSVKNEbFhF0Fd0FmYJi1Z/re7r7rWer3R1Wd5fbtmR4Yki9kntdLgdtnqXrqqU8956mnns9PP00/7i+pv6DGofGT/YO7akPMiXf++8KxHrlOxhbz24snBk1tGSyL3X/32f2Au36iLP7dj9TYL9hkBRgB93FtOpCMY4caJdMwbUhyRDVnOT/G1TyiBiCduM+r+KQKv4xtSy58tiUoACqoUtEXfIfx4A45+xh58hLAXd21iHakWNAWe2Qei1ypgud95/MLbMGAO3DQ4A6KfhDUvL1Hh6LG2bEZCwBhKdarXhhz/Vd+wu6//OCi4A4qSuB++IaDbtv+5DEN8Ds7iilp2SJsLP+NREMp485ijDx5MRudxsyWcg8wFmAXk7oumJTWtncUa1B56ex6B/+uA1hTosFuyf1l6WNoyaVN2iQsAkVaPMy2ieYfnsEsn11YquBg2nQoZPlskdCkbnVSnM3ta7NG7NUHmPYv8WD8YP53zqmDkbRcR5ywrHPoj9/4ufXCqOBA7FtAynq1vdUj2nXgNPBm+9AyujymAX51RaU0zSzCN3EwjEmPVAwTz2KMPHkxoGuUv5R7gINy/wxbUwHgo0dGQXigdyUHsCazSbfk/rL0MUzE0kzZGiHBzXvwTvXhGcze+vhN1niJbToUsrde1NWsVUZoNmjzT4Dtcnl6gGl/YvgSRuW/c04djOSLjbWqyw5w9cFLP6cyo4LF7Dj/u2G9WtMMcFYuP+B7Wo1Du+H6mAb4a067Bkc4fOW0hVaXCLh5I/RHjFmOqXeRl/2xxcB4Jzq0M6ahT52r9+X2I7sa4CcJz5/v4WCNZfEZfU/fAXlMD8TCiTfu2q9tVP8+CvA/XHfgD4GhsBay4jgO42qFhDb8+8n6sJi2Jkc4CzIJfNvn+cc+H9/2l9RfUKmY7eOGi7IwZW2w+d6pv7BwrEeuE3ZCsKL4CWNpAg5h26z8jcsQ+yMTRSJGXNiBo8Z+XIgmWTZJPCbKfTAy7vrRKFJftyG/wH6dU7IFxoTObJ8/T16QevD7s6T6sR3ECItH6EhuOjVLGVwgqX2MhE+WmCWyKBObWKj3ZMQW03LBieSrZ1+2wBb6tpv2dzDS/qWMyU+OUP/0k4TTesqGxtmxGQsAmbgM9lxI4Nq89sLjWPnS5y/QaV4GDoQvu2IJrVm6PKYBfvPRm3n7OW9nyzHqQEM3V3HzgUn4xjMkf3X6FewKmkggnFxJ41LF6CNsiUQy60PbtxVrSx0++CzBx59dJVzZTJldZgPN6lIXfPk0xVqkzFEyG+gN1hMtpsKIi1a12HduJ2Utyv/PcL52K3BtV/Dmc6/j7U9/J98/dRkfulik7EDTdZg9vo9Ts0AI2k2HD10ssM7qMPWUNsKNMdNhNoAvnTTJ7pqV9uFDFwl+vkHnAtuAlMQO1Po+O5YLQkGBCahru4XwyntPfT5/cdoVGcjbNmuueydr/vTdUHH1fZKur/p+z6qnAOp06lRlSjEjnf0nTFWmEKjfrn3atbz5rDdz7dOu5ednruXDF1tpm1v15bSeeWmhTbMBfOZZZ/GpE69g39ld9tWziSh13yUwXwnY89uvY+uLX8H7TnleeqQdoPTEJ+pThhKnHDG1qQ31osmLQMfkLYvGK97B1Msvx6ko/eIm+p3q/2vrekydNY9TjtQzq/APlwR8+yR7QR48QH3NKgbrNqTMRLuCJl866qnsCpokGJCSajztZIG92M0mEy+8ksRV+U7TmozplhMh1G0cVhI+cUmZ/zzJoexmnuv95ZOYaypWKyEkNNbhPPsDDE+4PI3BT/v1AvNRqZHFIT4wdTlz56xL+y4syb8/ezl/d6HD4PW/RT+opu00Ujn3XNX/Ssy0tmW5vMrES34j000QpRvFkuIiExx7RKpbhBrj3cEE/3b6Gaw6s4WliWs7vs/Plh1ZGMe0tHcs+dFJZ/O+U55Hb2IFEsGuoMn7Tnle6ux888JLcqOaOWQS6Jd9uk42BpFONd22QuCHAa/fM8fmrjow8u2T7AXz9iMXutx8ok0yVAxdkzyV6y47meecegSN805nalObXlX1uq/3TCQw3bAf1gbrgeQAvtH/+7L56M2cf/4KHvjbX2fDNX/A7uv/DIDdE4KSTJg9+xm8ZM2pfO8tF9AIXGY++Slm/+VfKK8MmZl1uOqVLtHuZ/NLay/nAy88lXNHnv+sD9zMPQ+1+cqrzuVLP/wQX3zw4/zzJWv48I+38xdr+tyqAeKft03zxDWnQnUWpu6Bv34dPO13C8+afsfvs+f//iunCpcjX3G3ar/uAy+EL9y9nV/7xHf4+/JfcFZyBzxzFbziFq666Spu3XErr97boPkkh5vWncCHJ17N0U/6B/5rx3/R33U29z33+XzwxafDRy/g3AdvpXvim9nK33JsEnPPjM0tlWPZM2hjJ33iks1Vz7mO77/1Qm783nau+cy/8abvv5uz9Wbp19edgefa/HDrbTx5+j7cNWtoPEuxVLWPkWy+9U0cPYhZtvZ87tjzLd4gz4Ybb+EpRzyV5z8vy4TdfPTmseO1+ejNRM9NeOKb/hWAM9ZP8JnfeRpPfON52JZANr+Ct+JrvPAJT+HGL6zlD9fdyBFrd/Ppp/07T3rFFaw+bZaf/6DBN58k+M2P3kzDL3Pz53/Af6w7ndiyeePtfw9A7elPJzr2WOa/9QWO3NzCY8h9e59P8OOvqsbkCqiZ08WNV7yDhn87PHgr1wxfzrNu+jZPqO2gv8OhPBnSuOY9NP75ZfCU34GL3sXdn7kQOtsXzYOvrlrBcNtWvnHKBfzZ+l/ivS84hZd86rt4jsWpRzb55Mq/h+/+Pe9vvI5/js/mSUc0+MALTy3oLNz2EHGrxVl/+QHuPe98Li+3qD075j/CE7kqfC0f+41NXH/cSvo/+Qn3/81zAHjNRScS33kf02xD+FV4tUrhPGLbj5jR3m3bqxH9zjU03/U6ALx6zFAf2fiSeCpPe5KgeftWoq5DecWA+552FEx/D3HhedxQ/UU+cesDbNr5I952ixrz4KST6HzjG7i1Em/8NWjZFp+65OPU7u+y7yMfAeAJl+zmZk7mW0e9kjc98Fv85KGjSb6lctqbl13BxJbXwbKjecXkR/ni3Tu4+OTVfOmenfxe+V9xJ6s8+IUebz7zt3jz7B2I+Z1pLrvIlSrwXIeb15/Bib96BeccM8lL/uZWzj12BfE9/wgxzDz9XPjSvzBoLsdv7aW8ajXRzp04ExNUvvBvnHf9f/DElVW++vvnseOP/pjWpz/N0f4lJDueSTz4AE4zy/R71es/y/FP/iP42U3ccdnNfPETD/Abyzdwx5YZ7plt8/FXnclxq/XKHPVpbOjxrScHnP8Rn3uPfhJP+tk97Hr18/mFq9+2YK4cCnlMe/Cp6ENLzmTGkj50wJUJA10rY6CLZqWlQkPSAwdByWUQjt/c6Ovf273QkN7gWDZ10cHL7eQ34yFEfaiuULta/daCZ1nCbLmPTwsxtbU9c12sWaB02qHjNZCuj8uQQRRnp0KllZFF9NR7RahOLQmRQNQnclxKcYIdq2PX8wNVCVD128rK99oqFNMI3LR4V760gj1U3kuJhEDrsmNiM+7S/YUwV9d8ECVEcUKUSBqBqmCorlH/dJMhxEP6GjhlrDKChg50Buo55oh6nslHeCXsZgM5gK6tJlmcKzyWrweTP+hkdNgQHRLHhVC31ZLZuEbqOabgWL6apPHghesSdbs4MsHTBcJaXTWmzbKrbFM/py7m8Rwrtbe8WL6n6p7rw0jCkvTsGh5hQZc5lTIQFiQ6HJWb5e1umMbgI8shWJYrcpdLHxvYLg3mEKZbFjh6XBzLSds5V8rr22zwJHh6g9kWdoFvVAjwRMjszLT6u5vNhTQq2Gul83Hr3i42MSKJsF2lu1rYJen308NQRkegYvCOJbAtQSxlOv/bvZBY152aM0ThfZUdYA5o2Y1GOo9SvMgdCrMtgSfCAmjWS/V0DKNhX9+bFHAjFX1dIlw6PkzOKh14zQPH5h+uPC4A3hi+vXwU4CWhLig00CQgplRoEgqkNqiy69CPxsfGjIG0ukOG+lvOtWyazBcBPolg2AW3DH4DejMLniXQhbuS4YK/AWlt7ZKJsye6X+ZIeqmGtH18hvTDJHfsX2R0b+a9ka47IBII+4ROCS9OsCUk2tBne6Hqt7TSImrm2HWz7GasOHmAHygSBFcmBPrztWuy8eylA/wwlzrXD+NUz43ATVNBh6Euwyo1e5XWRxILSrFi2JrrqfsyJp88VZuPVa8jQ0HfAHyugmAe4POlCowOG3SI3RJSq1ZYpOBvJqspGbyYB59oYhFfF7Fq96K0n/0wB/ByHt+1Uz3kRZQ8VffcsP9Y0LNr+ELpxZziDXMpnL3EQsR9fX32e6s3TGPwkWVRWT6R6Su3AT20XWqyQ1Iy9W4ysLBF1s48sUZaSE0k+KZ6pLAyvlEhERZ4DOnP7lV6czMAFOaYdb/FUHtTD+ztpguZZav+rmSoasqbU8VkQBzFEtuyFMDHMl0o2t0hkSNIBMyHgoHl4AwUwBsidKtRT+dRPzTVXNUKJ2wbxxL4DLFzgamG14BQA/ygo++NC7iRSqjeF+LR8WGipXRQXraSR0seXwA/0UyPFA8dVcI3CpWCzYqaknGEAqkT1n3HHes55e9r90I0fSKuZVERgxTgq0miYl2DOXA8CCYyIMiJhf6cJIKRPF0gra1dSj14TfNnPHi/QWJ7GuDjrAyA8eBl5mGKSOWOCguIeoS2ixfHWElWM6bdC3MevAYBDdLNoDTWg3cG6rkOkpI29E4kFlx3IAnzAB/FqZ6b5cyD18yLlKTSWxQOiYVFMjRjnH255EsVGBGer7w8KYiEAvh8CQNTmwjIPPicDpuiAyWXWC/swpLZAqonqylXMFou2DxfdtSkD3R5AdPeRqC/GvVzarKD74734IXvIftFD75j1fC1w2AWy0FubehKkS4e+WSedi9UXKsoD76+MnOKLD0fpLCIhE01mSPSfMQImRYbsy07Bc75ggevw10keHrBtYWd1ajRG6U+IaVIl6l2c1VWTbaPTBBDZWdzg4hJndFj26o/kwxgOMDKk+R42Sara2cevAHqdi8ksTTA9yVD203PxJiN9rwHn+JFLoTn2BY+w0KqaNkpQ6TGMNILxiDcvwcfUmI+AE/XwqkcBvj9izF8y/Owamoihw64kAN47cGnIRor9eB911lSiGaogczVWGiMuGHAajALTgB+c7wHL3MTrt9e8HdTerWEbosO0aQevN8gtn18QgYjHny7F0LYTe8RoQF4CUlEaNl4caIIIzTAt3qh6p8UaRE1kyFRD8Z78E5fl76VYCdqIZrT65E4qBCNHg+hxqafevCl1IPvD5WiPQ1k8bBLZNvEBuBtK/WQzKf5/EiIRuo0yGGi6pIkw2Ga7SEcJ+XnTD34nA6booNwHRL9JaHGbSREY+8/RGN11TjUaqodrd4w7Wc+RFOTc3iOPdYOLc9fEKKZt2r4IyGaYQ54unkPPpcm2eqGDPUiHlk29WY1nROWDlkmrgtCUE7mGZRMyea0NI0O0SQIAfP5BTUtRhenzo8lrDQ+LixIUF5wE6UXr5T7ohJZ391hNj9WeBrgLQWgy+M+YjgoENWbMEuYJKrctiWIE1mYv7Hx4HuycBbA0vtodr2R0iamX/zmq8TRHrwYFkBTCJF68PFAhUUHOYdlHMBHskTHz76qvInVPFryuAJ44TjpZ5sJ0chIGVAaUzO0ZqFAOhqw7fGfxkAKPO1eiCnpbum9f/MZWjcn4wZz4PrKgx8TgxfS0LXLsR6+maiLefC23yS2PTwxZBgXAX5+EBHmD3gMFRAbrym0bdxxHnyUIMmFaPQX0KIx+IEGeMDRbE+dSAPIQYRozH5D1VOLqwG2RuAiUw9eYBPj6AUvHvaJbKsA8GYCmSJTXddD5qoexmXz6a76IofDtBpjMQavdZkbl2VWB1w7PRylPPjxMfi0dj0iHRfhOFg6zlutKw/e0PI1y/qrUT+nIufxXWt8iMb3dUEwvXhbgq4ICCwD8OqeYe7W+VhAbOwt+322l8XgQ2EzUS6lxNbGg090kbUgnqWvKy8KKwfwQsXgq55DbNkkuopiWkhNyALAp6EbS9K3yvhiSEN0tP7CVPcilwLshtlpoeWBzuSRQ6xKhUbcxxoOledtQmy5csGOJXA0wBt9JhJiW9Wpb/eS9CsGIdIFyG400vEZxglJIrN9BdtRMXhCXQspJxpjEg30eYelAPD67wPpZfMNkMHDLJO+BHmcALwuDpQjRR66AldK4mi8Bw+CWFed8ywx9tNYSskwjaWF9PVmmyH3MBtJKcAjwfEhGO/BW4kyahXLXfh386ntMrLJasoF+w1iy0s9NzN8UsdeO63spJyI5rJ3oXLKS5EizDYeebtrPHgr9SikXgCLMfjMTBz95eFIiaOPf8+GOY94iWL6Wvdd+lGSjk9+k7U3JI2/AiRhj9i2ibVnP3TsXIhG4ru2Ci+UFZgK3yP2dEgu1jMqysrSFmLwKcBn42I8eNOeYohmvAdv50k23CwMEBgPXsd4674GeP2cajKH79rjQzReqVDSV7glerKU8+BNiCZD8vkYhA4d5HPIW70wF4O3qQfZnElDNK4hiJmlqz10mWQlEhzLYRAl1HV566SSUVyqfykCfBaigZ5VwSNMPfhADNOv7rwH70c5gC/lKrXWa9SjHlakiLbNopJyssYSx7awRNGDB8UelQiY7araNKozGSGQ3agXYuaDKIE0RGPh2BYew3ShSykbtZ6TofpnL4wLuJGKvi4P8AMH+iJHUHyI5XEC8FqJrptRv2kPPonGx+ABEr2hGFhZrC4veW+q3QvpjXjwnjb4er62heMvGoMXBuCFHOvhG6/WoejB2/r5tj9BZJXSkIWpi1LWfeq21aYNfhMx4sFHQlCKI6yE9OBJuxeqfsssi0ZqgCp68Ln4cm9WtxFs3b453ZylHmiBDJSqnsMwSujlY/DSALxI48wAMuyR2CLnwecAPknwdbzYED1Yvk9cMqQVGsijELsyxoM3Xyl6XLpWTQN8DrDzC7OerKObrPnN1jS+D7hlnUXTCyk5loq3R0n6nHI8h+/YY+3Q8nyQkkRzhIqSS1+6qW7Ml18/51nOxTJ9tgnRDKOE7jCmZA53ua4KZ+g5Y2q1J/rsgDecTXkB4tDC1gudLezUgweIctR46n3Z160t7JRBSViSrijjk3nwlpApa9NiAL+slPXLrteoDru4UYjle9niYTZZk6Tgwef1GWuu2NlelC5ywrZzAN8oeNz9MFbhKsBynHST1YBmxdVnCPQinej9lPwzFnjwwlIAr/e85n1R3Ig9xPK4Avg8KbIC+AwsDVjnAT7WnmlgqY2+Ucmv/q1eSG9oPHgD8NrrzDFK4foqBt9vwUhRI0t71SziwYexNk5TqEvGkMRprNsOmoTCT7MnDOHG8qoy7p5Ou2LZUWo/gLwHD6UoUh68BuJWN9ShqyxEY9jjlQevAT5HCGzrmvnKg1d6bxn7PJhNVh3WqfkKJGZzm4/GLDt9WQT4YQ+ZD9E4VuohRXGuDrjx4EseUckU/Ndx8Sg6QIhG9W+Pu4Ya81ilPMDn0yTVZ7nx3FMPXhQ9eCMlHedt90J8x8J3beJEIjU4lOM5PNcaa4cmDmwyckTJoytdPL1pn4ZockdcZ0OZevDm9LMBm+XLNSAbYEuJxPURNltQtYZYMqTt6r2LUGAKGtuWTT+K07GLyoY5yXjwUMp78EIgSi7Cgg5lApHF4AGE+aIi63sQZwDfzHnwdrVCud/FjYZQ8lLyDrOIxIki/LAMwOf0GdkWUqj02xTgcx68VW8UPO5BlIDZP7AtHFvgizAtdGb4h81CKscAfGs0Bu/4RImT7nnNe3ZxETjE8jgD+FIhBu8gcbXRpGCdm3SRDin4VpJuquQlv/q3eyE9nXNtikgZL6VR8OAD5cHLBIZzheelYZNFY/AJji2w85UY4zCNddvBMkKrlIYthhokJzXAD+d1DH7iKMRQZ9PkPHgAL1TGWvWcogdvAF5768qD1259LvRi9dsIqTdZdQipnXrwB65xYsSEaAxItHOxaRMS6QwknihOkMQWWRaNlffgJZ72tsNy5lGmdGhmo9Rwh7ouuE7G9mUWJz0uu5wp6nIeO0eIXEiT1JPZd4oe/GiIxojx4Nu9EN+18Q2Lj47BB/EcvmONtUNzSjOZ1/bjluglLi4RgiTdnM978MNhT+31kHnwRleTyzWZRinzXE3/hAXYgklbLSatHMAbK3AtleJZNQCf+yLCUvytqQev9aEAXjIvlNOwQuSSDDQFocidDynH2QLQdHMAXyvj9+cpxRGRW0L4PqJUSp2QMJa4tqU8eCkL+kzsjCvWxOCFbadfWuM9eAPwyoP3Rj34OALtgBEOCnoe/XeiPtLxCaWTzrd5zykuAodYHmcA72TkzTpEU9JG048WhmgMqXBgqZV+tDZ+3oNvd4d0tAdva8D1RjdZQW+y6sMjeS89SbDiXFx8kRi8a1vYMjfg8TD1lK1gglCUUq/WpG0agI/NJuuyoxA6tdAAvHHu/IFEOjaNwKXVG+o+CkJX7UmYDcpG4KYZKXkPnt4MFgIpHByzgZ08/DTJqo7jmolQz+XBdwZFD56oD3ZWF3zgZJMjTmQKmobEWvg+cRIhLIkwi1AcIxwXy/P268HvsKYoEeLmcsOFJSE2XKDFGHxKlZhjocrbmjnoNIwSDfBaV9qDd+SQqhWOtcOUrWhO20/Jp6MP6/gizHnw2T3D4XxaGsZ4xm0dY1y9QgO8zvG2NC2esHTNFxuW22oBm3YV+CehVcyDD2NqeuzCQAO8batsJEEhBg+a5cySzEtlU6tEzv714idy+y1VmTlH9dxhKLsSUJprYSEZWC4iF6aBogcfjfHgTQ2btOBaLpPKbtSLAB/FJPrLwHLUQSefMN2zrjrl1A7UC5TOhvnQbiEPvg+uT5i4OQ++lH69PhrymCb8AODuG9jz7muZvlMydVabXXfWSEKLdhk+9gzBrcc1mNu9mUuO3kzw48/yO61P0PmyGrTvnwZvu9ABKZmKYl450+KSxOe+lRdQ2fo1Vso9bJeTXB9dwb8k5/DU+mf4/hF3sKnX57LZed49OUHLtmnEMW/YO8PmTpfXhi9jo/sQv8oXSSTMyCpCQJN5WveW2XVnEzTD0PKN80xs6LKDSd41vIIbk3MA+IH3UhwiPBFxQ3mCv5is0LEtVoYxF840+f35H/HEwd9TW/s5qN3CG3cNeEFnFyqHQ9KhRPhzm523T6BqnSQMpYcbRUQW7GzCu15qsXzPaazrHsmTa5/mP/c4/O4XJJaEqJJw5Mlt9iU1+rc5CN3e4OQh3z1pyBtXLk8pHaQQXHpXxIu/AiCZL5f52JOfxxdXPZnn2N/mD+xPscaaJsHClgm7xAoePO211HyHFTf/McuE8tSkUA7nF6tlrlu+jFnbIglrrN59Gl8b/l8A3lP/QzbdeCPLdyrv7w9fYtGfTLhqps8FnZA6c7S2lNl9Rx0ZWdiBpLqmQ/u+iqaSkCRCMOf7NHq9nBEJLD9h8tQuy9er0MAQhxIRe35QZfoeBYBHXbgbf0KDjR3wxWWTvD2QzNsWzTihZVtMRgn/9ECLJvNsu2c5nR8qcD7q4l14tZgOHrEoUWeeh5LlHGFNMyd96qKPRPBQspxVl70D95QrAbj9xg+x4nN/Ru8/HUU0EAmkD7dsPJGXHv1VTul/iL7TYBAlTLkxH/30HwJw9MW76E2X2HHbBP7UkOZ5fZpS6Xrnz+q07qqi6u2AxEWEmrBXewJOOWblxjla/YDud30kkr11wT+cL7jvWMkr97W5pNPhoS1N5u8MkJHQbE2Kacxc+9PjLP7otjlWfzMACXY5YdXGWRobekgJs1sDdtzRREZqDFaf0qa6vo+F5CE5yZ9GV1AtObyT99PeErDzzmau5HOGXU45ZnLjHM31vfQvZoHrSI//2llhxbd9ShHM1KFTKrNuuksSeFhhH/T7q6f0mVrfYruc5APWCznxu9/nzB//RM2jMqza2OL9p1X4TKMMUrIykvz+zD42d7r8Y+VXecPei7jUupnXOTewRkwzI6tYlqDBHEj4UrXMny6b4Bn/BVfcrOrtzNQhPLXDU48UeM+6HjYeXMGx/RF+PLZr0dx9A3z+lcieA1TZeXstLajf6MLV/ypBtLn5hM+y4/6f8HfyyzhOzH0oDtIfVoyLI9jhOrx1chlieh8Xb/mkMg4Ba8U017kf4bT4p6y1/pNXMck+2+KtK5bR115f27a5dlIVejqpfT/Pl/8BQjFDLdcA1t4SsPu75mi1IOo67L69jo1kzYZp3uV+BEK4MTkHh4gIi69Wylw/WUnfs9u1+fRkm5PwcQYRa+LtbAcmmUUdVtTe+habXXc10nfJ0E4zc5wE1szAMT+V3HnCXZw0dzN3POBz9ZdlmiXhdiweurWJLdL8EaKuQ/sOm5tWlJGrsiJJZ/8g5vlfI31Xtdvj6ts+wXGn/pCrnvAVytp1tkhAwGr2sOzON2CJBCeX3SFQ4P7WyUyvljvHnqmb+eJ0mc2dLv3uPLPeEHOwe+iqcbt+skyFfZzzg4Ddt9dTG4h7gvZ9FUipJASWRIN7sRph0rfYc1sZR4Y0NvTSLz/LyXvw2fVf9AXXlmXa1pbez4mQ6aIVWAM66BQ8WwFOlQHo2PlaS+2ZVOmbkWKtNY38wqvmOykkAAAgAElEQVTAsrh9ywwn3flmZvd69KiBOVDWh013/pi2FeCvHtLSHuNZg2+l7bPsDOAcETPBPAhlh+3vmbMCAsJcaCRHRhF1Hbbf2kgfIhBMzsLVX5J8CMHbTpigdp/D6jv8lCTFUPEJSK/9+raYibvLKRbHXZsdt2f56ztub6T3J32LHbc3mAIaG3qsFWpe/Et0Nu1tQeHatP259u66vYGl781fdcdOnxXf9lPimGWz0BBqw9rq9dPnJH2Ludt9qgSs3TDNa7f8LdM/reu0XYHswvbbm+xZYUEDEILdrkjn/r72LJdaN/Mu9yOp3Zv5D5l9n/4jyXNukWkPls3C4NsV/osOT//nl6ssnYME+cXksR2i+drbIOyln+yjbCmGXUVYIdMr7qIshoWUsV6pOMn7lsX7JpoLquKWxZBfsf+dQG9WbXOcdGKP3nuJfQu+WPjJtfvu2oL2ydhi99219B2vc24AJJ6I8Ih430Rz0fd4hJwm7gMWDuK4d+XFkkovfcvis/UKz/smC5hprDEsOlYseN43i9e96D/kAsYlN4654Id3pEY+KiURp3yweRnXX2nFvG9Chbz6/S47KtnBGFOd0+hkfL/H1W4eX885Px5GLHs8wI9rK8Bcnug69+f9lSG2Rpojoh587W2su+t6ymLI7JbygnucOGH33bXCHsWrnc/mHirTbubbcSDbKIi0FhSAN3Oqb1m436ns91l+BBd8hwX2YfR8oDkBal5cZN+2pHaPGz8A9zuVBW3IhmOknHPuGTN3V8bOgSu+MRLK1fZXIuR1zg2L2r2xmRf9h6Q00h4vUu20Zahw7RDJYxvg29sAtZ+5mBh2lT2OyWXO/jYc8/2yc5FUP5sk3T0fLFJTfqdjs5y5sX+LuuOfm/99jdiLrVMwbZJF27LTsfEZUtOe3+ggLvauvBi9JBwcw9LotYvdK7tLf6aR/fUXVE2aTi5lLj9+Ox17Sf0+kIw+I+8Q5P99sbbmc2Dy11v7rTM/RtrbWCnVuYbF2JWirl3Yo1ijvwjMu8378zZ/KHRkxry5BLtZjAEq6i4+XqO/N+gsud3jrltKO8c9Y7F3jrN5MyfXiOmFf8xds9j9hXZqXDsU8tgG+MZagAWrbF4Mu8qKyBj7eIAwsnpMmhpAjJVyrXqL7FusjmKmaYz9m1Me/9z879vl8jSUEuIs2pbVUYzPkJ7UR6xH2rPYu/Ji9GJxcAxLo9cudq9Y6HQeUPbXX9CHYnLubn78Vkfxkvp9IBl9Rj5Ekz/wtVhb8yZVWBwOFuAba9kt1AnHxdiVnHJcAPjtZHVlhEXmnOZKFRwKHZkxby3Bbhabmk558fEa/X2O8pLbPe66pbRz3DMWe+c4mzdzcrucXPjH3DWL3V9op8a1QyGPbYB/xh+DGyATEK5cwJZi2FVk4rJ8z2n0ZKnIDDPiXvhJwjUzLUbxuytL/EP8i+mJ0aOHIf5Ijru59+PRM+nKEqOycuPcgvYJO2Hlxrn0HX8aXZHGfrfIlVwz01r0Pb4YcmeiCB1GB3Hcu/ISC6UXP0m4fHaez5zLAmaaZByLji35zEjB/HGsNqFtc9OJZ9AboweAobSJxoRJxvXXSiyumVGpiWUr5Mgwy0wZ6n81Ohnf73HAOh5s8+OR/ZYD6UpWeXFcWwFW5oA/qyQhC170qEQjROqJHcAz/pgHT3stPVli2bELSYeHts3KjXO5U81wffz83LvHh2gOZBsFEckCGzBzyk8SwlMXsj6NXnvTqSxg5DJ6PtCcADUvbkmOX1K7x40fqA3M0TZkBDcjGUu5Z0xsXNi/cXMgPyf/NLpi7PyHzGbGzZmBo9oZC1fh2iGSxzbAb7wCnvV+wMEpJUxtauOUI73jDx++SHDHsVX6Oy7jtvaV/EV0ecHYN3ZqrIpihJRMhRFvmd7H5sTnZzW1IS0lbEsmeZu4mrdEL+Wf4vMBmIpj3jK9j6kwQkjJRGhx7bTaSb8p2cQfxb9FLAVSwt6kylDa1Nf3WLlpNmMDKkes2tSmsaFHS1Z4fXgVNybnpB78g3IVmztdrs29Z1UYc96utWzuqBKq9ybrADWIUmb/i460WK11YRiDhrlCYPdOwc+OFRy18zRO2n0iF65qccMFig1KAmElYe1TWjTO7DIoO2l7V26a48JVLabCCKTEkpJvn2hxwwUZw9B8OeD9p1/JX6x9Ie8KVSaIRNUCAZihxvdOv45bNr6TUKqMCynV3y+eV/1dFcYgIRk2OW3XcWzuqHiPR8gRZkNOqEVoKox443SbzZ0u9Q29Qr+dckTzCR2EGxem8d5arcAcBBK7HDOlxwNgXnoqEyP3lS7qWc2Q0bFZqTkJ6jGEuopdaFIE7YyMbqjBXAK7pNpb+Fh8QcogtC2ZZMvT3gkbr2DTpVfz3eNfRf3IXCoekkHZ5XOnnktjQy899AZwo3x6xpCU23Q3efBSqg3IFTk7xJUkul6PdMEqJanupp7SxjszZi4IkEj26Tn182Mlb9mzj/NWt6me0ccux6md2aW4cO2XfxFaZ3ewzDVlyapNbSobBtTX99I5a95ZPaOPWK/GeLuc5A3hVcyUjqCxoXitGTfzTzOf6ut72VzQqjh7ap7W2R32aealfXX40Qa1MRpPNLSnntlAfX1Pzfs1v879p69J32mVE9ZuauGt3FCYk2bu152YG5NzeH14Vbpo96Sb6v7i+S5vmd7Hz4+VfOiijAlqX13p6KlHCuzn/vUh22CFxzrAA2y8AllZg3BdGk95AsdcupsTr9xB68Ij+WDlIc6//3yc3ukAyuPNGf7t/V9m85Gf46Pnf5Nn3H8ul3S68Ps/ZObIXwbgm8lGzhm+n9e85o/Y8q7N/PqliqHI3nAOf1W6gfdNr+LuLQ/y+gdWpyDUp0T3+Mu5T67hrurTOSP8MHvqJyGecD7LPraDY+76Ga03XM4xl+6m/su/BMDfRhfx5je8hS3v2sydbzgPgJ7Ovtjc6fIL95/H2c7Huffe69kzq/6uPs3VRLCkRJxwCUIIWptezenDvyE41uOYS3dzwotnOP7yXfz7JVkW1ZnLG/z+mV/ltvaVPIhaSM6prOXci7dz4pXb2fi6M9WE+pWXcMpd93DCb8Ycc+lubl93Ips7XR6690/4y6d9ne+95Pvc85Lvc92qPtMvegqv+Z2/YdNdd1HbfAnrlgXMaCo/UarxA/80AH560qvZdOnV3LvqIu6V6wifeBHHxZ/k6MEn+Kh1OZu7fezZv2Lux++ic9/ruW6jGrvI9nGTAa6jD31ZCXdv3cZN27bz9OUqvfQnlTMpbZCq32/dxDGX7mZq0yzHX76Loz7z6bT/Dxx7mrrmhbsY/MZRnHDlDtzffJIC9xf/E8kft3jS4O/oOw2sfJilpJOXnSAdm5u2befu4FT+YfsuAO61juFBWy28O8rHACCrE4hf+QwAX03UOHSfsJmXD68B4BvJKQxLTXYf/2LOGb6f7Udemr5z1cm/VPiKKC2L2PNrZ3LbupMAeMJE0RVMLBuE5B+TZ/DBI96pftSz/Nu+sp3lF/2S6v+rJjnhnh9z0l3f4YTfdtn1ouO4/9efxpEvmMF+8Qaa5zyJoz72M878zl0c+6IZzr54O1ev3MDeHe/nkpWnI9Y/lece+1F+vvlI/BeVOP63Jzj2sl2ceOUOTrtomg9WHuKmbdt5YMWZ/OSlz+KEK3fw7Auu4wu/fSvOtTNMX/09Ght6qi1X7uCYS3cTnnAEfxapL5E9L/oy73vndbzglElwguzaV07wyt/6EO9/8z9wwo9+zJuv+Vve+vK/Z+JjOxHHXYSYOpndzhTf9pSr/cPaOZw/1aZ90XpOunI7N7z4zdSfppwPb90G7OcEnHDlDo79w6fQ2NAjXncW5wzfz43JOWw78cmpPR33uY+reVF7Np98cJY/uPd4XhC/jM2dLtIJCESI71rcmJzDAAXsX08UO9e/JmciBJx+4jX89N4/469qezj3NWdw0pXb+ewzL+XcD27Fe9PWQwruuaF/bIvEUYc5coeHOjo+7RLp4++qOqAQ2Sdrz/LwXAvPsWij60r0ZpBdTfigU5w8fYDG1jWqhe1RsgUD1KdY5GQB54F02bq3S5sKzqCNlFCJ51T5Ai1WWX3qJ3vv1+/ppG00BcZM+wHaVNi6V5ci1Yajsie0hwjQ2gpISjXlmQw0wQVuGWmV8OwIqeuykAzT9zVQJxY3iF2ZQmfuT3WBlKle14tdxFh08GkGuVOrQZOmmE8PibS66vmrXZ1rPpyjEqlnJF11GCuMJQ0xjwia6bO6dg1kwoRjyiQLyrpi4tBW9c9LmnUov2nptrcAUI/3UdYbz2kf9JjYzUz/ga65gkxoDFW/y50H1W/+RMYC5tYRzhiAD7JnmXeZiRQlgkqiPvHLseqr5fnp+K/XenYGrdT7HkiXyG3g6fpB+QN2vfZ0sa9ezHTfoq/toGwVMzYSYSEsZTM75/UBQO3Bb5Eri7rJn6aO+gjHZ08YUBF9anGrYLOmRtGeMFC2owvqlWyLppinZ9cK18+SzYmmmGe5LmYX4qQlJUp+xgebvsfxaEv1e2BKe0T9os79pjqo1y3am7qpCb0WFTlPWzSYJ2BFuB2An8eq/6vcXlqcTFpOOl5GL1auTtSkrbMFejPp6WXhqjY2xTxTuguJ18CRAxqBOmFcESrby4y3+eegpPboIq+Zvq8lK8wPx7O8PVJ5fAC8tFWhom5WLrerPWCHOB38qZKpx64Mvmt7+I46VdiSBuBbab0RA36+3v22NWOL7fi4tsVA85nFTmaofUo8sK9LS1Yp6ZKnfjyryhdocSoqk9tqbQFgudXBM1kZ+tizaT9AS1Z5YJ/+QtDxvbIYpkW5LIB96ll+bVL3Te/YOD6Jo0hChD5aLuRQlwQgLfp0pNidKVQ/i15L1UfXTErrrd20ZBUQ2YQCCCao00kBvt0LaQYlVjrZYaJV8U6tIKXbYZzQoIMoT6TP6jn1VB8AzcDFlQNCaTOwAnwxpKQ9+HzopDz/AADLhtsX9gEYiFJ6HB+gnDudujJS9zT6OnMhaKYAG7qNFFylZSE8XbrBHwH4fVvSErJxLKjqA0VN1KJmlYN0/I2e7WE73SDtUyLyGrihOsCVP305mN9X8ODtUsKeXuZclEdScqUQCEvSlhV2GYDXs/zn0YqibvIAH/YRbsADPU/r46GCzaJr3D808GmU3bSgnmsLGnQYuPX0+kQ4BQelQYcJXxBJiwQrPcXrBWN24p2ANupkbFqPJuxBqZp1JJigWXZz9hapNum/0d1LOZlnVlRpU2X58CEAtkp1/mWl08PRtYESy6Kmx8voRfRbaerqhKUBvt/KCFRc1cYGHVbpUsZRqUFJqoXG4AbAej3eZtyN4xWXGun7WrJKu/vonGZ93AC8OoKZAUoHNYAlIpqBmgyr3GL51K7tq2Pjjl3w4C1dUKspOlgCXE1x52q6OuF4CuBNfM0tAvz8IGKWCjXmAamAPueBlKrKy7Y1KcdyO5dTaDx4ih78vK5L0NcTu2qrImGg94p13Ru7MkHVc5i31CTB9UlsX9Wx9vVBlGSQgqop+lQTuZOdpoZOb6bwVVSlly6EBYD3m1STuZTntdULaQQuy+3M0Cuo59sa4JNwSEUMsIIM4Ad6UZrQ+mgELk4ypE+JgVA1eFxbgV8+u8WN9UKc5PSYqwM0oIRVqaSbjkGutolpV3pvkHnwYamRgqt0XFUpVF9TkOFcWkIWaaXeW2Cpf1p+kI6/0bPVb6U1hfqUiL0GzkABfL5+SjS/t7BvZJcS2pGdLvS+KHp+0lIA36JKxxTY0x78Q8MyA7uc6WY4lzGLRX2sUsDuUM+buFP0mnUphulIe/Ca1Ma1LRpinqjUSK+Xjp8uQKDmUd2VhDrHyDdlur2FZXKF66cevJ968ANVAkSHxgia1AMF8FJK2r2cB+83IexiIZmlSltW8PTYPpAogF9ud7F1Rc1YWJT1eBm9iN5Mugg1zUGl3gjAywpN0WGZLik7cOu4ckgzKKVf/gBVPd5m3M38ib1G+r42lUet4NjjBOCtBbv93VyIph4ow5p09CTWvVYAr0q3Ks8U6LdSsoE6HQJXKNYWwNZ0dbbl4tgiBVtKGcCbEEpLqhU+YICVhAVQCBpFkt0JKwNCA/DdfIhG5hcQ9fyaHaU1W6z8FqIGzFntBeEEiuZPDLE9jXDJgEagywKL3LtHpd9aUBTNLIT1EQ++nCjdzPZCZnshjbLLMmthMryjwxD2QD3XKk+kXxMDVwO8blOj7GInA/q4DGRJh2h07f/FEqzHyFCoYlS2brPv7Odz2G+kHnzsZQCfOA6Y4mujAE82Bm7uUIZpo+V5C7x+0S968LHXxB4u9OCT3owKK+p22CXJgBJSF8HyRw/VCKFCNLJCYlY0be/TcYWhO5LG22+rqqfxALuUec+j/TQlo1tUVUgtmIB4QMUKFXet18yud/1sbqDs27fjDOA1eArLoi+LBeqsUkBLt8EzJYOjngJ3N1tgm0FJFQAMY8JYZiHDXJvbVJhJsrmzVYeoJqwurt5YHsZjbCEe0NA2UjfeeK+V1g2ydRsnrA4VHULsOXU8OaRRLnrwo7I7UjaU5OyhLavFuvGHUB4nAC8WpKGZEEdgxalBGU859eAtD8+x8UY8+JL+VLaFZJmdnZx0TAleISjZVrpDbnnqXuXRq0nVlhVqosdyoY00N6DlejFXtgCy2qPKh2jyAD+QxoMP03cVum7ik+Ye1ye2fEVU4GUeXVV2sQSFsq0LpNdaUBStLSvUfMVuk0rQxNc6a/VCWt1Qf6oufLanr3N0tUuCiXSxMODTNAAfuFhRnwElerh4IsTVE+pg8spDHUqzytrrtRaZTF4DdClcgNhr5kI0tuLb1f0dFbPe5E/oGpsUnge2Q8/K0QkO56hr2xpIl8RvpLHffBVTsx+UAXxCnxKBjl8HFAFe6BDNwK2TGGYpPVRtKsrTzktvJvVMHS8o2FreZoUuzjUrK1kMHlghWlTEAOk30ustN0i/MECFaHwRE+rvHC9XodOEOY3YpawNKW2fLtKVevDaxucHEXvnDQViLgavZW9cTue1FDa7mCCWgibzuClJ9/jFfoV2BtP4/HAO9B6cVVJfGQ06BDpENkdFMVUFbub1j5EdA52x5GXjcNiDP4DIeKFHN8BV/I92nMa3DXCYide3PXzXwnMt2saD77WyzR1ghZuFLuy+DoMIG9e20op+jheQSJF61wAtbVhpbDvnWVQnihRdaQwQMg8+H4PPeVXmHRUrTPPyC1in45P7jOfiBESW8n4dN/N+rUGbRuBS358Hn9uPyLfFeNz5d7rRHIKEHa0+UaI8qtoYgPd1RU1be/IEzTSEFpWUB1/X9zUDF8IeISW6iSK4cPWm4sGcDA2FrgdT0Yu+vchk0uBgAFb6zcyDt50CwIxKyvKTK3mbniTV9dx7dvGEyxpLAzolpD+BGLQRJIVNVkuHbUx/rVLCQLpUggCEVciDVy9T9i29Zgbwuh1tWSXxRtqeCz24Xrlga3mbtVIPvkKjXEr/tlaqzUOrvCz9TTg+ochspKrK3y3w4AEGOTsHcLwMlN1h3oP3CwussUGzN9UsL/Tgd4VB6ugkfhOJSqaoMZ+Wbw6T8QBvqmmW41xe/dwOAOxSmRYVqnTwxYChtJmN1RwbjcGPykMG4HU7pRMwxE25eg+1PD4APskBvFbcULpEOARWkpaRbTAPwUR67dB28V0bz7HoCJ8EC3ozVJK51NBX5OLjhq7OEhauYzEXa2ozLyDEoU8pNTTjKZnd87xnUa01iTU4t6lSScYAvAnRCBvhqbY0y2766RtYEWb4hJervxEo72ZPZGq5e0SWh0eI45iauUBvhobv0KRDz1FtDaWNLFUzPQ7noLOnoNe28eDy4jcRMqFGj637Mu+7Es8xIzPAaFFVGUVAyXjwfhaDjzX41PWC1whciAYMhUcncajQx7YNt64awzmh64bk3mN+M22OLAPwSqeeGCxol9EdkBFf+83UGYhtpxAiyPSt/r0r1DOqukxzi2o6uyxN+9bXG2zmS2V1DuBTHYpegUnMGbRoU1vgwTcqJXCCtBaNsTtV012C30xL45Lz4FM7NH3IefCloFL04HM2K/Qmazr+epFbowHerkxk17s+sWa6mhU1bBLcwcxYgB9qD35Yaupby8TYzMkAe2DYswYK4HMhMmMzJrusno/Ba9kVBlmoUv/elhUq8Vxavtl48JFX1IvZP/KiXILEnEoUMF86Ngml3jQDSsxGjqIizHvw+j5ja5G0eKhjF9updXbYg9+PyDjJQjQTRwEqHWuIg2dlVG5VOa/IMNKi/w6+qxhnSo5D36lBv0VNzrPbWQNQiCM7feVRWMLCtQVzof7k9H2GOPRlifXL1Ge4V1Nx9ifYRYAEsGybWQ0IW+UqXDlMU7DQBpdusgYTNLSHu35ZOd28qlhhegLdrh+h/sUtg+PRLLtprA83ILJUDN5xcllEvRarygmuiOmU1dHoOVFBmHZqPTKzpfDfbaqpx52KvqcuOjywN/OogniOB0xqHrDbWZNmmJgMo7w3ZntlcHxqmBh8CaIeQ6tEJ3api27mueuN72l3jdZj7j326kKbU4Cv6rFJ5tklJ4g0uJixlr7qhyFMFuUJhIDE1gCf2+RLpbkegJ1CbeDVdMhkt7NmgQdv9hi61SOBrCb6ADfV4Qqnly0wWk+7ndVpv+2SVAAfuOD6KauTsTuhTyBblYmCBz+0fIa4ytPO6YZ+KyMvCSpZqBKKC5kO0RRi8MBUorzaUnV5dr0TIPWG9ENCjYXo7CEWBuBzVSv1GIR1pRNPh55mqSL6JkTTU+DuZGmqJmvGOBSpTebaPB2VUw/e9LtNlSCeo6RJRmKdIRY3NhT0sszqYpHghnOZrrQH73rldK9CzO9kKErMhDaBGNIInCzkqm3D2GaLKtMdTZyuU6VFsEylaR+OwS8uMsodqZ7YAKh63qF08EWUxvzK8Rw01ipvyJIgRBq+8Rybnl0jmdtFWQyYCxRo5jdAbb3haAmLkm0xb0I0rkeIzQCXqYYCgUpDxdmPtnWIZuSzvqMBfkuigcnEukc9eO2RA6xbVibBIhKOOlShwwGivqbwjnrgsnNgPHifUJSo0cPRMV+hPfg1Om20X1uftcmAl9Yj++5XOYkNpY+xHry+p8l8waPyoln2yRo9XZhmLjiCqugRDgc5gM+8Mc+xwG+mcc9G4ELYJxIl5mKbBvNpeqTUdWFavmrXg3oSdUSFttChkGVqYsZ2EeDdZFZlJlm1tF2gsmYgx99rPqNti9jOxeDNWHoNKKuFfJs0AN9Pn1nYZAWGGuAHNQVmK5hJ922EiWnb3UKIxo9m6TpNhLZhW4domoHK6jH8vOs0wFs6ROOVizF4Y2+OKbdgxjfnwftBhRibecaEonQefHskBr86VqDn15dn1zteqqstiQ5Hzu8mEWacMw8+1Itv0lTtMamTc6KS47/t62fqOZH76jMORZYmmdu8JFuwRNBULGayghe18czpXQ3wYtmGgl4mRIcaXQQy09XcTrA9PNfOvnTmdhKKEi1dEG7CkzToMC8qqW08oG2jLSvsmRuk7THtbQTuYQ9+fyLjWDHJAEwosIqwCbHxcpusfjQH5WUI28EQ7xhvwnctOlaNWB8+GtbVcybEeIDPZ9E4bokYh8jyUm+0uVwBzpHWwhg86EM9ZLm5abbKaAw+yLJM1i9Xxh8Jj7IYEuj4q91YV3hHMygxHesNPddnKEqsEjPpJisW0G+laaOx9jS6dj2bpMuMB3+/eq5+dktWsslkRP+tITpsNTHRoIQzbNOiyqyoFHQ615rOMiT8Rvo837UhmEjDOM3AhahHZHl0ExdPRJkH71jgBAz8FQU9du1a+nVkPK9Yg4hVV+1whi3aMgtHmHYZADYAa1dyAC/sLETg1RSKBo207/fHqh0NnXY5rK3LbbIqMAl1GCLU71sh96Z7Ksajm3S6hU3WcjKn0jW1DZsQTbOsAL4klb0Y2xBCguPQrJSITYhGp02qpusMrhTgs+yQckXpY07kwnRGdIhmlop6t/7bykgBfLk+mcuiCdKvnTT3vrMbaZtxzmDH7I9Yy9VYuV4Zz7GYF7UcPWJ/JIsmOxxnHIrmSIhmKNQXS5odpx2JFlWc4Sy+9uANwDv6/cbuG6KTeeJmLsxuB9fX52aq6W+h5TOtAb7uRDRFh65VTfVhbHNWVJme16mz5ktKz+9HK4vmUWV0EkL8MvA+1B7UR6SU79rf9Q+H0an9+c+z/XV/CDJJWWgaG3rMSp8q/WJJK014sPO2porbl+HmU57Clkv/gLnbPsH17v+ntmYF9KWNL2JVeEw/5IuVMm9YOQlSUo9cXrmvxQu6+5iVPhUGBRaaCWfAW62PpvcP3WbK1nL7jR/i5DvfhC9C5qVHVQzIvQaAjnSpiBCJqsnx7vAK/s0+l2fG3+S97l/zpUqZd01O0LZtVkQxr9mnGKVorOMTtZew9f6f8gb3U2lNDkvAru9V2fejOoZRasXGOZobevT1l46U6uyUBSrcEy5Mc5yWNd4W/ip31p/Jay88juecegR86z3wtWuLRdpGSHeEIOtr7rqWqPHZlb/LnzxwMpdaN/PnpQ/i6AukIRzJ9WHfz4qsWJMb55jY0Cs821yb/2371ibzd/okoYXtxaw8dZbG+t6CdpnxuzE5h2v8z/PSLZ9j+63NAhuRWC9T2zLv+qdyg2tXqgViKor5vX0tnvZd2H1XU9WZadaYPH4HqzbM0sGjokMrUsIMVW4RJ3Mx/7Wg0B1Ae2vAztsayMRS9Vo2Drhp7SZ+xflaoZJoa2vATt1Wqyz58cRajn1oe6or+2SYPmo5Z/KjhS8Bhk6Vf+yfxQvtr1MSMd1givJFqjZ5/LmXY8UhD8lJPuT8CpeeMsUZd71elYMRKvQxs+6ZbHjwn2r+CA8AAAyOSURBVHV9IYElZKrbfF/f51zFqZe8jCMe/EI6D4xOJLBPpxjbhlO2YFQS6kdw84ZX8OLbNqR/mSi7vOVZJ/Ec+9vIz74MpJqLP5BHcqF9l2JOklXKDPBEyMzPA3bdNrHAjnDLyLBbsNtIuDg5Gs2O3eCrgxN4tnNL2i9jB7HMec3afsfZ1/GlPbycTxfmd2FOHYTsj9HpUQN4IYQN/BR4JrANuB14oZTyh4vdc7AA3/7859nxpjchh5nyhZ0UikYVrt9iWGFypAy25GenH8EFR30HTyxekvSLlTLX5tiGQFWRM4WG8jKQNjYJjijqNhYuW468nKktn12UFGAx6coSn47P5Ur763y16u23LQNpI1DEGoW+39YslFben64O1JbXh1fxb/Z5/J9NWzntrjdgs7juDiRD6fCP8flcaX99v2MwfvwO3IeDvc/o+uJtt7D39uoB7xtnG79wT8TV/yqx4qXpW0oWEM3sr+2rN7Vp5p4z7jpG3IZx9x2oHSpuLgo8wYvZ92J9GJWhdPhU8gtcbn3joOeBEWODhuYS4LnOt3m3+xFKMkttHtemh2tHeVlqX8fJuPmZn1PXXXbyQYH8/gD+0QzRnAncK6X8uZRyCHwSePahfMHu97y3AO6wOKsLLMaqJDj++w/sF1hgPIOPYXIZFU/EC4wfwJYh67cuzviyPzGsUp6ID9gWT8QF4wHd95Hi3PvT1YHa8jrnBnphzLq7rn9E4A5QElHat/3JUhiADsV9Rtetu8tLum/ceDzvmxTA/UDvXAwsFmv7npHnLIXNatx9B2qHLaMiCTyL2/dSAa8kIl5ofe1hgzvkGdAyeY31qQK4L9amh2tHB3ruUmXc/MzPqeu/8pOH//AReTQB/gjgwdx/b9O/FUQI8TIhxB1CiDv27NlzUC+IduwY//sSmWIO9HteDsQ2tFSx90c/daB7dTHYh9OWR9L3cbJG7AVIWYceqdgcWC8Ptw8P5z6bZMn3jdP7Yqw9B6vvpbbhkTAe/U/IUsb7QGJsMPvvxdmU8nKo58KhEtOf7a2D+6Len/yPb7JKKT8spTxDSnnGihUrDnxDTpypqfG/L5Ep5kC/5+VAbENLlXh/zA8HulcP18NpyyPp+zjZLtVmnWEdeqQSL8EUH24fHs59MdaS7xun98VYew5W30ttwyNhPPqfkKWM94HE2GD234uzKeXlUM+FQyWmP2uaC2v0PFx5NAH+IWBd7r/X6t8Omax89asQpWJGx2KsLrAYq5Lkx086koHc/+q9P3alURlIm0gu/IaLhcvW9YszvuxPDKvUQNoHbMtA2gxlsU74UthzDqYtfxpdQeDaPHjaa9P85ocrQ+mkfdufPNw+HOx9RteNjd0l3TduPD5zrmL/Weo7F9sKW6ztK0aesxQ2q3H3HagdsXAUy1BOFrPvpW7nDaXDPybPeFjzwIixwbz8efIChqJ4MnZcmw7FXHgkW5fj5md+Tr32wuMe/sNH5NEE+NuBY4QQRwkhSsCVwI2H8gWNZz2LqXe8A2dS5S875YipM+eob+gxQ1Wx8siM6ai6oV9kOipL/vOss7j1svdyrXgFe5Nqeu289JjHS3fIL+50uXbvTMrkUg8dfm9PyEXzPfbJKjPUSKTgITnJa8Or+SPxe8xQTe8fuE3s5/41T/iND/GD09/OdiZJpGBvUlXvyfVLAh089skqCYLtKGab97hXc614BWfNWbxlT8YmNBXFXDs7ZHOnB4113H36dbxFvJxtySSJVDv79fWG7Uix1zjliNWavWYeT7cfIlM2K1gGuSqZCPX7TlbwhvAq7qw/k+suO5lNl16N/dwPMnAbKTuT6XOisoiJpIWUKjtidExmqPG59W/kw9VX8LrwaqUz/ZxE60ICsRRjWbFWbpqlvl6NwT5ZVX3Q79ubqN9q6/vUNvVxKkmh75X1g7RdM1KN37ZkkteHV/GW6KW8Z8NLqZ1FgdFn1aY20ZF24V0Xz3d5zZ4uq8OMHeyZK9scsamFVVZsTkmzRrApoba+T4safRGk/dwnq3xKXMi8VS/qUEJ1fX8BS1V904Ab155d0FV9Q49VueuscsI9Rx3FfLmc3lc6I+HLG86lG5gv3yJID9wmn7V+WdkNgm4whf3cD2I/96/pBlMkKP1c5/4e3zn93YUxb1Hj5xuuhMY6NeaMjLkex32yyjvd36V22fv4welvZycrSKSgRY2B20Si/j1/T5Zvqh2Axjp+cPrb+ab3C2nbJ8ou513+CkrP/ctCW/9P/EtsZzJ97j5ZpTaiq5QNakMPgmWEVjY2EgitoDAXjJ72Jpn+DYNbrO+REmJt/+a9xr5eG17NW8TL6QZTSMSCOXWwWTT7k0c7TfJi4L2oNMm/lVK+Y3/XP5w0ycNyWA7LYfnfLPvLonlk39YHECnll4AvPZrvOCyH5bAclsMyXv7HN1kPy2E5LIflsDw6chjgD8thOSyH5XEqhwH+sByWw3JYHqdyGOAPy2E5LIflcSqPahbNwYoQYg+w9WHePgks7Sjb40f+N/YZ/nf2+3Cf//fIwfZ7vZRy7InD/6cA/pGIEOKOxVKFHq/y/7d3fyFSlXEYx79PVlIqmf0Ricg/dZFB2RYhaRIEld5oYBSVSQTdGORFkGKRdFdQQSBlkbCWVFRKEQTlEoYXaibr/0wtLxRzLwrLIAn9dXHerXHZ2cSZs8d5z/OBZY/vnB3eh5/z45wzM++pY2aoZ25nro925vYlGjOzTLnBm5llKqcG/3bVE6hAHTNDPXM7c320LXc21+DNzOxMOR3Bm5lZAzd4M7NMdXyDl3S/pH2SDkhaUvV8yiTpkKSdknolbU1j4yR9LWl/+n151fNshaRVkvok7WoYGzSjCm+k2u+Q1FXdzFvTJPdySUdSvXvT6qz9jy1NufdJuq+aWbdG0rWSvpG0R9JuSc+k8WzrPUTmcmodER37Q7EM8UFgMnAxsB2YWvW8Ssx7CLhywNgrwJK0vQR4uep5tphxFtAF7Pq/jMAc4EuKhc2nA5urnn+bcy8Hnh1k36np//pIYFJ6DYyoOsM5ZJ4AdKXtMcCPKVu29R4icym17vQj+NJv7N0B5gLdabsbmFfhXFoWEd8Cvw4YbpZxLrA6CpuAsZIGv4/jea5J7mbmAh9GxMmI+Bk4QPFa6CgRcTQitqXtP4C9FPdtzrbeQ2RupqVad3qDP6sbe2ckgK8kfS/pqTQ2PiL67z7+CzC+mqmVqlnGOtT/6XQ5YlXD5bfsckuaCNwKbKYm9R6QGUqodac3+LqZGRFdwGxgkaRZjQ9GcU6X9ede65CxwZvAFGAacBR4tdrplEPSaOBTYHFE/N74WK71HiRzKbXu9AZf+o29zycRcST97gPWUZyqHes/TU2/+6qbYWmaZcy6/hFxLCJORcRp4B3+OzXPJrekiyga3ZqIWJuGs673YJnLqnWnN/jSb+x9vpA0StKY/m3gXmAXRd6FabeFwGfVzLBUzTJ+DjyePl0xHTjecGrf8QZcX36Aot5Q5H5Y0khJk4AbgC3DPb9WSRLwLrA3Il5reCjbejfLXFqtq35XuQ3vSs+heCf6ILCs6vmUmHMyxbvp24Hd/VmBK4AeYD+wHhhX9VxbzPkBxSnq3xTXG59slpHi0xQrUu13ArdXPf82534v5dqRXugTGvZflnLvA2ZXPf9zzDyT4vLLDqA3/czJud5DZC6l1l6qwMwsU51+icbMzJpwgzczy5QbvJlZptzgzcwy5QZvZpYpN3izNpB0t6Qvqp6HWSM3eDOzTLnBW61IekzSlrTm9kpJIySdkPR6Wp+7R9JVad9pkjalBaDWNaxLfr2k9ZK2S9omaUp6+tGSPpH0g6Q16VuLZpVxg7fakHQj8BAwIyKmAaeAR4FRwNaIuAnYALyY/mQ18FxE3EzxLcP+8TXAioi4BbiT4huoUKwMuJhiDe/JwIzSQ5kN4cKqJ2A2jO4BbgO+SwfXl1AsZHUa+Cjt8z6wVtJlwNiI2JDGu4GP03pA10TEOoCI+AsgPd+WiDic/t0LTAQ2lh/LbHBu8FYnArojYukZg9ILA/Y71/U7TjZsn8KvL6uYL9FYnfQA8yVdDf/e+/M6itfB/LTPI8DGiDgO/CbprjS+ANgQxV14Dkual55jpKRLhzWF2VnyEYbVRkTskfQ8xV2xLqBYuXER8CdwR3qsj+I6PRRL1b6VGvhPwBNpfAGwUtJL6TkeHMYYZmfNq0la7Uk6ERGjq56HWbv5Eo2ZWaZ8BG9mlikfwZuZZcoN3swsU27wZmaZcoM3M8uUG7yZWab+Aa0nQ4NzO38iAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from piq import LPIPS\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "train_accu = []\n",
        "train_losses = []\n",
        "train_accu1 = []\n",
        "train_accu2 = []\n",
        "train_accu3 = []\n",
        "train_losses1 = []\n",
        "train_losses2 = []\n",
        "train_losses3 = []\n",
        "val_accu = []\n",
        "val_losses = []\n",
        "\n",
        "print(len(train_loader))\n",
        "\n",
        "#Lpips traditional perceptual loss\n",
        "lpips = LPIPS()\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    running_loss = 0\n",
        "    running_loss1 = 0\n",
        "    running_loss2 = 0\n",
        "    running_loss3 = 0\n",
        "    total = 0\n",
        "    total1 = 0\n",
        "    total2 = 0\n",
        "    total3 = 0\n",
        "    correct = 0\n",
        "    correct1 = 0\n",
        "    correct2 = 0\n",
        "    correct3 = 0\n",
        "\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = lpips(gts, pre_res[0])\n",
        "            loss2    = lpips(gts, pre_res[1])\n",
        "            loss3    = lpips(gts, pre_res[2])\n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "\n",
        "            #loss graph\n",
        "            running_loss1 += loss1.item()\n",
        "            running_loss2 += loss2.item()\n",
        "            running_loss3 += loss3.item()\n",
        "            predicted1 = pre_res[0]\n",
        "            predicted2 = pre_res[1]\n",
        "            predicted3 = pre_res[2]\n",
        "            total1 += images.size(0)\n",
        "            total2 += gts.size(0)\n",
        "            total3 += depths.size(0)\n",
        "            correct1 += predicted1.eq(images).sum().item()\n",
        "            correct2 += predicted2.eq(gts).sum().item()\n",
        "            correct3 += predicted3.eq(depths).sum().item()\n",
        "\n",
        "            running_loss += loss_all.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = gt + loss + predicted\n",
        "            total += images.size(0)\n",
        "            correct += outputs.eq(images).sum().item()\n",
        "            \n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "\n",
        "        train_loss = running_loss/len(train_loader)\n",
        "        train_loss1=running_loss1/len(train_loader)\n",
        "        train_loss2=running_loss2/len(train_loader)\n",
        "        train_loss3=running_loss3/len(train_loader)\n",
        "        accu = 100.*correct/total\n",
        "        accu1=100.*correct1/total1\n",
        "        accu2=100.*correct2/total2\n",
        "        accu3=100.*correct3/total3        \n",
        "        train_accu1.append(accu1)\n",
        "        train_accu2.append(accu2)\n",
        "        train_accu3.append(accu3)\n",
        "        train_losses1.append(train_loss1)\n",
        "        train_losses2.append(train_loss2)\n",
        "        train_losses3.append(train_loss3)\n",
        "        train_accu.append(accu)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "           \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-8)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "            mae_sum += np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "\n",
        "            #loss graph\n",
        "            running_loss += mae_sum.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = gt + loss + predicted\n",
        "            total += test_loader.size\n",
        "            correct += outputs.eq(image).sum().item()\n",
        "\n",
        "\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "       \n",
        "        val_loss=running_loss/len(test_loader)\n",
        "        accu=100.*correct/total\n",
        "        val_accu.append(accu)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_best_epoch_perceptual_loss_same_input.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n",
        "\n",
        "plt.plot(train_losses, '-o')\n",
        "plt.plot(train_losses1,'-o')\n",
        "plt.plot(train_losses2,'-o')\n",
        "plt.plot(train_losses3,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Perceptual Loss','Loss1', 'Loss2', 'Loss3'])\n",
        "plt.title('Train Losses')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_accu, '-o')\n",
        "plt.plot(train_accu1,'-o')\n",
        "plt.plot(train_accu2,'-o')\n",
        "plt.plot(train_accu3,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Accuracy','Acc1', 'Acc2', 'Acc3'])\n",
        "plt.title('Train Accuracy')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(val_losses,'-o')\n",
        "plt.plot(val_accu,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Losses','Accuracy'])\n",
        "plt.title('Test Losses and Accuracy')\n",
        " \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLyEvPIzJ93s"
      },
      "source": [
        "### Traing with SSIM Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f-X7u0NIKBOg",
        "outputId": "aa2a967a-f157-40ec-d5d0-31c836603466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USE GPU 0\n",
            "load data...\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/traindataset_only_depth/RGB/depth_00.png', '/content/tmp/traindataset_only_depth/RGB/depth_01.png', '/content/tmp/traindataset_only_depth/RGB/depth_02.png', '/content/tmp/traindataset_only_depth/RGB/depth_10.png', '/content/tmp/traindataset_only_depth/RGB/depth_100.png', '/content/tmp/traindataset_only_depth/RGB/depth_101.png', '/content/tmp/traindataset_only_depth/RGB/depth_102.png', '/content/tmp/traindataset_only_depth/RGB/depth_11.png', '/content/tmp/traindataset_only_depth/RGB/depth_110.png', '/content/tmp/traindataset_only_depth/RGB/depth_111.png', '/content/tmp/traindataset_only_depth/RGB/depth_112.png', '/content/tmp/traindataset_only_depth/RGB/depth_12.png', '/content/tmp/traindataset_only_depth/RGB/depth_120.png', '/content/tmp/traindataset_only_depth/RGB/depth_121.png', '/content/tmp/traindataset_only_depth/RGB/depth_122.png', '/content/tmp/traindataset_only_depth/RGB/depth_130.png', '/content/tmp/traindataset_only_depth/RGB/depth_131.png', '/content/tmp/traindataset_only_depth/RGB/depth_132.png', '/content/tmp/traindataset_only_depth/RGB/depth_140.png', '/content/tmp/traindataset_only_depth/RGB/depth_141.png', '/content/tmp/traindataset_only_depth/RGB/depth_142.png', '/content/tmp/traindataset_only_depth/RGB/depth_150.png', '/content/tmp/traindataset_only_depth/RGB/depth_151.png', '/content/tmp/traindataset_only_depth/RGB/depth_152.png', '/content/tmp/traindataset_only_depth/RGB/depth_160.png', '/content/tmp/traindataset_only_depth/RGB/depth_161.png', '/content/tmp/traindataset_only_depth/RGB/depth_162.png', '/content/tmp/traindataset_only_depth/RGB/depth_170.png', '/content/tmp/traindataset_only_depth/RGB/depth_171.png', '/content/tmp/traindataset_only_depth/RGB/depth_172.png', '/content/tmp/traindataset_only_depth/RGB/depth_180.png', '/content/tmp/traindataset_only_depth/RGB/depth_181.png', '/content/tmp/traindataset_only_depth/RGB/depth_182.png', '/content/tmp/traindataset_only_depth/RGB/depth_190.png', '/content/tmp/traindataset_only_depth/RGB/depth_191.png', '/content/tmp/traindataset_only_depth/RGB/depth_192.png', '/content/tmp/traindataset_only_depth/RGB/depth_20.png', '/content/tmp/traindataset_only_depth/RGB/depth_200.png', '/content/tmp/traindataset_only_depth/RGB/depth_201.png', '/content/tmp/traindataset_only_depth/RGB/depth_202.png', '/content/tmp/traindataset_only_depth/RGB/depth_21.png', '/content/tmp/traindataset_only_depth/RGB/depth_210.png', '/content/tmp/traindataset_only_depth/RGB/depth_211.png', '/content/tmp/traindataset_only_depth/RGB/depth_212.png', '/content/tmp/traindataset_only_depth/RGB/depth_22.png', '/content/tmp/traindataset_only_depth/RGB/depth_220.png', '/content/tmp/traindataset_only_depth/RGB/depth_221.png', '/content/tmp/traindataset_only_depth/RGB/depth_222.png', '/content/tmp/traindataset_only_depth/RGB/depth_230.png', '/content/tmp/traindataset_only_depth/RGB/depth_231.png', '/content/tmp/traindataset_only_depth/RGB/depth_232.png', '/content/tmp/traindataset_only_depth/RGB/depth_240.png', '/content/tmp/traindataset_only_depth/RGB/depth_241.png', '/content/tmp/traindataset_only_depth/RGB/depth_242.png', '/content/tmp/traindataset_only_depth/RGB/depth_250.png', '/content/tmp/traindataset_only_depth/RGB/depth_251.png', '/content/tmp/traindataset_only_depth/RGB/depth_252.png', '/content/tmp/traindataset_only_depth/RGB/depth_260.png', '/content/tmp/traindataset_only_depth/RGB/depth_261.png', '/content/tmp/traindataset_only_depth/RGB/depth_262.png', '/content/tmp/traindataset_only_depth/RGB/depth_270.png', '/content/tmp/traindataset_only_depth/RGB/depth_271.png', '/content/tmp/traindataset_only_depth/RGB/depth_272.png', '/content/tmp/traindataset_only_depth/RGB/depth_280.png', '/content/tmp/traindataset_only_depth/RGB/depth_281.png', '/content/tmp/traindataset_only_depth/RGB/depth_282.png', '/content/tmp/traindataset_only_depth/RGB/depth_290.png', '/content/tmp/traindataset_only_depth/RGB/depth_291.png', '/content/tmp/traindataset_only_depth/RGB/depth_292.png', '/content/tmp/traindataset_only_depth/RGB/depth_30.png', '/content/tmp/traindataset_only_depth/RGB/depth_300.png', '/content/tmp/traindataset_only_depth/RGB/depth_301.png', '/content/tmp/traindataset_only_depth/RGB/depth_302.png', '/content/tmp/traindataset_only_depth/RGB/depth_31.png', '/content/tmp/traindataset_only_depth/RGB/depth_310.png', '/content/tmp/traindataset_only_depth/RGB/depth_311.png', '/content/tmp/traindataset_only_depth/RGB/depth_312.png', '/content/tmp/traindataset_only_depth/RGB/depth_32.png', '/content/tmp/traindataset_only_depth/RGB/depth_320.png', '/content/tmp/traindataset_only_depth/RGB/depth_321.png', '/content/tmp/traindataset_only_depth/RGB/depth_322.png', '/content/tmp/traindataset_only_depth/RGB/depth_330.png', '/content/tmp/traindataset_only_depth/RGB/depth_331.png', '/content/tmp/traindataset_only_depth/RGB/depth_332.png', '/content/tmp/traindataset_only_depth/RGB/depth_340.png', '/content/tmp/traindataset_only_depth/RGB/depth_341.png', '/content/tmp/traindataset_only_depth/RGB/depth_342.png', '/content/tmp/traindataset_only_depth/RGB/depth_350.png', '/content/tmp/traindataset_only_depth/RGB/depth_351.png', '/content/tmp/traindataset_only_depth/RGB/depth_352.png', '/content/tmp/traindataset_only_depth/RGB/depth_360.png', '/content/tmp/traindataset_only_depth/RGB/depth_361.png', '/content/tmp/traindataset_only_depth/RGB/depth_362.png', '/content/tmp/traindataset_only_depth/RGB/depth_370.png', '/content/tmp/traindataset_only_depth/RGB/depth_371.png', '/content/tmp/traindataset_only_depth/RGB/depth_372.png', '/content/tmp/traindataset_only_depth/RGB/depth_380.png', '/content/tmp/traindataset_only_depth/RGB/depth_381.png', '/content/tmp/traindataset_only_depth/RGB/depth_382.png', '/content/tmp/traindataset_only_depth/RGB/depth_390.png', '/content/tmp/traindataset_only_depth/RGB/depth_391.png', '/content/tmp/traindataset_only_depth/RGB/depth_392.png', '/content/tmp/traindataset_only_depth/RGB/depth_40.png', '/content/tmp/traindataset_only_depth/RGB/depth_400.png', '/content/tmp/traindataset_only_depth/RGB/depth_401.png', '/content/tmp/traindataset_only_depth/RGB/depth_402.png', '/content/tmp/traindataset_only_depth/RGB/depth_41.png', '/content/tmp/traindataset_only_depth/RGB/depth_410.png', '/content/tmp/traindataset_only_depth/RGB/depth_411.png', '/content/tmp/traindataset_only_depth/RGB/depth_412.png', '/content/tmp/traindataset_only_depth/RGB/depth_42.png', '/content/tmp/traindataset_only_depth/RGB/depth_420.png', '/content/tmp/traindataset_only_depth/RGB/depth_421.png', '/content/tmp/traindataset_only_depth/RGB/depth_422.png', '/content/tmp/traindataset_only_depth/RGB/depth_430.png', '/content/tmp/traindataset_only_depth/RGB/depth_431.png', '/content/tmp/traindataset_only_depth/RGB/depth_432.png', '/content/tmp/traindataset_only_depth/RGB/depth_440.png', '/content/tmp/traindataset_only_depth/RGB/depth_441.png', '/content/tmp/traindataset_only_depth/RGB/depth_442.png', '/content/tmp/traindataset_only_depth/RGB/depth_450.png', '/content/tmp/traindataset_only_depth/RGB/depth_451.png', '/content/tmp/traindataset_only_depth/RGB/depth_452.png', '/content/tmp/traindataset_only_depth/RGB/depth_460.png', '/content/tmp/traindataset_only_depth/RGB/depth_461.png', '/content/tmp/traindataset_only_depth/RGB/depth_462.png', '/content/tmp/traindataset_only_depth/RGB/depth_470.png', '/content/tmp/traindataset_only_depth/RGB/depth_471.png', '/content/tmp/traindataset_only_depth/RGB/depth_472.png', '/content/tmp/traindataset_only_depth/RGB/depth_480.png', '/content/tmp/traindataset_only_depth/RGB/depth_481.png', '/content/tmp/traindataset_only_depth/RGB/depth_482.png', '/content/tmp/traindataset_only_depth/RGB/depth_490.png', '/content/tmp/traindataset_only_depth/RGB/depth_491.png', '/content/tmp/traindataset_only_depth/RGB/depth_492.png', '/content/tmp/traindataset_only_depth/RGB/depth_50.png', '/content/tmp/traindataset_only_depth/RGB/depth_500.png', '/content/tmp/traindataset_only_depth/RGB/depth_501.png', '/content/tmp/traindataset_only_depth/RGB/depth_502.png', '/content/tmp/traindataset_only_depth/RGB/depth_51.png', '/content/tmp/traindataset_only_depth/RGB/depth_510.png', '/content/tmp/traindataset_only_depth/RGB/depth_511.png', '/content/tmp/traindataset_only_depth/RGB/depth_512.png', '/content/tmp/traindataset_only_depth/RGB/depth_52.png', '/content/tmp/traindataset_only_depth/RGB/depth_520.png', '/content/tmp/traindataset_only_depth/RGB/depth_521.png', '/content/tmp/traindataset_only_depth/RGB/depth_522.png', '/content/tmp/traindataset_only_depth/RGB/depth_530.png', '/content/tmp/traindataset_only_depth/RGB/depth_531.png', '/content/tmp/traindataset_only_depth/RGB/depth_532.png', '/content/tmp/traindataset_only_depth/RGB/depth_540.png', '/content/tmp/traindataset_only_depth/RGB/depth_541.png', '/content/tmp/traindataset_only_depth/RGB/depth_542.png', '/content/tmp/traindataset_only_depth/RGB/depth_550.png', '/content/tmp/traindataset_only_depth/RGB/depth_551.png', '/content/tmp/traindataset_only_depth/RGB/depth_552.png', '/content/tmp/traindataset_only_depth/RGB/depth_560.png', '/content/tmp/traindataset_only_depth/RGB/depth_561.png', '/content/tmp/traindataset_only_depth/RGB/depth_562.png', '/content/tmp/traindataset_only_depth/RGB/depth_570.png', '/content/tmp/traindataset_only_depth/RGB/depth_571.png', '/content/tmp/traindataset_only_depth/RGB/depth_572.png', '/content/tmp/traindataset_only_depth/RGB/depth_580.png', '/content/tmp/traindataset_only_depth/RGB/depth_581.png', '/content/tmp/traindataset_only_depth/RGB/depth_582.png', '/content/tmp/traindataset_only_depth/RGB/depth_590.png', '/content/tmp/traindataset_only_depth/RGB/depth_591.png', '/content/tmp/traindataset_only_depth/RGB/depth_592.png', '/content/tmp/traindataset_only_depth/RGB/depth_60.png', '/content/tmp/traindataset_only_depth/RGB/depth_600.png', '/content/tmp/traindataset_only_depth/RGB/depth_601.png', '/content/tmp/traindataset_only_depth/RGB/depth_602.png', '/content/tmp/traindataset_only_depth/RGB/depth_61.png', '/content/tmp/traindataset_only_depth/RGB/depth_610.png', '/content/tmp/traindataset_only_depth/RGB/depth_611.png', '/content/tmp/traindataset_only_depth/RGB/depth_612.png', '/content/tmp/traindataset_only_depth/RGB/depth_62.png', '/content/tmp/traindataset_only_depth/RGB/depth_620.png', '/content/tmp/traindataset_only_depth/RGB/depth_621.png', '/content/tmp/traindataset_only_depth/RGB/depth_622.png', '/content/tmp/traindataset_only_depth/RGB/depth_630.png', '/content/tmp/traindataset_only_depth/RGB/depth_631.png', '/content/tmp/traindataset_only_depth/RGB/depth_632.png', '/content/tmp/traindataset_only_depth/RGB/depth_640.png', '/content/tmp/traindataset_only_depth/RGB/depth_641.png', '/content/tmp/traindataset_only_depth/RGB/depth_642.png', '/content/tmp/traindataset_only_depth/RGB/depth_650.png', '/content/tmp/traindataset_only_depth/RGB/depth_651.png', '/content/tmp/traindataset_only_depth/RGB/depth_652.png', '/content/tmp/traindataset_only_depth/RGB/depth_660.png', '/content/tmp/traindataset_only_depth/RGB/depth_661.png', '/content/tmp/traindataset_only_depth/RGB/depth_662.png', '/content/tmp/traindataset_only_depth/RGB/depth_670.png', '/content/tmp/traindataset_only_depth/RGB/depth_671.png', '/content/tmp/traindataset_only_depth/RGB/depth_672.png', '/content/tmp/traindataset_only_depth/RGB/depth_680.png', '/content/tmp/traindataset_only_depth/RGB/depth_681.png', '/content/tmp/traindataset_only_depth/RGB/depth_682.png', '/content/tmp/traindataset_only_depth/RGB/depth_690.png', '/content/tmp/traindataset_only_depth/RGB/depth_691.png', '/content/tmp/traindataset_only_depth/RGB/depth_692.png', '/content/tmp/traindataset_only_depth/RGB/depth_70.png', '/content/tmp/traindataset_only_depth/RGB/depth_700.png', '/content/tmp/traindataset_only_depth/RGB/depth_701.png', '/content/tmp/traindataset_only_depth/RGB/depth_702.png', '/content/tmp/traindataset_only_depth/RGB/depth_71.png', '/content/tmp/traindataset_only_depth/RGB/depth_710.png', '/content/tmp/traindataset_only_depth/RGB/depth_711.png', '/content/tmp/traindataset_only_depth/RGB/depth_712.png', '/content/tmp/traindataset_only_depth/RGB/depth_72.png', '/content/tmp/traindataset_only_depth/RGB/depth_720.png', '/content/tmp/traindataset_only_depth/RGB/depth_721.png', '/content/tmp/traindataset_only_depth/RGB/depth_722.png', '/content/tmp/traindataset_only_depth/RGB/depth_730.png', '/content/tmp/traindataset_only_depth/RGB/depth_731.png', '/content/tmp/traindataset_only_depth/RGB/depth_732.png', '/content/tmp/traindataset_only_depth/RGB/depth_740.png', '/content/tmp/traindataset_only_depth/RGB/depth_741.png', '/content/tmp/traindataset_only_depth/RGB/depth_742.png', '/content/tmp/traindataset_only_depth/RGB/depth_750.png', '/content/tmp/traindataset_only_depth/RGB/depth_751.png', '/content/tmp/traindataset_only_depth/RGB/depth_752.png', '/content/tmp/traindataset_only_depth/RGB/depth_760.png', '/content/tmp/traindataset_only_depth/RGB/depth_761.png', '/content/tmp/traindataset_only_depth/RGB/depth_762.png', '/content/tmp/traindataset_only_depth/RGB/depth_770.png', '/content/tmp/traindataset_only_depth/RGB/depth_771.png', '/content/tmp/traindataset_only_depth/RGB/depth_772.png', '/content/tmp/traindataset_only_depth/RGB/depth_780.png', '/content/tmp/traindataset_only_depth/RGB/depth_781.png', '/content/tmp/traindataset_only_depth/RGB/depth_782.png', '/content/tmp/traindataset_only_depth/RGB/depth_790.png', '/content/tmp/traindataset_only_depth/RGB/depth_791.png', '/content/tmp/traindataset_only_depth/RGB/depth_792.png', '/content/tmp/traindataset_only_depth/RGB/depth_80.png', '/content/tmp/traindataset_only_depth/RGB/depth_81.png', '/content/tmp/traindataset_only_depth/RGB/depth_82.png', '/content/tmp/traindataset_only_depth/RGB/depth_90.png', '/content/tmp/traindataset_only_depth/RGB/depth_91.png', '/content/tmp/traindataset_only_depth/RGB/depth_92.png'] ['/content/tmp/traindataset_only_depth/GT/GT_00.png', '/content/tmp/traindataset_only_depth/GT/GT_01.png', '/content/tmp/traindataset_only_depth/GT/GT_02.png', '/content/tmp/traindataset_only_depth/GT/GT_10.png', '/content/tmp/traindataset_only_depth/GT/GT_100.png', '/content/tmp/traindataset_only_depth/GT/GT_101.png', '/content/tmp/traindataset_only_depth/GT/GT_102.png', '/content/tmp/traindataset_only_depth/GT/GT_11.png', '/content/tmp/traindataset_only_depth/GT/GT_110.png', '/content/tmp/traindataset_only_depth/GT/GT_111.png', '/content/tmp/traindataset_only_depth/GT/GT_112.png', '/content/tmp/traindataset_only_depth/GT/GT_12.png', '/content/tmp/traindataset_only_depth/GT/GT_120.png', '/content/tmp/traindataset_only_depth/GT/GT_121.png', '/content/tmp/traindataset_only_depth/GT/GT_122.png', '/content/tmp/traindataset_only_depth/GT/GT_130.png', '/content/tmp/traindataset_only_depth/GT/GT_131.png', '/content/tmp/traindataset_only_depth/GT/GT_132.png', '/content/tmp/traindataset_only_depth/GT/GT_140.png', '/content/tmp/traindataset_only_depth/GT/GT_141.png', '/content/tmp/traindataset_only_depth/GT/GT_142.png', '/content/tmp/traindataset_only_depth/GT/GT_150.png', '/content/tmp/traindataset_only_depth/GT/GT_151.png', '/content/tmp/traindataset_only_depth/GT/GT_152.png', '/content/tmp/traindataset_only_depth/GT/GT_160.png', '/content/tmp/traindataset_only_depth/GT/GT_161.png', '/content/tmp/traindataset_only_depth/GT/GT_162.png', '/content/tmp/traindataset_only_depth/GT/GT_170.png', '/content/tmp/traindataset_only_depth/GT/GT_171.png', '/content/tmp/traindataset_only_depth/GT/GT_172.png', '/content/tmp/traindataset_only_depth/GT/GT_180.png', '/content/tmp/traindataset_only_depth/GT/GT_181.png', '/content/tmp/traindataset_only_depth/GT/GT_182.png', '/content/tmp/traindataset_only_depth/GT/GT_190.png', '/content/tmp/traindataset_only_depth/GT/GT_191.png', '/content/tmp/traindataset_only_depth/GT/GT_192.png', '/content/tmp/traindataset_only_depth/GT/GT_20.png', '/content/tmp/traindataset_only_depth/GT/GT_200.png', '/content/tmp/traindataset_only_depth/GT/GT_201.png', '/content/tmp/traindataset_only_depth/GT/GT_202.png', '/content/tmp/traindataset_only_depth/GT/GT_21.png', '/content/tmp/traindataset_only_depth/GT/GT_210.png', '/content/tmp/traindataset_only_depth/GT/GT_211.png', '/content/tmp/traindataset_only_depth/GT/GT_212.png', '/content/tmp/traindataset_only_depth/GT/GT_22.png', '/content/tmp/traindataset_only_depth/GT/GT_220.png', '/content/tmp/traindataset_only_depth/GT/GT_221.png', '/content/tmp/traindataset_only_depth/GT/GT_222.png', '/content/tmp/traindataset_only_depth/GT/GT_230.png', '/content/tmp/traindataset_only_depth/GT/GT_231.png', '/content/tmp/traindataset_only_depth/GT/GT_232.png', '/content/tmp/traindataset_only_depth/GT/GT_240.png', '/content/tmp/traindataset_only_depth/GT/GT_241.png', '/content/tmp/traindataset_only_depth/GT/GT_242.png', '/content/tmp/traindataset_only_depth/GT/GT_250.png', '/content/tmp/traindataset_only_depth/GT/GT_251.png', '/content/tmp/traindataset_only_depth/GT/GT_252.png', '/content/tmp/traindataset_only_depth/GT/GT_260.png', '/content/tmp/traindataset_only_depth/GT/GT_261.png', '/content/tmp/traindataset_only_depth/GT/GT_262.png', '/content/tmp/traindataset_only_depth/GT/GT_270.png', '/content/tmp/traindataset_only_depth/GT/GT_271.png', '/content/tmp/traindataset_only_depth/GT/GT_272.png', '/content/tmp/traindataset_only_depth/GT/GT_280.png', '/content/tmp/traindataset_only_depth/GT/GT_281.png', '/content/tmp/traindataset_only_depth/GT/GT_282.png', '/content/tmp/traindataset_only_depth/GT/GT_290.png', '/content/tmp/traindataset_only_depth/GT/GT_291.png', '/content/tmp/traindataset_only_depth/GT/GT_292.png', '/content/tmp/traindataset_only_depth/GT/GT_30.png', '/content/tmp/traindataset_only_depth/GT/GT_300.png', '/content/tmp/traindataset_only_depth/GT/GT_301.png', '/content/tmp/traindataset_only_depth/GT/GT_302.png', '/content/tmp/traindataset_only_depth/GT/GT_31.png', '/content/tmp/traindataset_only_depth/GT/GT_310.png', '/content/tmp/traindataset_only_depth/GT/GT_311.png', '/content/tmp/traindataset_only_depth/GT/GT_312.png', '/content/tmp/traindataset_only_depth/GT/GT_32.png', '/content/tmp/traindataset_only_depth/GT/GT_320.png', '/content/tmp/traindataset_only_depth/GT/GT_321.png', '/content/tmp/traindataset_only_depth/GT/GT_322.png', '/content/tmp/traindataset_only_depth/GT/GT_330.png', '/content/tmp/traindataset_only_depth/GT/GT_331.png', '/content/tmp/traindataset_only_depth/GT/GT_332.png', '/content/tmp/traindataset_only_depth/GT/GT_340.png', '/content/tmp/traindataset_only_depth/GT/GT_341.png', '/content/tmp/traindataset_only_depth/GT/GT_342.png', '/content/tmp/traindataset_only_depth/GT/GT_350.png', '/content/tmp/traindataset_only_depth/GT/GT_351.png', '/content/tmp/traindataset_only_depth/GT/GT_352.png', '/content/tmp/traindataset_only_depth/GT/GT_360.png', '/content/tmp/traindataset_only_depth/GT/GT_361.png', '/content/tmp/traindataset_only_depth/GT/GT_362.png', '/content/tmp/traindataset_only_depth/GT/GT_370.png', '/content/tmp/traindataset_only_depth/GT/GT_371.png', '/content/tmp/traindataset_only_depth/GT/GT_372.png', '/content/tmp/traindataset_only_depth/GT/GT_380.png', '/content/tmp/traindataset_only_depth/GT/GT_381.png', '/content/tmp/traindataset_only_depth/GT/GT_382.png', '/content/tmp/traindataset_only_depth/GT/GT_390.png', '/content/tmp/traindataset_only_depth/GT/GT_391.png', '/content/tmp/traindataset_only_depth/GT/GT_392.png', '/content/tmp/traindataset_only_depth/GT/GT_40.png', '/content/tmp/traindataset_only_depth/GT/GT_400.png', '/content/tmp/traindataset_only_depth/GT/GT_401.png', '/content/tmp/traindataset_only_depth/GT/GT_402.png', '/content/tmp/traindataset_only_depth/GT/GT_41.png', '/content/tmp/traindataset_only_depth/GT/GT_410.png', '/content/tmp/traindataset_only_depth/GT/GT_411.png', '/content/tmp/traindataset_only_depth/GT/GT_412.png', '/content/tmp/traindataset_only_depth/GT/GT_42.png', '/content/tmp/traindataset_only_depth/GT/GT_420.png', '/content/tmp/traindataset_only_depth/GT/GT_421.png', '/content/tmp/traindataset_only_depth/GT/GT_422.png', '/content/tmp/traindataset_only_depth/GT/GT_430.png', '/content/tmp/traindataset_only_depth/GT/GT_431.png', '/content/tmp/traindataset_only_depth/GT/GT_432.png', '/content/tmp/traindataset_only_depth/GT/GT_440.png', '/content/tmp/traindataset_only_depth/GT/GT_441.png', '/content/tmp/traindataset_only_depth/GT/GT_442.png', '/content/tmp/traindataset_only_depth/GT/GT_450.png', '/content/tmp/traindataset_only_depth/GT/GT_451.png', '/content/tmp/traindataset_only_depth/GT/GT_452.png', '/content/tmp/traindataset_only_depth/GT/GT_460.png', '/content/tmp/traindataset_only_depth/GT/GT_461.png', '/content/tmp/traindataset_only_depth/GT/GT_462.png', '/content/tmp/traindataset_only_depth/GT/GT_470.png', '/content/tmp/traindataset_only_depth/GT/GT_471.png', '/content/tmp/traindataset_only_depth/GT/GT_472.png', '/content/tmp/traindataset_only_depth/GT/GT_480.png', '/content/tmp/traindataset_only_depth/GT/GT_481.png', '/content/tmp/traindataset_only_depth/GT/GT_482.png', '/content/tmp/traindataset_only_depth/GT/GT_490.png', '/content/tmp/traindataset_only_depth/GT/GT_491.png', '/content/tmp/traindataset_only_depth/GT/GT_492.png', '/content/tmp/traindataset_only_depth/GT/GT_50.png', '/content/tmp/traindataset_only_depth/GT/GT_500.png', '/content/tmp/traindataset_only_depth/GT/GT_501.png', '/content/tmp/traindataset_only_depth/GT/GT_502.png', '/content/tmp/traindataset_only_depth/GT/GT_51.png', '/content/tmp/traindataset_only_depth/GT/GT_510.png', '/content/tmp/traindataset_only_depth/GT/GT_511.png', '/content/tmp/traindataset_only_depth/GT/GT_512.png', '/content/tmp/traindataset_only_depth/GT/GT_52.png', '/content/tmp/traindataset_only_depth/GT/GT_520.png', '/content/tmp/traindataset_only_depth/GT/GT_521.png', '/content/tmp/traindataset_only_depth/GT/GT_522.png', '/content/tmp/traindataset_only_depth/GT/GT_530.png', '/content/tmp/traindataset_only_depth/GT/GT_531.png', '/content/tmp/traindataset_only_depth/GT/GT_532.png', '/content/tmp/traindataset_only_depth/GT/GT_540.png', '/content/tmp/traindataset_only_depth/GT/GT_541.png', '/content/tmp/traindataset_only_depth/GT/GT_542.png', '/content/tmp/traindataset_only_depth/GT/GT_550.png', '/content/tmp/traindataset_only_depth/GT/GT_551.png', '/content/tmp/traindataset_only_depth/GT/GT_552.png', '/content/tmp/traindataset_only_depth/GT/GT_560.png', '/content/tmp/traindataset_only_depth/GT/GT_561.png', '/content/tmp/traindataset_only_depth/GT/GT_562.png', '/content/tmp/traindataset_only_depth/GT/GT_570.png', '/content/tmp/traindataset_only_depth/GT/GT_571.png', '/content/tmp/traindataset_only_depth/GT/GT_572.png', '/content/tmp/traindataset_only_depth/GT/GT_580.png', '/content/tmp/traindataset_only_depth/GT/GT_581.png', '/content/tmp/traindataset_only_depth/GT/GT_582.png', '/content/tmp/traindataset_only_depth/GT/GT_590.png', '/content/tmp/traindataset_only_depth/GT/GT_591.png', '/content/tmp/traindataset_only_depth/GT/GT_592.png', '/content/tmp/traindataset_only_depth/GT/GT_60.png', '/content/tmp/traindataset_only_depth/GT/GT_600.png', '/content/tmp/traindataset_only_depth/GT/GT_601.png', '/content/tmp/traindataset_only_depth/GT/GT_602.png', '/content/tmp/traindataset_only_depth/GT/GT_61.png', '/content/tmp/traindataset_only_depth/GT/GT_610.png', '/content/tmp/traindataset_only_depth/GT/GT_611.png', '/content/tmp/traindataset_only_depth/GT/GT_612.png', '/content/tmp/traindataset_only_depth/GT/GT_62.png', '/content/tmp/traindataset_only_depth/GT/GT_620.png', '/content/tmp/traindataset_only_depth/GT/GT_621.png', '/content/tmp/traindataset_only_depth/GT/GT_622.png', '/content/tmp/traindataset_only_depth/GT/GT_630.png', '/content/tmp/traindataset_only_depth/GT/GT_631.png', '/content/tmp/traindataset_only_depth/GT/GT_632.png', '/content/tmp/traindataset_only_depth/GT/GT_640.png', '/content/tmp/traindataset_only_depth/GT/GT_641.png', '/content/tmp/traindataset_only_depth/GT/GT_642.png', '/content/tmp/traindataset_only_depth/GT/GT_650.png', '/content/tmp/traindataset_only_depth/GT/GT_651.png', '/content/tmp/traindataset_only_depth/GT/GT_652.png', '/content/tmp/traindataset_only_depth/GT/GT_660.png', '/content/tmp/traindataset_only_depth/GT/GT_661.png', '/content/tmp/traindataset_only_depth/GT/GT_662.png', '/content/tmp/traindataset_only_depth/GT/GT_670.png', '/content/tmp/traindataset_only_depth/GT/GT_671.png', '/content/tmp/traindataset_only_depth/GT/GT_672.png', '/content/tmp/traindataset_only_depth/GT/GT_680.png', '/content/tmp/traindataset_only_depth/GT/GT_681.png', '/content/tmp/traindataset_only_depth/GT/GT_682.png', '/content/tmp/traindataset_only_depth/GT/GT_690.png', '/content/tmp/traindataset_only_depth/GT/GT_691.png', '/content/tmp/traindataset_only_depth/GT/GT_692.png', '/content/tmp/traindataset_only_depth/GT/GT_70.png', '/content/tmp/traindataset_only_depth/GT/GT_700.png', '/content/tmp/traindataset_only_depth/GT/GT_701.png', '/content/tmp/traindataset_only_depth/GT/GT_702.png', '/content/tmp/traindataset_only_depth/GT/GT_71.png', '/content/tmp/traindataset_only_depth/GT/GT_710.png', '/content/tmp/traindataset_only_depth/GT/GT_711.png', '/content/tmp/traindataset_only_depth/GT/GT_712.png', '/content/tmp/traindataset_only_depth/GT/GT_72.png', '/content/tmp/traindataset_only_depth/GT/GT_720.png', '/content/tmp/traindataset_only_depth/GT/GT_721.png', '/content/tmp/traindataset_only_depth/GT/GT_722.png', '/content/tmp/traindataset_only_depth/GT/GT_730.png', '/content/tmp/traindataset_only_depth/GT/GT_731.png', '/content/tmp/traindataset_only_depth/GT/GT_732.png', '/content/tmp/traindataset_only_depth/GT/GT_740.png', '/content/tmp/traindataset_only_depth/GT/GT_741.png', '/content/tmp/traindataset_only_depth/GT/GT_742.png', '/content/tmp/traindataset_only_depth/GT/GT_750.png', '/content/tmp/traindataset_only_depth/GT/GT_751.png', '/content/tmp/traindataset_only_depth/GT/GT_752.png', '/content/tmp/traindataset_only_depth/GT/GT_760.png', '/content/tmp/traindataset_only_depth/GT/GT_761.png', '/content/tmp/traindataset_only_depth/GT/GT_762.png', '/content/tmp/traindataset_only_depth/GT/GT_770.png', '/content/tmp/traindataset_only_depth/GT/GT_771.png', '/content/tmp/traindataset_only_depth/GT/GT_772.png', '/content/tmp/traindataset_only_depth/GT/GT_780.png', '/content/tmp/traindataset_only_depth/GT/GT_781.png', '/content/tmp/traindataset_only_depth/GT/GT_782.png', '/content/tmp/traindataset_only_depth/GT/GT_790.png', '/content/tmp/traindataset_only_depth/GT/GT_791.png', '/content/tmp/traindataset_only_depth/GT/GT_792.png', '/content/tmp/traindataset_only_depth/GT/GT_80.png', '/content/tmp/traindataset_only_depth/GT/GT_81.png', '/content/tmp/traindataset_only_depth/GT/GT_82.png', '/content/tmp/traindataset_only_depth/GT/GT_90.png', '/content/tmp/traindataset_only_depth/GT/GT_91.png', '/content/tmp/traindataset_only_depth/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7f4dc8f92f10>\n",
            "Start train...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-01 18:28:25.141779 Epoch [001/250], Step [0001/0060], Loss1: 0.0515 Loss2: 0.0533 Loss3: 0.1466\n",
            "2022-08-01 18:28:53.708889 Epoch [001/250], Step [0050/0060], Loss1: -0.8905 Loss2: -0.8886 Loss3: -0.8851\n",
            "2022-08-01 18:28:59.548060 Epoch [001/250], Step [0060/0060], Loss1: -0.7986 Loss2: -0.8530 Loss3: -0.8570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 MAE: 0.2666885386068354 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-08-01 18:29:09.541007 Epoch [002/250], Step [0001/0060], Loss1: -0.8574 Loss2: -0.8837 Loss3: -0.8780\n",
            "2022-08-01 18:29:38.135409 Epoch [002/250], Step [0050/0060], Loss1: -0.9457 Loss2: -0.9369 Loss3: -0.9553\n",
            "2022-08-01 18:29:43.973002 Epoch [002/250], Step [0060/0060], Loss1: -0.9411 Loss2: -0.9346 Loss3: -0.9508\n",
            "Epoch: 2 MAE: 0.24625908564007468 ####  bestMAE: 0.2666885386068354 bestEpoch: 0\n",
            "best epoch:2\n",
            "2022-08-01 18:29:55.833565 Epoch [003/250], Step [0001/0060], Loss1: -0.9554 Loss2: -0.9375 Loss3: -0.9641\n",
            "2022-08-01 18:30:25.279454 Epoch [003/250], Step [0050/0060], Loss1: -0.9537 Loss2: -0.9349 Loss3: -0.9587\n",
            "2022-08-01 18:30:31.123259 Epoch [003/250], Step [0060/0060], Loss1: -0.9441 Loss2: -0.9292 Loss3: -0.9548\n",
            "Epoch: 3 MAE: 0.17958114482738355 ####  bestMAE: 0.24625908564007468 bestEpoch: 2\n",
            "best epoch:3\n",
            "2022-08-01 18:30:41.294456 Epoch [004/250], Step [0001/0060], Loss1: -0.9565 Loss2: -0.9539 Loss3: -0.9703\n",
            "2022-08-01 18:31:10.621838 Epoch [004/250], Step [0050/0060], Loss1: -0.9669 Loss2: -0.9586 Loss3: -0.9736\n",
            "2022-08-01 18:31:16.410202 Epoch [004/250], Step [0060/0060], Loss1: -0.9596 Loss2: -0.9564 Loss3: -0.9705\n",
            "Epoch: 4 MAE: 0.19702985369969922 ####  bestMAE: 0.17958114482738355 bestEpoch: 3\n",
            "2022-08-01 18:31:24.090471 Epoch [005/250], Step [0001/0060], Loss1: -0.9342 Loss2: -0.9213 Loss3: -0.9465\n",
            "2022-08-01 18:31:52.970797 Epoch [005/250], Step [0050/0060], Loss1: -0.9709 Loss2: -0.9589 Loss3: -0.9774\n",
            "2022-08-01 18:31:58.806756 Epoch [005/250], Step [0060/0060], Loss1: -0.9556 Loss2: -0.9482 Loss3: -0.9652\n",
            "Epoch: 5 MAE: 0.1505701490937086 ####  bestMAE: 0.17958114482738355 bestEpoch: 3\n",
            "best epoch:5\n",
            "2022-08-01 18:32:11.340124 Epoch [006/250], Step [0001/0060], Loss1: -0.9624 Loss2: -0.9479 Loss3: -0.9724\n",
            "2022-08-01 18:32:41.321674 Epoch [006/250], Step [0050/0060], Loss1: -0.9711 Loss2: -0.9586 Loss3: -0.9779\n",
            "2022-08-01 18:32:47.199228 Epoch [006/250], Step [0060/0060], Loss1: -0.9736 Loss2: -0.9568 Loss3: -0.9802\n",
            "Epoch: 6 MAE: 0.13289189666667306 ####  bestMAE: 0.1505701490937086 bestEpoch: 5\n",
            "best epoch:6\n",
            "2022-08-01 18:32:57.609438 Epoch [007/250], Step [0001/0060], Loss1: -0.9735 Loss2: -0.9601 Loss3: -0.9802\n",
            "2022-08-01 18:33:27.481926 Epoch [007/250], Step [0050/0060], Loss1: -0.9752 Loss2: -0.9588 Loss3: -0.9815\n",
            "2022-08-01 18:33:33.342452 Epoch [007/250], Step [0060/0060], Loss1: -0.9656 Loss2: -0.9581 Loss3: -0.9748\n",
            "Epoch: 7 MAE: 0.12752628114488393 ####  bestMAE: 0.13289189666667306 bestEpoch: 6\n",
            "best epoch:7\n",
            "2022-08-01 18:33:43.680129 Epoch [008/250], Step [0001/0060], Loss1: -0.9748 Loss2: -0.9642 Loss3: -0.9823\n",
            "2022-08-01 18:34:12.892058 Epoch [008/250], Step [0050/0060], Loss1: -0.9762 Loss2: -0.9701 Loss3: -0.9835\n",
            "2022-08-01 18:34:18.773082 Epoch [008/250], Step [0060/0060], Loss1: -0.9766 Loss2: -0.9643 Loss3: -0.9833\n",
            "Epoch: 8 MAE: 0.12916339692615325 ####  bestMAE: 0.12752628114488393 bestEpoch: 7\n",
            "2022-08-01 18:34:26.500603 Epoch [009/250], Step [0001/0060], Loss1: -0.9711 Loss2: -0.9601 Loss3: -0.9772\n",
            "2022-08-01 18:34:55.243402 Epoch [009/250], Step [0050/0060], Loss1: -0.9739 Loss2: -0.9710 Loss3: -0.9830\n",
            "2022-08-01 18:35:01.102591 Epoch [009/250], Step [0060/0060], Loss1: -0.9789 Loss2: -0.9687 Loss3: -0.9839\n",
            "Epoch: 9 MAE: 0.11984912075062909 ####  bestMAE: 0.12752628114488393 bestEpoch: 7\n",
            "best epoch:9\n",
            "2022-08-01 18:35:11.199619 Epoch [010/250], Step [0001/0060], Loss1: -0.9589 Loss2: -0.9423 Loss3: -0.9660\n",
            "2022-08-01 18:35:40.548073 Epoch [010/250], Step [0050/0060], Loss1: -0.9809 Loss2: -0.9740 Loss3: -0.9861\n",
            "2022-08-01 18:35:46.419437 Epoch [010/250], Step [0060/0060], Loss1: -0.9761 Loss2: -0.9684 Loss3: -0.9852\n",
            "Epoch: 10 MAE: 0.11545859240981006 ####  bestMAE: 0.11984912075062909 bestEpoch: 9\n",
            "best epoch:10\n",
            "2022-08-01 18:35:59.021551 Epoch [011/250], Step [0001/0060], Loss1: -0.9676 Loss2: -0.9561 Loss3: -0.9729\n",
            "2022-08-01 18:36:28.600817 Epoch [011/250], Step [0050/0060], Loss1: -0.9807 Loss2: -0.9702 Loss3: -0.9847\n",
            "2022-08-01 18:36:34.477326 Epoch [011/250], Step [0060/0060], Loss1: -0.9707 Loss2: -0.9645 Loss3: -0.9764\n",
            "Epoch: 11 MAE: 0.12520447503952753 ####  bestMAE: 0.11545859240981006 bestEpoch: 10\n",
            "2022-08-01 18:36:42.150516 Epoch [012/250], Step [0001/0060], Loss1: -0.9767 Loss2: -0.9681 Loss3: -0.9802\n",
            "2022-08-01 18:37:10.921688 Epoch [012/250], Step [0050/0060], Loss1: -0.9780 Loss2: -0.9716 Loss3: -0.9827\n",
            "2022-08-01 18:37:16.763662 Epoch [012/250], Step [0060/0060], Loss1: -0.9818 Loss2: -0.9756 Loss3: -0.9864\n",
            "Epoch: 12 MAE: 0.12120700200398762 ####  bestMAE: 0.11545859240981006 bestEpoch: 10\n",
            "2022-08-01 18:37:24.542589 Epoch [013/250], Step [0001/0060], Loss1: -0.9776 Loss2: -0.9679 Loss3: -0.9816\n",
            "2022-08-01 18:37:53.302939 Epoch [013/250], Step [0050/0060], Loss1: -0.9817 Loss2: -0.9741 Loss3: -0.9858\n",
            "2022-08-01 18:37:59.173178 Epoch [013/250], Step [0060/0060], Loss1: -0.9763 Loss2: -0.9755 Loss3: -0.9848\n",
            "Epoch: 13 MAE: 0.10123050255750218 ####  bestMAE: 0.11545859240981006 bestEpoch: 10\n",
            "best epoch:13\n",
            "2022-08-01 18:38:09.321448 Epoch [014/250], Step [0001/0060], Loss1: -0.9828 Loss2: -0.9752 Loss3: -0.9867\n",
            "2022-08-01 18:38:38.556029 Epoch [014/250], Step [0050/0060], Loss1: -0.9771 Loss2: -0.9698 Loss3: -0.9811\n",
            "2022-08-01 18:38:44.421710 Epoch [014/250], Step [0060/0060], Loss1: -0.9702 Loss2: -0.9639 Loss3: -0.9791\n",
            "Epoch: 14 MAE: 0.11241205225545896 ####  bestMAE: 0.10123050255750218 bestEpoch: 13\n",
            "2022-08-01 18:38:52.079364 Epoch [015/250], Step [0001/0060], Loss1: -0.9828 Loss2: -0.9743 Loss3: -0.9875\n",
            "2022-08-01 18:39:20.997033 Epoch [015/250], Step [0050/0060], Loss1: -0.9824 Loss2: -0.9762 Loss3: -0.9866\n",
            "2022-08-01 18:39:26.878228 Epoch [015/250], Step [0060/0060], Loss1: -0.9798 Loss2: -0.9727 Loss3: -0.9853\n",
            "Epoch: 15 MAE: 0.09499865375498615 ####  bestMAE: 0.10123050255750218 bestEpoch: 13\n",
            "best epoch:15\n",
            "2022-08-01 18:39:39.465556 Epoch [016/250], Step [0001/0060], Loss1: -0.9842 Loss2: -0.9766 Loss3: -0.9876\n",
            "2022-08-01 18:40:09.365223 Epoch [016/250], Step [0050/0060], Loss1: -0.9586 Loss2: -0.9379 Loss3: -0.9674\n",
            "2022-08-01 18:40:15.197953 Epoch [016/250], Step [0060/0060], Loss1: -0.9838 Loss2: -0.9752 Loss3: -0.9869\n",
            "Epoch: 16 MAE: 0.09676995696214141 ####  bestMAE: 0.09499865375498615 bestEpoch: 15\n",
            "2022-08-01 18:40:22.819672 Epoch [017/250], Step [0001/0060], Loss1: -0.9776 Loss2: -0.9696 Loss3: -0.9832\n",
            "2022-08-01 18:40:51.794783 Epoch [017/250], Step [0050/0060], Loss1: -0.9841 Loss2: -0.9774 Loss3: -0.9891\n",
            "2022-08-01 18:40:57.655929 Epoch [017/250], Step [0060/0060], Loss1: -0.9850 Loss2: -0.9778 Loss3: -0.9894\n",
            "Epoch: 17 MAE: 0.09510748293033983 ####  bestMAE: 0.09499865375498615 bestEpoch: 15\n",
            "2022-08-01 18:41:05.374922 Epoch [018/250], Step [0001/0060], Loss1: -0.9819 Loss2: -0.9721 Loss3: -0.9868\n",
            "2022-08-01 18:41:34.184790 Epoch [018/250], Step [0050/0060], Loss1: -0.9812 Loss2: -0.9705 Loss3: -0.9860\n",
            "2022-08-01 18:41:40.114626 Epoch [018/250], Step [0060/0060], Loss1: -0.9839 Loss2: -0.9717 Loss3: -0.9881\n",
            "Epoch: 18 MAE: 0.0935682334092559 ####  bestMAE: 0.09499865375498615 bestEpoch: 15\n",
            "best epoch:18\n",
            "2022-08-01 18:41:50.242161 Epoch [019/250], Step [0001/0060], Loss1: -0.9816 Loss2: -0.9781 Loss3: -0.9874\n",
            "2022-08-01 18:42:19.657644 Epoch [019/250], Step [0050/0060], Loss1: -0.9835 Loss2: -0.9733 Loss3: -0.9879\n",
            "2022-08-01 18:42:25.535335 Epoch [019/250], Step [0060/0060], Loss1: -0.9835 Loss2: -0.9758 Loss3: -0.9875\n",
            "Epoch: 19 MAE: 0.08699960365497249 ####  bestMAE: 0.0935682334092559 bestEpoch: 18\n",
            "best epoch:19\n",
            "2022-08-01 18:42:35.972590 Epoch [020/250], Step [0001/0060], Loss1: -0.9796 Loss2: -0.9712 Loss3: -0.9853\n",
            "2022-08-01 18:43:05.278532 Epoch [020/250], Step [0050/0060], Loss1: -0.9836 Loss2: -0.9799 Loss3: -0.9878\n",
            "2022-08-01 18:43:11.131896 Epoch [020/250], Step [0060/0060], Loss1: -0.9845 Loss2: -0.9744 Loss3: -0.9880\n",
            "Epoch: 20 MAE: 0.09768348058064778 ####  bestMAE: 0.08699960365497249 bestEpoch: 19\n",
            "2022-08-01 18:43:21.155553 Epoch [021/250], Step [0001/0060], Loss1: -0.9777 Loss2: -0.9749 Loss3: -0.9841\n",
            "2022-08-01 18:43:50.102815 Epoch [021/250], Step [0050/0060], Loss1: -0.9816 Loss2: -0.9745 Loss3: -0.9854\n",
            "2022-08-01 18:43:55.963209 Epoch [021/250], Step [0060/0060], Loss1: -0.9858 Loss2: -0.9806 Loss3: -0.9891\n",
            "Epoch: 21 MAE: 0.10103004344556697 ####  bestMAE: 0.08699960365497249 bestEpoch: 19\n",
            "2022-08-01 18:44:03.683728 Epoch [022/250], Step [0001/0060], Loss1: -0.9854 Loss2: -0.9784 Loss3: -0.9890\n",
            "2022-08-01 18:44:32.283470 Epoch [022/250], Step [0050/0060], Loss1: -0.9858 Loss2: -0.9783 Loss3: -0.9887\n",
            "2022-08-01 18:44:38.087049 Epoch [022/250], Step [0060/0060], Loss1: -0.9781 Loss2: -0.9772 Loss3: -0.9852\n",
            "Epoch: 22 MAE: 0.10065167189905884 ####  bestMAE: 0.08699960365497249 bestEpoch: 19\n",
            "2022-08-01 18:44:45.765574 Epoch [023/250], Step [0001/0060], Loss1: -0.9837 Loss2: -0.9751 Loss3: -0.9845\n",
            "2022-08-01 18:45:14.258242 Epoch [023/250], Step [0050/0060], Loss1: -0.9805 Loss2: -0.9698 Loss3: -0.9853\n",
            "2022-08-01 18:45:20.095249 Epoch [023/250], Step [0060/0060], Loss1: -0.9847 Loss2: -0.9759 Loss3: -0.9874\n",
            "Epoch: 23 MAE: 0.09116481932382732 ####  bestMAE: 0.08699960365497249 bestEpoch: 19\n",
            "2022-08-01 18:45:27.745487 Epoch [024/250], Step [0001/0060], Loss1: -0.9857 Loss2: -0.9799 Loss3: -0.9889\n",
            "2022-08-01 18:45:56.495568 Epoch [024/250], Step [0050/0060], Loss1: -0.9822 Loss2: -0.9761 Loss3: -0.9858\n",
            "2022-08-01 18:46:02.389085 Epoch [024/250], Step [0060/0060], Loss1: -0.9873 Loss2: -0.9778 Loss3: -0.9894\n",
            "Epoch: 24 MAE: 0.08656097301099668 ####  bestMAE: 0.08699960365497249 bestEpoch: 19\n",
            "best epoch:24\n",
            "2022-08-01 18:46:12.597084 Epoch [025/250], Step [0001/0060], Loss1: -0.9841 Loss2: -0.9774 Loss3: -0.9880\n",
            "2022-08-01 18:46:42.350598 Epoch [025/250], Step [0050/0060], Loss1: -0.9851 Loss2: -0.9795 Loss3: -0.9885\n",
            "2022-08-01 18:46:48.181223 Epoch [025/250], Step [0060/0060], Loss1: -0.9871 Loss2: -0.9813 Loss3: -0.9896\n",
            "Epoch: 25 MAE: 0.08569695114458677 ####  bestMAE: 0.08656097301099668 bestEpoch: 24\n",
            "best epoch:25\n",
            "2022-08-01 18:47:00.837854 Epoch [026/250], Step [0001/0060], Loss1: -0.9870 Loss2: -0.9803 Loss3: -0.9904\n",
            "2022-08-01 18:47:30.680909 Epoch [026/250], Step [0050/0060], Loss1: -0.9818 Loss2: -0.9781 Loss3: -0.9855\n",
            "2022-08-01 18:47:36.540772 Epoch [026/250], Step [0060/0060], Loss1: -0.9849 Loss2: -0.9758 Loss3: -0.9882\n",
            "Epoch: 26 MAE: 0.08123184214193356 ####  bestMAE: 0.08569695114458677 bestEpoch: 25\n",
            "best epoch:26\n",
            "2022-08-01 18:47:46.744523 Epoch [027/250], Step [0001/0060], Loss1: -0.9877 Loss2: -0.9820 Loss3: -0.9907\n",
            "2022-08-01 18:48:16.477197 Epoch [027/250], Step [0050/0060], Loss1: -0.9859 Loss2: -0.9795 Loss3: -0.9884\n",
            "2022-08-01 18:48:22.315169 Epoch [027/250], Step [0060/0060], Loss1: -0.9883 Loss2: -0.9825 Loss3: -0.9908\n",
            "Epoch: 27 MAE: 0.08543131116836791 ####  bestMAE: 0.08123184214193356 bestEpoch: 26\n",
            "2022-08-01 18:48:30.024403 Epoch [028/250], Step [0001/0060], Loss1: -0.9813 Loss2: -0.9744 Loss3: -0.9851\n",
            "2022-08-01 18:48:58.697313 Epoch [028/250], Step [0050/0060], Loss1: -0.9879 Loss2: -0.9820 Loss3: -0.9903\n",
            "2022-08-01 18:49:04.523848 Epoch [028/250], Step [0060/0060], Loss1: -0.9866 Loss2: -0.9834 Loss3: -0.9903\n",
            "Epoch: 28 MAE: 0.08122109039750679 ####  bestMAE: 0.08123184214193356 bestEpoch: 26\n",
            "best epoch:28\n",
            "2022-08-01 18:49:14.781723 Epoch [029/250], Step [0001/0060], Loss1: -0.9837 Loss2: -0.9773 Loss3: -0.9867\n",
            "2022-08-01 18:49:43.918407 Epoch [029/250], Step [0050/0060], Loss1: -0.9841 Loss2: -0.9728 Loss3: -0.9850\n",
            "2022-08-01 18:49:49.797389 Epoch [029/250], Step [0060/0060], Loss1: -0.9873 Loss2: -0.9798 Loss3: -0.9890\n",
            "Epoch: 29 MAE: 0.08023408304446591 ####  bestMAE: 0.08122109039750679 bestEpoch: 28\n",
            "best epoch:29\n",
            "2022-08-01 18:50:00.085918 Epoch [030/250], Step [0001/0060], Loss1: -0.9865 Loss2: -0.9767 Loss3: -0.9887\n",
            "2022-08-01 18:50:29.193142 Epoch [030/250], Step [0050/0060], Loss1: -0.9868 Loss2: -0.9780 Loss3: -0.9891\n",
            "2022-08-01 18:50:35.020812 Epoch [030/250], Step [0060/0060], Loss1: -0.9845 Loss2: -0.9745 Loss3: -0.9867\n",
            "Epoch: 30 MAE: 0.08535422834769757 ####  bestMAE: 0.08023408304446591 bestEpoch: 29\n",
            "2022-08-01 18:50:45.270857 Epoch [031/250], Step [0001/0060], Loss1: -0.9806 Loss2: -0.9686 Loss3: -0.9826\n",
            "2022-08-01 18:51:14.188606 Epoch [031/250], Step [0050/0060], Loss1: -0.9859 Loss2: -0.9766 Loss3: -0.9885\n",
            "2022-08-01 18:51:20.039730 Epoch [031/250], Step [0060/0060], Loss1: -0.9850 Loss2: -0.9789 Loss3: -0.9876\n",
            "Epoch: 31 MAE: 0.08055405137400143 ####  bestMAE: 0.08023408304446591 bestEpoch: 29\n",
            "2022-08-01 18:51:27.706663 Epoch [032/250], Step [0001/0060], Loss1: -0.9881 Loss2: -0.9771 Loss3: -0.9902\n",
            "2022-08-01 18:51:56.479171 Epoch [032/250], Step [0050/0060], Loss1: -0.9876 Loss2: -0.9804 Loss3: -0.9903\n",
            "2022-08-01 18:52:02.299133 Epoch [032/250], Step [0060/0060], Loss1: -0.9774 Loss2: -0.9773 Loss3: -0.9860\n",
            "Epoch: 32 MAE: 0.07737949568127828 ####  bestMAE: 0.08023408304446591 bestEpoch: 29\n",
            "best epoch:32\n",
            "2022-08-01 18:52:12.556165 Epoch [033/250], Step [0001/0060], Loss1: -0.9887 Loss2: -0.9837 Loss3: -0.9912\n",
            "2022-08-01 18:52:41.570775 Epoch [033/250], Step [0050/0060], Loss1: -0.9876 Loss2: -0.9809 Loss3: -0.9897\n",
            "2022-08-01 18:52:47.418827 Epoch [033/250], Step [0060/0060], Loss1: -0.9875 Loss2: -0.9804 Loss3: -0.9895\n",
            "Epoch: 33 MAE: 0.07409208444060474 ####  bestMAE: 0.07737949568127828 bestEpoch: 32\n",
            "best epoch:33\n",
            "2022-08-01 18:52:57.612072 Epoch [034/250], Step [0001/0060], Loss1: -0.9823 Loss2: -0.9775 Loss3: -0.9868\n",
            "2022-08-01 18:53:26.509214 Epoch [034/250], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9806 Loss3: -0.9903\n",
            "2022-08-01 18:53:32.256469 Epoch [034/250], Step [0060/0060], Loss1: -0.9895 Loss2: -0.9826 Loss3: -0.9915\n",
            "Epoch: 34 MAE: 0.08763662883213587 ####  bestMAE: 0.07409208444060474 bestEpoch: 33\n",
            "2022-08-01 18:53:39.912581 Epoch [035/250], Step [0001/0060], Loss1: -0.9882 Loss2: -0.9825 Loss3: -0.9899\n",
            "2022-08-01 18:54:08.514894 Epoch [035/250], Step [0050/0060], Loss1: -0.9874 Loss2: -0.9831 Loss3: -0.9897\n",
            "2022-08-01 18:54:14.410463 Epoch [035/250], Step [0060/0060], Loss1: -0.9850 Loss2: -0.9792 Loss3: -0.9888\n",
            "Epoch: 35 MAE: 0.09279285239164162 ####  bestMAE: 0.07409208444060474 bestEpoch: 33\n",
            "2022-08-01 18:54:24.600470 Epoch [036/250], Step [0001/0060], Loss1: -0.9872 Loss2: -0.9794 Loss3: -0.9902\n",
            "2022-08-01 18:54:53.619445 Epoch [036/250], Step [0050/0060], Loss1: -0.9834 Loss2: -0.9745 Loss3: -0.9847\n",
            "2022-08-01 18:54:59.437515 Epoch [036/250], Step [0060/0060], Loss1: -0.9868 Loss2: -0.9811 Loss3: -0.9890\n",
            "Epoch: 36 MAE: 0.08723471586035672 ####  bestMAE: 0.07409208444060474 bestEpoch: 33\n",
            "2022-08-01 18:55:07.025782 Epoch [037/250], Step [0001/0060], Loss1: -0.9884 Loss2: -0.9790 Loss3: -0.9898\n",
            "2022-08-01 18:55:35.755340 Epoch [037/250], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9837 Loss3: -0.9913\n",
            "2022-08-01 18:55:41.588381 Epoch [037/250], Step [0060/0060], Loss1: -0.9898 Loss2: -0.9846 Loss3: -0.9911\n",
            "Epoch: 37 MAE: 0.08820700690859837 ####  bestMAE: 0.07409208444060474 bestEpoch: 33\n",
            "2022-08-01 18:55:49.284012 Epoch [038/250], Step [0001/0060], Loss1: -0.9892 Loss2: -0.9826 Loss3: -0.9907\n",
            "2022-08-01 18:56:18.026220 Epoch [038/250], Step [0050/0060], Loss1: -0.9850 Loss2: -0.9789 Loss3: -0.9880\n",
            "2022-08-01 18:56:23.907844 Epoch [038/250], Step [0060/0060], Loss1: -0.9852 Loss2: -0.9791 Loss3: -0.9876\n",
            "Epoch: 38 MAE: 0.07928640345417 ####  bestMAE: 0.07409208444060474 bestEpoch: 33\n",
            "2022-08-01 18:56:31.688120 Epoch [039/250], Step [0001/0060], Loss1: -0.9874 Loss2: -0.9802 Loss3: -0.9887\n",
            "2022-08-01 18:57:00.382038 Epoch [039/250], Step [0050/0060], Loss1: -0.9880 Loss2: -0.9809 Loss3: -0.9896\n",
            "2022-08-01 18:57:06.246299 Epoch [039/250], Step [0060/0060], Loss1: -0.9852 Loss2: -0.9728 Loss3: -0.9837\n",
            "Epoch: 39 MAE: 0.09244775913379812 ####  bestMAE: 0.07409208444060474 bestEpoch: 33\n",
            "2022-08-01 18:57:14.045107 Epoch [040/250], Step [0001/0060], Loss1: -0.9843 Loss2: -0.9761 Loss3: -0.9847\n",
            "2022-08-01 18:57:42.872454 Epoch [040/250], Step [0050/0060], Loss1: -0.9880 Loss2: -0.9819 Loss3: -0.9900\n",
            "2022-08-01 18:57:48.702948 Epoch [040/250], Step [0060/0060], Loss1: -0.9880 Loss2: -0.9828 Loss3: -0.9901\n",
            "Epoch: 40 MAE: 0.07696822923327248 ####  bestMAE: 0.07409208444060474 bestEpoch: 33\n",
            "2022-08-01 18:57:58.967907 Epoch [041/250], Step [0001/0060], Loss1: -0.9891 Loss2: -0.9837 Loss3: -0.9910\n",
            "2022-08-01 18:58:27.788209 Epoch [041/250], Step [0050/0060], Loss1: -0.9885 Loss2: -0.9819 Loss3: -0.9904\n",
            "2022-08-01 18:58:33.628359 Epoch [041/250], Step [0060/0060], Loss1: -0.9878 Loss2: -0.9792 Loss3: -0.9897\n",
            "Epoch: 41 MAE: 0.08276031504232417 ####  bestMAE: 0.07409208444060474 bestEpoch: 33\n",
            "2022-08-01 18:58:41.374425 Epoch [042/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9847 Loss3: -0.9917\n",
            "2022-08-01 18:59:09.971659 Epoch [042/250], Step [0050/0060], Loss1: -0.9881 Loss2: -0.9835 Loss3: -0.9894\n",
            "2022-08-01 18:59:15.870952 Epoch [042/250], Step [0060/0060], Loss1: -0.9883 Loss2: -0.9846 Loss3: -0.9905\n",
            "Epoch: 42 MAE: 0.07643964151856762 ####  bestMAE: 0.07409208444060474 bestEpoch: 33\n",
            "2022-08-01 18:59:23.658583 Epoch [043/250], Step [0001/0060], Loss1: -0.9870 Loss2: -0.9817 Loss3: -0.9900\n",
            "2022-08-01 18:59:52.491021 Epoch [043/250], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9868 Loss3: -0.9927\n",
            "2022-08-01 18:59:58.367558 Epoch [043/250], Step [0060/0060], Loss1: -0.9890 Loss2: -0.9814 Loss3: -0.9910\n",
            "Epoch: 43 MAE: 0.07679785819280716 ####  bestMAE: 0.07409208444060474 bestEpoch: 33\n",
            "2022-08-01 19:00:06.150699 Epoch [044/250], Step [0001/0060], Loss1: -0.9823 Loss2: -0.9781 Loss3: -0.9872\n",
            "2022-08-01 19:00:34.923497 Epoch [044/250], Step [0050/0060], Loss1: -0.9852 Loss2: -0.9774 Loss3: -0.9868\n",
            "2022-08-01 19:00:40.768598 Epoch [044/250], Step [0060/0060], Loss1: -0.9882 Loss2: -0.9793 Loss3: -0.9899\n",
            "Epoch: 44 MAE: 0.07778259489271376 ####  bestMAE: 0.07409208444060474 bestEpoch: 33\n",
            "2022-08-01 19:00:48.577429 Epoch [045/250], Step [0001/0060], Loss1: -0.9879 Loss2: -0.9820 Loss3: -0.9901\n",
            "2022-08-01 19:01:17.238704 Epoch [045/250], Step [0050/0060], Loss1: -0.9893 Loss2: -0.9833 Loss3: -0.9908\n",
            "2022-08-01 19:01:23.095960 Epoch [045/250], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9816 Loss3: -0.9919\n",
            "Epoch: 45 MAE: 0.07832315798158998 ####  bestMAE: 0.07409208444060474 bestEpoch: 33\n",
            "2022-08-01 19:01:33.324752 Epoch [046/250], Step [0001/0060], Loss1: -0.9881 Loss2: -0.9824 Loss3: -0.9904\n",
            "2022-08-01 19:02:02.253260 Epoch [046/250], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9816 Loss3: -0.9901\n",
            "2022-08-01 19:02:08.056535 Epoch [046/250], Step [0060/0060], Loss1: -0.9848 Loss2: -0.9772 Loss3: -0.9871\n",
            "Epoch: 46 MAE: 0.07293627496749633 ####  bestMAE: 0.07409208444060474 bestEpoch: 33\n",
            "best epoch:46\n",
            "2022-08-01 19:02:18.061858 Epoch [047/250], Step [0001/0060], Loss1: -0.9878 Loss2: -0.9794 Loss3: -0.9894\n",
            "2022-08-01 19:02:47.285342 Epoch [047/250], Step [0050/0060], Loss1: -0.9860 Loss2: -0.9847 Loss3: -0.9898\n",
            "2022-08-01 19:02:53.191404 Epoch [047/250], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9851 Loss3: -0.9918\n",
            "Epoch: 47 MAE: 0.07924332351280901 ####  bestMAE: 0.07293627496749633 bestEpoch: 46\n",
            "2022-08-01 19:03:00.903151 Epoch [048/250], Step [0001/0060], Loss1: -0.9858 Loss2: -0.9755 Loss3: -0.9877\n",
            "2022-08-01 19:03:29.591218 Epoch [048/250], Step [0050/0060], Loss1: -0.9875 Loss2: -0.9844 Loss3: -0.9904\n",
            "2022-08-01 19:03:35.526022 Epoch [048/250], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9817 Loss3: -0.9904\n",
            "Epoch: 48 MAE: 0.08170024392466065 ####  bestMAE: 0.07293627496749633 bestEpoch: 46\n",
            "2022-08-01 19:03:43.253919 Epoch [049/250], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9855 Loss3: -0.9927\n",
            "2022-08-01 19:04:11.963997 Epoch [049/250], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9802 Loss3: -0.9887\n",
            "2022-08-01 19:04:17.798718 Epoch [049/250], Step [0060/0060], Loss1: -0.9883 Loss2: -0.9816 Loss3: -0.9899\n",
            "Epoch: 49 MAE: 0.07663755815495889 ####  bestMAE: 0.07293627496749633 bestEpoch: 46\n",
            "2022-08-01 19:04:25.453754 Epoch [050/250], Step [0001/0060], Loss1: -0.9874 Loss2: -0.9814 Loss3: -0.9898\n",
            "2022-08-01 19:04:54.207281 Epoch [050/250], Step [0050/0060], Loss1: -0.9859 Loss2: -0.9838 Loss3: -0.9902\n",
            "2022-08-01 19:05:00.114187 Epoch [050/250], Step [0060/0060], Loss1: -0.9896 Loss2: -0.9826 Loss3: -0.9913\n",
            "Epoch: 50 MAE: 0.0772883366781568 ####  bestMAE: 0.07293627496749633 bestEpoch: 46\n",
            "2022-08-01 19:05:10.143473 Epoch [051/250], Step [0001/0060], Loss1: -0.9885 Loss2: -0.9824 Loss3: -0.9903\n",
            "2022-08-01 19:05:39.899350 Epoch [051/250], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9867 Loss3: -0.9919\n",
            "2022-08-01 19:05:45.775008 Epoch [051/250], Step [0060/0060], Loss1: -0.9874 Loss2: -0.9759 Loss3: -0.9892\n",
            "Epoch: 51 MAE: 0.07388690595273618 ####  bestMAE: 0.07293627496749633 bestEpoch: 46\n",
            "2022-08-01 19:05:53.384595 Epoch [052/250], Step [0001/0060], Loss1: -0.9861 Loss2: -0.9766 Loss3: -0.9885\n",
            "2022-08-01 19:06:22.055699 Epoch [052/250], Step [0050/0060], Loss1: -0.9875 Loss2: -0.9801 Loss3: -0.9898\n",
            "2022-08-01 19:06:27.974982 Epoch [052/250], Step [0060/0060], Loss1: -0.9895 Loss2: -0.9812 Loss3: -0.9902\n",
            "Epoch: 52 MAE: 0.08150252387637186 ####  bestMAE: 0.07293627496749633 bestEpoch: 46\n",
            "2022-08-01 19:06:35.634792 Epoch [053/250], Step [0001/0060], Loss1: -0.9855 Loss2: -0.9759 Loss3: -0.9871\n",
            "2022-08-01 19:07:04.225746 Epoch [053/250], Step [0050/0060], Loss1: -0.9889 Loss2: -0.9839 Loss3: -0.9909\n",
            "2022-08-01 19:07:10.088973 Epoch [053/250], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9866 Loss3: -0.9917\n",
            "Epoch: 53 MAE: 0.07647839026476341 ####  bestMAE: 0.07293627496749633 bestEpoch: 46\n",
            "2022-08-01 19:07:17.819908 Epoch [054/250], Step [0001/0060], Loss1: -0.9860 Loss2: -0.9773 Loss3: -0.9872\n",
            "2022-08-01 19:07:46.450309 Epoch [054/250], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9827 Loss3: -0.9901\n",
            "2022-08-01 19:07:52.305436 Epoch [054/250], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9805 Loss3: -0.9904\n",
            "Epoch: 54 MAE: 0.08055811402658936 ####  bestMAE: 0.07293627496749633 bestEpoch: 46\n",
            "2022-08-01 19:08:00.119580 Epoch [055/250], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9846 Loss3: -0.9912\n",
            "2022-08-01 19:08:28.774341 Epoch [055/250], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9833 Loss3: -0.9900\n",
            "2022-08-01 19:08:34.636091 Epoch [055/250], Step [0060/0060], Loss1: -0.9882 Loss2: -0.9811 Loss3: -0.9898\n",
            "Epoch: 55 MAE: 0.08366869325991032 ####  bestMAE: 0.07293627496749633 bestEpoch: 46\n",
            "2022-08-01 19:08:44.759947 Epoch [056/250], Step [0001/0060], Loss1: -0.9881 Loss2: -0.9825 Loss3: -0.9896\n",
            "2022-08-01 19:09:13.912440 Epoch [056/250], Step [0050/0060], Loss1: -0.9900 Loss2: -0.9844 Loss3: -0.9900\n",
            "2022-08-01 19:09:19.788117 Epoch [056/250], Step [0060/0060], Loss1: -0.9876 Loss2: -0.9809 Loss3: -0.9886\n",
            "Epoch: 56 MAE: 0.07994083101787261 ####  bestMAE: 0.07293627496749633 bestEpoch: 46\n",
            "2022-08-01 19:09:27.470823 Epoch [057/250], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9865 Loss3: -0.9921\n",
            "2022-08-01 19:09:56.117150 Epoch [057/250], Step [0050/0060], Loss1: -0.9894 Loss2: -0.9834 Loss3: -0.9912\n",
            "2022-08-01 19:10:02.014054 Epoch [057/250], Step [0060/0060], Loss1: -0.9878 Loss2: -0.9802 Loss3: -0.9895\n",
            "Epoch: 57 MAE: 0.07158886904438969 ####  bestMAE: 0.07293627496749633 bestEpoch: 46\n",
            "best epoch:57\n",
            "2022-08-01 19:10:12.084447 Epoch [058/250], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9838 Loss3: -0.9910\n",
            "2022-08-01 19:10:40.914275 Epoch [058/250], Step [0050/0060], Loss1: -0.9900 Loss2: -0.9866 Loss3: -0.9917\n",
            "2022-08-01 19:10:46.686207 Epoch [058/250], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9865 Loss3: -0.9920\n",
            "Epoch: 58 MAE: 0.0843423634483701 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:10:54.380189 Epoch [059/250], Step [0001/0060], Loss1: -0.9879 Loss2: -0.9818 Loss3: -0.9899\n",
            "2022-08-01 19:11:23.111627 Epoch [059/250], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9848 Loss3: -0.9916\n",
            "2022-08-01 19:11:28.942937 Epoch [059/250], Step [0060/0060], Loss1: -0.9871 Loss2: -0.9811 Loss3: -0.9898\n",
            "Epoch: 59 MAE: 0.074386150622494 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:11:36.639627 Epoch [060/250], Step [0001/0060], Loss1: -0.9897 Loss2: -0.9860 Loss3: -0.9918\n",
            "2022-08-01 19:12:05.210300 Epoch [060/250], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9861 Loss3: -0.9918\n",
            "2022-08-01 19:12:11.056675 Epoch [060/250], Step [0060/0060], Loss1: -0.9893 Loss2: -0.9830 Loss3: -0.9907\n",
            "Epoch: 60 MAE: 0.07562995204219113 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:12:21.384765 Epoch [061/250], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9842 Loss3: -0.9908\n",
            "2022-08-01 19:12:50.490351 Epoch [061/250], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9867 Loss3: -0.9924\n",
            "2022-08-01 19:12:56.274046 Epoch [061/250], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9852 Loss3: -0.9913\n",
            "Epoch: 61 MAE: 0.07424723115547625 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:13:04.010031 Epoch [062/250], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9840 Loss3: -0.9921\n",
            "2022-08-01 19:13:32.671701 Epoch [062/250], Step [0050/0060], Loss1: -0.9885 Loss2: -0.9835 Loss3: -0.9904\n",
            "2022-08-01 19:13:38.558009 Epoch [062/250], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9860 Loss3: -0.9915\n",
            "Epoch: 62 MAE: 0.0764754667736235 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:13:46.183448 Epoch [063/250], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9864 Loss3: -0.9921\n",
            "2022-08-01 19:14:14.938266 Epoch [063/250], Step [0050/0060], Loss1: -0.9900 Loss2: -0.9857 Loss3: -0.9914\n",
            "2022-08-01 19:14:20.770889 Epoch [063/250], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9868 Loss3: -0.9931\n",
            "Epoch: 63 MAE: 0.07681150037775594 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:14:28.392596 Epoch [064/250], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9833 Loss3: -0.9922\n",
            "2022-08-01 19:14:57.071654 Epoch [064/250], Step [0050/0060], Loss1: -0.9870 Loss2: -0.9773 Loss3: -0.9890\n",
            "2022-08-01 19:15:02.888591 Epoch [064/250], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9827 Loss3: -0.9906\n",
            "Epoch: 64 MAE: 0.07530514177191194 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:15:10.645466 Epoch [065/250], Step [0001/0060], Loss1: -0.9887 Loss2: -0.9797 Loss3: -0.9902\n",
            "2022-08-01 19:15:39.302488 Epoch [065/250], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9859 Loss3: -0.9916\n",
            "2022-08-01 19:15:45.188057 Epoch [065/250], Step [0060/0060], Loss1: -0.9908 Loss2: -0.9858 Loss3: -0.9923\n",
            "Epoch: 65 MAE: 0.07510492223911187 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:15:55.298564 Epoch [066/250], Step [0001/0060], Loss1: -0.9916 Loss2: -0.9862 Loss3: -0.9928\n",
            "2022-08-01 19:16:24.468804 Epoch [066/250], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9826 Loss3: -0.9913\n",
            "2022-08-01 19:16:30.318315 Epoch [066/250], Step [0060/0060], Loss1: -0.9884 Loss2: -0.9837 Loss3: -0.9898\n",
            "Epoch: 66 MAE: 0.07551048561378763 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:16:37.984437 Epoch [067/250], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9832 Loss3: -0.9910\n",
            "2022-08-01 19:17:06.518067 Epoch [067/250], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9846 Loss3: -0.9920\n",
            "2022-08-01 19:17:12.459967 Epoch [067/250], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9867 Loss3: -0.9925\n",
            "Epoch: 67 MAE: 0.07604835661630781 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:17:20.165464 Epoch [068/250], Step [0001/0060], Loss1: -0.9874 Loss2: -0.9814 Loss3: -0.9893\n",
            "2022-08-01 19:17:48.772541 Epoch [068/250], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9844 Loss3: -0.9910\n",
            "2022-08-01 19:17:54.616739 Epoch [068/250], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9854 Loss3: -0.9912\n",
            "Epoch: 68 MAE: 0.0761144917604154 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:18:02.272646 Epoch [069/250], Step [0001/0060], Loss1: -0.9883 Loss2: -0.9797 Loss3: -0.9901\n",
            "2022-08-01 19:18:30.754807 Epoch [069/250], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9840 Loss3: -0.9916\n",
            "2022-08-01 19:18:36.592248 Epoch [069/250], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9844 Loss3: -0.9918\n",
            "Epoch: 69 MAE: 0.07580932551590852 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:18:44.275306 Epoch [070/250], Step [0001/0060], Loss1: -0.9889 Loss2: -0.9835 Loss3: -0.9903\n",
            "2022-08-01 19:19:12.944106 Epoch [070/250], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9851 Loss3: -0.9920\n",
            "2022-08-01 19:19:18.734307 Epoch [070/250], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9857 Loss3: -0.9913\n",
            "Epoch: 70 MAE: 0.07664318503526153 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:19:28.820517 Epoch [071/250], Step [0001/0060], Loss1: -0.9864 Loss2: -0.9757 Loss3: -0.9883\n",
            "2022-08-01 19:19:57.676219 Epoch [071/250], Step [0050/0060], Loss1: -0.9872 Loss2: -0.9769 Loss3: -0.9886\n",
            "2022-08-01 19:20:03.463398 Epoch [071/250], Step [0060/0060], Loss1: -0.9890 Loss2: -0.9834 Loss3: -0.9900\n",
            "Epoch: 71 MAE: 0.07633934227877825 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:20:11.150682 Epoch [072/250], Step [0001/0060], Loss1: -0.9877 Loss2: -0.9800 Loss3: -0.9896\n",
            "2022-08-01 19:20:39.707644 Epoch [072/250], Step [0050/0060], Loss1: -0.9891 Loss2: -0.9840 Loss3: -0.9906\n",
            "2022-08-01 19:20:45.555356 Epoch [072/250], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9877 Loss3: -0.9922\n",
            "Epoch: 72 MAE: 0.07609551813236619 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:20:53.252446 Epoch [073/250], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9841 Loss3: -0.9910\n",
            "2022-08-01 19:21:21.884087 Epoch [073/250], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9874 Loss3: -0.9922\n",
            "2022-08-01 19:21:27.725931 Epoch [073/250], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9861 Loss3: -0.9920\n",
            "Epoch: 73 MAE: 0.07688424736103686 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:21:35.480519 Epoch [074/250], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9867 Loss3: -0.9920\n",
            "2022-08-01 19:22:04.040008 Epoch [074/250], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9855 Loss3: -0.9918\n",
            "2022-08-01 19:22:09.880003 Epoch [074/250], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9862 Loss3: -0.9926\n",
            "Epoch: 74 MAE: 0.07474196065670598 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:22:17.624417 Epoch [075/250], Step [0001/0060], Loss1: -0.9875 Loss2: -0.9800 Loss3: -0.9891\n",
            "2022-08-01 19:22:46.390586 Epoch [075/250], Step [0050/0060], Loss1: -0.9912 Loss2: -0.9849 Loss3: -0.9925\n",
            "2022-08-01 19:22:52.186284 Epoch [075/250], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9824 Loss3: -0.9906\n",
            "Epoch: 75 MAE: 0.07734054716806565 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:23:02.335324 Epoch [076/250], Step [0001/0060], Loss1: -0.9873 Loss2: -0.9824 Loss3: -0.9888\n",
            "2022-08-01 19:23:31.407917 Epoch [076/250], Step [0050/0060], Loss1: -0.9917 Loss2: -0.9879 Loss3: -0.9929\n",
            "2022-08-01 19:23:37.242855 Epoch [076/250], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9877 Loss3: -0.9921\n",
            "Epoch: 76 MAE: 0.07536603745960054 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:23:44.870178 Epoch [077/250], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9880 Loss3: -0.9927\n",
            "2022-08-01 19:24:13.567480 Epoch [077/250], Step [0050/0060], Loss1: -0.9893 Loss2: -0.9848 Loss3: -0.9910\n",
            "2022-08-01 19:24:19.464052 Epoch [077/250], Step [0060/0060], Loss1: -0.9893 Loss2: -0.9821 Loss3: -0.9906\n",
            "Epoch: 77 MAE: 0.0744980219684581 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:24:27.131784 Epoch [078/250], Step [0001/0060], Loss1: -0.9867 Loss2: -0.9818 Loss3: -0.9886\n",
            "2022-08-01 19:24:55.724123 Epoch [078/250], Step [0050/0060], Loss1: -0.9862 Loss2: -0.9807 Loss3: -0.9887\n",
            "2022-08-01 19:25:01.547993 Epoch [078/250], Step [0060/0060], Loss1: -0.9891 Loss2: -0.9837 Loss3: -0.9910\n",
            "Epoch: 78 MAE: 0.07808217820667086 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:25:09.202532 Epoch [079/250], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9865 Loss3: -0.9922\n",
            "2022-08-01 19:25:37.796739 Epoch [079/250], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9821 Loss3: -0.9903\n",
            "2022-08-01 19:25:43.654288 Epoch [079/250], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9845 Loss3: -0.9917\n",
            "Epoch: 79 MAE: 0.07526515506562732 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:25:51.396170 Epoch [080/250], Step [0001/0060], Loss1: -0.9892 Loss2: -0.9812 Loss3: -0.9905\n",
            "2022-08-01 19:26:20.063230 Epoch [080/250], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9766 Loss3: -0.9881\n",
            "2022-08-01 19:26:25.907822 Epoch [080/250], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9872 Loss3: -0.9922\n",
            "Epoch: 80 MAE: 0.07550074456230045 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:26:35.930901 Epoch [081/250], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9868 Loss3: -0.9921\n",
            "2022-08-01 19:27:05.222670 Epoch [081/250], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9864 Loss3: -0.9922\n",
            "2022-08-01 19:27:11.044029 Epoch [081/250], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9850 Loss3: -0.9912\n",
            "Epoch: 81 MAE: 0.0750482878609309 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:27:18.772099 Epoch [082/250], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9835 Loss3: -0.9918\n",
            "2022-08-01 19:27:47.399260 Epoch [082/250], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9855 Loss3: -0.9915\n",
            "2022-08-01 19:27:53.267836 Epoch [082/250], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9856 Loss3: -0.9912\n",
            "Epoch: 82 MAE: 0.07372242806449769 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:28:00.888028 Epoch [083/250], Step [0001/0060], Loss1: -0.9892 Loss2: -0.9834 Loss3: -0.9907\n",
            "2022-08-01 19:28:29.471276 Epoch [083/250], Step [0050/0060], Loss1: -0.9898 Loss2: -0.9855 Loss3: -0.9910\n",
            "2022-08-01 19:28:35.310462 Epoch [083/250], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9859 Loss3: -0.9925\n",
            "Epoch: 83 MAE: 0.0766528389441273 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:28:43.022750 Epoch [084/250], Step [0001/0060], Loss1: -0.9866 Loss2: -0.9821 Loss3: -0.9888\n",
            "2022-08-01 19:29:11.400567 Epoch [084/250], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9837 Loss3: -0.9919\n",
            "2022-08-01 19:29:17.306931 Epoch [084/250], Step [0060/0060], Loss1: -0.9883 Loss2: -0.9834 Loss3: -0.9900\n",
            "Epoch: 84 MAE: 0.07480880666662151 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:29:24.929942 Epoch [085/250], Step [0001/0060], Loss1: -0.9904 Loss2: -0.9839 Loss3: -0.9916\n",
            "2022-08-01 19:29:53.425508 Epoch [085/250], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9849 Loss3: -0.9917\n",
            "2022-08-01 19:29:59.302224 Epoch [085/250], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9855 Loss3: -0.9918\n",
            "Epoch: 85 MAE: 0.07657219987697704 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:30:09.331533 Epoch [086/250], Step [0001/0060], Loss1: -0.9858 Loss2: -0.9778 Loss3: -0.9880\n",
            "2022-08-01 19:30:38.968473 Epoch [086/250], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9828 Loss3: -0.9902\n",
            "2022-08-01 19:30:44.744289 Epoch [086/250], Step [0060/0060], Loss1: -0.9910 Loss2: -0.9859 Loss3: -0.9922\n",
            "Epoch: 86 MAE: 0.07544264167704909 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:30:52.396242 Epoch [087/250], Step [0001/0060], Loss1: -0.9871 Loss2: -0.9785 Loss3: -0.9888\n",
            "2022-08-01 19:31:20.960434 Epoch [087/250], Step [0050/0060], Loss1: -0.9871 Loss2: -0.9809 Loss3: -0.9887\n",
            "2022-08-01 19:31:26.857856 Epoch [087/250], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9843 Loss3: -0.9912\n",
            "Epoch: 87 MAE: 0.07820702078481197 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:31:34.570105 Epoch [088/250], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9860 Loss3: -0.9920\n",
            "2022-08-01 19:32:03.069610 Epoch [088/250], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9853 Loss3: -0.9921\n",
            "2022-08-01 19:32:08.873832 Epoch [088/250], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9864 Loss3: -0.9912\n",
            "Epoch: 88 MAE: 0.076343663129857 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:32:16.598672 Epoch [089/250], Step [0001/0060], Loss1: -0.9906 Loss2: -0.9847 Loss3: -0.9918\n",
            "2022-08-01 19:32:45.296608 Epoch [089/250], Step [0050/0060], Loss1: -0.9918 Loss2: -0.9868 Loss3: -0.9930\n",
            "2022-08-01 19:32:51.148341 Epoch [089/250], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9870 Loss3: -0.9924\n",
            "Epoch: 89 MAE: 0.0738368710512837 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:32:58.910547 Epoch [090/250], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9853 Loss3: -0.9913\n",
            "2022-08-01 19:33:27.541087 Epoch [090/250], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9863 Loss3: -0.9913\n",
            "2022-08-01 19:33:33.369908 Epoch [090/250], Step [0060/0060], Loss1: -0.9888 Loss2: -0.9830 Loss3: -0.9903\n",
            "Epoch: 90 MAE: 0.07662673218540413 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:33:43.574008 Epoch [091/250], Step [0001/0060], Loss1: -0.9848 Loss2: -0.9771 Loss3: -0.9870\n",
            "2022-08-01 19:34:12.522942 Epoch [091/250], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9854 Loss3: -0.9920\n",
            "2022-08-01 19:34:18.365271 Epoch [091/250], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9842 Loss3: -0.9918\n",
            "Epoch: 91 MAE: 0.07642302175047533 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:34:25.948772 Epoch [092/250], Step [0001/0060], Loss1: -0.9892 Loss2: -0.9844 Loss3: -0.9907\n",
            "2022-08-01 19:34:54.516242 Epoch [092/250], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9829 Loss3: -0.9907\n",
            "2022-08-01 19:35:00.404464 Epoch [092/250], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9845 Loss3: -0.9906\n",
            "Epoch: 92 MAE: 0.07578304316000961 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:35:08.108221 Epoch [093/250], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9867 Loss3: -0.9920\n",
            "2022-08-01 19:35:36.744561 Epoch [093/250], Step [0050/0060], Loss1: -0.9886 Loss2: -0.9839 Loss3: -0.9902\n",
            "2022-08-01 19:35:42.563213 Epoch [093/250], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9871 Loss3: -0.9915\n",
            "Epoch: 93 MAE: 0.07587206517577799 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:35:50.342128 Epoch [094/250], Step [0001/0060], Loss1: -0.9885 Loss2: -0.9830 Loss3: -0.9899\n",
            "2022-08-01 19:36:18.983567 Epoch [094/250], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9865 Loss3: -0.9923\n",
            "2022-08-01 19:36:24.820707 Epoch [094/250], Step [0060/0060], Loss1: -0.9922 Loss2: -0.9881 Loss3: -0.9933\n",
            "Epoch: 94 MAE: 0.07614108499395786 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:36:32.571153 Epoch [095/250], Step [0001/0060], Loss1: -0.9878 Loss2: -0.9768 Loss3: -0.9889\n",
            "2022-08-01 19:37:01.177724 Epoch [095/250], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9844 Loss3: -0.9917\n",
            "2022-08-01 19:37:07.003880 Epoch [095/250], Step [0060/0060], Loss1: -0.9867 Loss2: -0.9810 Loss3: -0.9886\n",
            "Epoch: 95 MAE: 0.07578887894040062 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:37:17.142443 Epoch [096/250], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9835 Loss3: -0.9918\n",
            "2022-08-01 19:37:46.121289 Epoch [096/250], Step [0050/0060], Loss1: -0.9898 Loss2: -0.9852 Loss3: -0.9912\n",
            "2022-08-01 19:37:51.909020 Epoch [096/250], Step [0060/0060], Loss1: -0.9918 Loss2: -0.9878 Loss3: -0.9930\n",
            "Epoch: 96 MAE: 0.07573748689479928 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:37:59.507624 Epoch [097/250], Step [0001/0060], Loss1: -0.9867 Loss2: -0.9810 Loss3: -0.9884\n",
            "2022-08-01 19:38:28.036541 Epoch [097/250], Step [0050/0060], Loss1: -0.9898 Loss2: -0.9839 Loss3: -0.9913\n",
            "2022-08-01 19:38:33.828189 Epoch [097/250], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9855 Loss3: -0.9915\n",
            "Epoch: 97 MAE: 0.0759602261598779 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:38:41.567722 Epoch [098/250], Step [0001/0060], Loss1: -0.9918 Loss2: -0.9878 Loss3: -0.9929\n",
            "2022-08-01 19:39:10.178158 Epoch [098/250], Step [0050/0060], Loss1: -0.9912 Loss2: -0.9860 Loss3: -0.9924\n",
            "2022-08-01 19:39:15.979274 Epoch [098/250], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9845 Loss3: -0.9919\n",
            "Epoch: 98 MAE: 0.07862110940236894 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:39:23.636114 Epoch [099/250], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9855 Loss3: -0.9920\n",
            "2022-08-01 19:39:52.301515 Epoch [099/250], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9880 Loss3: -0.9924\n",
            "2022-08-01 19:39:58.143728 Epoch [099/250], Step [0060/0060], Loss1: -0.9923 Loss2: -0.9888 Loss3: -0.9934\n",
            "Epoch: 99 MAE: 0.07526283037094841 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:40:05.790467 Epoch [100/250], Step [0001/0060], Loss1: -0.9915 Loss2: -0.9856 Loss3: -0.9927\n",
            "2022-08-01 19:40:34.600753 Epoch [100/250], Step [0050/0060], Loss1: -0.9882 Loss2: -0.9814 Loss3: -0.9898\n",
            "2022-08-01 19:40:40.451710 Epoch [100/250], Step [0060/0060], Loss1: -0.9870 Loss2: -0.9807 Loss3: -0.9891\n",
            "Epoch: 100 MAE: 0.07603022812535525 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:40:50.549681 Epoch [101/250], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9849 Loss3: -0.9917\n",
            "2022-08-01 19:41:19.875071 Epoch [101/250], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9863 Loss3: -0.9922\n",
            "2022-08-01 19:41:25.782996 Epoch [101/250], Step [0060/0060], Loss1: -0.9878 Loss2: -0.9827 Loss3: -0.9900\n",
            "Epoch: 101 MAE: 0.07584812351004785 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:41:33.454338 Epoch [102/250], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9859 Loss3: -0.9924\n",
            "2022-08-01 19:42:02.018937 Epoch [102/250], Step [0050/0060], Loss1: -0.9894 Loss2: -0.9842 Loss3: -0.9911\n",
            "2022-08-01 19:42:07.842419 Epoch [102/250], Step [0060/0060], Loss1: -0.9888 Loss2: -0.9822 Loss3: -0.9901\n",
            "Epoch: 102 MAE: 0.07434288807016204 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:42:15.572003 Epoch [103/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9859 Loss3: -0.9914\n",
            "2022-08-01 19:42:44.058589 Epoch [103/250], Step [0050/0060], Loss1: -0.9913 Loss2: -0.9863 Loss3: -0.9924\n",
            "2022-08-01 19:42:49.906027 Epoch [103/250], Step [0060/0060], Loss1: -0.9870 Loss2: -0.9807 Loss3: -0.9886\n",
            "Epoch: 103 MAE: 0.07636760479558712 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:42:57.718418 Epoch [104/250], Step [0001/0060], Loss1: -0.9906 Loss2: -0.9849 Loss3: -0.9918\n",
            "2022-08-01 19:43:26.351554 Epoch [104/250], Step [0050/0060], Loss1: -0.9900 Loss2: -0.9858 Loss3: -0.9916\n",
            "2022-08-01 19:43:32.177143 Epoch [104/250], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9851 Loss3: -0.9924\n",
            "Epoch: 104 MAE: 0.07634657274478328 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:43:40.003051 Epoch [105/250], Step [0001/0060], Loss1: -0.9921 Loss2: -0.9874 Loss3: -0.9932\n",
            "2022-08-01 19:44:08.640025 Epoch [105/250], Step [0050/0060], Loss1: -0.9875 Loss2: -0.9825 Loss3: -0.9891\n",
            "2022-08-01 19:44:14.473753 Epoch [105/250], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9864 Loss3: -0.9924\n",
            "Epoch: 105 MAE: 0.07454822595788059 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:44:24.655469 Epoch [106/250], Step [0001/0060], Loss1: -0.9924 Loss2: -0.9894 Loss3: -0.9934\n",
            "2022-08-01 19:44:53.975382 Epoch [106/250], Step [0050/0060], Loss1: -0.9887 Loss2: -0.9800 Loss3: -0.9903\n",
            "2022-08-01 19:44:59.817574 Epoch [106/250], Step [0060/0060], Loss1: -0.9884 Loss2: -0.9832 Loss3: -0.9901\n",
            "Epoch: 106 MAE: 0.07746780526701108 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:45:07.582122 Epoch [107/250], Step [0001/0060], Loss1: -0.9875 Loss2: -0.9783 Loss3: -0.9892\n",
            "2022-08-01 19:45:36.169389 Epoch [107/250], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9839 Loss3: -0.9915\n",
            "2022-08-01 19:45:42.024156 Epoch [107/250], Step [0060/0060], Loss1: -0.9841 Loss2: -0.9744 Loss3: -0.9867\n",
            "Epoch: 107 MAE: 0.07617088600441262 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:45:49.769043 Epoch [108/250], Step [0001/0060], Loss1: -0.9887 Loss2: -0.9836 Loss3: -0.9905\n",
            "2022-08-01 19:46:18.176168 Epoch [108/250], Step [0050/0060], Loss1: -0.9878 Loss2: -0.9813 Loss3: -0.9892\n",
            "2022-08-01 19:46:23.961563 Epoch [108/250], Step [0060/0060], Loss1: -0.9921 Loss2: -0.9873 Loss3: -0.9931\n",
            "Epoch: 108 MAE: 0.07568755871404415 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:46:31.610905 Epoch [109/250], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9876 Loss3: -0.9925\n",
            "2022-08-01 19:47:00.218776 Epoch [109/250], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9863 Loss3: -0.9920\n",
            "2022-08-01 19:47:06.059745 Epoch [109/250], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9867 Loss3: -0.9928\n",
            "Epoch: 109 MAE: 0.0777905106922937 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:47:13.847360 Epoch [110/250], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9870 Loss3: -0.9920\n",
            "2022-08-01 19:47:42.427819 Epoch [110/250], Step [0050/0060], Loss1: -0.9900 Loss2: -0.9868 Loss3: -0.9911\n",
            "2022-08-01 19:47:48.229146 Epoch [110/250], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9886 Loss3: -0.9930\n",
            "Epoch: 110 MAE: 0.0737110766153487 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:47:58.525668 Epoch [111/250], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9851 Loss3: -0.9908\n",
            "2022-08-01 19:48:28.102296 Epoch [111/250], Step [0050/0060], Loss1: -0.9900 Loss2: -0.9849 Loss3: -0.9914\n",
            "2022-08-01 19:48:33.917858 Epoch [111/250], Step [0060/0060], Loss1: -0.9878 Loss2: -0.9787 Loss3: -0.9890\n",
            "Epoch: 111 MAE: 0.07631694294157479 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:48:41.446780 Epoch [112/250], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9879 Loss3: -0.9925\n",
            "2022-08-01 19:49:10.112891 Epoch [112/250], Step [0050/0060], Loss1: -0.9889 Loss2: -0.9805 Loss3: -0.9899\n",
            "2022-08-01 19:49:15.988128 Epoch [112/250], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9868 Loss3: -0.9924\n",
            "Epoch: 112 MAE: 0.07580371236044264 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:49:23.631276 Epoch [113/250], Step [0001/0060], Loss1: -0.9921 Loss2: -0.9884 Loss3: -0.9933\n",
            "2022-08-01 19:49:52.322781 Epoch [113/250], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9872 Loss3: -0.9923\n",
            "2022-08-01 19:49:58.205206 Epoch [113/250], Step [0060/0060], Loss1: -0.9898 Loss2: -0.9829 Loss3: -0.9909\n",
            "Epoch: 113 MAE: 0.07544176969578656 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:50:05.770292 Epoch [114/250], Step [0001/0060], Loss1: -0.9894 Loss2: -0.9852 Loss3: -0.9912\n",
            "2022-08-01 19:50:34.311148 Epoch [114/250], Step [0050/0060], Loss1: -0.9897 Loss2: -0.9859 Loss3: -0.9910\n",
            "2022-08-01 19:50:40.173936 Epoch [114/250], Step [0060/0060], Loss1: -0.9867 Loss2: -0.9811 Loss3: -0.9885\n",
            "Epoch: 114 MAE: 0.07704644334379324 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:50:47.853750 Epoch [115/250], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9837 Loss3: -0.9909\n",
            "2022-08-01 19:51:16.528484 Epoch [115/250], Step [0050/0060], Loss1: -0.9882 Loss2: -0.9832 Loss3: -0.9903\n",
            "2022-08-01 19:51:22.392371 Epoch [115/250], Step [0060/0060], Loss1: -0.9835 Loss2: -0.9763 Loss3: -0.9861\n",
            "Epoch: 115 MAE: 0.07752274356821859 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:51:32.488878 Epoch [116/250], Step [0001/0060], Loss1: -0.9916 Loss2: -0.9884 Loss3: -0.9929\n",
            "2022-08-01 19:52:01.680757 Epoch [116/250], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9861 Loss3: -0.9917\n",
            "2022-08-01 19:52:07.506639 Epoch [116/250], Step [0060/0060], Loss1: -0.9880 Loss2: -0.9828 Loss3: -0.9893\n",
            "Epoch: 116 MAE: 0.07614558078624586 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:52:15.222281 Epoch [117/250], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9852 Loss3: -0.9905\n",
            "2022-08-01 19:52:43.939057 Epoch [117/250], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9865 Loss3: -0.9922\n",
            "2022-08-01 19:52:49.801268 Epoch [117/250], Step [0060/0060], Loss1: -0.9923 Loss2: -0.9878 Loss3: -0.9934\n",
            "Epoch: 117 MAE: 0.07509172767558425 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:52:57.464327 Epoch [118/250], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9862 Loss3: -0.9917\n",
            "2022-08-01 19:53:26.246955 Epoch [118/250], Step [0050/0060], Loss1: -0.9877 Loss2: -0.9794 Loss3: -0.9894\n",
            "2022-08-01 19:53:32.112178 Epoch [118/250], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9845 Loss3: -0.9914\n",
            "Epoch: 118 MAE: 0.07486313224469546 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:53:39.785791 Epoch [119/250], Step [0001/0060], Loss1: -0.9884 Loss2: -0.9831 Loss3: -0.9903\n",
            "2022-08-01 19:54:08.465296 Epoch [119/250], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9829 Loss3: -0.9917\n",
            "2022-08-01 19:54:14.281741 Epoch [119/250], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9846 Loss3: -0.9917\n",
            "Epoch: 119 MAE: 0.07546022162866341 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:54:22.007594 Epoch [120/250], Step [0001/0060], Loss1: -0.9894 Loss2: -0.9844 Loss3: -0.9910\n",
            "2022-08-01 19:54:50.347628 Epoch [120/250], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9867 Loss3: -0.9925\n",
            "2022-08-01 19:54:56.149657 Epoch [120/250], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9831 Loss3: -0.9911\n",
            "Epoch: 120 MAE: 0.07604925382704962 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:55:06.213981 Epoch [121/250], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9876 Loss3: -0.9924\n",
            "2022-08-01 19:55:35.525134 Epoch [121/250], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9829 Loss3: -0.9903\n",
            "2022-08-01 19:55:41.427140 Epoch [121/250], Step [0060/0060], Loss1: -0.9877 Loss2: -0.9821 Loss3: -0.9892\n",
            "Epoch: 121 MAE: 0.07703030016056446 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:55:49.057620 Epoch [122/250], Step [0001/0060], Loss1: -0.9890 Loss2: -0.9846 Loss3: -0.9906\n",
            "2022-08-01 19:56:17.597927 Epoch [122/250], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9836 Loss3: -0.9911\n",
            "2022-08-01 19:56:23.451523 Epoch [122/250], Step [0060/0060], Loss1: -0.9876 Loss2: -0.9834 Loss3: -0.9895\n",
            "Epoch: 122 MAE: 0.07717605298158355 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:56:31.102758 Epoch [123/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9848 Loss3: -0.9912\n",
            "2022-08-01 19:56:59.774141 Epoch [123/250], Step [0050/0060], Loss1: -0.9831 Loss2: -0.9721 Loss3: -0.9854\n",
            "2022-08-01 19:57:05.564516 Epoch [123/250], Step [0060/0060], Loss1: -0.9891 Loss2: -0.9848 Loss3: -0.9906\n",
            "Epoch: 123 MAE: 0.07641737569576848 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:57:13.294638 Epoch [124/250], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9847 Loss3: -0.9923\n",
            "2022-08-01 19:57:42.147157 Epoch [124/250], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9836 Loss3: -0.9908\n",
            "2022-08-01 19:57:47.964336 Epoch [124/250], Step [0060/0060], Loss1: -0.9869 Loss2: -0.9789 Loss3: -0.9887\n",
            "Epoch: 124 MAE: 0.07680563311097482 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:57:55.619894 Epoch [125/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9838 Loss3: -0.9912\n",
            "2022-08-01 19:58:24.450237 Epoch [125/250], Step [0050/0060], Loss1: -0.9927 Loss2: -0.9887 Loss3: -0.9937\n",
            "2022-08-01 19:58:30.302359 Epoch [125/250], Step [0060/0060], Loss1: -0.9893 Loss2: -0.9859 Loss3: -0.9910\n",
            "Epoch: 125 MAE: 0.07629966488590949 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:58:40.398269 Epoch [126/250], Step [0001/0060], Loss1: -0.9921 Loss2: -0.9850 Loss3: -0.9931\n",
            "2022-08-01 19:59:09.443716 Epoch [126/250], Step [0050/0060], Loss1: -0.9874 Loss2: -0.9790 Loss3: -0.9888\n",
            "2022-08-01 19:59:15.321376 Epoch [126/250], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9840 Loss3: -0.9923\n",
            "Epoch: 126 MAE: 0.07671420919832096 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 19:59:22.954993 Epoch [127/250], Step [0001/0060], Loss1: -0.9866 Loss2: -0.9812 Loss3: -0.9880\n",
            "2022-08-01 19:59:51.621079 Epoch [127/250], Step [0050/0060], Loss1: -0.9862 Loss2: -0.9798 Loss3: -0.9882\n",
            "2022-08-01 19:59:57.500221 Epoch [127/250], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9859 Loss3: -0.9922\n",
            "Epoch: 127 MAE: 0.07627256181504992 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:00:05.123527 Epoch [128/250], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9854 Loss3: -0.9907\n",
            "2022-08-01 20:00:33.841975 Epoch [128/250], Step [0050/0060], Loss1: -0.9918 Loss2: -0.9865 Loss3: -0.9932\n",
            "2022-08-01 20:00:39.669901 Epoch [128/250], Step [0060/0060], Loss1: -0.9910 Loss2: -0.9857 Loss3: -0.9920\n",
            "Epoch: 128 MAE: 0.07624673177325537 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:00:47.484831 Epoch [129/250], Step [0001/0060], Loss1: -0.9915 Loss2: -0.9853 Loss3: -0.9926\n",
            "2022-08-01 20:01:16.198876 Epoch [129/250], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9862 Loss3: -0.9922\n",
            "2022-08-01 20:01:22.026974 Epoch [129/250], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9865 Loss3: -0.9920\n",
            "Epoch: 129 MAE: 0.07536740525058966 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:01:29.605273 Epoch [130/250], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9848 Loss3: -0.9920\n",
            "2022-08-01 20:01:58.420545 Epoch [130/250], Step [0050/0060], Loss1: -0.9876 Loss2: -0.9809 Loss3: -0.9891\n",
            "2022-08-01 20:02:04.285257 Epoch [130/250], Step [0060/0060], Loss1: -0.9918 Loss2: -0.9878 Loss3: -0.9928\n",
            "Epoch: 130 MAE: 0.07582663475521029 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:02:14.322595 Epoch [131/250], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9874 Loss3: -0.9920\n",
            "2022-08-01 20:02:43.694259 Epoch [131/250], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9867 Loss3: -0.9917\n",
            "2022-08-01 20:02:49.518637 Epoch [131/250], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9867 Loss3: -0.9921\n",
            "Epoch: 131 MAE: 0.07632589531954002 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:02:57.199831 Epoch [132/250], Step [0001/0060], Loss1: -0.9913 Loss2: -0.9870 Loss3: -0.9923\n",
            "2022-08-01 20:03:25.655817 Epoch [132/250], Step [0050/0060], Loss1: -0.9921 Loss2: -0.9870 Loss3: -0.9932\n",
            "2022-08-01 20:03:31.448151 Epoch [132/250], Step [0060/0060], Loss1: -0.9898 Loss2: -0.9841 Loss3: -0.9910\n",
            "Epoch: 132 MAE: 0.0765901287018307 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:03:39.067007 Epoch [133/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9818 Loss3: -0.9911\n",
            "2022-08-01 20:04:07.765094 Epoch [133/250], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9852 Loss3: -0.9909\n",
            "2022-08-01 20:04:13.647779 Epoch [133/250], Step [0060/0060], Loss1: -0.9885 Loss2: -0.9828 Loss3: -0.9901\n",
            "Epoch: 133 MAE: 0.07715619309238657 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:04:21.386282 Epoch [134/250], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9873 Loss3: -0.9921\n",
            "2022-08-01 20:04:50.148913 Epoch [134/250], Step [0050/0060], Loss1: -0.9920 Loss2: -0.9878 Loss3: -0.9931\n",
            "2022-08-01 20:04:55.982882 Epoch [134/250], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9852 Loss3: -0.9921\n",
            "Epoch: 134 MAE: 0.07727661470887522 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:05:03.744707 Epoch [135/250], Step [0001/0060], Loss1: -0.9880 Loss2: -0.9824 Loss3: -0.9895\n",
            "2022-08-01 20:05:32.400440 Epoch [135/250], Step [0050/0060], Loss1: -0.9922 Loss2: -0.9854 Loss3: -0.9931\n",
            "2022-08-01 20:05:38.224232 Epoch [135/250], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9837 Loss3: -0.9906\n",
            "Epoch: 135 MAE: 0.07533723765580112 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:05:48.399557 Epoch [136/250], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9861 Loss3: -0.9909\n",
            "2022-08-01 20:06:17.829374 Epoch [136/250], Step [0050/0060], Loss1: -0.9875 Loss2: -0.9808 Loss3: -0.9892\n",
            "2022-08-01 20:06:23.652880 Epoch [136/250], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9884 Loss3: -0.9930\n",
            "Epoch: 136 MAE: 0.07636291730971563 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:06:31.337456 Epoch [137/250], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9882 Loss3: -0.9921\n",
            "2022-08-01 20:07:00.002218 Epoch [137/250], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9847 Loss3: -0.9913\n",
            "2022-08-01 20:07:05.802445 Epoch [137/250], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9873 Loss3: -0.9922\n",
            "Epoch: 137 MAE: 0.07725175075430087 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:07:13.461919 Epoch [138/250], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9850 Loss3: -0.9916\n",
            "2022-08-01 20:07:42.263833 Epoch [138/250], Step [0050/0060], Loss1: -0.9921 Loss2: -0.9883 Loss3: -0.9931\n",
            "2022-08-01 20:07:48.071796 Epoch [138/250], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9817 Loss3: -0.9920\n",
            "Epoch: 138 MAE: 0.0748587439804481 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:07:55.707589 Epoch [139/250], Step [0001/0060], Loss1: -0.9865 Loss2: -0.9795 Loss3: -0.9882\n",
            "2022-08-01 20:08:24.327559 Epoch [139/250], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9849 Loss3: -0.9909\n",
            "2022-08-01 20:08:30.175536 Epoch [139/250], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9816 Loss3: -0.9911\n",
            "Epoch: 139 MAE: 0.07656987276026808 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:08:37.816349 Epoch [140/250], Step [0001/0060], Loss1: -0.9883 Loss2: -0.9845 Loss3: -0.9896\n",
            "2022-08-01 20:09:06.546580 Epoch [140/250], Step [0050/0060], Loss1: -0.9863 Loss2: -0.9790 Loss3: -0.9879\n",
            "2022-08-01 20:09:12.445667 Epoch [140/250], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9868 Loss3: -0.9929\n",
            "Epoch: 140 MAE: 0.07754876505130183 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:09:22.538392 Epoch [141/250], Step [0001/0060], Loss1: -0.9925 Loss2: -0.9892 Loss3: -0.9936\n",
            "2022-08-01 20:09:51.751992 Epoch [141/250], Step [0050/0060], Loss1: -0.9897 Loss2: -0.9859 Loss3: -0.9911\n",
            "2022-08-01 20:09:57.559937 Epoch [141/250], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9879 Loss3: -0.9929\n",
            "Epoch: 141 MAE: 0.07530897564358181 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:10:05.171761 Epoch [142/250], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9865 Loss3: -0.9924\n",
            "2022-08-01 20:10:33.890237 Epoch [142/250], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9855 Loss3: -0.9921\n",
            "2022-08-01 20:10:39.673791 Epoch [142/250], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9850 Loss3: -0.9912\n",
            "Epoch: 142 MAE: 0.07572120202281489 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:10:47.474604 Epoch [143/250], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9863 Loss3: -0.9926\n",
            "2022-08-01 20:11:16.147525 Epoch [143/250], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9846 Loss3: -0.9912\n",
            "2022-08-01 20:11:21.945461 Epoch [143/250], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9862 Loss3: -0.9918\n",
            "Epoch: 143 MAE: 0.07624077428585636 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:11:29.621010 Epoch [144/250], Step [0001/0060], Loss1: -0.9915 Loss2: -0.9873 Loss3: -0.9926\n",
            "2022-08-01 20:11:58.176031 Epoch [144/250], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9861 Loss3: -0.9916\n",
            "2022-08-01 20:12:03.952573 Epoch [144/250], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9836 Loss3: -0.9907\n",
            "Epoch: 144 MAE: 0.07590354429981698 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:12:11.551666 Epoch [145/250], Step [0001/0060], Loss1: -0.9891 Loss2: -0.9853 Loss3: -0.9904\n",
            "2022-08-01 20:12:40.327844 Epoch [145/250], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9831 Loss3: -0.9904\n",
            "2022-08-01 20:12:46.170800 Epoch [145/250], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9836 Loss3: -0.9916\n",
            "Epoch: 145 MAE: 0.0781869615827288 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:12:56.319005 Epoch [146/250], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9867 Loss3: -0.9923\n",
            "2022-08-01 20:13:25.614025 Epoch [146/250], Step [0050/0060], Loss1: -0.9920 Loss2: -0.9881 Loss3: -0.9929\n",
            "2022-08-01 20:13:31.442673 Epoch [146/250], Step [0060/0060], Loss1: -0.9887 Loss2: -0.9811 Loss3: -0.9903\n",
            "Epoch: 146 MAE: 0.07662686115850215 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:13:39.045047 Epoch [147/250], Step [0001/0060], Loss1: -0.9919 Loss2: -0.9871 Loss3: -0.9930\n",
            "2022-08-01 20:14:07.711940 Epoch [147/250], Step [0050/0060], Loss1: -0.9880 Loss2: -0.9831 Loss3: -0.9897\n",
            "2022-08-01 20:14:13.538364 Epoch [147/250], Step [0060/0060], Loss1: -0.9871 Loss2: -0.9807 Loss3: -0.9887\n",
            "Epoch: 147 MAE: 0.07739464749734867 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:14:21.184368 Epoch [148/250], Step [0001/0060], Loss1: -0.9920 Loss2: -0.9885 Loss3: -0.9933\n",
            "2022-08-01 20:14:49.882711 Epoch [148/250], Step [0050/0060], Loss1: -0.9918 Loss2: -0.9873 Loss3: -0.9927\n",
            "2022-08-01 20:14:55.694393 Epoch [148/250], Step [0060/0060], Loss1: -0.9873 Loss2: -0.9762 Loss3: -0.9887\n",
            "Epoch: 148 MAE: 0.0771881478425687 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:15:03.344889 Epoch [149/250], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9845 Loss3: -0.9916\n",
            "2022-08-01 20:15:31.954488 Epoch [149/250], Step [0050/0060], Loss1: -0.9891 Loss2: -0.9836 Loss3: -0.9904\n",
            "2022-08-01 20:15:37.773003 Epoch [149/250], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9864 Loss3: -0.9923\n",
            "Epoch: 149 MAE: 0.07686500917666801 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:15:45.525463 Epoch [150/250], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9867 Loss3: -0.9926\n",
            "2022-08-01 20:16:14.193728 Epoch [150/250], Step [0050/0060], Loss1: -0.9913 Loss2: -0.9871 Loss3: -0.9926\n",
            "2022-08-01 20:16:20.016201 Epoch [150/250], Step [0060/0060], Loss1: -0.9921 Loss2: -0.9880 Loss3: -0.9933\n",
            "Epoch: 150 MAE: 0.0760333609707141 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:16:32.595263 Epoch [151/250], Step [0001/0060], Loss1: -0.9916 Loss2: -0.9873 Loss3: -0.9927\n",
            "2022-08-01 20:17:01.701816 Epoch [151/250], Step [0050/0060], Loss1: -0.9918 Loss2: -0.9859 Loss3: -0.9930\n",
            "2022-08-01 20:17:07.606910 Epoch [151/250], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9809 Loss3: -0.9895\n",
            "Epoch: 151 MAE: 0.0769949946327815 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:17:15.398812 Epoch [152/250], Step [0001/0060], Loss1: -0.9882 Loss2: -0.9819 Loss3: -0.9898\n",
            "2022-08-01 20:17:44.053229 Epoch [152/250], Step [0050/0060], Loss1: -0.9919 Loss2: -0.9864 Loss3: -0.9931\n",
            "2022-08-01 20:17:49.957362 Epoch [152/250], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9881 Loss3: -0.9923\n",
            "Epoch: 152 MAE: 0.07692027485559856 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:17:57.657114 Epoch [153/250], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9868 Loss3: -0.9922\n",
            "2022-08-01 20:18:26.308730 Epoch [153/250], Step [0050/0060], Loss1: -0.9917 Loss2: -0.9877 Loss3: -0.9928\n",
            "2022-08-01 20:18:32.149825 Epoch [153/250], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9866 Loss3: -0.9921\n",
            "Epoch: 153 MAE: 0.07578838141506941 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:18:39.792188 Epoch [154/250], Step [0001/0060], Loss1: -0.9917 Loss2: -0.9870 Loss3: -0.9928\n",
            "2022-08-01 20:19:08.553787 Epoch [154/250], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9861 Loss3: -0.9917\n",
            "2022-08-01 20:19:14.396002 Epoch [154/250], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9852 Loss3: -0.9910\n",
            "Epoch: 154 MAE: 0.07803444039884697 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:19:22.046876 Epoch [155/250], Step [0001/0060], Loss1: -0.9891 Loss2: -0.9825 Loss3: -0.9904\n",
            "2022-08-01 20:19:50.512422 Epoch [155/250], Step [0050/0060], Loss1: -0.9891 Loss2: -0.9838 Loss3: -0.9905\n",
            "2022-08-01 20:19:56.338629 Epoch [155/250], Step [0060/0060], Loss1: -0.9898 Loss2: -0.9830 Loss3: -0.9910\n",
            "Epoch: 155 MAE: 0.07738498526275472 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:20:06.808141 Epoch [156/250], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9877 Loss3: -0.9924\n",
            "2022-08-01 20:20:36.119667 Epoch [156/250], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9839 Loss3: -0.9918\n",
            "2022-08-01 20:20:41.984671 Epoch [156/250], Step [0060/0060], Loss1: -0.9918 Loss2: -0.9877 Loss3: -0.9930\n",
            "Epoch: 156 MAE: 0.0781811686419936 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:20:49.537129 Epoch [157/250], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9855 Loss3: -0.9920\n",
            "2022-08-01 20:21:18.207430 Epoch [157/250], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9855 Loss3: -0.9914\n",
            "2022-08-01 20:21:24.093162 Epoch [157/250], Step [0060/0060], Loss1: -0.9920 Loss2: -0.9883 Loss3: -0.9930\n",
            "Epoch: 157 MAE: 0.07534013046789419 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:21:31.748278 Epoch [158/250], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9862 Loss3: -0.9923\n",
            "2022-08-01 20:22:00.346785 Epoch [158/250], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9847 Loss3: -0.9907\n",
            "2022-08-01 20:22:06.184947 Epoch [158/250], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9868 Loss3: -0.9928\n",
            "Epoch: 158 MAE: 0.0776116176383205 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:22:13.863957 Epoch [159/250], Step [0001/0060], Loss1: -0.9904 Loss2: -0.9853 Loss3: -0.9916\n",
            "2022-08-01 20:22:42.648259 Epoch [159/250], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9847 Loss3: -0.9909\n",
            "2022-08-01 20:22:48.479471 Epoch [159/250], Step [0060/0060], Loss1: -0.9921 Loss2: -0.9854 Loss3: -0.9931\n",
            "Epoch: 159 MAE: 0.07631282089879274 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:22:56.217121 Epoch [160/250], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9852 Loss3: -0.9907\n",
            "2022-08-01 20:23:24.953746 Epoch [160/250], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9871 Loss3: -0.9919\n",
            "2022-08-01 20:23:30.803893 Epoch [160/250], Step [0060/0060], Loss1: -0.9896 Loss2: -0.9845 Loss3: -0.9910\n",
            "Epoch: 160 MAE: 0.0782650468210695 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:23:41.142279 Epoch [161/250], Step [0001/0060], Loss1: -0.9916 Loss2: -0.9861 Loss3: -0.9925\n",
            "2022-08-01 20:24:10.639562 Epoch [161/250], Step [0050/0060], Loss1: -0.9884 Loss2: -0.9823 Loss3: -0.9901\n",
            "2022-08-01 20:24:16.520890 Epoch [161/250], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9853 Loss3: -0.9915\n",
            "Epoch: 161 MAE: 0.07849758637645259 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:24:24.287503 Epoch [162/250], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9855 Loss3: -0.9924\n",
            "2022-08-01 20:24:52.936488 Epoch [162/250], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9868 Loss3: -0.9920\n",
            "2022-08-01 20:24:58.787279 Epoch [162/250], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9853 Loss3: -0.9915\n",
            "Epoch: 162 MAE: 0.07851145360835647 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:25:06.377667 Epoch [163/250], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9832 Loss3: -0.9913\n",
            "2022-08-01 20:25:35.027724 Epoch [163/250], Step [0050/0060], Loss1: -0.9889 Loss2: -0.9844 Loss3: -0.9909\n",
            "2022-08-01 20:25:40.892651 Epoch [163/250], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9855 Loss3: -0.9917\n",
            "Epoch: 163 MAE: 0.0786555562700544 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:25:48.630419 Epoch [164/250], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9843 Loss3: -0.9920\n",
            "2022-08-01 20:26:17.321663 Epoch [164/250], Step [0050/0060], Loss1: -0.9918 Loss2: -0.9862 Loss3: -0.9929\n",
            "2022-08-01 20:26:23.157007 Epoch [164/250], Step [0060/0060], Loss1: -0.9920 Loss2: -0.9885 Loss3: -0.9931\n",
            "Epoch: 164 MAE: 0.07690666471208843 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:26:30.742681 Epoch [165/250], Step [0001/0060], Loss1: -0.9913 Loss2: -0.9867 Loss3: -0.9924\n",
            "2022-08-01 20:26:59.498602 Epoch [165/250], Step [0050/0060], Loss1: -0.9917 Loss2: -0.9870 Loss3: -0.9927\n",
            "2022-08-01 20:27:05.305649 Epoch [165/250], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9875 Loss3: -0.9923\n",
            "Epoch: 165 MAE: 0.07717166441458244 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:27:15.436045 Epoch [166/250], Step [0001/0060], Loss1: -0.9880 Loss2: -0.9822 Loss3: -0.9895\n",
            "2022-08-01 20:27:44.225948 Epoch [166/250], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9840 Loss3: -0.9916\n",
            "2022-08-01 20:27:49.993633 Epoch [166/250], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9863 Loss3: -0.9923\n",
            "Epoch: 166 MAE: 0.07792459154885911 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:27:57.639781 Epoch [167/250], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9857 Loss3: -0.9921\n",
            "2022-08-01 20:28:26.294539 Epoch [167/250], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9863 Loss3: -0.9921\n",
            "2022-08-01 20:28:32.136241 Epoch [167/250], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9837 Loss3: -0.9917\n",
            "Epoch: 167 MAE: 0.07680073581675373 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:28:39.846169 Epoch [168/250], Step [0001/0060], Loss1: -0.9897 Loss2: -0.9852 Loss3: -0.9909\n",
            "2022-08-01 20:29:08.787830 Epoch [168/250], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9851 Loss3: -0.9920\n",
            "2022-08-01 20:29:14.648319 Epoch [168/250], Step [0060/0060], Loss1: -0.9862 Loss2: -0.9798 Loss3: -0.9881\n",
            "Epoch: 168 MAE: 0.07808546752526016 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:29:22.350617 Epoch [169/250], Step [0001/0060], Loss1: -0.9926 Loss2: -0.9879 Loss3: -0.9936\n",
            "2022-08-01 20:29:51.094398 Epoch [169/250], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9850 Loss3: -0.9914\n",
            "2022-08-01 20:29:57.112316 Epoch [169/250], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9854 Loss3: -0.9913\n",
            "Epoch: 169 MAE: 0.07710911463177393 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:30:04.855313 Epoch [170/250], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9852 Loss3: -0.9919\n",
            "2022-08-01 20:30:33.545739 Epoch [170/250], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9825 Loss3: -0.9912\n",
            "2022-08-01 20:30:39.430881 Epoch [170/250], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9834 Loss3: -0.9913\n",
            "Epoch: 170 MAE: 0.07626891570116477 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:30:49.550728 Epoch [171/250], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9855 Loss3: -0.9920\n",
            "2022-08-01 20:31:18.762626 Epoch [171/250], Step [0050/0060], Loss1: -0.9893 Loss2: -0.9843 Loss3: -0.9904\n",
            "2022-08-01 20:31:24.600914 Epoch [171/250], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9870 Loss3: -0.9917\n",
            "Epoch: 171 MAE: 0.07775692076910111 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:31:32.386860 Epoch [172/250], Step [0001/0060], Loss1: -0.9915 Loss2: -0.9860 Loss3: -0.9925\n",
            "2022-08-01 20:32:01.176637 Epoch [172/250], Step [0050/0060], Loss1: -0.9885 Loss2: -0.9811 Loss3: -0.9897\n",
            "2022-08-01 20:32:07.016232 Epoch [172/250], Step [0060/0060], Loss1: -0.9862 Loss2: -0.9794 Loss3: -0.9877\n",
            "Epoch: 172 MAE: 0.07746698389608393 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:32:14.713148 Epoch [173/250], Step [0001/0060], Loss1: -0.9890 Loss2: -0.9832 Loss3: -0.9903\n",
            "2022-08-01 20:32:43.347747 Epoch [173/250], Step [0050/0060], Loss1: -0.9921 Loss2: -0.9881 Loss3: -0.9931\n",
            "2022-08-01 20:32:49.220717 Epoch [173/250], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9867 Loss3: -0.9916\n",
            "Epoch: 173 MAE: 0.07863027915752754 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:32:57.006491 Epoch [174/250], Step [0001/0060], Loss1: -0.9873 Loss2: -0.9814 Loss3: -0.9891\n",
            "2022-08-01 20:33:25.569520 Epoch [174/250], Step [0050/0060], Loss1: -0.9897 Loss2: -0.9848 Loss3: -0.9911\n",
            "2022-08-01 20:33:31.420102 Epoch [174/250], Step [0060/0060], Loss1: -0.9884 Loss2: -0.9835 Loss3: -0.9898\n",
            "Epoch: 174 MAE: 0.07816316231217965 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:33:39.117730 Epoch [175/250], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9848 Loss3: -0.9913\n",
            "2022-08-01 20:34:07.777120 Epoch [175/250], Step [0050/0060], Loss1: -0.9878 Loss2: -0.9832 Loss3: -0.9892\n",
            "2022-08-01 20:34:13.654207 Epoch [175/250], Step [0060/0060], Loss1: -0.9925 Loss2: -0.9894 Loss3: -0.9934\n",
            "Epoch: 175 MAE: 0.07641177197612782 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:34:23.748116 Epoch [176/250], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9874 Loss3: -0.9926\n",
            "2022-08-01 20:34:53.271455 Epoch [176/250], Step [0050/0060], Loss1: -0.9889 Loss2: -0.9843 Loss3: -0.9901\n",
            "2022-08-01 20:34:59.084081 Epoch [176/250], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9858 Loss3: -0.9925\n",
            "Epoch: 176 MAE: 0.0773953325281698 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:35:06.657402 Epoch [177/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9858 Loss3: -0.9911\n",
            "2022-08-01 20:35:35.254808 Epoch [177/250], Step [0050/0060], Loss1: -0.9918 Loss2: -0.9881 Loss3: -0.9928\n",
            "2022-08-01 20:35:41.069810 Epoch [177/250], Step [0060/0060], Loss1: -0.9896 Loss2: -0.9850 Loss3: -0.9910\n",
            "Epoch: 177 MAE: 0.07680989386543396 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:35:48.782840 Epoch [178/250], Step [0001/0060], Loss1: -0.9916 Loss2: -0.9867 Loss3: -0.9927\n",
            "2022-08-01 20:36:17.570654 Epoch [178/250], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9862 Loss3: -0.9919\n",
            "2022-08-01 20:36:23.391738 Epoch [178/250], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9850 Loss3: -0.9913\n",
            "Epoch: 178 MAE: 0.0783716080680726 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:36:30.961195 Epoch [179/250], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9817 Loss3: -0.9918\n",
            "2022-08-01 20:36:59.627719 Epoch [179/250], Step [0050/0060], Loss1: -0.9874 Loss2: -0.9811 Loss3: -0.9892\n",
            "2022-08-01 20:37:05.461415 Epoch [179/250], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9878 Loss3: -0.9924\n",
            "Epoch: 179 MAE: 0.07731049017931421 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:37:13.195398 Epoch [180/250], Step [0001/0060], Loss1: -0.9920 Loss2: -0.9856 Loss3: -0.9930\n",
            "2022-08-01 20:37:41.857544 Epoch [180/250], Step [0050/0060], Loss1: -0.9856 Loss2: -0.9771 Loss3: -0.9868\n",
            "2022-08-01 20:37:47.706879 Epoch [180/250], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9852 Loss3: -0.9918\n",
            "Epoch: 180 MAE: 0.07857051218628254 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:37:57.909232 Epoch [181/250], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9861 Loss3: -0.9913\n",
            "2022-08-01 20:38:27.059516 Epoch [181/250], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9861 Loss3: -0.9922\n",
            "2022-08-01 20:38:32.919270 Epoch [181/250], Step [0060/0060], Loss1: -0.9893 Loss2: -0.9835 Loss3: -0.9908\n",
            "Epoch: 181 MAE: 0.07856451085004856 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:38:40.717197 Epoch [182/250], Step [0001/0060], Loss1: -0.9913 Loss2: -0.9853 Loss3: -0.9924\n",
            "2022-08-01 20:39:09.326289 Epoch [182/250], Step [0050/0060], Loss1: -0.9920 Loss2: -0.9883 Loss3: -0.9931\n",
            "2022-08-01 20:39:15.180050 Epoch [182/250], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9860 Loss3: -0.9923\n",
            "Epoch: 182 MAE: 0.07785134714116497 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:39:22.901316 Epoch [183/250], Step [0001/0060], Loss1: -0.9918 Loss2: -0.9870 Loss3: -0.9929\n",
            "2022-08-01 20:39:51.624575 Epoch [183/250], Step [0050/0060], Loss1: -0.9922 Loss2: -0.9883 Loss3: -0.9933\n",
            "2022-08-01 20:39:57.528603 Epoch [183/250], Step [0060/0060], Loss1: -0.9898 Loss2: -0.9826 Loss3: -0.9912\n",
            "Epoch: 183 MAE: 0.07669789960144688 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:40:05.104653 Epoch [184/250], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9855 Loss3: -0.9921\n",
            "2022-08-01 20:40:33.798308 Epoch [184/250], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9854 Loss3: -0.9922\n",
            "2022-08-01 20:40:39.603825 Epoch [184/250], Step [0060/0060], Loss1: -0.9908 Loss2: -0.9866 Loss3: -0.9919\n",
            "Epoch: 184 MAE: 0.07678472014331311 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:40:47.333032 Epoch [185/250], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9880 Loss3: -0.9927\n",
            "2022-08-01 20:41:16.128391 Epoch [185/250], Step [0050/0060], Loss1: -0.9882 Loss2: -0.9817 Loss3: -0.9897\n",
            "2022-08-01 20:41:21.920763 Epoch [185/250], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9844 Loss3: -0.9906\n",
            "Epoch: 185 MAE: 0.0768732457438474 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:41:32.169111 Epoch [186/250], Step [0001/0060], Loss1: -0.9906 Loss2: -0.9871 Loss3: -0.9918\n",
            "2022-08-01 20:42:01.158110 Epoch [186/250], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9842 Loss3: -0.9920\n",
            "2022-08-01 20:42:07.034366 Epoch [186/250], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9870 Loss3: -0.9923\n",
            "Epoch: 186 MAE: 0.07698402944696012 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:42:14.822727 Epoch [187/250], Step [0001/0060], Loss1: -0.9917 Loss2: -0.9881 Loss3: -0.9927\n",
            "2022-08-01 20:42:43.451786 Epoch [187/250], Step [0050/0060], Loss1: -0.9882 Loss2: -0.9814 Loss3: -0.9896\n",
            "2022-08-01 20:42:49.228319 Epoch [187/250], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9848 Loss3: -0.9919\n",
            "Epoch: 187 MAE: 0.07673807391413934 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:42:56.866690 Epoch [188/250], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9836 Loss3: -0.9908\n",
            "2022-08-01 20:43:25.456061 Epoch [188/250], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9837 Loss3: -0.9908\n",
            "2022-08-01 20:43:31.313705 Epoch [188/250], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9859 Loss3: -0.9919\n",
            "Epoch: 188 MAE: 0.07704641604549671 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:43:39.004249 Epoch [189/250], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9874 Loss3: -0.9922\n",
            "2022-08-01 20:44:07.769516 Epoch [189/250], Step [0050/0060], Loss1: -0.9880 Loss2: -0.9808 Loss3: -0.9897\n",
            "2022-08-01 20:44:13.601482 Epoch [189/250], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9870 Loss3: -0.9928\n",
            "Epoch: 189 MAE: 0.07725428682155708 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:44:21.310525 Epoch [190/250], Step [0001/0060], Loss1: -0.9922 Loss2: -0.9872 Loss3: -0.9932\n",
            "2022-08-01 20:44:50.013447 Epoch [190/250], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9867 Loss3: -0.9916\n",
            "2022-08-01 20:44:55.830057 Epoch [190/250], Step [0060/0060], Loss1: -0.9921 Loss2: -0.9868 Loss3: -0.9930\n",
            "Epoch: 190 MAE: 0.07708968359326561 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:45:06.079756 Epoch [191/250], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9859 Loss3: -0.9922\n",
            "2022-08-01 20:45:35.164011 Epoch [191/250], Step [0050/0060], Loss1: -0.9891 Loss2: -0.9836 Loss3: -0.9902\n",
            "2022-08-01 20:45:40.956616 Epoch [191/250], Step [0060/0060], Loss1: -0.9876 Loss2: -0.9813 Loss3: -0.9889\n",
            "Epoch: 191 MAE: 0.07727217941687851 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:45:48.687549 Epoch [192/250], Step [0001/0060], Loss1: -0.9906 Loss2: -0.9836 Loss3: -0.9916\n",
            "2022-08-01 20:46:17.524863 Epoch [192/250], Step [0050/0060], Loss1: -0.9893 Loss2: -0.9837 Loss3: -0.9903\n",
            "2022-08-01 20:46:23.342127 Epoch [192/250], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9862 Loss3: -0.9929\n",
            "Epoch: 192 MAE: 0.07547101328612635 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:46:31.072982 Epoch [193/250], Step [0001/0060], Loss1: -0.9883 Loss2: -0.9813 Loss3: -0.9897\n",
            "2022-08-01 20:46:59.676332 Epoch [193/250], Step [0050/0060], Loss1: -0.9880 Loss2: -0.9838 Loss3: -0.9896\n",
            "2022-08-01 20:47:05.448929 Epoch [193/250], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9867 Loss3: -0.9910\n",
            "Epoch: 193 MAE: 0.07662873157117732 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:47:13.206507 Epoch [194/250], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9841 Loss3: -0.9909\n",
            "2022-08-01 20:47:41.840464 Epoch [194/250], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9791 Loss3: -0.9900\n",
            "2022-08-01 20:47:47.740053 Epoch [194/250], Step [0060/0060], Loss1: -0.9925 Loss2: -0.9878 Loss3: -0.9936\n",
            "Epoch: 194 MAE: 0.07647825564026203 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:47:55.544933 Epoch [195/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9832 Loss3: -0.9912\n",
            "2022-08-01 20:48:24.140455 Epoch [195/250], Step [0050/0060], Loss1: -0.9915 Loss2: -0.9882 Loss3: -0.9926\n",
            "2022-08-01 20:48:29.991061 Epoch [195/250], Step [0060/0060], Loss1: -0.9865 Loss2: -0.9787 Loss3: -0.9880\n",
            "Epoch: 195 MAE: 0.07803543146325168 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:48:40.195292 Epoch [196/250], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9811 Loss3: -0.9905\n",
            "2022-08-01 20:49:09.355095 Epoch [196/250], Step [0050/0060], Loss1: -0.9852 Loss2: -0.9798 Loss3: -0.9875\n",
            "2022-08-01 20:49:15.209260 Epoch [196/250], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9879 Loss3: -0.9926\n",
            "Epoch: 196 MAE: 0.07618725443643236 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:49:22.947823 Epoch [197/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9854 Loss3: -0.9914\n",
            "2022-08-01 20:49:51.541812 Epoch [197/250], Step [0050/0060], Loss1: -0.9897 Loss2: -0.9831 Loss3: -0.9910\n",
            "2022-08-01 20:49:57.418609 Epoch [197/250], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9882 Loss3: -0.9927\n",
            "Epoch: 197 MAE: 0.0784608544748296 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:50:05.062495 Epoch [198/250], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9841 Loss3: -0.9919\n",
            "2022-08-01 20:50:33.464212 Epoch [198/250], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9866 Loss3: -0.9919\n",
            "2022-08-01 20:50:39.230341 Epoch [198/250], Step [0060/0060], Loss1: -0.9916 Loss2: -0.9879 Loss3: -0.9926\n",
            "Epoch: 198 MAE: 0.07590581010889123 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:50:46.799727 Epoch [199/250], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9865 Loss3: -0.9920\n",
            "2022-08-01 20:51:15.408077 Epoch [199/250], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9856 Loss3: -0.9919\n",
            "2022-08-01 20:51:21.301984 Epoch [199/250], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9861 Loss3: -0.9915\n",
            "Epoch: 199 MAE: 0.07882373703850641 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:51:29.029232 Epoch [200/250], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9871 Loss3: -0.9922\n",
            "2022-08-01 20:51:57.689755 Epoch [200/250], Step [0050/0060], Loss1: -0.9918 Loss2: -0.9876 Loss3: -0.9929\n",
            "2022-08-01 20:52:03.567754 Epoch [200/250], Step [0060/0060], Loss1: -0.9876 Loss2: -0.9821 Loss3: -0.9889\n",
            "Epoch: 200 MAE: 0.07770340228206897 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:52:14.014427 Epoch [201/250], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9864 Loss3: -0.9913\n",
            "2022-08-01 20:52:43.219055 Epoch [201/250], Step [0050/0060], Loss1: -0.9885 Loss2: -0.9821 Loss3: -0.9900\n",
            "2022-08-01 20:52:49.062406 Epoch [201/250], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9855 Loss3: -0.9906\n",
            "Epoch: 201 MAE: 0.07712033150688048 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:52:56.794561 Epoch [202/250], Step [0001/0060], Loss1: -0.9919 Loss2: -0.9875 Loss3: -0.9931\n",
            "2022-08-01 20:53:25.385330 Epoch [202/250], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9780 Loss3: -0.9885\n",
            "2022-08-01 20:53:31.243701 Epoch [202/250], Step [0060/0060], Loss1: -0.9930 Loss2: -0.9891 Loss3: -0.9939\n",
            "Epoch: 202 MAE: 0.07701499550430868 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:53:39.001992 Epoch [203/250], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9828 Loss3: -0.9910\n",
            "2022-08-01 20:54:07.737042 Epoch [203/250], Step [0050/0060], Loss1: -0.9883 Loss2: -0.9801 Loss3: -0.9896\n",
            "2022-08-01 20:54:13.578089 Epoch [203/250], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9865 Loss3: -0.9916\n",
            "Epoch: 203 MAE: 0.07707774919176859 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:54:21.304065 Epoch [204/250], Step [0001/0060], Loss1: -0.9889 Loss2: -0.9826 Loss3: -0.9901\n",
            "2022-08-01 20:54:49.976103 Epoch [204/250], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9856 Loss3: -0.9919\n",
            "2022-08-01 20:54:55.850421 Epoch [204/250], Step [0060/0060], Loss1: -0.9890 Loss2: -0.9832 Loss3: -0.9904\n",
            "Epoch: 204 MAE: 0.0784156254359654 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:55:03.652746 Epoch [205/250], Step [0001/0060], Loss1: -0.9875 Loss2: -0.9824 Loss3: -0.9891\n",
            "2022-08-01 20:55:32.472310 Epoch [205/250], Step [0050/0060], Loss1: -0.9891 Loss2: -0.9803 Loss3: -0.9903\n",
            "2022-08-01 20:55:38.349252 Epoch [205/250], Step [0060/0060], Loss1: -0.9888 Loss2: -0.9797 Loss3: -0.9900\n",
            "Epoch: 205 MAE: 0.07704472980802018 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:55:48.326898 Epoch [206/250], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9864 Loss3: -0.9926\n",
            "2022-08-01 20:56:17.359284 Epoch [206/250], Step [0050/0060], Loss1: -0.9873 Loss2: -0.9812 Loss3: -0.9889\n",
            "2022-08-01 20:56:23.166657 Epoch [206/250], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9874 Loss3: -0.9925\n",
            "Epoch: 206 MAE: 0.0773561093163869 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:56:30.917441 Epoch [207/250], Step [0001/0060], Loss1: -0.9874 Loss2: -0.9819 Loss3: -0.9888\n",
            "2022-08-01 20:56:59.953471 Epoch [207/250], Step [0050/0060], Loss1: -0.9921 Loss2: -0.9875 Loss3: -0.9932\n",
            "2022-08-01 20:57:05.805950 Epoch [207/250], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9835 Loss3: -0.9912\n",
            "Epoch: 207 MAE: 0.07515718545863238 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:57:13.604368 Epoch [208/250], Step [0001/0060], Loss1: -0.9880 Loss2: -0.9824 Loss3: -0.9895\n",
            "2022-08-01 20:57:42.330371 Epoch [208/250], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9854 Loss3: -0.9919\n",
            "2022-08-01 20:57:48.197427 Epoch [208/250], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9870 Loss3: -0.9920\n",
            "Epoch: 208 MAE: 0.07835616530564729 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:57:55.860918 Epoch [209/250], Step [0001/0060], Loss1: -0.9870 Loss2: -0.9773 Loss3: -0.9884\n",
            "2022-08-01 20:58:24.613727 Epoch [209/250], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9842 Loss3: -0.9913\n",
            "2022-08-01 20:58:30.420712 Epoch [209/250], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9846 Loss3: -0.9920\n",
            "Epoch: 209 MAE: 0.07885148270420295 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:58:38.123037 Epoch [210/250], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9872 Loss3: -0.9922\n",
            "2022-08-01 20:59:06.861843 Epoch [210/250], Step [0050/0060], Loss1: -0.9913 Loss2: -0.9868 Loss3: -0.9924\n",
            "2022-08-01 20:59:12.699537 Epoch [210/250], Step [0060/0060], Loss1: -0.9910 Loss2: -0.9863 Loss3: -0.9920\n",
            "Epoch: 210 MAE: 0.07810828017179296 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 20:59:23.160079 Epoch [211/250], Step [0001/0060], Loss1: -0.9887 Loss2: -0.9837 Loss3: -0.9902\n",
            "2022-08-01 20:59:52.447002 Epoch [211/250], Step [0050/0060], Loss1: -0.9921 Loss2: -0.9886 Loss3: -0.9931\n",
            "2022-08-01 20:59:58.303516 Epoch [211/250], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9856 Loss3: -0.9915\n",
            "Epoch: 211 MAE: 0.07701782246746086 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:00:06.042436 Epoch [212/250], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9868 Loss3: -0.9922\n",
            "2022-08-01 21:00:34.800029 Epoch [212/250], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9863 Loss3: -0.9919\n",
            "2022-08-01 21:00:40.695071 Epoch [212/250], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9868 Loss3: -0.9926\n",
            "Epoch: 212 MAE: 0.07673348078652033 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:00:48.439483 Epoch [213/250], Step [0001/0060], Loss1: -0.9915 Loss2: -0.9873 Loss3: -0.9925\n",
            "2022-08-01 21:01:17.157319 Epoch [213/250], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9878 Loss3: -0.9927\n",
            "2022-08-01 21:01:23.101900 Epoch [213/250], Step [0060/0060], Loss1: -0.9881 Loss2: -0.9824 Loss3: -0.9895\n",
            "Epoch: 213 MAE: 0.07801662722592631 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:01:31.250505 Epoch [214/250], Step [0001/0060], Loss1: -0.9890 Loss2: -0.9839 Loss3: -0.9903\n",
            "2022-08-01 21:01:59.985784 Epoch [214/250], Step [0050/0060], Loss1: -0.9912 Loss2: -0.9871 Loss3: -0.9923\n",
            "2022-08-01 21:02:05.783724 Epoch [214/250], Step [0060/0060], Loss1: -0.9918 Loss2: -0.9880 Loss3: -0.9929\n",
            "Epoch: 214 MAE: 0.07831321842455992 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:02:13.471795 Epoch [215/250], Step [0001/0060], Loss1: -0.9878 Loss2: -0.9795 Loss3: -0.9892\n",
            "2022-08-01 21:02:42.217167 Epoch [215/250], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9856 Loss3: -0.9925\n",
            "2022-08-01 21:02:47.998112 Epoch [215/250], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9836 Loss3: -0.9912\n",
            "Epoch: 215 MAE: 0.07720784273097123 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:02:58.279557 Epoch [216/250], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9871 Loss3: -0.9916\n",
            "2022-08-01 21:03:27.662761 Epoch [216/250], Step [0050/0060], Loss1: -0.9916 Loss2: -0.9871 Loss3: -0.9928\n",
            "2022-08-01 21:03:33.517326 Epoch [216/250], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9828 Loss3: -0.9913\n",
            "Epoch: 216 MAE: 0.07776625870396851 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:03:41.196129 Epoch [217/250], Step [0001/0060], Loss1: -0.9889 Loss2: -0.9823 Loss3: -0.9904\n",
            "2022-08-01 21:04:10.573068 Epoch [217/250], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9858 Loss3: -0.9915\n",
            "2022-08-01 21:04:16.565904 Epoch [217/250], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9850 Loss3: -0.9909\n",
            "Epoch: 217 MAE: 0.07745777619578852 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:04:24.279480 Epoch [218/250], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9861 Loss3: -0.9918\n",
            "2022-08-01 21:04:52.858031 Epoch [218/250], Step [0050/0060], Loss1: -0.9900 Loss2: -0.9860 Loss3: -0.9912\n",
            "2022-08-01 21:04:58.653506 Epoch [218/250], Step [0060/0060], Loss1: -0.9910 Loss2: -0.9874 Loss3: -0.9921\n",
            "Epoch: 218 MAE: 0.0782367647261847 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:05:06.357352 Epoch [219/250], Step [0001/0060], Loss1: -0.9917 Loss2: -0.9877 Loss3: -0.9930\n",
            "2022-08-01 21:05:35.196705 Epoch [219/250], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9833 Loss3: -0.9909\n",
            "2022-08-01 21:05:41.071125 Epoch [219/250], Step [0060/0060], Loss1: -0.9916 Loss2: -0.9867 Loss3: -0.9927\n",
            "Epoch: 219 MAE: 0.08025417065494275 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:05:48.807704 Epoch [220/250], Step [0001/0060], Loss1: -0.9894 Loss2: -0.9837 Loss3: -0.9907\n",
            "2022-08-01 21:06:17.799393 Epoch [220/250], Step [0050/0060], Loss1: -0.9881 Loss2: -0.9816 Loss3: -0.9899\n",
            "2022-08-01 21:06:23.667725 Epoch [220/250], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9875 Loss3: -0.9927\n",
            "Epoch: 220 MAE: 0.07797656518441659 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:06:34.069771 Epoch [221/250], Step [0001/0060], Loss1: -0.9886 Loss2: -0.9827 Loss3: -0.9901\n",
            "2022-08-01 21:07:03.506462 Epoch [221/250], Step [0050/0060], Loss1: -0.9894 Loss2: -0.9830 Loss3: -0.9910\n",
            "2022-08-01 21:07:09.424286 Epoch [221/250], Step [0060/0060], Loss1: -0.9880 Loss2: -0.9785 Loss3: -0.9894\n",
            "Epoch: 221 MAE: 0.07832164774496085 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:07:17.417154 Epoch [222/250], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9875 Loss3: -0.9923\n",
            "2022-08-01 21:07:46.471930 Epoch [222/250], Step [0050/0060], Loss1: -0.9919 Loss2: -0.9869 Loss3: -0.9929\n",
            "2022-08-01 21:07:52.301265 Epoch [222/250], Step [0060/0060], Loss1: -0.9886 Loss2: -0.9830 Loss3: -0.9900\n",
            "Epoch: 222 MAE: 0.07754972765685389 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:08:00.210528 Epoch [223/250], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9854 Loss3: -0.9916\n",
            "2022-08-01 21:08:29.070243 Epoch [223/250], Step [0050/0060], Loss1: -0.9915 Loss2: -0.9866 Loss3: -0.9926\n",
            "2022-08-01 21:08:34.915225 Epoch [223/250], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9845 Loss3: -0.9916\n",
            "Epoch: 223 MAE: 0.07788549075050961 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:08:42.949114 Epoch [224/250], Step [0001/0060], Loss1: -0.9920 Loss2: -0.9892 Loss3: -0.9930\n",
            "2022-08-01 21:09:11.818894 Epoch [224/250], Step [0050/0060], Loss1: -0.9915 Loss2: -0.9873 Loss3: -0.9927\n",
            "2022-08-01 21:09:17.699732 Epoch [224/250], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9839 Loss3: -0.9915\n",
            "Epoch: 224 MAE: 0.07565023270864334 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:09:25.688146 Epoch [225/250], Step [0001/0060], Loss1: -0.9885 Loss2: -0.9826 Loss3: -0.9899\n",
            "2022-08-01 21:09:54.740219 Epoch [225/250], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9857 Loss3: -0.9917\n",
            "2022-08-01 21:10:00.624518 Epoch [225/250], Step [0060/0060], Loss1: -0.9922 Loss2: -0.9873 Loss3: -0.9932\n",
            "Epoch: 225 MAE: 0.07786604866148934 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:10:10.788629 Epoch [226/250], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9857 Loss3: -0.9923\n",
            "2022-08-01 21:10:40.085895 Epoch [226/250], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9843 Loss3: -0.9916\n",
            "2022-08-01 21:10:45.963460 Epoch [226/250], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9843 Loss3: -0.9921\n",
            "Epoch: 226 MAE: 0.07716221940580496 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:10:53.661861 Epoch [227/250], Step [0001/0060], Loss1: -0.9890 Loss2: -0.9811 Loss3: -0.9904\n",
            "2022-08-01 21:11:22.691712 Epoch [227/250], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9850 Loss3: -0.9917\n",
            "2022-08-01 21:11:28.506140 Epoch [227/250], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9879 Loss3: -0.9929\n",
            "Epoch: 227 MAE: 0.07634176809321003 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:11:36.527447 Epoch [228/250], Step [0001/0060], Loss1: -0.9890 Loss2: -0.9840 Loss3: -0.9903\n",
            "2022-08-01 21:12:05.185007 Epoch [228/250], Step [0050/0060], Loss1: -0.9919 Loss2: -0.9891 Loss3: -0.9931\n",
            "2022-08-01 21:12:11.094009 Epoch [228/250], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9881 Loss3: -0.9924\n",
            "Epoch: 228 MAE: 0.0769790394596322 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:12:18.914119 Epoch [229/250], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9860 Loss3: -0.9917\n",
            "2022-08-01 21:12:47.834551 Epoch [229/250], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9853 Loss3: -0.9918\n",
            "2022-08-01 21:12:53.709660 Epoch [229/250], Step [0060/0060], Loss1: -0.9890 Loss2: -0.9832 Loss3: -0.9905\n",
            "Epoch: 229 MAE: 0.07787069583065295 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:13:01.510102 Epoch [230/250], Step [0001/0060], Loss1: -0.9897 Loss2: -0.9850 Loss3: -0.9909\n",
            "2022-08-01 21:13:30.260706 Epoch [230/250], Step [0050/0060], Loss1: -0.9918 Loss2: -0.9860 Loss3: -0.9929\n",
            "2022-08-01 21:13:36.105746 Epoch [230/250], Step [0060/0060], Loss1: -0.9923 Loss2: -0.9888 Loss3: -0.9933\n",
            "Epoch: 230 MAE: 0.07793134018226909 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:13:46.367828 Epoch [231/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9865 Loss3: -0.9912\n",
            "2022-08-01 21:14:15.700901 Epoch [231/250], Step [0050/0060], Loss1: -0.9913 Loss2: -0.9858 Loss3: -0.9924\n",
            "2022-08-01 21:14:21.568242 Epoch [231/250], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9860 Loss3: -0.9924\n",
            "Epoch: 231 MAE: 0.07849666509678759 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:14:29.370575 Epoch [232/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9857 Loss3: -0.9915\n",
            "2022-08-01 21:14:58.333980 Epoch [232/250], Step [0050/0060], Loss1: -0.9917 Loss2: -0.9871 Loss3: -0.9929\n",
            "2022-08-01 21:15:04.175351 Epoch [232/250], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9847 Loss3: -0.9922\n",
            "Epoch: 232 MAE: 0.07877035615305421 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:15:11.969246 Epoch [233/250], Step [0001/0060], Loss1: -0.9923 Loss2: -0.9867 Loss3: -0.9934\n",
            "2022-08-01 21:15:40.808540 Epoch [233/250], Step [0050/0060], Loss1: -0.9921 Loss2: -0.9865 Loss3: -0.9930\n",
            "2022-08-01 21:15:46.696201 Epoch [233/250], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9863 Loss3: -0.9916\n",
            "Epoch: 233 MAE: 0.0790343393598284 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:15:54.486255 Epoch [234/250], Step [0001/0060], Loss1: -0.9915 Loss2: -0.9865 Loss3: -0.9925\n",
            "2022-08-01 21:16:23.387509 Epoch [234/250], Step [0050/0060], Loss1: -0.9874 Loss2: -0.9798 Loss3: -0.9893\n",
            "2022-08-01 21:16:29.259433 Epoch [234/250], Step [0060/0060], Loss1: -0.9886 Loss2: -0.9841 Loss3: -0.9902\n",
            "Epoch: 234 MAE: 0.07823965299697148 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:16:36.907876 Epoch [235/250], Step [0001/0060], Loss1: -0.9926 Loss2: -0.9881 Loss3: -0.9937\n",
            "2022-08-01 21:17:05.866147 Epoch [235/250], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9862 Loss3: -0.9914\n",
            "2022-08-01 21:17:11.733559 Epoch [235/250], Step [0060/0060], Loss1: -0.9869 Loss2: -0.9805 Loss3: -0.9890\n",
            "Epoch: 235 MAE: 0.07749858159867544 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:17:22.037182 Epoch [236/250], Step [0001/0060], Loss1: -0.9913 Loss2: -0.9858 Loss3: -0.9925\n",
            "2022-08-01 21:17:51.592200 Epoch [236/250], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9850 Loss3: -0.9920\n",
            "2022-08-01 21:17:57.497489 Epoch [236/250], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9826 Loss3: -0.9916\n",
            "Epoch: 236 MAE: 0.07727823681301539 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:18:05.280930 Epoch [237/250], Step [0001/0060], Loss1: -0.9916 Loss2: -0.9867 Loss3: -0.9926\n",
            "2022-08-01 21:18:33.963642 Epoch [237/250], Step [0050/0060], Loss1: -0.9919 Loss2: -0.9860 Loss3: -0.9929\n",
            "2022-08-01 21:18:39.787341 Epoch [237/250], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9849 Loss3: -0.9924\n",
            "Epoch: 237 MAE: 0.07685294923328216 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:18:47.489638 Epoch [238/250], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9857 Loss3: -0.9917\n",
            "2022-08-01 21:19:16.128342 Epoch [238/250], Step [0050/0060], Loss1: -0.9879 Loss2: -0.9799 Loss3: -0.9894\n",
            "2022-08-01 21:19:22.101337 Epoch [238/250], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9836 Loss3: -0.9913\n",
            "Epoch: 238 MAE: 0.0774249469918549 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:19:29.943564 Epoch [239/250], Step [0001/0060], Loss1: -0.9886 Loss2: -0.9828 Loss3: -0.9901\n",
            "2022-08-01 21:19:58.847053 Epoch [239/250], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9872 Loss3: -0.9922\n",
            "2022-08-01 21:20:04.687116 Epoch [239/250], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9870 Loss3: -0.9928\n",
            "Epoch: 239 MAE: 0.07728934424264094 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:20:12.433381 Epoch [240/250], Step [0001/0060], Loss1: -0.9915 Loss2: -0.9856 Loss3: -0.9925\n",
            "2022-08-01 21:20:41.385607 Epoch [240/250], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9868 Loss3: -0.9918\n",
            "2022-08-01 21:20:47.285491 Epoch [240/250], Step [0060/0060], Loss1: -0.9908 Loss2: -0.9837 Loss3: -0.9921\n",
            "Epoch: 240 MAE: 0.07730226042409423 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:20:57.622925 Epoch [241/250], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9848 Loss3: -0.9912\n",
            "2022-08-01 21:21:27.144943 Epoch [241/250], Step [0050/0060], Loss1: -0.9887 Loss2: -0.9834 Loss3: -0.9900\n",
            "2022-08-01 21:21:33.018480 Epoch [241/250], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9818 Loss3: -0.9906\n",
            "Epoch: 241 MAE: 0.07759296250721763 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:21:40.790233 Epoch [242/250], Step [0001/0060], Loss1: -0.9879 Loss2: -0.9814 Loss3: -0.9894\n",
            "2022-08-01 21:22:09.722216 Epoch [242/250], Step [0050/0060], Loss1: -0.9922 Loss2: -0.9887 Loss3: -0.9933\n",
            "2022-08-01 21:22:15.620368 Epoch [242/250], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9840 Loss3: -0.9915\n",
            "Epoch: 242 MAE: 0.07757443211066029 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:22:23.379828 Epoch [243/250], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9849 Loss3: -0.9908\n",
            "2022-08-01 21:22:52.191645 Epoch [243/250], Step [0050/0060], Loss1: -0.9891 Loss2: -0.9832 Loss3: -0.9908\n",
            "2022-08-01 21:22:58.090060 Epoch [243/250], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9859 Loss3: -0.9916\n",
            "Epoch: 243 MAE: 0.07555698606703017 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:23:05.908775 Epoch [244/250], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9839 Loss3: -0.9920\n",
            "2022-08-01 21:23:34.837258 Epoch [244/250], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9869 Loss3: -0.9921\n",
            "2022-08-01 21:23:40.720029 Epoch [244/250], Step [0060/0060], Loss1: -0.9860 Loss2: -0.9772 Loss3: -0.9876\n",
            "Epoch: 244 MAE: 0.07775889563182044 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:23:48.540690 Epoch [245/250], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9861 Loss3: -0.9913\n",
            "2022-08-01 21:24:17.493121 Epoch [245/250], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9842 Loss3: -0.9919\n",
            "2022-08-01 21:24:23.439856 Epoch [245/250], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9867 Loss3: -0.9921\n",
            "Epoch: 245 MAE: 0.07687778664644436 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:24:33.746276 Epoch [246/250], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9848 Loss3: -0.9915\n",
            "2022-08-01 21:25:03.110653 Epoch [246/250], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9842 Loss3: -0.9921\n",
            "2022-08-01 21:25:09.028547 Epoch [246/250], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9842 Loss3: -0.9920\n",
            "Epoch: 246 MAE: 0.07719461738747897 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:25:16.961036 Epoch [247/250], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9840 Loss3: -0.9910\n",
            "2022-08-01 21:25:45.875020 Epoch [247/250], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9872 Loss3: -0.9924\n",
            "2022-08-01 21:25:51.830822 Epoch [247/250], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9874 Loss3: -0.9925\n",
            "Epoch: 247 MAE: 0.07817936327091599 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:25:59.566604 Epoch [248/250], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9854 Loss3: -0.9913\n",
            "2022-08-01 21:26:28.540685 Epoch [248/250], Step [0050/0060], Loss1: -0.9926 Loss2: -0.9878 Loss3: -0.9937\n",
            "2022-08-01 21:26:34.439034 Epoch [248/250], Step [0060/0060], Loss1: -0.9923 Loss2: -0.9878 Loss3: -0.9933\n",
            "Epoch: 248 MAE: 0.07857176775654787 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n",
            "2022-08-01 21:26:42.304931 Epoch [249/250], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9856 Loss3: -0.9923\n",
            "2022-08-01 21:27:11.189567 Epoch [249/250], Step [0050/0060], Loss1: -0.9879 Loss2: -0.9813 Loss3: -0.9893\n",
            "2022-08-01 21:27:17.099005 Epoch [249/250], Step [0060/0060], Loss1: -0.9856 Loss2: -0.9750 Loss3: -0.9871\n",
            "Epoch: 249 MAE: 0.0793973094193393 ####  bestMAE: 0.07158886904438969 bestEpoch: 57\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "train_accu = []\n",
        "train_losses = []\n",
        "train_accu1 = []\n",
        "train_accu2 = []\n",
        "train_accu3 = []\n",
        "train_losses1 = []\n",
        "train_losses2 = []\n",
        "train_losses3 = []\n",
        "val_accu = []\n",
        "val_losses = []\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    running_loss = 0\n",
        "    running_loss1 = 0\n",
        "    running_loss2 = 0\n",
        "    running_loss3 = 0\n",
        "    total = 0\n",
        "    total1 = 0\n",
        "    total2 = 0\n",
        "    total3 = 0\n",
        "    correct = 0\n",
        "    correct1 = 0\n",
        "    correct2 = 0\n",
        "    correct3 = 0\n",
        "\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = fun_ssim(gts, pre_res[0])\n",
        "            loss2    = fun_ssim(gts, pre_res[1])\n",
        "            loss3    = fun_ssim(gts, pre_res[2])\n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "\n",
        "            #loss graph\n",
        "            running_loss1 += loss1.item()\n",
        "            running_loss2 += loss2.item()\n",
        "            running_loss3 += loss3.item()\n",
        "            predicted1 = pre_res[0]\n",
        "            predicted2 = pre_res[1]\n",
        "            predicted3 = pre_res[2]\n",
        "            total1 += images.size(0)\n",
        "            total2 += gts.size(0)\n",
        "            total3 += depths.size(0)\n",
        "            correct1 += predicted1.eq(images).sum().item()\n",
        "            correct2 += predicted2.eq(gts).sum().item()\n",
        "            correct3 += predicted3.eq(depths).sum().item()\n",
        "\n",
        "            running_loss += loss_all.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = gt + loss + predicted\n",
        "            total += images.size(0)\n",
        "            correct += outputs.eq(images).sum().item()\n",
        "            \n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "\n",
        "        train_loss = running_loss/len(train_loader)\n",
        "        train_loss1=running_loss1/len(train_loader)\n",
        "        train_loss2=running_loss2/len(train_loader)\n",
        "        train_loss3=running_loss3/len(train_loader)\n",
        "        accu = 100.*correct/total\n",
        "        accu1=100.*correct1/total1\n",
        "        accu2=100.*correct2/total2\n",
        "        accu3=100.*correct3/total3        \n",
        "        train_accu1.append(accu1)\n",
        "        train_accu2.append(accu2)\n",
        "        train_accu3.append(accu3)\n",
        "        train_losses1.append(train_loss1)\n",
        "        train_losses2.append(train_loss2)\n",
        "        train_losses3.append(train_loss3)\n",
        "        train_accu.append(accu)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "           \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-8)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "            mae_sum += np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "\n",
        "            #loss graph\n",
        "            running_loss += mae_sum.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = gt + loss + predicted\n",
        "            total += test_loader.size\n",
        "            correct += outputs.eq(image).sum().item()\n",
        "\n",
        "\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "       \n",
        "        val_loss=running_loss/len(test_loader)\n",
        "        accu=100.*correct/total\n",
        "        val_accu.append(accu)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_best_epoch_ssim_loss.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n",
        "\n",
        "plt.plot(train_losses, '-')\n",
        "plt.plot(train_losses1,'-')\n",
        "plt.plot(train_losses2,'-')\n",
        "plt.plot(train_losses3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['SSIM Loss','Loss1', 'Loss2', 'Loss3'])\n",
        "plt.title('Train Losses')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_accu, '-')\n",
        "plt.plot(train_accu1,'-')\n",
        "plt.plot(train_accu2,'-')\n",
        "plt.plot(train_accu3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Accuracy','Acc1', 'Acc2', 'Acc3'])\n",
        "plt.title('Train Accuracy')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(val_losses,'-o')\n",
        "plt.plot(val_accu,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Losses','Accuracy'])\n",
        "plt.title('Test Losses and Accuracy')\n",
        " \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTmvfpTvqukp"
      },
      "source": [
        "### Training With Structure Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPhbcvtXqzGZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "def structure_loss(pred, mask):\n",
        "    weit  = 1+5*torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15)-mask)\n",
        "    wbce  = F.binary_cross_entropy_with_logits(pred, mask, reduce='none')\n",
        "    wbce  = (weit*wbce).sum(dim=(2,3))/weit.sum(dim=(2,3))\n",
        "\n",
        "    pred  = torch.sigmoid(pred)\n",
        "    inter = ((pred*mask)*weit).sum(dim=(2,3))\n",
        "    union = ((pred+mask)*weit).sum(dim=(2,3))\n",
        "    wiou  = 1-(inter+1)/(union-inter+1)\n",
        "    return (wbce+wiou).mean()\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "train_accu = []\n",
        "train_losses = []\n",
        "train_accu1 = []\n",
        "train_accu2 = []\n",
        "train_accu3 = []\n",
        "train_losses1 = []\n",
        "train_losses2 = []\n",
        "train_losses3 = []\n",
        "val_accu = []\n",
        "val_losses = []\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    running_loss = 0\n",
        "    running_loss1 = 0\n",
        "    running_loss2 = 0\n",
        "    running_loss3 = 0\n",
        "    total = 0\n",
        "    total1 = 0\n",
        "    total2 = 0\n",
        "    total3 = 0\n",
        "    correct = 0\n",
        "    correct1 = 0\n",
        "    correct2 = 0\n",
        "    correct3 = 0\n",
        "\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = structure_loss(gts, pre_res[0])\n",
        "            loss2    = structure_loss(gts, pre_res[1])\n",
        "            loss3    = structure_loss(gts, pre_res[2])\n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "\n",
        "            #loss graph\n",
        "            running_loss1 += loss1.item()\n",
        "            running_loss2 += loss2.item()\n",
        "            running_loss3 += loss3.item()\n",
        "            predicted1 = pre_res[0]\n",
        "            predicted2 = pre_res[1]\n",
        "            predicted3 = pre_res[2]\n",
        "            total1 += images.size(0)\n",
        "            total2 += gts.size(0)\n",
        "            total3 += depths.size(0)\n",
        "            correct1 += predicted1.eq(images).sum().item()\n",
        "            correct2 += predicted2.eq(gts).sum().item()\n",
        "            correct3 += predicted3.eq(depths).sum().item()\n",
        "\n",
        "            running_loss += loss_all.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = gt + loss + predicted\n",
        "            total += images.size(0)\n",
        "            correct += outputs.eq(images).sum().item()\n",
        "            \n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "\n",
        "        train_loss = running_loss/len(train_loader)\n",
        "        train_loss1=running_loss1/len(train_loader)\n",
        "        train_loss2=running_loss2/len(train_loader)\n",
        "        train_loss3=running_loss3/len(train_loader)\n",
        "        accu = 100.*correct/total\n",
        "        accu1=100.*correct1/total1\n",
        "        accu2=100.*correct2/total2\n",
        "        accu3=100.*correct3/total3        \n",
        "        train_accu1.append(accu1)\n",
        "        train_accu2.append(accu2)\n",
        "        train_accu3.append(accu3)\n",
        "        train_losses1.append(train_loss1)\n",
        "        train_losses2.append(train_loss2)\n",
        "        train_losses3.append(train_loss3)\n",
        "        train_accu.append(accu)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "           \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-8)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "            mae_sum += np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "\n",
        "            #loss graph\n",
        "            running_loss += mae_sum.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = gt + loss + predicted\n",
        "            total += test_loader.size\n",
        "            correct += outputs.eq(image).sum().item()\n",
        "\n",
        "\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "       \n",
        "        val_loss=running_loss/len(test_loader)\n",
        "        accu=100.*correct/total\n",
        "        val_accu.append(accu)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_best_epoch_structure_loss.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n",
        "\n",
        "plt.plot(train_losses, '-')\n",
        "plt.plot(train_losses1,'-')\n",
        "plt.plot(train_losses2,'-')\n",
        "plt.plot(train_losses3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['SSIM Loss','Loss1', 'Loss2', 'Loss3'])\n",
        "plt.title('Train Losses')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_accu, '-')\n",
        "plt.plot(train_accu1,'-')\n",
        "plt.plot(train_accu2,'-')\n",
        "plt.plot(train_accu3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Accuracy','Acc1', 'Acc2', 'Acc3'])\n",
        "plt.title('Train Accuracy')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(val_losses,'-o')\n",
        "plt.plot(val_accu,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Losses','Accuracy'])\n",
        "plt.title('Test Losses and Accuracy')\n",
        " \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1IWxjtGMjW6"
      },
      "source": [
        "### Training with SSIM and PSNR metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R1OONUr9MtQt",
        "outputId": "5214374a-3066-43b1-a5a3-5c77c3071085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE GPU 0\n",
            "load data...\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/traindataset_only_depth/RGB/depth_00.png', '/content/tmp/traindataset_only_depth/RGB/depth_01.png', '/content/tmp/traindataset_only_depth/RGB/depth_02.png', '/content/tmp/traindataset_only_depth/RGB/depth_10.png', '/content/tmp/traindataset_only_depth/RGB/depth_100.png', '/content/tmp/traindataset_only_depth/RGB/depth_101.png', '/content/tmp/traindataset_only_depth/RGB/depth_102.png', '/content/tmp/traindataset_only_depth/RGB/depth_11.png', '/content/tmp/traindataset_only_depth/RGB/depth_110.png', '/content/tmp/traindataset_only_depth/RGB/depth_111.png', '/content/tmp/traindataset_only_depth/RGB/depth_112.png', '/content/tmp/traindataset_only_depth/RGB/depth_12.png', '/content/tmp/traindataset_only_depth/RGB/depth_120.png', '/content/tmp/traindataset_only_depth/RGB/depth_121.png', '/content/tmp/traindataset_only_depth/RGB/depth_122.png', '/content/tmp/traindataset_only_depth/RGB/depth_130.png', '/content/tmp/traindataset_only_depth/RGB/depth_131.png', '/content/tmp/traindataset_only_depth/RGB/depth_132.png', '/content/tmp/traindataset_only_depth/RGB/depth_140.png', '/content/tmp/traindataset_only_depth/RGB/depth_141.png', '/content/tmp/traindataset_only_depth/RGB/depth_142.png', '/content/tmp/traindataset_only_depth/RGB/depth_150.png', '/content/tmp/traindataset_only_depth/RGB/depth_151.png', '/content/tmp/traindataset_only_depth/RGB/depth_152.png', '/content/tmp/traindataset_only_depth/RGB/depth_160.png', '/content/tmp/traindataset_only_depth/RGB/depth_161.png', '/content/tmp/traindataset_only_depth/RGB/depth_162.png', '/content/tmp/traindataset_only_depth/RGB/depth_170.png', '/content/tmp/traindataset_only_depth/RGB/depth_171.png', '/content/tmp/traindataset_only_depth/RGB/depth_172.png', '/content/tmp/traindataset_only_depth/RGB/depth_180.png', '/content/tmp/traindataset_only_depth/RGB/depth_181.png', '/content/tmp/traindataset_only_depth/RGB/depth_182.png', '/content/tmp/traindataset_only_depth/RGB/depth_190.png', '/content/tmp/traindataset_only_depth/RGB/depth_191.png', '/content/tmp/traindataset_only_depth/RGB/depth_192.png', '/content/tmp/traindataset_only_depth/RGB/depth_20.png', '/content/tmp/traindataset_only_depth/RGB/depth_200.png', '/content/tmp/traindataset_only_depth/RGB/depth_201.png', '/content/tmp/traindataset_only_depth/RGB/depth_202.png', '/content/tmp/traindataset_only_depth/RGB/depth_21.png', '/content/tmp/traindataset_only_depth/RGB/depth_210.png', '/content/tmp/traindataset_only_depth/RGB/depth_211.png', '/content/tmp/traindataset_only_depth/RGB/depth_212.png', '/content/tmp/traindataset_only_depth/RGB/depth_22.png', '/content/tmp/traindataset_only_depth/RGB/depth_220.png', '/content/tmp/traindataset_only_depth/RGB/depth_221.png', '/content/tmp/traindataset_only_depth/RGB/depth_222.png', '/content/tmp/traindataset_only_depth/RGB/depth_230.png', '/content/tmp/traindataset_only_depth/RGB/depth_231.png', '/content/tmp/traindataset_only_depth/RGB/depth_232.png', '/content/tmp/traindataset_only_depth/RGB/depth_240.png', '/content/tmp/traindataset_only_depth/RGB/depth_241.png', '/content/tmp/traindataset_only_depth/RGB/depth_242.png', '/content/tmp/traindataset_only_depth/RGB/depth_250.png', '/content/tmp/traindataset_only_depth/RGB/depth_251.png', '/content/tmp/traindataset_only_depth/RGB/depth_252.png', '/content/tmp/traindataset_only_depth/RGB/depth_260.png', '/content/tmp/traindataset_only_depth/RGB/depth_261.png', '/content/tmp/traindataset_only_depth/RGB/depth_262.png', '/content/tmp/traindataset_only_depth/RGB/depth_270.png', '/content/tmp/traindataset_only_depth/RGB/depth_271.png', '/content/tmp/traindataset_only_depth/RGB/depth_272.png', '/content/tmp/traindataset_only_depth/RGB/depth_280.png', '/content/tmp/traindataset_only_depth/RGB/depth_281.png', '/content/tmp/traindataset_only_depth/RGB/depth_282.png', '/content/tmp/traindataset_only_depth/RGB/depth_290.png', '/content/tmp/traindataset_only_depth/RGB/depth_291.png', '/content/tmp/traindataset_only_depth/RGB/depth_292.png', '/content/tmp/traindataset_only_depth/RGB/depth_30.png', '/content/tmp/traindataset_only_depth/RGB/depth_300.png', '/content/tmp/traindataset_only_depth/RGB/depth_301.png', '/content/tmp/traindataset_only_depth/RGB/depth_302.png', '/content/tmp/traindataset_only_depth/RGB/depth_31.png', '/content/tmp/traindataset_only_depth/RGB/depth_310.png', '/content/tmp/traindataset_only_depth/RGB/depth_311.png', '/content/tmp/traindataset_only_depth/RGB/depth_312.png', '/content/tmp/traindataset_only_depth/RGB/depth_32.png', '/content/tmp/traindataset_only_depth/RGB/depth_320.png', '/content/tmp/traindataset_only_depth/RGB/depth_321.png', '/content/tmp/traindataset_only_depth/RGB/depth_322.png', '/content/tmp/traindataset_only_depth/RGB/depth_330.png', '/content/tmp/traindataset_only_depth/RGB/depth_331.png', '/content/tmp/traindataset_only_depth/RGB/depth_332.png', '/content/tmp/traindataset_only_depth/RGB/depth_340.png', '/content/tmp/traindataset_only_depth/RGB/depth_341.png', '/content/tmp/traindataset_only_depth/RGB/depth_342.png', '/content/tmp/traindataset_only_depth/RGB/depth_350.png', '/content/tmp/traindataset_only_depth/RGB/depth_351.png', '/content/tmp/traindataset_only_depth/RGB/depth_352.png', '/content/tmp/traindataset_only_depth/RGB/depth_360.png', '/content/tmp/traindataset_only_depth/RGB/depth_361.png', '/content/tmp/traindataset_only_depth/RGB/depth_362.png', '/content/tmp/traindataset_only_depth/RGB/depth_370.png', '/content/tmp/traindataset_only_depth/RGB/depth_371.png', '/content/tmp/traindataset_only_depth/RGB/depth_372.png', '/content/tmp/traindataset_only_depth/RGB/depth_380.png', '/content/tmp/traindataset_only_depth/RGB/depth_381.png', '/content/tmp/traindataset_only_depth/RGB/depth_382.png', '/content/tmp/traindataset_only_depth/RGB/depth_390.png', '/content/tmp/traindataset_only_depth/RGB/depth_391.png', '/content/tmp/traindataset_only_depth/RGB/depth_392.png', '/content/tmp/traindataset_only_depth/RGB/depth_40.png', '/content/tmp/traindataset_only_depth/RGB/depth_400.png', '/content/tmp/traindataset_only_depth/RGB/depth_401.png', '/content/tmp/traindataset_only_depth/RGB/depth_402.png', '/content/tmp/traindataset_only_depth/RGB/depth_41.png', '/content/tmp/traindataset_only_depth/RGB/depth_410.png', '/content/tmp/traindataset_only_depth/RGB/depth_411.png', '/content/tmp/traindataset_only_depth/RGB/depth_412.png', '/content/tmp/traindataset_only_depth/RGB/depth_42.png', '/content/tmp/traindataset_only_depth/RGB/depth_420.png', '/content/tmp/traindataset_only_depth/RGB/depth_421.png', '/content/tmp/traindataset_only_depth/RGB/depth_422.png', '/content/tmp/traindataset_only_depth/RGB/depth_430.png', '/content/tmp/traindataset_only_depth/RGB/depth_431.png', '/content/tmp/traindataset_only_depth/RGB/depth_432.png', '/content/tmp/traindataset_only_depth/RGB/depth_440.png', '/content/tmp/traindataset_only_depth/RGB/depth_441.png', '/content/tmp/traindataset_only_depth/RGB/depth_442.png', '/content/tmp/traindataset_only_depth/RGB/depth_450.png', '/content/tmp/traindataset_only_depth/RGB/depth_451.png', '/content/tmp/traindataset_only_depth/RGB/depth_452.png', '/content/tmp/traindataset_only_depth/RGB/depth_460.png', '/content/tmp/traindataset_only_depth/RGB/depth_461.png', '/content/tmp/traindataset_only_depth/RGB/depth_462.png', '/content/tmp/traindataset_only_depth/RGB/depth_470.png', '/content/tmp/traindataset_only_depth/RGB/depth_471.png', '/content/tmp/traindataset_only_depth/RGB/depth_472.png', '/content/tmp/traindataset_only_depth/RGB/depth_480.png', '/content/tmp/traindataset_only_depth/RGB/depth_481.png', '/content/tmp/traindataset_only_depth/RGB/depth_482.png', '/content/tmp/traindataset_only_depth/RGB/depth_490.png', '/content/tmp/traindataset_only_depth/RGB/depth_491.png', '/content/tmp/traindataset_only_depth/RGB/depth_492.png', '/content/tmp/traindataset_only_depth/RGB/depth_50.png', '/content/tmp/traindataset_only_depth/RGB/depth_500.png', '/content/tmp/traindataset_only_depth/RGB/depth_501.png', '/content/tmp/traindataset_only_depth/RGB/depth_502.png', '/content/tmp/traindataset_only_depth/RGB/depth_51.png', '/content/tmp/traindataset_only_depth/RGB/depth_510.png', '/content/tmp/traindataset_only_depth/RGB/depth_511.png', '/content/tmp/traindataset_only_depth/RGB/depth_512.png', '/content/tmp/traindataset_only_depth/RGB/depth_52.png', '/content/tmp/traindataset_only_depth/RGB/depth_520.png', '/content/tmp/traindataset_only_depth/RGB/depth_521.png', '/content/tmp/traindataset_only_depth/RGB/depth_522.png', '/content/tmp/traindataset_only_depth/RGB/depth_530.png', '/content/tmp/traindataset_only_depth/RGB/depth_531.png', '/content/tmp/traindataset_only_depth/RGB/depth_532.png', '/content/tmp/traindataset_only_depth/RGB/depth_540.png', '/content/tmp/traindataset_only_depth/RGB/depth_541.png', '/content/tmp/traindataset_only_depth/RGB/depth_542.png', '/content/tmp/traindataset_only_depth/RGB/depth_550.png', '/content/tmp/traindataset_only_depth/RGB/depth_551.png', '/content/tmp/traindataset_only_depth/RGB/depth_552.png', '/content/tmp/traindataset_only_depth/RGB/depth_560.png', '/content/tmp/traindataset_only_depth/RGB/depth_561.png', '/content/tmp/traindataset_only_depth/RGB/depth_562.png', '/content/tmp/traindataset_only_depth/RGB/depth_570.png', '/content/tmp/traindataset_only_depth/RGB/depth_571.png', '/content/tmp/traindataset_only_depth/RGB/depth_572.png', '/content/tmp/traindataset_only_depth/RGB/depth_580.png', '/content/tmp/traindataset_only_depth/RGB/depth_581.png', '/content/tmp/traindataset_only_depth/RGB/depth_582.png', '/content/tmp/traindataset_only_depth/RGB/depth_590.png', '/content/tmp/traindataset_only_depth/RGB/depth_591.png', '/content/tmp/traindataset_only_depth/RGB/depth_592.png', '/content/tmp/traindataset_only_depth/RGB/depth_60.png', '/content/tmp/traindataset_only_depth/RGB/depth_600.png', '/content/tmp/traindataset_only_depth/RGB/depth_601.png', '/content/tmp/traindataset_only_depth/RGB/depth_602.png', '/content/tmp/traindataset_only_depth/RGB/depth_61.png', '/content/tmp/traindataset_only_depth/RGB/depth_610.png', '/content/tmp/traindataset_only_depth/RGB/depth_611.png', '/content/tmp/traindataset_only_depth/RGB/depth_612.png', '/content/tmp/traindataset_only_depth/RGB/depth_62.png', '/content/tmp/traindataset_only_depth/RGB/depth_620.png', '/content/tmp/traindataset_only_depth/RGB/depth_621.png', '/content/tmp/traindataset_only_depth/RGB/depth_622.png', '/content/tmp/traindataset_only_depth/RGB/depth_630.png', '/content/tmp/traindataset_only_depth/RGB/depth_631.png', '/content/tmp/traindataset_only_depth/RGB/depth_632.png', '/content/tmp/traindataset_only_depth/RGB/depth_640.png', '/content/tmp/traindataset_only_depth/RGB/depth_641.png', '/content/tmp/traindataset_only_depth/RGB/depth_642.png', '/content/tmp/traindataset_only_depth/RGB/depth_650.png', '/content/tmp/traindataset_only_depth/RGB/depth_651.png', '/content/tmp/traindataset_only_depth/RGB/depth_652.png', '/content/tmp/traindataset_only_depth/RGB/depth_660.png', '/content/tmp/traindataset_only_depth/RGB/depth_661.png', '/content/tmp/traindataset_only_depth/RGB/depth_662.png', '/content/tmp/traindataset_only_depth/RGB/depth_670.png', '/content/tmp/traindataset_only_depth/RGB/depth_671.png', '/content/tmp/traindataset_only_depth/RGB/depth_672.png', '/content/tmp/traindataset_only_depth/RGB/depth_680.png', '/content/tmp/traindataset_only_depth/RGB/depth_681.png', '/content/tmp/traindataset_only_depth/RGB/depth_682.png', '/content/tmp/traindataset_only_depth/RGB/depth_690.png', '/content/tmp/traindataset_only_depth/RGB/depth_691.png', '/content/tmp/traindataset_only_depth/RGB/depth_692.png', '/content/tmp/traindataset_only_depth/RGB/depth_70.png', '/content/tmp/traindataset_only_depth/RGB/depth_700.png', '/content/tmp/traindataset_only_depth/RGB/depth_701.png', '/content/tmp/traindataset_only_depth/RGB/depth_702.png', '/content/tmp/traindataset_only_depth/RGB/depth_71.png', '/content/tmp/traindataset_only_depth/RGB/depth_710.png', '/content/tmp/traindataset_only_depth/RGB/depth_711.png', '/content/tmp/traindataset_only_depth/RGB/depth_712.png', '/content/tmp/traindataset_only_depth/RGB/depth_72.png', '/content/tmp/traindataset_only_depth/RGB/depth_720.png', '/content/tmp/traindataset_only_depth/RGB/depth_721.png', '/content/tmp/traindataset_only_depth/RGB/depth_722.png', '/content/tmp/traindataset_only_depth/RGB/depth_730.png', '/content/tmp/traindataset_only_depth/RGB/depth_731.png', '/content/tmp/traindataset_only_depth/RGB/depth_732.png', '/content/tmp/traindataset_only_depth/RGB/depth_740.png', '/content/tmp/traindataset_only_depth/RGB/depth_741.png', '/content/tmp/traindataset_only_depth/RGB/depth_742.png', '/content/tmp/traindataset_only_depth/RGB/depth_750.png', '/content/tmp/traindataset_only_depth/RGB/depth_751.png', '/content/tmp/traindataset_only_depth/RGB/depth_752.png', '/content/tmp/traindataset_only_depth/RGB/depth_760.png', '/content/tmp/traindataset_only_depth/RGB/depth_761.png', '/content/tmp/traindataset_only_depth/RGB/depth_762.png', '/content/tmp/traindataset_only_depth/RGB/depth_770.png', '/content/tmp/traindataset_only_depth/RGB/depth_771.png', '/content/tmp/traindataset_only_depth/RGB/depth_772.png', '/content/tmp/traindataset_only_depth/RGB/depth_780.png', '/content/tmp/traindataset_only_depth/RGB/depth_781.png', '/content/tmp/traindataset_only_depth/RGB/depth_782.png', '/content/tmp/traindataset_only_depth/RGB/depth_790.png', '/content/tmp/traindataset_only_depth/RGB/depth_791.png', '/content/tmp/traindataset_only_depth/RGB/depth_792.png', '/content/tmp/traindataset_only_depth/RGB/depth_80.png', '/content/tmp/traindataset_only_depth/RGB/depth_81.png', '/content/tmp/traindataset_only_depth/RGB/depth_82.png', '/content/tmp/traindataset_only_depth/RGB/depth_90.png', '/content/tmp/traindataset_only_depth/RGB/depth_91.png', '/content/tmp/traindataset_only_depth/RGB/depth_92.png'] ['/content/tmp/traindataset_only_depth/GT/GT_00.png', '/content/tmp/traindataset_only_depth/GT/GT_01.png', '/content/tmp/traindataset_only_depth/GT/GT_02.png', '/content/tmp/traindataset_only_depth/GT/GT_10.png', '/content/tmp/traindataset_only_depth/GT/GT_100.png', '/content/tmp/traindataset_only_depth/GT/GT_101.png', '/content/tmp/traindataset_only_depth/GT/GT_102.png', '/content/tmp/traindataset_only_depth/GT/GT_11.png', '/content/tmp/traindataset_only_depth/GT/GT_110.png', '/content/tmp/traindataset_only_depth/GT/GT_111.png', '/content/tmp/traindataset_only_depth/GT/GT_112.png', '/content/tmp/traindataset_only_depth/GT/GT_12.png', '/content/tmp/traindataset_only_depth/GT/GT_120.png', '/content/tmp/traindataset_only_depth/GT/GT_121.png', '/content/tmp/traindataset_only_depth/GT/GT_122.png', '/content/tmp/traindataset_only_depth/GT/GT_130.png', '/content/tmp/traindataset_only_depth/GT/GT_131.png', '/content/tmp/traindataset_only_depth/GT/GT_132.png', '/content/tmp/traindataset_only_depth/GT/GT_140.png', '/content/tmp/traindataset_only_depth/GT/GT_141.png', '/content/tmp/traindataset_only_depth/GT/GT_142.png', '/content/tmp/traindataset_only_depth/GT/GT_150.png', '/content/tmp/traindataset_only_depth/GT/GT_151.png', '/content/tmp/traindataset_only_depth/GT/GT_152.png', '/content/tmp/traindataset_only_depth/GT/GT_160.png', '/content/tmp/traindataset_only_depth/GT/GT_161.png', '/content/tmp/traindataset_only_depth/GT/GT_162.png', '/content/tmp/traindataset_only_depth/GT/GT_170.png', '/content/tmp/traindataset_only_depth/GT/GT_171.png', '/content/tmp/traindataset_only_depth/GT/GT_172.png', '/content/tmp/traindataset_only_depth/GT/GT_180.png', '/content/tmp/traindataset_only_depth/GT/GT_181.png', '/content/tmp/traindataset_only_depth/GT/GT_182.png', '/content/tmp/traindataset_only_depth/GT/GT_190.png', '/content/tmp/traindataset_only_depth/GT/GT_191.png', '/content/tmp/traindataset_only_depth/GT/GT_192.png', '/content/tmp/traindataset_only_depth/GT/GT_20.png', '/content/tmp/traindataset_only_depth/GT/GT_200.png', '/content/tmp/traindataset_only_depth/GT/GT_201.png', '/content/tmp/traindataset_only_depth/GT/GT_202.png', '/content/tmp/traindataset_only_depth/GT/GT_21.png', '/content/tmp/traindataset_only_depth/GT/GT_210.png', '/content/tmp/traindataset_only_depth/GT/GT_211.png', '/content/tmp/traindataset_only_depth/GT/GT_212.png', '/content/tmp/traindataset_only_depth/GT/GT_22.png', '/content/tmp/traindataset_only_depth/GT/GT_220.png', '/content/tmp/traindataset_only_depth/GT/GT_221.png', '/content/tmp/traindataset_only_depth/GT/GT_222.png', '/content/tmp/traindataset_only_depth/GT/GT_230.png', '/content/tmp/traindataset_only_depth/GT/GT_231.png', '/content/tmp/traindataset_only_depth/GT/GT_232.png', '/content/tmp/traindataset_only_depth/GT/GT_240.png', '/content/tmp/traindataset_only_depth/GT/GT_241.png', '/content/tmp/traindataset_only_depth/GT/GT_242.png', '/content/tmp/traindataset_only_depth/GT/GT_250.png', '/content/tmp/traindataset_only_depth/GT/GT_251.png', '/content/tmp/traindataset_only_depth/GT/GT_252.png', '/content/tmp/traindataset_only_depth/GT/GT_260.png', '/content/tmp/traindataset_only_depth/GT/GT_261.png', '/content/tmp/traindataset_only_depth/GT/GT_262.png', '/content/tmp/traindataset_only_depth/GT/GT_270.png', '/content/tmp/traindataset_only_depth/GT/GT_271.png', '/content/tmp/traindataset_only_depth/GT/GT_272.png', '/content/tmp/traindataset_only_depth/GT/GT_280.png', '/content/tmp/traindataset_only_depth/GT/GT_281.png', '/content/tmp/traindataset_only_depth/GT/GT_282.png', '/content/tmp/traindataset_only_depth/GT/GT_290.png', '/content/tmp/traindataset_only_depth/GT/GT_291.png', '/content/tmp/traindataset_only_depth/GT/GT_292.png', '/content/tmp/traindataset_only_depth/GT/GT_30.png', '/content/tmp/traindataset_only_depth/GT/GT_300.png', '/content/tmp/traindataset_only_depth/GT/GT_301.png', '/content/tmp/traindataset_only_depth/GT/GT_302.png', '/content/tmp/traindataset_only_depth/GT/GT_31.png', '/content/tmp/traindataset_only_depth/GT/GT_310.png', '/content/tmp/traindataset_only_depth/GT/GT_311.png', '/content/tmp/traindataset_only_depth/GT/GT_312.png', '/content/tmp/traindataset_only_depth/GT/GT_32.png', '/content/tmp/traindataset_only_depth/GT/GT_320.png', '/content/tmp/traindataset_only_depth/GT/GT_321.png', '/content/tmp/traindataset_only_depth/GT/GT_322.png', '/content/tmp/traindataset_only_depth/GT/GT_330.png', '/content/tmp/traindataset_only_depth/GT/GT_331.png', '/content/tmp/traindataset_only_depth/GT/GT_332.png', '/content/tmp/traindataset_only_depth/GT/GT_340.png', '/content/tmp/traindataset_only_depth/GT/GT_341.png', '/content/tmp/traindataset_only_depth/GT/GT_342.png', '/content/tmp/traindataset_only_depth/GT/GT_350.png', '/content/tmp/traindataset_only_depth/GT/GT_351.png', '/content/tmp/traindataset_only_depth/GT/GT_352.png', '/content/tmp/traindataset_only_depth/GT/GT_360.png', '/content/tmp/traindataset_only_depth/GT/GT_361.png', '/content/tmp/traindataset_only_depth/GT/GT_362.png', '/content/tmp/traindataset_only_depth/GT/GT_370.png', '/content/tmp/traindataset_only_depth/GT/GT_371.png', '/content/tmp/traindataset_only_depth/GT/GT_372.png', '/content/tmp/traindataset_only_depth/GT/GT_380.png', '/content/tmp/traindataset_only_depth/GT/GT_381.png', '/content/tmp/traindataset_only_depth/GT/GT_382.png', '/content/tmp/traindataset_only_depth/GT/GT_390.png', '/content/tmp/traindataset_only_depth/GT/GT_391.png', '/content/tmp/traindataset_only_depth/GT/GT_392.png', '/content/tmp/traindataset_only_depth/GT/GT_40.png', '/content/tmp/traindataset_only_depth/GT/GT_400.png', '/content/tmp/traindataset_only_depth/GT/GT_401.png', '/content/tmp/traindataset_only_depth/GT/GT_402.png', '/content/tmp/traindataset_only_depth/GT/GT_41.png', '/content/tmp/traindataset_only_depth/GT/GT_410.png', '/content/tmp/traindataset_only_depth/GT/GT_411.png', '/content/tmp/traindataset_only_depth/GT/GT_412.png', '/content/tmp/traindataset_only_depth/GT/GT_42.png', '/content/tmp/traindataset_only_depth/GT/GT_420.png', '/content/tmp/traindataset_only_depth/GT/GT_421.png', '/content/tmp/traindataset_only_depth/GT/GT_422.png', '/content/tmp/traindataset_only_depth/GT/GT_430.png', '/content/tmp/traindataset_only_depth/GT/GT_431.png', '/content/tmp/traindataset_only_depth/GT/GT_432.png', '/content/tmp/traindataset_only_depth/GT/GT_440.png', '/content/tmp/traindataset_only_depth/GT/GT_441.png', '/content/tmp/traindataset_only_depth/GT/GT_442.png', '/content/tmp/traindataset_only_depth/GT/GT_450.png', '/content/tmp/traindataset_only_depth/GT/GT_451.png', '/content/tmp/traindataset_only_depth/GT/GT_452.png', '/content/tmp/traindataset_only_depth/GT/GT_460.png', '/content/tmp/traindataset_only_depth/GT/GT_461.png', '/content/tmp/traindataset_only_depth/GT/GT_462.png', '/content/tmp/traindataset_only_depth/GT/GT_470.png', '/content/tmp/traindataset_only_depth/GT/GT_471.png', '/content/tmp/traindataset_only_depth/GT/GT_472.png', '/content/tmp/traindataset_only_depth/GT/GT_480.png', '/content/tmp/traindataset_only_depth/GT/GT_481.png', '/content/tmp/traindataset_only_depth/GT/GT_482.png', '/content/tmp/traindataset_only_depth/GT/GT_490.png', '/content/tmp/traindataset_only_depth/GT/GT_491.png', '/content/tmp/traindataset_only_depth/GT/GT_492.png', '/content/tmp/traindataset_only_depth/GT/GT_50.png', '/content/tmp/traindataset_only_depth/GT/GT_500.png', '/content/tmp/traindataset_only_depth/GT/GT_501.png', '/content/tmp/traindataset_only_depth/GT/GT_502.png', '/content/tmp/traindataset_only_depth/GT/GT_51.png', '/content/tmp/traindataset_only_depth/GT/GT_510.png', '/content/tmp/traindataset_only_depth/GT/GT_511.png', '/content/tmp/traindataset_only_depth/GT/GT_512.png', '/content/tmp/traindataset_only_depth/GT/GT_52.png', '/content/tmp/traindataset_only_depth/GT/GT_520.png', '/content/tmp/traindataset_only_depth/GT/GT_521.png', '/content/tmp/traindataset_only_depth/GT/GT_522.png', '/content/tmp/traindataset_only_depth/GT/GT_530.png', '/content/tmp/traindataset_only_depth/GT/GT_531.png', '/content/tmp/traindataset_only_depth/GT/GT_532.png', '/content/tmp/traindataset_only_depth/GT/GT_540.png', '/content/tmp/traindataset_only_depth/GT/GT_541.png', '/content/tmp/traindataset_only_depth/GT/GT_542.png', '/content/tmp/traindataset_only_depth/GT/GT_550.png', '/content/tmp/traindataset_only_depth/GT/GT_551.png', '/content/tmp/traindataset_only_depth/GT/GT_552.png', '/content/tmp/traindataset_only_depth/GT/GT_560.png', '/content/tmp/traindataset_only_depth/GT/GT_561.png', '/content/tmp/traindataset_only_depth/GT/GT_562.png', '/content/tmp/traindataset_only_depth/GT/GT_570.png', '/content/tmp/traindataset_only_depth/GT/GT_571.png', '/content/tmp/traindataset_only_depth/GT/GT_572.png', '/content/tmp/traindataset_only_depth/GT/GT_580.png', '/content/tmp/traindataset_only_depth/GT/GT_581.png', '/content/tmp/traindataset_only_depth/GT/GT_582.png', '/content/tmp/traindataset_only_depth/GT/GT_590.png', '/content/tmp/traindataset_only_depth/GT/GT_591.png', '/content/tmp/traindataset_only_depth/GT/GT_592.png', '/content/tmp/traindataset_only_depth/GT/GT_60.png', '/content/tmp/traindataset_only_depth/GT/GT_600.png', '/content/tmp/traindataset_only_depth/GT/GT_601.png', '/content/tmp/traindataset_only_depth/GT/GT_602.png', '/content/tmp/traindataset_only_depth/GT/GT_61.png', '/content/tmp/traindataset_only_depth/GT/GT_610.png', '/content/tmp/traindataset_only_depth/GT/GT_611.png', '/content/tmp/traindataset_only_depth/GT/GT_612.png', '/content/tmp/traindataset_only_depth/GT/GT_62.png', '/content/tmp/traindataset_only_depth/GT/GT_620.png', '/content/tmp/traindataset_only_depth/GT/GT_621.png', '/content/tmp/traindataset_only_depth/GT/GT_622.png', '/content/tmp/traindataset_only_depth/GT/GT_630.png', '/content/tmp/traindataset_only_depth/GT/GT_631.png', '/content/tmp/traindataset_only_depth/GT/GT_632.png', '/content/tmp/traindataset_only_depth/GT/GT_640.png', '/content/tmp/traindataset_only_depth/GT/GT_641.png', '/content/tmp/traindataset_only_depth/GT/GT_642.png', '/content/tmp/traindataset_only_depth/GT/GT_650.png', '/content/tmp/traindataset_only_depth/GT/GT_651.png', '/content/tmp/traindataset_only_depth/GT/GT_652.png', '/content/tmp/traindataset_only_depth/GT/GT_660.png', '/content/tmp/traindataset_only_depth/GT/GT_661.png', '/content/tmp/traindataset_only_depth/GT/GT_662.png', '/content/tmp/traindataset_only_depth/GT/GT_670.png', '/content/tmp/traindataset_only_depth/GT/GT_671.png', '/content/tmp/traindataset_only_depth/GT/GT_672.png', '/content/tmp/traindataset_only_depth/GT/GT_680.png', '/content/tmp/traindataset_only_depth/GT/GT_681.png', '/content/tmp/traindataset_only_depth/GT/GT_682.png', '/content/tmp/traindataset_only_depth/GT/GT_690.png', '/content/tmp/traindataset_only_depth/GT/GT_691.png', '/content/tmp/traindataset_only_depth/GT/GT_692.png', '/content/tmp/traindataset_only_depth/GT/GT_70.png', '/content/tmp/traindataset_only_depth/GT/GT_700.png', '/content/tmp/traindataset_only_depth/GT/GT_701.png', '/content/tmp/traindataset_only_depth/GT/GT_702.png', '/content/tmp/traindataset_only_depth/GT/GT_71.png', '/content/tmp/traindataset_only_depth/GT/GT_710.png', '/content/tmp/traindataset_only_depth/GT/GT_711.png', '/content/tmp/traindataset_only_depth/GT/GT_712.png', '/content/tmp/traindataset_only_depth/GT/GT_72.png', '/content/tmp/traindataset_only_depth/GT/GT_720.png', '/content/tmp/traindataset_only_depth/GT/GT_721.png', '/content/tmp/traindataset_only_depth/GT/GT_722.png', '/content/tmp/traindataset_only_depth/GT/GT_730.png', '/content/tmp/traindataset_only_depth/GT/GT_731.png', '/content/tmp/traindataset_only_depth/GT/GT_732.png', '/content/tmp/traindataset_only_depth/GT/GT_740.png', '/content/tmp/traindataset_only_depth/GT/GT_741.png', '/content/tmp/traindataset_only_depth/GT/GT_742.png', '/content/tmp/traindataset_only_depth/GT/GT_750.png', '/content/tmp/traindataset_only_depth/GT/GT_751.png', '/content/tmp/traindataset_only_depth/GT/GT_752.png', '/content/tmp/traindataset_only_depth/GT/GT_760.png', '/content/tmp/traindataset_only_depth/GT/GT_761.png', '/content/tmp/traindataset_only_depth/GT/GT_762.png', '/content/tmp/traindataset_only_depth/GT/GT_770.png', '/content/tmp/traindataset_only_depth/GT/GT_771.png', '/content/tmp/traindataset_only_depth/GT/GT_772.png', '/content/tmp/traindataset_only_depth/GT/GT_780.png', '/content/tmp/traindataset_only_depth/GT/GT_781.png', '/content/tmp/traindataset_only_depth/GT/GT_782.png', '/content/tmp/traindataset_only_depth/GT/GT_790.png', '/content/tmp/traindataset_only_depth/GT/GT_791.png', '/content/tmp/traindataset_only_depth/GT/GT_792.png', '/content/tmp/traindataset_only_depth/GT/GT_80.png', '/content/tmp/traindataset_only_depth/GT/GT_81.png', '/content/tmp/traindataset_only_depth/GT/GT_82.png', '/content/tmp/traindataset_only_depth/GT/GT_90.png', '/content/tmp/traindataset_only_depth/GT/GT_91.png', '/content/tmp/traindataset_only_depth/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7fd7c099c350>\n",
            "Start train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-08-02 15:54:29.903766 Epoch [001/250], Step [0001/0060], Loss1: -0.0296 Loss2: 0.1592 Loss3: -0.1349\n",
            "2022-08-02 15:54:58.769417 Epoch [001/250], Step [0050/0060], Loss1: -0.9035 Loss2: -0.8832 Loss3: -0.9006\n",
            "2022-08-02 15:55:04.653441 Epoch [001/250], Step [0060/0060], Loss1: -0.9302 Loss2: -0.9152 Loss3: -0.9310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 MAE: 58.9378226155079 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-08-02 15:55:12.503193 Epoch [002/250], Step [0001/0060], Loss1: -0.9135 Loss2: -0.8958 Loss3: -0.9154\n",
            "2022-08-02 15:55:41.592904 Epoch [002/250], Step [0050/0060], Loss1: -0.8645 Loss2: -0.8738 Loss3: -0.9415\n",
            "2022-08-02 15:55:47.489903 Epoch [002/250], Step [0060/0060], Loss1: -0.9499 Loss2: -0.9443 Loss3: -0.9586\n",
            "Epoch: 2 MAE: 58.78397990760697 ####  bestMAE: 58.9378226155079 bestEpoch: 0\n",
            "best epoch:2\n",
            "2022-08-02 15:55:57.708507 Epoch [003/250], Step [0001/0060], Loss1: -0.9231 Loss2: -0.9253 Loss3: -0.9495\n",
            "2022-08-02 15:56:27.173502 Epoch [003/250], Step [0050/0060], Loss1: -0.9419 Loss2: -0.9537 Loss3: -0.9679\n",
            "2022-08-02 15:56:33.104038 Epoch [003/250], Step [0060/0060], Loss1: -0.9601 Loss2: -0.9585 Loss3: -0.9651\n",
            "Epoch: 3 MAE: 58.842672602020365 ####  bestMAE: 58.78397990760697 bestEpoch: 2\n",
            "2022-08-02 15:56:40.978144 Epoch [004/250], Step [0001/0060], Loss1: -0.9630 Loss2: -0.9566 Loss3: -0.9730\n",
            "2022-08-02 15:57:09.838331 Epoch [004/250], Step [0050/0060], Loss1: -0.9150 Loss2: -0.9100 Loss3: -0.9412\n",
            "2022-08-02 15:57:15.711837 Epoch [004/250], Step [0060/0060], Loss1: -0.9019 Loss2: -0.9155 Loss3: -0.9605\n",
            "Epoch: 4 MAE: 58.55281501428835 ####  bestMAE: 58.78397990760697 bestEpoch: 2\n",
            "best epoch:4\n",
            "2022-08-02 15:57:25.936197 Epoch [005/250], Step [0001/0060], Loss1: -0.9698 Loss2: -0.9597 Loss3: -0.9783\n",
            "2022-08-02 15:57:55.515512 Epoch [005/250], Step [0050/0060], Loss1: -0.9582 Loss2: -0.9541 Loss3: -0.9677\n",
            "2022-08-02 15:58:01.376836 Epoch [005/250], Step [0060/0060], Loss1: -0.9649 Loss2: -0.9609 Loss3: -0.9803\n",
            "Epoch: 5 MAE: 58.5904784420819 ####  bestMAE: 58.55281501428835 bestEpoch: 4\n",
            "2022-08-02 15:58:11.632802 Epoch [006/250], Step [0001/0060], Loss1: -0.9575 Loss2: -0.9497 Loss3: -0.9722\n",
            "2022-08-02 15:58:40.932240 Epoch [006/250], Step [0050/0060], Loss1: -0.9708 Loss2: -0.9692 Loss3: -0.9834\n",
            "2022-08-02 15:58:46.771871 Epoch [006/250], Step [0060/0060], Loss1: -0.9731 Loss2: -0.9650 Loss3: -0.9804\n",
            "Epoch: 6 MAE: 58.52803206753843 ####  bestMAE: 58.55281501428835 bestEpoch: 4\n",
            "best epoch:6\n",
            "2022-08-02 15:58:57.151671 Epoch [007/250], Step [0001/0060], Loss1: -0.9643 Loss2: -0.9559 Loss3: -0.9793\n",
            "2022-08-02 15:59:26.836748 Epoch [007/250], Step [0050/0060], Loss1: -0.9696 Loss2: -0.9662 Loss3: -0.9839\n",
            "2022-08-02 15:59:32.724614 Epoch [007/250], Step [0060/0060], Loss1: -0.9643 Loss2: -0.9641 Loss3: -0.9817\n",
            "Epoch: 7 MAE: 58.661175920035966 ####  bestMAE: 58.52803206753843 bestEpoch: 6\n",
            "2022-08-02 15:59:40.600650 Epoch [008/250], Step [0001/0060], Loss1: -0.9704 Loss2: -0.9722 Loss3: -0.9832\n",
            "2022-08-02 16:00:09.549752 Epoch [008/250], Step [0050/0060], Loss1: -0.9598 Loss2: -0.9545 Loss3: -0.9716\n",
            "2022-08-02 16:00:15.389188 Epoch [008/250], Step [0060/0060], Loss1: -0.9722 Loss2: -0.9679 Loss3: -0.9783\n",
            "Epoch: 8 MAE: 58.56155015885723 ####  bestMAE: 58.52803206753843 bestEpoch: 6\n",
            "2022-08-02 16:00:23.282469 Epoch [009/250], Step [0001/0060], Loss1: -0.9756 Loss2: -0.9687 Loss3: -0.9838\n",
            "2022-08-02 16:00:52.094500 Epoch [009/250], Step [0050/0060], Loss1: -0.9757 Loss2: -0.9726 Loss3: -0.9862\n",
            "2022-08-02 16:00:57.963880 Epoch [009/250], Step [0060/0060], Loss1: -0.9786 Loss2: -0.9747 Loss3: -0.9874\n",
            "Epoch: 9 MAE: 58.45958674671183 ####  bestMAE: 58.52803206753843 bestEpoch: 6\n",
            "best epoch:9\n",
            "2022-08-02 16:01:08.361467 Epoch [010/250], Step [0001/0060], Loss1: -0.9759 Loss2: -0.9696 Loss3: -0.9863\n",
            "2022-08-02 16:01:37.544970 Epoch [010/250], Step [0050/0060], Loss1: -0.9792 Loss2: -0.9736 Loss3: -0.9865\n",
            "2022-08-02 16:01:43.344056 Epoch [010/250], Step [0060/0060], Loss1: -0.9779 Loss2: -0.9683 Loss3: -0.9816\n",
            "Epoch: 10 MAE: 58.60718887759798 ####  bestMAE: 58.45958674671183 bestEpoch: 9\n",
            "2022-08-02 16:01:53.648800 Epoch [011/250], Step [0001/0060], Loss1: -0.9694 Loss2: -0.9668 Loss3: -0.9828\n",
            "2022-08-02 16:02:23.048736 Epoch [011/250], Step [0050/0060], Loss1: -0.9799 Loss2: -0.9731 Loss3: -0.9816\n",
            "2022-08-02 16:02:28.882265 Epoch [011/250], Step [0060/0060], Loss1: -0.9762 Loss2: -0.9724 Loss3: -0.9845\n",
            "Epoch: 11 MAE: 58.56047167452516 ####  bestMAE: 58.45958674671183 bestEpoch: 9\n",
            "2022-08-02 16:02:36.770532 Epoch [012/250], Step [0001/0060], Loss1: -0.9766 Loss2: -0.9676 Loss3: -0.9826\n",
            "2022-08-02 16:03:05.737261 Epoch [012/250], Step [0050/0060], Loss1: -0.9726 Loss2: -0.9682 Loss3: -0.9820\n",
            "2022-08-02 16:03:11.656691 Epoch [012/250], Step [0060/0060], Loss1: -0.9817 Loss2: -0.9749 Loss3: -0.9874\n",
            "Epoch: 12 MAE: 58.503528120268264 ####  bestMAE: 58.45958674671183 bestEpoch: 9\n",
            "2022-08-02 16:03:19.605591 Epoch [013/250], Step [0001/0060], Loss1: -0.9751 Loss2: -0.9679 Loss3: -0.9828\n",
            "2022-08-02 16:03:48.585933 Epoch [013/250], Step [0050/0060], Loss1: -0.9370 Loss2: -0.9323 Loss3: -0.9637\n",
            "2022-08-02 16:03:54.496013 Epoch [013/250], Step [0060/0060], Loss1: -0.9832 Loss2: -0.9775 Loss3: -0.9890\n",
            "Epoch: 13 MAE: 58.5903246348985 ####  bestMAE: 58.45958674671183 bestEpoch: 9\n",
            "2022-08-02 16:04:02.359002 Epoch [014/250], Step [0001/0060], Loss1: -0.9820 Loss2: -0.9787 Loss3: -0.9876\n",
            "2022-08-02 16:04:31.238286 Epoch [014/250], Step [0050/0060], Loss1: -0.9816 Loss2: -0.9768 Loss3: -0.9870\n",
            "2022-08-02 16:04:37.085678 Epoch [014/250], Step [0060/0060], Loss1: -0.9756 Loss2: -0.9670 Loss3: -0.9830\n",
            "Epoch: 14 MAE: 58.41849503371211 ####  bestMAE: 58.45958674671183 bestEpoch: 9\n",
            "best epoch:14\n",
            "2022-08-02 16:04:47.361036 Epoch [015/250], Step [0001/0060], Loss1: -0.9796 Loss2: -0.9745 Loss3: -0.9870\n",
            "2022-08-02 16:05:16.515607 Epoch [015/250], Step [0050/0060], Loss1: -0.9796 Loss2: -0.9779 Loss3: -0.9868\n",
            "2022-08-02 16:05:22.374259 Epoch [015/250], Step [0060/0060], Loss1: -0.9822 Loss2: -0.9723 Loss3: -0.9869\n",
            "Epoch: 15 MAE: 58.61552340700933 ####  bestMAE: 58.41849503371211 bestEpoch: 14\n",
            "2022-08-02 16:05:32.629729 Epoch [016/250], Step [0001/0060], Loss1: -0.9818 Loss2: -0.9749 Loss3: -0.9878\n",
            "2022-08-02 16:06:02.302612 Epoch [016/250], Step [0050/0060], Loss1: -0.9744 Loss2: -0.9645 Loss3: -0.9852\n",
            "2022-08-02 16:06:08.144343 Epoch [016/250], Step [0060/0060], Loss1: -0.9775 Loss2: -0.9713 Loss3: -0.9852\n",
            "Epoch: 16 MAE: 58.39224077658128 ####  bestMAE: 58.41849503371211 bestEpoch: 14\n",
            "best epoch:16\n",
            "2022-08-02 16:06:18.714266 Epoch [017/250], Step [0001/0060], Loss1: -0.9769 Loss2: -0.9749 Loss3: -0.9864\n",
            "2022-08-02 16:06:47.889521 Epoch [017/250], Step [0050/0060], Loss1: -0.9833 Loss2: -0.9750 Loss3: -0.9868\n",
            "2022-08-02 16:06:53.710914 Epoch [017/250], Step [0060/0060], Loss1: -0.9829 Loss2: -0.9793 Loss3: -0.9886\n",
            "Epoch: 17 MAE: 58.58394413746717 ####  bestMAE: 58.39224077658128 bestEpoch: 16\n",
            "2022-08-02 16:07:01.576925 Epoch [018/250], Step [0001/0060], Loss1: -0.9779 Loss2: -0.9702 Loss3: -0.9853\n",
            "2022-08-02 16:07:30.533532 Epoch [018/250], Step [0050/0060], Loss1: -0.9824 Loss2: -0.9755 Loss3: -0.9865\n",
            "2022-08-02 16:07:36.442807 Epoch [018/250], Step [0060/0060], Loss1: -0.9844 Loss2: -0.9770 Loss3: -0.9893\n",
            "Epoch: 18 MAE: 58.59654345350191 ####  bestMAE: 58.39224077658128 bestEpoch: 16\n",
            "2022-08-02 16:07:44.411119 Epoch [019/250], Step [0001/0060], Loss1: -0.9802 Loss2: -0.9727 Loss3: -0.9855\n",
            "2022-08-02 16:08:13.220565 Epoch [019/250], Step [0050/0060], Loss1: -0.9812 Loss2: -0.9760 Loss3: -0.9869\n",
            "2022-08-02 16:08:19.191646 Epoch [019/250], Step [0060/0060], Loss1: -0.9836 Loss2: -0.9705 Loss3: -0.9880\n",
            "Epoch: 19 MAE: 58.536129719626956 ####  bestMAE: 58.39224077658128 bestEpoch: 16\n",
            "2022-08-02 16:08:27.005364 Epoch [020/250], Step [0001/0060], Loss1: -0.9838 Loss2: -0.9780 Loss3: -0.9881\n",
            "2022-08-02 16:08:55.681667 Epoch [020/250], Step [0050/0060], Loss1: -0.9827 Loss2: -0.9773 Loss3: -0.9896\n",
            "2022-08-02 16:09:01.529135 Epoch [020/250], Step [0060/0060], Loss1: -0.9826 Loss2: -0.9771 Loss3: -0.9865\n",
            "Epoch: 20 MAE: 58.43356302410552 ####  bestMAE: 58.39224077658128 bestEpoch: 16\n",
            "2022-08-02 16:09:11.971613 Epoch [021/250], Step [0001/0060], Loss1: -0.9823 Loss2: -0.9778 Loss3: -0.9875\n",
            "2022-08-02 16:09:41.403150 Epoch [021/250], Step [0050/0060], Loss1: -0.9857 Loss2: -0.9782 Loss3: -0.9900\n",
            "2022-08-02 16:09:47.224168 Epoch [021/250], Step [0060/0060], Loss1: -0.9789 Loss2: -0.9733 Loss3: -0.9853\n",
            "Epoch: 21 MAE: 58.48293239172825 ####  bestMAE: 58.39224077658128 bestEpoch: 16\n",
            "2022-08-02 16:09:55.093678 Epoch [022/250], Step [0001/0060], Loss1: -0.9851 Loss2: -0.9807 Loss3: -0.9892\n",
            "2022-08-02 16:10:23.941449 Epoch [022/250], Step [0050/0060], Loss1: -0.9838 Loss2: -0.9748 Loss3: -0.9887\n",
            "2022-08-02 16:10:29.754368 Epoch [022/250], Step [0060/0060], Loss1: -0.9854 Loss2: -0.9824 Loss3: -0.9903\n",
            "Epoch: 22 MAE: 58.47168871507257 ####  bestMAE: 58.39224077658128 bestEpoch: 16\n",
            "2022-08-02 16:10:37.534230 Epoch [023/250], Step [0001/0060], Loss1: -0.9851 Loss2: -0.9802 Loss3: -0.9853\n",
            "2022-08-02 16:11:06.064509 Epoch [023/250], Step [0050/0060], Loss1: -0.9828 Loss2: -0.9736 Loss3: -0.9864\n",
            "2022-08-02 16:11:11.832237 Epoch [023/250], Step [0060/0060], Loss1: -0.9854 Loss2: -0.9778 Loss3: -0.9890\n",
            "Epoch: 23 MAE: 58.56993154635427 ####  bestMAE: 58.39224077658128 bestEpoch: 16\n",
            "2022-08-02 16:11:19.715813 Epoch [024/250], Step [0001/0060], Loss1: -0.9812 Loss2: -0.9704 Loss3: -0.9857\n",
            "2022-08-02 16:11:48.448517 Epoch [024/250], Step [0050/0060], Loss1: -0.9844 Loss2: -0.9781 Loss3: -0.9877\n",
            "2022-08-02 16:11:54.301957 Epoch [024/250], Step [0060/0060], Loss1: -0.9857 Loss2: -0.9788 Loss3: -0.9893\n",
            "Epoch: 24 MAE: 58.443318352215115 ####  bestMAE: 58.39224077658128 bestEpoch: 16\n",
            "2022-08-02 16:12:02.042469 Epoch [025/250], Step [0001/0060], Loss1: -0.9851 Loss2: -0.9776 Loss3: -0.9893\n",
            "2022-08-02 16:12:30.786186 Epoch [025/250], Step [0050/0060], Loss1: -0.9840 Loss2: -0.9778 Loss3: -0.9892\n",
            "2022-08-02 16:12:36.645506 Epoch [025/250], Step [0060/0060], Loss1: -0.9807 Loss2: -0.9782 Loss3: -0.9867\n",
            "Epoch: 25 MAE: 58.63106135943173 ####  bestMAE: 58.39224077658128 bestEpoch: 16\n",
            "2022-08-02 16:12:46.914537 Epoch [026/250], Step [0001/0060], Loss1: -0.9868 Loss2: -0.9807 Loss3: -0.9904\n",
            "2022-08-02 16:13:16.200324 Epoch [026/250], Step [0050/0060], Loss1: -0.9858 Loss2: -0.9779 Loss3: -0.9898\n",
            "2022-08-02 16:13:22.053435 Epoch [026/250], Step [0060/0060], Loss1: -0.9865 Loss2: -0.9813 Loss3: -0.9884\n",
            "Epoch: 26 MAE: 58.37233204742816 ####  bestMAE: 58.39224077658128 bestEpoch: 16\n",
            "best epoch:26\n",
            "2022-08-02 16:13:32.313278 Epoch [027/250], Step [0001/0060], Loss1: -0.9850 Loss2: -0.9793 Loss3: -0.9886\n",
            "2022-08-02 16:14:01.999349 Epoch [027/250], Step [0050/0060], Loss1: -0.9852 Loss2: -0.9808 Loss3: -0.9892\n",
            "2022-08-02 16:14:07.965187 Epoch [027/250], Step [0060/0060], Loss1: -0.9839 Loss2: -0.9797 Loss3: -0.9867\n",
            "Epoch: 27 MAE: 58.644482112927534 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:14:15.893904 Epoch [028/250], Step [0001/0060], Loss1: -0.9705 Loss2: -0.9660 Loss3: -0.9774\n",
            "2022-08-02 16:14:44.890917 Epoch [028/250], Step [0050/0060], Loss1: -0.9811 Loss2: -0.9727 Loss3: -0.9862\n",
            "2022-08-02 16:14:50.769806 Epoch [028/250], Step [0060/0060], Loss1: -0.9868 Loss2: -0.9812 Loss3: -0.9900\n",
            "Epoch: 28 MAE: 58.49384794750644 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:14:58.722276 Epoch [029/250], Step [0001/0060], Loss1: -0.9814 Loss2: -0.9707 Loss3: -0.9860\n",
            "2022-08-02 16:15:27.689758 Epoch [029/250], Step [0050/0060], Loss1: -0.9865 Loss2: -0.9812 Loss3: -0.9887\n",
            "2022-08-02 16:15:33.625451 Epoch [029/250], Step [0060/0060], Loss1: -0.9878 Loss2: -0.9833 Loss3: -0.9906\n",
            "Epoch: 29 MAE: 58.6205415716044 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:15:41.475672 Epoch [030/250], Step [0001/0060], Loss1: -0.9826 Loss2: -0.9756 Loss3: -0.9883\n",
            "2022-08-02 16:16:10.285783 Epoch [030/250], Step [0050/0060], Loss1: -0.9882 Loss2: -0.9831 Loss3: -0.9912\n",
            "2022-08-02 16:16:16.121646 Epoch [030/250], Step [0060/0060], Loss1: -0.9868 Loss2: -0.9779 Loss3: -0.9896\n",
            "Epoch: 30 MAE: 58.587497724137705 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:16:26.380278 Epoch [031/250], Step [0001/0060], Loss1: -0.9839 Loss2: -0.9768 Loss3: -0.9880\n",
            "2022-08-02 16:16:55.635236 Epoch [031/250], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9834 Loss3: -0.9911\n",
            "2022-08-02 16:17:01.511375 Epoch [031/250], Step [0060/0060], Loss1: -0.9881 Loss2: -0.9826 Loss3: -0.9908\n",
            "Epoch: 31 MAE: 58.60755879431812 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:17:09.374875 Epoch [032/250], Step [0001/0060], Loss1: -0.9843 Loss2: -0.9792 Loss3: -0.9881\n",
            "2022-08-02 16:17:38.404801 Epoch [032/250], Step [0050/0060], Loss1: -0.9894 Loss2: -0.9827 Loss3: -0.9907\n",
            "2022-08-02 16:17:44.295207 Epoch [032/250], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9818 Loss3: -0.9904\n",
            "Epoch: 32 MAE: 58.5170035950134 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:17:52.126166 Epoch [033/250], Step [0001/0060], Loss1: -0.9861 Loss2: -0.9795 Loss3: -0.9894\n",
            "2022-08-02 16:18:20.796061 Epoch [033/250], Step [0050/0060], Loss1: -0.9837 Loss2: -0.9820 Loss3: -0.9890\n",
            "2022-08-02 16:18:26.612666 Epoch [033/250], Step [0060/0060], Loss1: -0.9848 Loss2: -0.9781 Loss3: -0.9891\n",
            "Epoch: 33 MAE: 58.465152662918285 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:18:34.402075 Epoch [034/250], Step [0001/0060], Loss1: -0.9862 Loss2: -0.9801 Loss3: -0.9895\n",
            "2022-08-02 16:19:03.298934 Epoch [034/250], Step [0050/0060], Loss1: -0.9883 Loss2: -0.9849 Loss3: -0.9912\n",
            "2022-08-02 16:19:09.310486 Epoch [034/250], Step [0060/0060], Loss1: -0.9871 Loss2: -0.9809 Loss3: -0.9897\n",
            "Epoch: 34 MAE: 58.55303066723939 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:19:17.135872 Epoch [035/250], Step [0001/0060], Loss1: -0.9870 Loss2: -0.9803 Loss3: -0.9898\n",
            "2022-08-02 16:19:46.039067 Epoch [035/250], Step [0050/0060], Loss1: -0.9866 Loss2: -0.9801 Loss3: -0.9890\n",
            "2022-08-02 16:19:51.913072 Epoch [035/250], Step [0060/0060], Loss1: -0.9890 Loss2: -0.9823 Loss3: -0.9915\n",
            "Epoch: 35 MAE: 58.427852477105354 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:20:02.453979 Epoch [036/250], Step [0001/0060], Loss1: -0.9869 Loss2: -0.9830 Loss3: -0.9904\n",
            "2022-08-02 16:20:31.742935 Epoch [036/250], Step [0050/0060], Loss1: -0.9863 Loss2: -0.9819 Loss3: -0.9894\n",
            "2022-08-02 16:20:37.560157 Epoch [036/250], Step [0060/0060], Loss1: -0.9859 Loss2: -0.9792 Loss3: -0.9891\n",
            "Epoch: 36 MAE: 58.45039954329292 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:20:45.403643 Epoch [037/250], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9852 Loss3: -0.9915\n",
            "2022-08-02 16:21:14.168898 Epoch [037/250], Step [0050/0060], Loss1: -0.9872 Loss2: -0.9806 Loss3: -0.9903\n",
            "2022-08-02 16:21:20.085075 Epoch [037/250], Step [0060/0060], Loss1: -0.9890 Loss2: -0.9856 Loss3: -0.9915\n",
            "Epoch: 37 MAE: 58.55886372096037 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:21:27.947271 Epoch [038/250], Step [0001/0060], Loss1: -0.9857 Loss2: -0.9814 Loss3: -0.9892\n",
            "2022-08-02 16:21:56.738094 Epoch [038/250], Step [0050/0060], Loss1: -0.9856 Loss2: -0.9790 Loss3: -0.9893\n",
            "2022-08-02 16:22:02.576143 Epoch [038/250], Step [0060/0060], Loss1: -0.9833 Loss2: -0.9783 Loss3: -0.9884\n",
            "Epoch: 38 MAE: 58.651032149357185 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:22:10.434619 Epoch [039/250], Step [0001/0060], Loss1: -0.9882 Loss2: -0.9829 Loss3: -0.9902\n",
            "2022-08-02 16:22:39.436673 Epoch [039/250], Step [0050/0060], Loss1: -0.9836 Loss2: -0.9783 Loss3: -0.9874\n",
            "2022-08-02 16:22:45.254630 Epoch [039/250], Step [0060/0060], Loss1: -0.9883 Loss2: -0.9820 Loss3: -0.9903\n",
            "Epoch: 39 MAE: 58.510257482044516 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:22:53.135485 Epoch [040/250], Step [0001/0060], Loss1: -0.9867 Loss2: -0.9782 Loss3: -0.9897\n",
            "2022-08-02 16:23:21.860975 Epoch [040/250], Step [0050/0060], Loss1: -0.9856 Loss2: -0.9812 Loss3: -0.9899\n",
            "2022-08-02 16:23:27.806649 Epoch [040/250], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9860 Loss3: -0.9920\n",
            "Epoch: 40 MAE: 58.482195572732635 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:23:38.011930 Epoch [041/250], Step [0001/0060], Loss1: -0.9876 Loss2: -0.9823 Loss3: -0.9909\n",
            "2022-08-02 16:24:07.136759 Epoch [041/250], Step [0050/0060], Loss1: -0.9874 Loss2: -0.9785 Loss3: -0.9895\n",
            "2022-08-02 16:24:12.946483 Epoch [041/250], Step [0060/0060], Loss1: -0.9857 Loss2: -0.9814 Loss3: -0.9896\n",
            "Epoch: 41 MAE: 58.43869313893339 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:24:20.943076 Epoch [042/250], Step [0001/0060], Loss1: -0.9881 Loss2: -0.9814 Loss3: -0.9904\n",
            "2022-08-02 16:24:49.795151 Epoch [042/250], Step [0050/0060], Loss1: -0.9871 Loss2: -0.9801 Loss3: -0.9897\n",
            "2022-08-02 16:24:55.632186 Epoch [042/250], Step [0060/0060], Loss1: -0.9837 Loss2: -0.9789 Loss3: -0.9889\n",
            "Epoch: 42 MAE: 58.52476990245249 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:25:03.588052 Epoch [043/250], Step [0001/0060], Loss1: -0.9874 Loss2: -0.9820 Loss3: -0.9895\n",
            "2022-08-02 16:25:32.501221 Epoch [043/250], Step [0050/0060], Loss1: -0.9882 Loss2: -0.9828 Loss3: -0.9913\n",
            "2022-08-02 16:25:38.409046 Epoch [043/250], Step [0060/0060], Loss1: -0.9831 Loss2: -0.9752 Loss3: -0.9870\n",
            "Epoch: 43 MAE: 58.43166982258533 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:25:46.410681 Epoch [044/250], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9825 Loss3: -0.9918\n",
            "2022-08-02 16:26:15.203362 Epoch [044/250], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9834 Loss3: -0.9912\n",
            "2022-08-02 16:26:21.038919 Epoch [044/250], Step [0060/0060], Loss1: -0.9858 Loss2: -0.9808 Loss3: -0.9888\n",
            "Epoch: 44 MAE: 58.544420760547 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:26:28.932912 Epoch [045/250], Step [0001/0060], Loss1: -0.9853 Loss2: -0.9819 Loss3: -0.9885\n",
            "2022-08-02 16:26:57.890107 Epoch [045/250], Step [0050/0060], Loss1: -0.9834 Loss2: -0.9766 Loss3: -0.9869\n",
            "2022-08-02 16:27:03.716661 Epoch [045/250], Step [0060/0060], Loss1: -0.9875 Loss2: -0.9778 Loss3: -0.9901\n",
            "Epoch: 45 MAE: 58.53761238192241 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:27:13.844969 Epoch [046/250], Step [0001/0060], Loss1: -0.9885 Loss2: -0.9837 Loss3: -0.9915\n",
            "2022-08-02 16:27:43.188624 Epoch [046/250], Step [0050/0060], Loss1: -0.9875 Loss2: -0.9818 Loss3: -0.9897\n",
            "2022-08-02 16:27:49.088909 Epoch [046/250], Step [0060/0060], Loss1: -0.9891 Loss2: -0.9829 Loss3: -0.9913\n",
            "Epoch: 46 MAE: 58.59020236228739 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:27:57.180731 Epoch [047/250], Step [0001/0060], Loss1: -0.9892 Loss2: -0.9811 Loss3: -0.9916\n",
            "2022-08-02 16:28:26.140033 Epoch [047/250], Step [0050/0060], Loss1: -0.9866 Loss2: -0.9828 Loss3: -0.9895\n",
            "2022-08-02 16:28:31.991657 Epoch [047/250], Step [0060/0060], Loss1: -0.9886 Loss2: -0.9847 Loss3: -0.9908\n",
            "Epoch: 47 MAE: 58.51098559332761 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:28:39.859790 Epoch [048/250], Step [0001/0060], Loss1: -0.9887 Loss2: -0.9830 Loss3: -0.9908\n",
            "2022-08-02 16:29:08.827858 Epoch [048/250], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9835 Loss3: -0.9916\n",
            "2022-08-02 16:29:14.673443 Epoch [048/250], Step [0060/0060], Loss1: -0.9889 Loss2: -0.9823 Loss3: -0.9916\n",
            "Epoch: 48 MAE: 58.470653353459646 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:29:22.567086 Epoch [049/250], Step [0001/0060], Loss1: -0.9888 Loss2: -0.9828 Loss3: -0.9911\n",
            "2022-08-02 16:29:51.317715 Epoch [049/250], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9827 Loss3: -0.9908\n",
            "2022-08-02 16:29:57.197589 Epoch [049/250], Step [0060/0060], Loss1: -0.9877 Loss2: -0.9830 Loss3: -0.9906\n",
            "Epoch: 49 MAE: 58.458631508862474 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "2022-08-02 16:30:04.969470 Epoch [050/250], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9836 Loss3: -0.9923\n",
            "2022-08-02 16:30:33.930918 Epoch [050/250], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9825 Loss3: -0.9920\n",
            "2022-08-02 16:30:39.749844 Epoch [050/250], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9852 Loss3: -0.9922\n",
            "Epoch: 50 MAE: 58.35975274286445 ####  bestMAE: 58.37233204742816 bestEpoch: 26\n",
            "best epoch:50\n",
            "2022-08-02 16:30:52.646199 Epoch [051/250], Step [0001/0060], Loss1: -0.9887 Loss2: -0.9836 Loss3: -0.9915\n",
            "2022-08-02 16:31:22.081593 Epoch [051/250], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9831 Loss3: -0.9918\n",
            "2022-08-02 16:31:27.930602 Epoch [051/250], Step [0060/0060], Loss1: -0.9887 Loss2: -0.9822 Loss3: -0.9902\n",
            "Epoch: 51 MAE: 58.474816313218746 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:31:35.750105 Epoch [052/250], Step [0001/0060], Loss1: -0.9871 Loss2: -0.9834 Loss3: -0.9902\n",
            "2022-08-02 16:32:04.630883 Epoch [052/250], Step [0050/0060], Loss1: -0.9894 Loss2: -0.9852 Loss3: -0.9913\n",
            "2022-08-02 16:32:10.616330 Epoch [052/250], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9843 Loss3: -0.9918\n",
            "Epoch: 52 MAE: 58.434647563568895 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:32:18.511782 Epoch [053/250], Step [0001/0060], Loss1: -0.9842 Loss2: -0.9766 Loss3: -0.9870\n",
            "2022-08-02 16:32:47.482403 Epoch [053/250], Step [0050/0060], Loss1: -0.9891 Loss2: -0.9837 Loss3: -0.9905\n",
            "2022-08-02 16:32:53.398632 Epoch [053/250], Step [0060/0060], Loss1: -0.9874 Loss2: -0.9833 Loss3: -0.9903\n",
            "Epoch: 53 MAE: 58.48471582013833 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:33:01.279255 Epoch [054/250], Step [0001/0060], Loss1: -0.9832 Loss2: -0.9793 Loss3: -0.9871\n",
            "2022-08-02 16:33:30.080887 Epoch [054/250], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9850 Loss3: -0.9912\n",
            "2022-08-02 16:33:35.932506 Epoch [054/250], Step [0060/0060], Loss1: -0.9898 Loss2: -0.9858 Loss3: -0.9911\n",
            "Epoch: 54 MAE: 58.461299018396986 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:33:43.846668 Epoch [055/250], Step [0001/0060], Loss1: -0.9841 Loss2: -0.9741 Loss3: -0.9869\n",
            "2022-08-02 16:34:12.727930 Epoch [055/250], Step [0050/0060], Loss1: -0.9893 Loss2: -0.9857 Loss3: -0.9913\n",
            "2022-08-02 16:34:18.634598 Epoch [055/250], Step [0060/0060], Loss1: -0.9908 Loss2: -0.9849 Loss3: -0.9927\n",
            "Epoch: 55 MAE: 58.52709464566573 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:34:28.769313 Epoch [056/250], Step [0001/0060], Loss1: -0.9874 Loss2: -0.9784 Loss3: -0.9886\n",
            "2022-08-02 16:34:57.983240 Epoch [056/250], Step [0050/0060], Loss1: -0.9846 Loss2: -0.9785 Loss3: -0.9871\n",
            "2022-08-02 16:35:03.818673 Epoch [056/250], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9860 Loss3: -0.9920\n",
            "Epoch: 56 MAE: 58.477118692741186 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:35:11.665149 Epoch [057/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9851 Loss3: -0.9916\n",
            "2022-08-02 16:35:40.571665 Epoch [057/250], Step [0050/0060], Loss1: -0.9858 Loss2: -0.9807 Loss3: -0.9896\n",
            "2022-08-02 16:35:46.421818 Epoch [057/250], Step [0060/0060], Loss1: -0.9872 Loss2: -0.9806 Loss3: -0.9901\n",
            "Epoch: 57 MAE: 58.47695024530703 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:35:54.174766 Epoch [058/250], Step [0001/0060], Loss1: -0.9837 Loss2: -0.9800 Loss3: -0.9872\n",
            "2022-08-02 16:36:22.960265 Epoch [058/250], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9857 Loss3: -0.9905\n",
            "2022-08-02 16:36:28.921868 Epoch [058/250], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9851 Loss3: -0.9927\n",
            "Epoch: 58 MAE: 58.54801533024111 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:36:36.732793 Epoch [059/250], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9864 Loss3: -0.9917\n",
            "2022-08-02 16:37:05.451320 Epoch [059/250], Step [0050/0060], Loss1: -0.9884 Loss2: -0.9834 Loss3: -0.9902\n",
            "2022-08-02 16:37:11.293309 Epoch [059/250], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9829 Loss3: -0.9909\n",
            "Epoch: 59 MAE: 58.498681603296504 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:37:19.146324 Epoch [060/250], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9859 Loss3: -0.9925\n",
            "2022-08-02 16:37:47.752474 Epoch [060/250], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9861 Loss3: -0.9920\n",
            "2022-08-02 16:37:53.557848 Epoch [060/250], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9866 Loss3: -0.9918\n",
            "Epoch: 60 MAE: 58.43735697088184 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:38:03.631366 Epoch [061/250], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9837 Loss3: -0.9912\n",
            "2022-08-02 16:38:33.255218 Epoch [061/250], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9827 Loss3: -0.9920\n",
            "2022-08-02 16:38:39.100216 Epoch [061/250], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9873 Loss3: -0.9924\n",
            "Epoch: 61 MAE: 58.49914650312965 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:38:46.884935 Epoch [062/250], Step [0001/0060], Loss1: -0.9888 Loss2: -0.9845 Loss3: -0.9908\n",
            "2022-08-02 16:39:15.647065 Epoch [062/250], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9853 Loss3: -0.9914\n",
            "2022-08-02 16:39:21.553819 Epoch [062/250], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9820 Loss3: -0.9901\n",
            "Epoch: 62 MAE: 58.46987051258183 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:39:29.444040 Epoch [063/250], Step [0001/0060], Loss1: -0.9915 Loss2: -0.9856 Loss3: -0.9927\n",
            "2022-08-02 16:39:58.087354 Epoch [063/250], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9833 Loss3: -0.9909\n",
            "2022-08-02 16:40:03.901885 Epoch [063/250], Step [0060/0060], Loss1: -0.9878 Loss2: -0.9809 Loss3: -0.9898\n",
            "Epoch: 63 MAE: 58.50836874816169 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:40:11.689134 Epoch [064/250], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9844 Loss3: -0.9914\n",
            "2022-08-02 16:40:40.435463 Epoch [064/250], Step [0050/0060], Loss1: -0.9918 Loss2: -0.9874 Loss3: -0.9931\n",
            "2022-08-02 16:40:46.235728 Epoch [064/250], Step [0060/0060], Loss1: -0.9876 Loss2: -0.9833 Loss3: -0.9900\n",
            "Epoch: 64 MAE: 58.58352013339297 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:40:54.100439 Epoch [065/250], Step [0001/0060], Loss1: -0.9917 Loss2: -0.9860 Loss3: -0.9930\n",
            "2022-08-02 16:41:22.989679 Epoch [065/250], Step [0050/0060], Loss1: -0.9884 Loss2: -0.9822 Loss3: -0.9902\n",
            "2022-08-02 16:41:28.796686 Epoch [065/250], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9851 Loss3: -0.9926\n",
            "Epoch: 65 MAE: 58.47746598714324 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:41:38.863204 Epoch [066/250], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9832 Loss3: -0.9919\n",
            "2022-08-02 16:42:08.061039 Epoch [066/250], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9846 Loss3: -0.9924\n",
            "2022-08-02 16:42:13.863171 Epoch [066/250], Step [0060/0060], Loss1: -0.9916 Loss2: -0.9868 Loss3: -0.9929\n",
            "Epoch: 66 MAE: 58.5305956905328 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:42:21.679903 Epoch [067/250], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9861 Loss3: -0.9916\n",
            "2022-08-02 16:42:50.352700 Epoch [067/250], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9856 Loss3: -0.9923\n",
            "2022-08-02 16:42:56.191125 Epoch [067/250], Step [0060/0060], Loss1: -0.9885 Loss2: -0.9812 Loss3: -0.9904\n",
            "Epoch: 67 MAE: 58.37694106939909 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:43:04.072455 Epoch [068/250], Step [0001/0060], Loss1: -0.9904 Loss2: -0.9845 Loss3: -0.9923\n",
            "2022-08-02 16:43:32.688531 Epoch [068/250], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9860 Loss3: -0.9917\n",
            "2022-08-02 16:43:38.610703 Epoch [068/250], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9879 Loss3: -0.9930\n",
            "Epoch: 68 MAE: 58.58510940672977 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:43:46.502906 Epoch [069/250], Step [0001/0060], Loss1: -0.9885 Loss2: -0.9829 Loss3: -0.9903\n",
            "2022-08-02 16:44:15.330157 Epoch [069/250], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9844 Loss3: -0.9910\n",
            "2022-08-02 16:44:21.193524 Epoch [069/250], Step [0060/0060], Loss1: -0.9888 Loss2: -0.9819 Loss3: -0.9905\n",
            "Epoch: 69 MAE: 58.454537700209315 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:44:29.088530 Epoch [070/250], Step [0001/0060], Loss1: -0.9880 Loss2: -0.9817 Loss3: -0.9896\n",
            "2022-08-02 16:44:57.595909 Epoch [070/250], Step [0050/0060], Loss1: -0.9875 Loss2: -0.9826 Loss3: -0.9897\n",
            "2022-08-02 16:45:03.476256 Epoch [070/250], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9861 Loss3: -0.9920\n",
            "Epoch: 70 MAE: 58.48656895009848 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:45:13.771044 Epoch [071/250], Step [0001/0060], Loss1: -0.9904 Loss2: -0.9872 Loss3: -0.9919\n",
            "2022-08-02 16:45:43.204606 Epoch [071/250], Step [0050/0060], Loss1: -0.9887 Loss2: -0.9798 Loss3: -0.9907\n",
            "2022-08-02 16:45:49.060308 Epoch [071/250], Step [0060/0060], Loss1: -0.9895 Loss2: -0.9833 Loss3: -0.9909\n",
            "Epoch: 71 MAE: 58.467473313775116 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:45:56.898531 Epoch [072/250], Step [0001/0060], Loss1: -0.9904 Loss2: -0.9864 Loss3: -0.9919\n",
            "2022-08-02 16:46:25.584263 Epoch [072/250], Step [0050/0060], Loss1: -0.9872 Loss2: -0.9790 Loss3: -0.9894\n",
            "2022-08-02 16:46:31.403520 Epoch [072/250], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9866 Loss3: -0.9922\n",
            "Epoch: 72 MAE: 58.58825649182839 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "2022-08-02 16:46:39.316744 Epoch [073/250], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9850 Loss3: -0.9915\n",
            "2022-08-02 16:47:08.026552 Epoch [073/250], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9865 Loss3: -0.9918\n",
            "2022-08-02 16:47:13.852180 Epoch [073/250], Step [0060/0060], Loss1: -0.9873 Loss2: -0.9807 Loss3: -0.9894\n",
            "Epoch: 73 MAE: 58.30933367640438 ####  bestMAE: 58.35975274286445 bestEpoch: 50\n",
            "best epoch:73\n",
            "2022-08-02 16:47:24.079846 Epoch [074/250], Step [0001/0060], Loss1: -0.9875 Loss2: -0.9821 Loss3: -0.9894\n",
            "2022-08-02 16:47:53.344044 Epoch [074/250], Step [0050/0060], Loss1: -0.9853 Loss2: -0.9790 Loss3: -0.9879\n",
            "2022-08-02 16:47:59.207985 Epoch [074/250], Step [0060/0060], Loss1: -0.9877 Loss2: -0.9807 Loss3: -0.9897\n",
            "Epoch: 74 MAE: 58.51188114294042 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 16:48:06.981491 Epoch [075/250], Step [0001/0060], Loss1: -0.9875 Loss2: -0.9790 Loss3: -0.9893\n",
            "2022-08-02 16:48:35.591187 Epoch [075/250], Step [0050/0060], Loss1: -0.9924 Loss2: -0.9870 Loss3: -0.9936\n",
            "2022-08-02 16:48:41.408767 Epoch [075/250], Step [0060/0060], Loss1: -0.9886 Loss2: -0.9817 Loss3: -0.9903\n",
            "Epoch: 75 MAE: 58.59996166646092 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 16:48:51.493127 Epoch [076/250], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9857 Loss3: -0.9917\n",
            "2022-08-02 16:49:20.831826 Epoch [076/250], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9847 Loss3: -0.9914\n",
            "2022-08-02 16:49:26.680439 Epoch [076/250], Step [0060/0060], Loss1: -0.9880 Loss2: -0.9812 Loss3: -0.9901\n",
            "Epoch: 76 MAE: 58.48552725888023 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 16:49:34.620477 Epoch [077/250], Step [0001/0060], Loss1: -0.9881 Loss2: -0.9839 Loss3: -0.9904\n",
            "2022-08-02 16:50:03.202335 Epoch [077/250], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9836 Loss3: -0.9916\n",
            "2022-08-02 16:50:09.165532 Epoch [077/250], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9847 Loss3: -0.9920\n",
            "Epoch: 77 MAE: 58.52508101136045 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 16:50:17.061846 Epoch [078/250], Step [0001/0060], Loss1: -0.9918 Loss2: -0.9878 Loss3: -0.9930\n",
            "2022-08-02 16:50:46.010606 Epoch [078/250], Step [0050/0060], Loss1: -0.9871 Loss2: -0.9776 Loss3: -0.9891\n",
            "2022-08-02 16:50:51.861928 Epoch [078/250], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9844 Loss3: -0.9930\n",
            "Epoch: 78 MAE: 58.4629483540536 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 16:50:59.719903 Epoch [079/250], Step [0001/0060], Loss1: -0.9867 Loss2: -0.9792 Loss3: -0.9891\n",
            "2022-08-02 16:51:28.382360 Epoch [079/250], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9870 Loss3: -0.9930\n",
            "2022-08-02 16:51:34.213704 Epoch [079/250], Step [0060/0060], Loss1: -0.9896 Loss2: -0.9858 Loss3: -0.9915\n",
            "Epoch: 79 MAE: 58.526164271221134 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 16:51:42.008957 Epoch [080/250], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9872 Loss3: -0.9925\n",
            "2022-08-02 16:52:10.697482 Epoch [080/250], Step [0050/0060], Loss1: -0.9872 Loss2: -0.9804 Loss3: -0.9892\n",
            "2022-08-02 16:52:16.509075 Epoch [080/250], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9828 Loss3: -0.9915\n",
            "Epoch: 80 MAE: 58.47727692665271 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 16:52:26.923916 Epoch [081/250], Step [0001/0060], Loss1: -0.9835 Loss2: -0.9772 Loss3: -0.9869\n",
            "2022-08-02 16:52:56.143102 Epoch [081/250], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9850 Loss3: -0.9920\n",
            "2022-08-02 16:53:02.053281 Epoch [081/250], Step [0060/0060], Loss1: -0.9895 Loss2: -0.9840 Loss3: -0.9911\n",
            "Epoch: 81 MAE: 58.56333237977525 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 16:53:09.925932 Epoch [082/250], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9848 Loss3: -0.9914\n",
            "2022-08-02 16:53:38.794951 Epoch [082/250], Step [0050/0060], Loss1: -0.9871 Loss2: -0.9803 Loss3: -0.9891\n",
            "2022-08-02 16:53:44.722452 Epoch [082/250], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9863 Loss3: -0.9924\n",
            "Epoch: 82 MAE: 58.46777115841071 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 16:53:52.562349 Epoch [083/250], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9852 Loss3: -0.9923\n",
            "2022-08-02 16:54:21.480043 Epoch [083/250], Step [0050/0060], Loss1: -0.9876 Loss2: -0.9822 Loss3: -0.9896\n",
            "2022-08-02 16:54:27.314220 Epoch [083/250], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9860 Loss3: -0.9925\n",
            "Epoch: 83 MAE: 58.44218103780765 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 16:54:35.094120 Epoch [084/250], Step [0001/0060], Loss1: -0.9882 Loss2: -0.9828 Loss3: -0.9902\n",
            "2022-08-02 16:55:04.015563 Epoch [084/250], Step [0050/0060], Loss1: -0.9869 Loss2: -0.9814 Loss3: -0.9894\n",
            "2022-08-02 16:55:09.884468 Epoch [084/250], Step [0060/0060], Loss1: -0.9835 Loss2: -0.9735 Loss3: -0.9860\n",
            "Epoch: 84 MAE: 58.524728314848176 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 16:55:17.693310 Epoch [085/250], Step [0001/0060], Loss1: -0.9810 Loss2: -0.9748 Loss3: -0.9856\n",
            "2022-08-02 16:55:46.388201 Epoch [085/250], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9832 Loss3: -0.9911\n",
            "2022-08-02 16:55:52.248930 Epoch [085/250], Step [0060/0060], Loss1: -0.9835 Loss2: -0.9728 Loss3: -0.9865\n",
            "Epoch: 85 MAE: 58.401853782569745 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 16:56:02.716017 Epoch [086/250], Step [0001/0060], Loss1: -0.9887 Loss2: -0.9832 Loss3: -0.9906\n",
            "2022-08-02 16:56:32.002556 Epoch [086/250], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9832 Loss3: -0.9909\n",
            "2022-08-02 16:56:37.857218 Epoch [086/250], Step [0060/0060], Loss1: -0.9898 Loss2: -0.9860 Loss3: -0.9914\n",
            "Epoch: 86 MAE: 58.49603396286243 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 16:56:45.813721 Epoch [087/250], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9846 Loss3: -0.9912\n",
            "2022-08-02 16:57:14.624117 Epoch [087/250], Step [0050/0060], Loss1: -0.9900 Loss2: -0.9816 Loss3: -0.9914\n",
            "2022-08-02 16:57:20.429779 Epoch [087/250], Step [0060/0060], Loss1: -0.9896 Loss2: -0.9841 Loss3: -0.9913\n",
            "Epoch: 87 MAE: 58.55729216925909 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 16:57:28.272036 Epoch [088/250], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9829 Loss3: -0.9914\n",
            "2022-08-02 16:57:57.040851 Epoch [088/250], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9864 Loss3: -0.9922\n",
            "2022-08-02 16:58:02.920589 Epoch [088/250], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9859 Loss3: -0.9916\n",
            "Epoch: 88 MAE: 58.48989309681165 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 16:58:10.723516 Epoch [089/250], Step [0001/0060], Loss1: -0.9874 Loss2: -0.9814 Loss3: -0.9894\n",
            "2022-08-02 16:58:39.454969 Epoch [089/250], Step [0050/0060], Loss1: -0.9898 Loss2: -0.9839 Loss3: -0.9914\n",
            "2022-08-02 16:58:45.254841 Epoch [089/250], Step [0060/0060], Loss1: -0.9883 Loss2: -0.9822 Loss3: -0.9904\n",
            "Epoch: 89 MAE: 58.355078702604125 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 16:58:53.078835 Epoch [090/250], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9853 Loss3: -0.9926\n",
            "2022-08-02 16:59:21.693013 Epoch [090/250], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9838 Loss3: -0.9912\n",
            "2022-08-02 16:59:27.576693 Epoch [090/250], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9865 Loss3: -0.9921\n",
            "Epoch: 90 MAE: 58.63607890538032 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 16:59:37.827127 Epoch [091/250], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9847 Loss3: -0.9915\n",
            "2022-08-02 17:00:07.372236 Epoch [091/250], Step [0050/0060], Loss1: -0.9885 Loss2: -0.9819 Loss3: -0.9902\n",
            "2022-08-02 17:00:13.264386 Epoch [091/250], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9871 Loss3: -0.9927\n",
            "Epoch: 91 MAE: 58.55891583512117 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:00:21.148557 Epoch [092/250], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9841 Loss3: -0.9912\n",
            "2022-08-02 17:00:49.965769 Epoch [092/250], Step [0050/0060], Loss1: -0.9912 Loss2: -0.9852 Loss3: -0.9926\n",
            "2022-08-02 17:00:55.797895 Epoch [092/250], Step [0060/0060], Loss1: -0.9882 Loss2: -0.9844 Loss3: -0.9904\n",
            "Epoch: 92 MAE: 58.484854969975025 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:01:03.717458 Epoch [093/250], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9839 Loss3: -0.9916\n",
            "2022-08-02 17:01:32.547570 Epoch [093/250], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9864 Loss3: -0.9917\n",
            "2022-08-02 17:01:38.452190 Epoch [093/250], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9845 Loss3: -0.9919\n",
            "Epoch: 93 MAE: 58.55914986522744 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:01:46.233849 Epoch [094/250], Step [0001/0060], Loss1: -0.9883 Loss2: -0.9827 Loss3: -0.9900\n",
            "2022-08-02 17:02:15.051648 Epoch [094/250], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9861 Loss3: -0.9922\n",
            "2022-08-02 17:02:20.901093 Epoch [094/250], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9872 Loss3: -0.9929\n",
            "Epoch: 94 MAE: 58.64455922408011 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:02:28.782668 Epoch [095/250], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9822 Loss3: -0.9911\n",
            "2022-08-02 17:02:57.429144 Epoch [095/250], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9852 Loss3: -0.9920\n",
            "2022-08-02 17:03:03.217381 Epoch [095/250], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9874 Loss3: -0.9926\n",
            "Epoch: 95 MAE: 58.536067626283675 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:03:13.454223 Epoch [096/250], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9876 Loss3: -0.9924\n",
            "2022-08-02 17:03:42.427728 Epoch [096/250], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9847 Loss3: -0.9921\n",
            "2022-08-02 17:03:48.317560 Epoch [096/250], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9866 Loss3: -0.9920\n",
            "Epoch: 96 MAE: 58.56080456523759 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:03:56.108426 Epoch [097/250], Step [0001/0060], Loss1: -0.9888 Loss2: -0.9816 Loss3: -0.9902\n",
            "2022-08-02 17:04:24.833772 Epoch [097/250], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9883 Loss3: -0.9925\n",
            "2022-08-02 17:04:30.712811 Epoch [097/250], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9874 Loss3: -0.9927\n",
            "Epoch: 97 MAE: 58.4361208217283 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:04:38.544515 Epoch [098/250], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9854 Loss3: -0.9927\n",
            "2022-08-02 17:05:07.315209 Epoch [098/250], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9852 Loss3: -0.9919\n",
            "2022-08-02 17:05:13.204520 Epoch [098/250], Step [0060/0060], Loss1: -0.9920 Loss2: -0.9878 Loss3: -0.9932\n",
            "Epoch: 98 MAE: 58.563117545112405 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:05:21.039673 Epoch [099/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9844 Loss3: -0.9916\n",
            "2022-08-02 17:05:49.970473 Epoch [099/250], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9861 Loss3: -0.9922\n",
            "2022-08-02 17:05:55.775783 Epoch [099/250], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9839 Loss3: -0.9920\n",
            "Epoch: 99 MAE: 58.4640923674646 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:06:03.589581 Epoch [100/250], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9860 Loss3: -0.9927\n",
            "2022-08-02 17:06:32.408567 Epoch [100/250], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9842 Loss3: -0.9920\n",
            "2022-08-02 17:06:38.235299 Epoch [100/250], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9847 Loss3: -0.9921\n",
            "Epoch: 100 MAE: 58.479992813648956 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:06:48.408889 Epoch [101/250], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9870 Loss3: -0.9922\n",
            "2022-08-02 17:07:17.671049 Epoch [101/250], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9827 Loss3: -0.9915\n",
            "2022-08-02 17:07:23.531850 Epoch [101/250], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9858 Loss3: -0.9929\n",
            "Epoch: 101 MAE: 58.44791454015926 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:07:31.364682 Epoch [102/250], Step [0001/0060], Loss1: -0.9879 Loss2: -0.9838 Loss3: -0.9900\n",
            "2022-08-02 17:08:00.310272 Epoch [102/250], Step [0050/0060], Loss1: -0.9900 Loss2: -0.9869 Loss3: -0.9915\n",
            "2022-08-02 17:08:06.149833 Epoch [102/250], Step [0060/0060], Loss1: -0.9856 Loss2: -0.9798 Loss3: -0.9879\n",
            "Epoch: 102 MAE: 58.4139240341252 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:08:13.983476 Epoch [103/250], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9863 Loss3: -0.9917\n",
            "2022-08-02 17:08:42.792181 Epoch [103/250], Step [0050/0060], Loss1: -0.9869 Loss2: -0.9783 Loss3: -0.9897\n",
            "2022-08-02 17:08:48.586790 Epoch [103/250], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9844 Loss3: -0.9916\n",
            "Epoch: 103 MAE: 58.42045896163405 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:08:56.504088 Epoch [104/250], Step [0001/0060], Loss1: -0.9883 Loss2: -0.9827 Loss3: -0.9901\n",
            "2022-08-02 17:09:25.233033 Epoch [104/250], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9881 Loss3: -0.9924\n",
            "2022-08-02 17:09:31.071822 Epoch [104/250], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9871 Loss3: -0.9926\n",
            "Epoch: 104 MAE: 58.58565415621084 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:09:38.866085 Epoch [105/250], Step [0001/0060], Loss1: -0.9906 Loss2: -0.9863 Loss3: -0.9922\n",
            "2022-08-02 17:10:07.501177 Epoch [105/250], Step [0050/0060], Loss1: -0.9870 Loss2: -0.9796 Loss3: -0.9890\n",
            "2022-08-02 17:10:13.323919 Epoch [105/250], Step [0060/0060], Loss1: -0.9919 Loss2: -0.9873 Loss3: -0.9932\n",
            "Epoch: 105 MAE: 58.45270227541602 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:10:23.719268 Epoch [106/250], Step [0001/0060], Loss1: -0.9882 Loss2: -0.9819 Loss3: -0.9902\n",
            "2022-08-02 17:10:52.630188 Epoch [106/250], Step [0050/0060], Loss1: -0.9883 Loss2: -0.9803 Loss3: -0.9899\n",
            "2022-08-02 17:10:58.535787 Epoch [106/250], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9829 Loss3: -0.9908\n",
            "Epoch: 106 MAE: 58.493125996736566 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:11:06.397411 Epoch [107/250], Step [0001/0060], Loss1: -0.9918 Loss2: -0.9879 Loss3: -0.9930\n",
            "2022-08-02 17:11:34.974662 Epoch [107/250], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9856 Loss3: -0.9921\n",
            "2022-08-02 17:11:40.859382 Epoch [107/250], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9845 Loss3: -0.9915\n",
            "Epoch: 107 MAE: 58.54894207432294 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:11:48.695498 Epoch [108/250], Step [0001/0060], Loss1: -0.9890 Loss2: -0.9827 Loss3: -0.9908\n",
            "2022-08-02 17:12:17.371659 Epoch [108/250], Step [0050/0060], Loss1: -0.9877 Loss2: -0.9824 Loss3: -0.9898\n",
            "2022-08-02 17:12:23.240960 Epoch [108/250], Step [0060/0060], Loss1: -0.9881 Loss2: -0.9813 Loss3: -0.9897\n",
            "Epoch: 108 MAE: 58.44049032773691 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:12:31.096505 Epoch [109/250], Step [0001/0060], Loss1: -0.9849 Loss2: -0.9772 Loss3: -0.9869\n",
            "2022-08-02 17:12:59.682272 Epoch [109/250], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9858 Loss3: -0.9927\n",
            "2022-08-02 17:13:05.537421 Epoch [109/250], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9854 Loss3: -0.9916\n",
            "Epoch: 109 MAE: 58.555710403427845 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:13:13.313657 Epoch [110/250], Step [0001/0060], Loss1: -0.9892 Loss2: -0.9857 Loss3: -0.9910\n",
            "2022-08-02 17:13:42.224463 Epoch [110/250], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9878 Loss3: -0.9922\n",
            "2022-08-02 17:13:48.068696 Epoch [110/250], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9857 Loss3: -0.9917\n",
            "Epoch: 110 MAE: 58.53634797713371 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:13:58.307616 Epoch [111/250], Step [0001/0060], Loss1: -0.9859 Loss2: -0.9801 Loss3: -0.9879\n",
            "2022-08-02 17:14:27.469563 Epoch [111/250], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9854 Loss3: -0.9925\n",
            "2022-08-02 17:14:33.347641 Epoch [111/250], Step [0060/0060], Loss1: -0.9898 Loss2: -0.9853 Loss3: -0.9914\n",
            "Epoch: 111 MAE: 58.51929561955397 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:14:41.194274 Epoch [112/250], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9835 Loss3: -0.9910\n",
            "2022-08-02 17:15:09.784905 Epoch [112/250], Step [0050/0060], Loss1: -0.9877 Loss2: -0.9821 Loss3: -0.9894\n",
            "2022-08-02 17:15:15.620817 Epoch [112/250], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9859 Loss3: -0.9925\n",
            "Epoch: 112 MAE: 58.37317466474868 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:15:23.449231 Epoch [113/250], Step [0001/0060], Loss1: -0.9904 Loss2: -0.9844 Loss3: -0.9918\n",
            "2022-08-02 17:15:52.089835 Epoch [113/250], Step [0050/0060], Loss1: -0.9876 Loss2: -0.9798 Loss3: -0.9895\n",
            "2022-08-02 17:15:57.884518 Epoch [113/250], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9864 Loss3: -0.9932\n",
            "Epoch: 113 MAE: 58.565200288571724 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:16:05.769565 Epoch [114/250], Step [0001/0060], Loss1: -0.9888 Loss2: -0.9802 Loss3: -0.9907\n",
            "2022-08-02 17:16:34.538405 Epoch [114/250], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9830 Loss3: -0.9916\n",
            "2022-08-02 17:16:40.362038 Epoch [114/250], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9852 Loss3: -0.9920\n",
            "Epoch: 114 MAE: 58.49788320533394 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:16:48.253810 Epoch [115/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9856 Loss3: -0.9918\n",
            "2022-08-02 17:17:16.931077 Epoch [115/250], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9834 Loss3: -0.9906\n",
            "2022-08-02 17:17:22.830043 Epoch [115/250], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9830 Loss3: -0.9912\n",
            "Epoch: 115 MAE: 58.36168084081663 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:17:33.042473 Epoch [116/250], Step [0001/0060], Loss1: -0.9906 Loss2: -0.9874 Loss3: -0.9923\n",
            "2022-08-02 17:18:02.620597 Epoch [116/250], Step [0050/0060], Loss1: -0.9920 Loss2: -0.9879 Loss3: -0.9933\n",
            "2022-08-02 17:18:08.484884 Epoch [116/250], Step [0060/0060], Loss1: -0.9921 Loss2: -0.9873 Loss3: -0.9933\n",
            "Epoch: 116 MAE: 58.626306188003504 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:18:16.241371 Epoch [117/250], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9840 Loss3: -0.9918\n",
            "2022-08-02 17:18:45.053146 Epoch [117/250], Step [0050/0060], Loss1: -0.9886 Loss2: -0.9833 Loss3: -0.9901\n",
            "2022-08-02 17:18:50.870568 Epoch [117/250], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9848 Loss3: -0.9922\n",
            "Epoch: 117 MAE: 58.44660490674902 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:18:58.735779 Epoch [118/250], Step [0001/0060], Loss1: -0.9921 Loss2: -0.9870 Loss3: -0.9936\n",
            "2022-08-02 17:19:27.509183 Epoch [118/250], Step [0050/0060], Loss1: -0.9898 Loss2: -0.9848 Loss3: -0.9911\n",
            "2022-08-02 17:19:33.315442 Epoch [118/250], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9873 Loss3: -0.9925\n",
            "Epoch: 118 MAE: 58.48049680789916 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:19:41.168158 Epoch [119/250], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9868 Loss3: -0.9929\n",
            "2022-08-02 17:20:09.970912 Epoch [119/250], Step [0050/0060], Loss1: -0.9874 Loss2: -0.9819 Loss3: -0.9894\n",
            "2022-08-02 17:20:15.803977 Epoch [119/250], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9868 Loss3: -0.9927\n",
            "Epoch: 119 MAE: 58.50177627445796 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:20:23.688394 Epoch [120/250], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9840 Loss3: -0.9913\n",
            "2022-08-02 17:20:52.557370 Epoch [120/250], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9796 Loss3: -0.9883\n",
            "2022-08-02 17:20:58.372916 Epoch [120/250], Step [0060/0060], Loss1: -0.9891 Loss2: -0.9845 Loss3: -0.9908\n",
            "Epoch: 120 MAE: 58.41075153454971 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:21:08.611567 Epoch [121/250], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9847 Loss3: -0.9918\n",
            "2022-08-02 17:21:38.430397 Epoch [121/250], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9858 Loss3: -0.9930\n",
            "2022-08-02 17:21:44.313518 Epoch [121/250], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9843 Loss3: -0.9913\n",
            "Epoch: 121 MAE: 58.431218698175385 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:21:52.290731 Epoch [122/250], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9853 Loss3: -0.9920\n",
            "2022-08-02 17:22:20.892826 Epoch [122/250], Step [0050/0060], Loss1: -0.9921 Loss2: -0.9885 Loss3: -0.9932\n",
            "2022-08-02 17:22:26.751310 Epoch [122/250], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9866 Loss3: -0.9924\n",
            "Epoch: 122 MAE: 58.62773690488064 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:22:34.631531 Epoch [123/250], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9848 Loss3: -0.9921\n",
            "2022-08-02 17:23:03.469986 Epoch [123/250], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9813 Loss3: -0.9906\n",
            "2022-08-02 17:23:09.323522 Epoch [123/250], Step [0060/0060], Loss1: -0.9884 Loss2: -0.9818 Loss3: -0.9901\n",
            "Epoch: 123 MAE: 58.457201992296625 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:23:17.259954 Epoch [124/250], Step [0001/0060], Loss1: -0.9876 Loss2: -0.9784 Loss3: -0.9893\n",
            "2022-08-02 17:23:45.933572 Epoch [124/250], Step [0050/0060], Loss1: -0.9912 Loss2: -0.9845 Loss3: -0.9926\n",
            "2022-08-02 17:23:51.803686 Epoch [124/250], Step [0060/0060], Loss1: -0.9840 Loss2: -0.9734 Loss3: -0.9865\n",
            "Epoch: 124 MAE: 58.382252882135894 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:23:59.780525 Epoch [125/250], Step [0001/0060], Loss1: -0.9889 Loss2: -0.9838 Loss3: -0.9905\n",
            "2022-08-02 17:24:28.559286 Epoch [125/250], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9825 Loss3: -0.9910\n",
            "2022-08-02 17:24:34.490115 Epoch [125/250], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9845 Loss3: -0.9920\n",
            "Epoch: 125 MAE: 58.50665376232619 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:24:44.790666 Epoch [126/250], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9863 Loss3: -0.9919\n",
            "2022-08-02 17:25:14.209014 Epoch [126/250], Step [0050/0060], Loss1: -0.9891 Loss2: -0.9844 Loss3: -0.9909\n",
            "2022-08-02 17:25:20.037406 Epoch [126/250], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9865 Loss3: -0.9929\n",
            "Epoch: 126 MAE: 58.57626839750587 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:25:27.835433 Epoch [127/250], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9855 Loss3: -0.9921\n",
            "2022-08-02 17:25:56.773539 Epoch [127/250], Step [0050/0060], Loss1: -0.9917 Loss2: -0.9856 Loss3: -0.9932\n",
            "2022-08-02 17:26:02.624456 Epoch [127/250], Step [0060/0060], Loss1: -0.9919 Loss2: -0.9885 Loss3: -0.9933\n",
            "Epoch: 127 MAE: 58.518886955243325 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:26:10.530559 Epoch [128/250], Step [0001/0060], Loss1: -0.9921 Loss2: -0.9888 Loss3: -0.9937\n",
            "2022-08-02 17:26:39.363500 Epoch [128/250], Step [0050/0060], Loss1: -0.9916 Loss2: -0.9865 Loss3: -0.9930\n",
            "2022-08-02 17:26:45.220592 Epoch [128/250], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9876 Loss3: -0.9923\n",
            "Epoch: 128 MAE: 58.42678082863712 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:26:53.172676 Epoch [129/250], Step [0001/0060], Loss1: -0.9913 Loss2: -0.9880 Loss3: -0.9926\n",
            "2022-08-02 17:27:22.067802 Epoch [129/250], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9858 Loss3: -0.9922\n",
            "2022-08-02 17:27:27.892605 Epoch [129/250], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9862 Loss3: -0.9927\n",
            "Epoch: 129 MAE: 58.530650964522174 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:27:35.833832 Epoch [130/250], Step [0001/0060], Loss1: -0.9855 Loss2: -0.9765 Loss3: -0.9879\n",
            "2022-08-02 17:28:04.624888 Epoch [130/250], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9866 Loss3: -0.9924\n",
            "2022-08-02 17:28:10.482473 Epoch [130/250], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9847 Loss3: -0.9915\n",
            "Epoch: 130 MAE: 58.521204982851586 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:28:20.625903 Epoch [131/250], Step [0001/0060], Loss1: -0.9863 Loss2: -0.9799 Loss3: -0.9883\n",
            "2022-08-02 17:28:49.906079 Epoch [131/250], Step [0050/0060], Loss1: -0.9889 Loss2: -0.9821 Loss3: -0.9905\n",
            "2022-08-02 17:28:55.723776 Epoch [131/250], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9853 Loss3: -0.9920\n",
            "Epoch: 131 MAE: 58.65044955719326 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:29:03.398631 Epoch [132/250], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9857 Loss3: -0.9912\n",
            "2022-08-02 17:29:32.267613 Epoch [132/250], Step [0050/0060], Loss1: -0.9921 Loss2: -0.9880 Loss3: -0.9933\n",
            "2022-08-02 17:29:38.111411 Epoch [132/250], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9834 Loss3: -0.9906\n",
            "Epoch: 132 MAE: 58.446081488500944 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:29:45.945417 Epoch [133/250], Step [0001/0060], Loss1: -0.9917 Loss2: -0.9870 Loss3: -0.9930\n",
            "2022-08-02 17:30:14.553745 Epoch [133/250], Step [0050/0060], Loss1: -0.9856 Loss2: -0.9805 Loss3: -0.9888\n",
            "2022-08-02 17:30:20.358099 Epoch [133/250], Step [0060/0060], Loss1: -0.9896 Loss2: -0.9830 Loss3: -0.9912\n",
            "Epoch: 133 MAE: 58.445535086031576 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:30:28.182821 Epoch [134/250], Step [0001/0060], Loss1: -0.9892 Loss2: -0.9828 Loss3: -0.9908\n",
            "2022-08-02 17:30:56.885761 Epoch [134/250], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9871 Loss3: -0.9919\n",
            "2022-08-02 17:31:02.691668 Epoch [134/250], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9839 Loss3: -0.9916\n",
            "Epoch: 134 MAE: 58.455939005126496 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:31:10.579563 Epoch [135/250], Step [0001/0060], Loss1: -0.9921 Loss2: -0.9887 Loss3: -0.9935\n",
            "2022-08-02 17:31:39.395173 Epoch [135/250], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9851 Loss3: -0.9912\n",
            "2022-08-02 17:31:45.282032 Epoch [135/250], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9846 Loss3: -0.9922\n",
            "Epoch: 135 MAE: 58.44403984221601 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:31:55.541320 Epoch [136/250], Step [0001/0060], Loss1: -0.9916 Loss2: -0.9880 Loss3: -0.9928\n",
            "2022-08-02 17:32:24.500717 Epoch [136/250], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9827 Loss3: -0.9899\n",
            "2022-08-02 17:32:30.487413 Epoch [136/250], Step [0060/0060], Loss1: -0.9895 Loss2: -0.9834 Loss3: -0.9909\n",
            "Epoch: 136 MAE: 58.48621387797564 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:32:38.345628 Epoch [137/250], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9861 Loss3: -0.9923\n",
            "2022-08-02 17:33:07.240917 Epoch [137/250], Step [0050/0060], Loss1: -0.9894 Loss2: -0.9838 Loss3: -0.9909\n",
            "2022-08-02 17:33:13.147591 Epoch [137/250], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9878 Loss3: -0.9929\n",
            "Epoch: 137 MAE: 58.38500971337902 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:33:21.027588 Epoch [138/250], Step [0001/0060], Loss1: -0.9920 Loss2: -0.9891 Loss3: -0.9935\n",
            "2022-08-02 17:33:49.870123 Epoch [138/250], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9842 Loss3: -0.9904\n",
            "2022-08-02 17:33:55.732637 Epoch [138/250], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9870 Loss3: -0.9930\n",
            "Epoch: 138 MAE: 58.4644679650993 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:34:03.535539 Epoch [139/250], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9858 Loss3: -0.9916\n",
            "2022-08-02 17:34:32.324853 Epoch [139/250], Step [0050/0060], Loss1: -0.9912 Loss2: -0.9863 Loss3: -0.9924\n",
            "2022-08-02 17:34:38.138542 Epoch [139/250], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9861 Loss3: -0.9920\n",
            "Epoch: 139 MAE: 58.466495192183274 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:34:45.963702 Epoch [140/250], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9830 Loss3: -0.9911\n",
            "2022-08-02 17:35:14.572110 Epoch [140/250], Step [0050/0060], Loss1: -0.9912 Loss2: -0.9883 Loss3: -0.9928\n",
            "2022-08-02 17:35:20.385480 Epoch [140/250], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9882 Loss3: -0.9930\n",
            "Epoch: 140 MAE: 58.47322028384979 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:35:30.810276 Epoch [141/250], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9853 Loss3: -0.9925\n",
            "2022-08-02 17:36:00.223648 Epoch [141/250], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9855 Loss3: -0.9917\n",
            "2022-08-02 17:36:06.036194 Epoch [141/250], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9833 Loss3: -0.9913\n",
            "Epoch: 141 MAE: 58.322027575824436 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:36:13.815916 Epoch [142/250], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9860 Loss3: -0.9918\n",
            "2022-08-02 17:36:42.542304 Epoch [142/250], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9840 Loss3: -0.9906\n",
            "2022-08-02 17:36:48.364034 Epoch [142/250], Step [0060/0060], Loss1: -0.9923 Loss2: -0.9895 Loss3: -0.9934\n",
            "Epoch: 142 MAE: 58.46737555368098 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:36:56.234005 Epoch [143/250], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9870 Loss3: -0.9919\n",
            "2022-08-02 17:37:24.728976 Epoch [143/250], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9873 Loss3: -0.9924\n",
            "2022-08-02 17:37:30.546927 Epoch [143/250], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9859 Loss3: -0.9926\n",
            "Epoch: 143 MAE: 58.417444981793125 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:37:38.293866 Epoch [144/250], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9863 Loss3: -0.9925\n",
            "2022-08-02 17:38:07.228711 Epoch [144/250], Step [0050/0060], Loss1: -0.9891 Loss2: -0.9827 Loss3: -0.9906\n",
            "2022-08-02 17:38:13.103842 Epoch [144/250], Step [0060/0060], Loss1: -0.9875 Loss2: -0.9837 Loss3: -0.9892\n",
            "Epoch: 144 MAE: 58.403986722498495 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:38:20.857840 Epoch [145/250], Step [0001/0060], Loss1: -0.9894 Loss2: -0.9838 Loss3: -0.9909\n",
            "2022-08-02 17:38:49.545233 Epoch [145/250], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9858 Loss3: -0.9919\n",
            "2022-08-02 17:38:55.479632 Epoch [145/250], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9856 Loss3: -0.9913\n",
            "Epoch: 145 MAE: 58.31886233480517 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:39:05.631944 Epoch [146/250], Step [0001/0060], Loss1: -0.9885 Loss2: -0.9836 Loss3: -0.9901\n",
            "2022-08-02 17:39:34.981110 Epoch [146/250], Step [0050/0060], Loss1: -0.9897 Loss2: -0.9846 Loss3: -0.9911\n",
            "2022-08-02 17:39:40.831018 Epoch [146/250], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9881 Loss3: -0.9930\n",
            "Epoch: 146 MAE: 58.60360442046198 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:39:48.631876 Epoch [147/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9846 Loss3: -0.9915\n",
            "2022-08-02 17:40:17.291336 Epoch [147/250], Step [0050/0060], Loss1: -0.9894 Loss2: -0.9824 Loss3: -0.9907\n",
            "2022-08-02 17:40:23.151275 Epoch [147/250], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9848 Loss3: -0.9924\n",
            "Epoch: 147 MAE: 58.59245636716531 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:40:31.021577 Epoch [148/250], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9876 Loss3: -0.9925\n",
            "2022-08-02 17:40:59.694905 Epoch [148/250], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9868 Loss3: -0.9922\n",
            "2022-08-02 17:41:05.495704 Epoch [148/250], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9824 Loss3: -0.9915\n",
            "Epoch: 148 MAE: 58.52002066646706 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:41:13.124450 Epoch [149/250], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9844 Loss3: -0.9914\n",
            "2022-08-02 17:41:41.634117 Epoch [149/250], Step [0050/0060], Loss1: -0.9900 Loss2: -0.9861 Loss3: -0.9914\n",
            "2022-08-02 17:41:47.447124 Epoch [149/250], Step [0060/0060], Loss1: -0.9883 Loss2: -0.9839 Loss3: -0.9901\n",
            "Epoch: 149 MAE: 58.383856313210465 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:41:55.416478 Epoch [150/250], Step [0001/0060], Loss1: -0.9892 Loss2: -0.9829 Loss3: -0.9907\n",
            "2022-08-02 17:42:24.128302 Epoch [150/250], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9823 Loss3: -0.9903\n",
            "2022-08-02 17:42:30.039242 Epoch [150/250], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9861 Loss3: -0.9929\n",
            "Epoch: 150 MAE: 58.475159890761695 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "2022-08-02 17:42:40.323894 Epoch [151/250], Step [0001/0060], Loss1: -0.9889 Loss2: -0.9842 Loss3: -0.9907\n",
            "2022-08-02 17:43:09.429015 Epoch [151/250], Step [0050/0060], Loss1: -0.9918 Loss2: -0.9876 Loss3: -0.9933\n",
            "2022-08-02 17:43:15.302484 Epoch [151/250], Step [0060/0060], Loss1: -0.9839 Loss2: -0.9775 Loss3: -0.9863\n",
            "Epoch: 151 MAE: 58.265671346796104 ####  bestMAE: 58.30933367640438 bestEpoch: 73\n",
            "best epoch:151\n",
            "2022-08-02 17:43:27.271397 Epoch [152/250], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9844 Loss3: -0.9920\n",
            "2022-08-02 17:43:56.289286 Epoch [152/250], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9860 Loss3: -0.9919\n",
            "2022-08-02 17:44:02.107804 Epoch [152/250], Step [0060/0060], Loss1: -0.9891 Loss2: -0.9834 Loss3: -0.9907\n",
            "Epoch: 152 MAE: 58.543000035802486 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:44:09.981429 Epoch [153/250], Step [0001/0060], Loss1: -0.9858 Loss2: -0.9773 Loss3: -0.9880\n",
            "2022-08-02 17:44:38.479969 Epoch [153/250], Step [0050/0060], Loss1: -0.9889 Loss2: -0.9813 Loss3: -0.9905\n",
            "2022-08-02 17:44:44.285726 Epoch [153/250], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9859 Loss3: -0.9908\n",
            "Epoch: 153 MAE: 58.51635075470436 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:44:52.050889 Epoch [154/250], Step [0001/0060], Loss1: -0.9915 Loss2: -0.9867 Loss3: -0.9930\n",
            "2022-08-02 17:45:20.338778 Epoch [154/250], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9871 Loss3: -0.9918\n",
            "2022-08-02 17:45:26.096280 Epoch [154/250], Step [0060/0060], Loss1: -0.9866 Loss2: -0.9799 Loss3: -0.9887\n",
            "Epoch: 154 MAE: 58.4841445701875 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:45:33.810383 Epoch [155/250], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9858 Loss3: -0.9921\n",
            "2022-08-02 17:46:02.464429 Epoch [155/250], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9851 Loss3: -0.9913\n",
            "2022-08-02 17:46:08.239911 Epoch [155/250], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9863 Loss3: -0.9924\n",
            "Epoch: 155 MAE: 58.52147529927809 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:46:18.429284 Epoch [156/250], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9849 Loss3: -0.9917\n",
            "2022-08-02 17:46:47.723629 Epoch [156/250], Step [0050/0060], Loss1: -0.9900 Loss2: -0.9845 Loss3: -0.9914\n",
            "2022-08-02 17:46:53.556014 Epoch [156/250], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9864 Loss3: -0.9916\n",
            "Epoch: 156 MAE: 58.64434360871382 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:47:01.230373 Epoch [157/250], Step [0001/0060], Loss1: -0.9870 Loss2: -0.9816 Loss3: -0.9887\n",
            "2022-08-02 17:47:29.853279 Epoch [157/250], Step [0050/0060], Loss1: -0.9921 Loss2: -0.9874 Loss3: -0.9933\n",
            "2022-08-02 17:47:35.645644 Epoch [157/250], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9864 Loss3: -0.9920\n",
            "Epoch: 157 MAE: 58.64524173140061 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:47:43.422848 Epoch [158/250], Step [0001/0060], Loss1: -0.9924 Loss2: -0.9879 Loss3: -0.9935\n",
            "2022-08-02 17:48:11.917746 Epoch [158/250], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9844 Loss3: -0.9911\n",
            "2022-08-02 17:48:17.672436 Epoch [158/250], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9850 Loss3: -0.9914\n",
            "Epoch: 158 MAE: 58.39211743365245 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:48:25.470592 Epoch [159/250], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9819 Loss3: -0.9911\n",
            "2022-08-02 17:48:54.174232 Epoch [159/250], Step [0050/0060], Loss1: -0.9887 Loss2: -0.9842 Loss3: -0.9901\n",
            "2022-08-02 17:48:59.952137 Epoch [159/250], Step [0060/0060], Loss1: -0.9867 Loss2: -0.9798 Loss3: -0.9884\n",
            "Epoch: 159 MAE: 58.314810063345966 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:49:07.697942 Epoch [160/250], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9844 Loss3: -0.9914\n",
            "2022-08-02 17:49:36.290014 Epoch [160/250], Step [0050/0060], Loss1: -0.9918 Loss2: -0.9872 Loss3: -0.9931\n",
            "2022-08-02 17:49:42.152592 Epoch [160/250], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9868 Loss3: -0.9919\n",
            "Epoch: 160 MAE: 58.387078529501814 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:49:52.516988 Epoch [161/250], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9864 Loss3: -0.9923\n",
            "2022-08-02 17:50:21.899181 Epoch [161/250], Step [0050/0060], Loss1: -0.9924 Loss2: -0.9886 Loss3: -0.9936\n",
            "2022-08-02 17:50:27.702336 Epoch [161/250], Step [0060/0060], Loss1: -0.9860 Loss2: -0.9814 Loss3: -0.9880\n",
            "Epoch: 161 MAE: 58.41227401507703 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:50:35.376850 Epoch [162/250], Step [0001/0060], Loss1: -0.9919 Loss2: -0.9869 Loss3: -0.9930\n",
            "2022-08-02 17:51:03.870156 Epoch [162/250], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9845 Loss3: -0.9917\n",
            "2022-08-02 17:51:09.712698 Epoch [162/250], Step [0060/0060], Loss1: -0.9886 Loss2: -0.9830 Loss3: -0.9904\n",
            "Epoch: 162 MAE: 58.3919940240535 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:51:17.397900 Epoch [163/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9850 Loss3: -0.9913\n",
            "2022-08-02 17:51:45.986872 Epoch [163/250], Step [0050/0060], Loss1: -0.9886 Loss2: -0.9836 Loss3: -0.9903\n",
            "2022-08-02 17:51:51.778663 Epoch [163/250], Step [0060/0060], Loss1: -0.9910 Loss2: -0.9856 Loss3: -0.9924\n",
            "Epoch: 163 MAE: 58.422946037435445 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:51:59.496502 Epoch [164/250], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9834 Loss3: -0.9907\n",
            "2022-08-02 17:52:28.116853 Epoch [164/250], Step [0050/0060], Loss1: -0.9912 Loss2: -0.9861 Loss3: -0.9923\n",
            "2022-08-02 17:52:33.997791 Epoch [164/250], Step [0060/0060], Loss1: -0.9845 Loss2: -0.9779 Loss3: -0.9868\n",
            "Epoch: 164 MAE: 58.42289451976745 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:52:41.617267 Epoch [165/250], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9844 Loss3: -0.9912\n",
            "2022-08-02 17:53:10.331207 Epoch [165/250], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9860 Loss3: -0.9918\n",
            "2022-08-02 17:53:16.132017 Epoch [165/250], Step [0060/0060], Loss1: -0.9887 Loss2: -0.9814 Loss3: -0.9903\n",
            "Epoch: 165 MAE: 58.43326821015678 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:53:26.446695 Epoch [166/250], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9845 Loss3: -0.9920\n",
            "2022-08-02 17:53:55.444441 Epoch [166/250], Step [0050/0060], Loss1: -0.9863 Loss2: -0.9805 Loss3: -0.9881\n",
            "2022-08-02 17:54:01.302286 Epoch [166/250], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9834 Loss3: -0.9909\n",
            "Epoch: 166 MAE: 58.44494598092447 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:54:08.986920 Epoch [167/250], Step [0001/0060], Loss1: -0.9904 Loss2: -0.9871 Loss3: -0.9918\n",
            "2022-08-02 17:54:37.706946 Epoch [167/250], Step [0050/0060], Loss1: -0.9889 Loss2: -0.9836 Loss3: -0.9906\n",
            "2022-08-02 17:54:43.508942 Epoch [167/250], Step [0060/0060], Loss1: -0.9888 Loss2: -0.9827 Loss3: -0.9906\n",
            "Epoch: 167 MAE: 58.62236525931411 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:54:51.169977 Epoch [168/250], Step [0001/0060], Loss1: -0.9925 Loss2: -0.9900 Loss3: -0.9938\n",
            "2022-08-02 17:55:19.864021 Epoch [168/250], Step [0050/0060], Loss1: -0.9877 Loss2: -0.9816 Loss3: -0.9895\n",
            "2022-08-02 17:55:25.687883 Epoch [168/250], Step [0060/0060], Loss1: -0.9895 Loss2: -0.9860 Loss3: -0.9914\n",
            "Epoch: 168 MAE: 58.46264960752775 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:55:33.403118 Epoch [169/250], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9839 Loss3: -0.9915\n",
            "2022-08-02 17:56:01.832424 Epoch [169/250], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9845 Loss3: -0.9913\n",
            "2022-08-02 17:56:07.646599 Epoch [169/250], Step [0060/0060], Loss1: -0.9881 Loss2: -0.9813 Loss3: -0.9902\n",
            "Epoch: 169 MAE: 58.31438307118991 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:56:15.374602 Epoch [170/250], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9843 Loss3: -0.9915\n",
            "2022-08-02 17:56:44.204822 Epoch [170/250], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9870 Loss3: -0.9921\n",
            "2022-08-02 17:56:49.999451 Epoch [170/250], Step [0060/0060], Loss1: -0.9925 Loss2: -0.9896 Loss3: -0.9937\n",
            "Epoch: 170 MAE: 58.55438211691293 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:57:00.032463 Epoch [171/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9851 Loss3: -0.9915\n",
            "2022-08-02 17:57:29.675736 Epoch [171/250], Step [0050/0060], Loss1: -0.9918 Loss2: -0.9882 Loss3: -0.9929\n",
            "2022-08-02 17:57:35.546868 Epoch [171/250], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9878 Loss3: -0.9927\n",
            "Epoch: 171 MAE: 58.585853819143516 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:57:43.086581 Epoch [172/250], Step [0001/0060], Loss1: -0.9919 Loss2: -0.9883 Loss3: -0.9933\n",
            "2022-08-02 17:58:11.893654 Epoch [172/250], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9853 Loss3: -0.9920\n",
            "2022-08-02 17:58:17.758565 Epoch [172/250], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9843 Loss3: -0.9909\n",
            "Epoch: 172 MAE: 58.45283688208948 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:58:25.529248 Epoch [173/250], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9852 Loss3: -0.9928\n",
            "2022-08-02 17:58:54.209262 Epoch [173/250], Step [0050/0060], Loss1: -0.9850 Loss2: -0.9778 Loss3: -0.9877\n",
            "2022-08-02 17:59:00.051574 Epoch [173/250], Step [0060/0060], Loss1: -0.9851 Loss2: -0.9760 Loss3: -0.9876\n",
            "Epoch: 173 MAE: 58.43779773345978 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:59:07.760549 Epoch [174/250], Step [0001/0060], Loss1: -0.9920 Loss2: -0.9867 Loss3: -0.9933\n",
            "2022-08-02 17:59:36.319418 Epoch [174/250], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9849 Loss3: -0.9911\n",
            "2022-08-02 17:59:42.104290 Epoch [174/250], Step [0060/0060], Loss1: -0.9888 Loss2: -0.9836 Loss3: -0.9905\n",
            "Epoch: 174 MAE: 58.31358997501443 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 17:59:49.752570 Epoch [175/250], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9882 Loss3: -0.9923\n",
            "2022-08-02 18:00:18.555256 Epoch [175/250], Step [0050/0060], Loss1: -0.9866 Loss2: -0.9816 Loss3: -0.9891\n",
            "2022-08-02 18:00:24.414574 Epoch [175/250], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9857 Loss3: -0.9926\n",
            "Epoch: 175 MAE: 58.542378314895714 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:00:34.477148 Epoch [176/250], Step [0001/0060], Loss1: -0.9913 Loss2: -0.9879 Loss3: -0.9927\n",
            "2022-08-02 18:01:03.581124 Epoch [176/250], Step [0050/0060], Loss1: -0.9877 Loss2: -0.9819 Loss3: -0.9897\n",
            "2022-08-02 18:01:09.403497 Epoch [176/250], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9859 Loss3: -0.9931\n",
            "Epoch: 176 MAE: 58.571452094706174 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:01:17.049528 Epoch [177/250], Step [0001/0060], Loss1: -0.9861 Loss2: -0.9818 Loss3: -0.9893\n",
            "2022-08-02 18:01:45.701448 Epoch [177/250], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9866 Loss3: -0.9926\n",
            "2022-08-02 18:01:51.539562 Epoch [177/250], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9875 Loss3: -0.9926\n",
            "Epoch: 177 MAE: 58.52756127442602 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:01:59.225319 Epoch [178/250], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9872 Loss3: -0.9920\n",
            "2022-08-02 18:02:27.980909 Epoch [178/250], Step [0050/0060], Loss1: -0.9913 Loss2: -0.9877 Loss3: -0.9924\n",
            "2022-08-02 18:02:33.833953 Epoch [178/250], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9860 Loss3: -0.9920\n",
            "Epoch: 178 MAE: 58.39566398374658 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:02:41.497063 Epoch [179/250], Step [0001/0060], Loss1: -0.9857 Loss2: -0.9779 Loss3: -0.9879\n",
            "2022-08-02 18:03:10.295998 Epoch [179/250], Step [0050/0060], Loss1: -0.9928 Loss2: -0.9892 Loss3: -0.9939\n",
            "2022-08-02 18:03:16.139584 Epoch [179/250], Step [0060/0060], Loss1: -0.9893 Loss2: -0.9840 Loss3: -0.9910\n",
            "Epoch: 179 MAE: 58.45485831237986 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:03:23.822457 Epoch [180/250], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9847 Loss3: -0.9922\n",
            "2022-08-02 18:03:52.553156 Epoch [180/250], Step [0050/0060], Loss1: -0.9920 Loss2: -0.9879 Loss3: -0.9931\n",
            "2022-08-02 18:03:58.443857 Epoch [180/250], Step [0060/0060], Loss1: -0.9898 Loss2: -0.9808 Loss3: -0.9912\n",
            "Epoch: 180 MAE: 58.386187832641895 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:04:08.525652 Epoch [181/250], Step [0001/0060], Loss1: -0.9881 Loss2: -0.9842 Loss3: -0.9898\n",
            "2022-08-02 18:04:37.965960 Epoch [181/250], Step [0050/0060], Loss1: -0.9913 Loss2: -0.9884 Loss3: -0.9924\n",
            "2022-08-02 18:04:43.758630 Epoch [181/250], Step [0060/0060], Loss1: -0.9876 Loss2: -0.9833 Loss3: -0.9895\n",
            "Epoch: 181 MAE: 58.43618824182592 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:04:51.417764 Epoch [182/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9844 Loss3: -0.9912\n",
            "2022-08-02 18:05:20.133517 Epoch [182/250], Step [0050/0060], Loss1: -0.9891 Loss2: -0.9838 Loss3: -0.9906\n",
            "2022-08-02 18:05:25.991072 Epoch [182/250], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9857 Loss3: -0.9917\n",
            "Epoch: 182 MAE: 58.4370186019462 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:05:33.602201 Epoch [183/250], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9865 Loss3: -0.9926\n",
            "2022-08-02 18:06:02.332111 Epoch [183/250], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9845 Loss3: -0.9923\n",
            "2022-08-02 18:06:08.186814 Epoch [183/250], Step [0060/0060], Loss1: -0.9872 Loss2: -0.9810 Loss3: -0.9890\n",
            "Epoch: 183 MAE: 58.49636669829302 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:06:15.912901 Epoch [184/250], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9877 Loss3: -0.9923\n",
            "2022-08-02 18:06:44.525333 Epoch [184/250], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9856 Loss3: -0.9927\n",
            "2022-08-02 18:06:50.308596 Epoch [184/250], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9876 Loss3: -0.9927\n",
            "Epoch: 184 MAE: 58.529854624439075 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:06:58.191033 Epoch [185/250], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9879 Loss3: -0.9926\n",
            "2022-08-02 18:07:27.018785 Epoch [185/250], Step [0050/0060], Loss1: -0.9916 Loss2: -0.9886 Loss3: -0.9932\n",
            "2022-08-02 18:07:32.832167 Epoch [185/250], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9878 Loss3: -0.9928\n",
            "Epoch: 185 MAE: 58.51444297589614 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:07:42.856652 Epoch [186/250], Step [0001/0060], Loss1: -0.9873 Loss2: -0.9811 Loss3: -0.9890\n",
            "2022-08-02 18:08:11.535400 Epoch [186/250], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9851 Loss3: -0.9914\n",
            "2022-08-02 18:08:17.325044 Epoch [186/250], Step [0060/0060], Loss1: -0.9916 Loss2: -0.9878 Loss3: -0.9928\n",
            "Epoch: 186 MAE: 58.51125439403227 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:08:25.125349 Epoch [187/250], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9865 Loss3: -0.9923\n",
            "2022-08-02 18:08:53.629612 Epoch [187/250], Step [0050/0060], Loss1: -0.9881 Loss2: -0.9803 Loss3: -0.9896\n",
            "2022-08-02 18:08:59.550864 Epoch [187/250], Step [0060/0060], Loss1: -0.9924 Loss2: -0.9893 Loss3: -0.9936\n",
            "Epoch: 187 MAE: 58.58021788796265 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:09:07.265287 Epoch [188/250], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9858 Loss3: -0.9919\n",
            "2022-08-02 18:09:35.586133 Epoch [188/250], Step [0050/0060], Loss1: -0.9887 Loss2: -0.9831 Loss3: -0.9904\n",
            "2022-08-02 18:09:41.392839 Epoch [188/250], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9872 Loss3: -0.9923\n",
            "Epoch: 188 MAE: 58.37394988362938 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:09:49.117635 Epoch [189/250], Step [0001/0060], Loss1: -0.9886 Loss2: -0.9859 Loss3: -0.9904\n",
            "2022-08-02 18:10:17.550369 Epoch [189/250], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9865 Loss3: -0.9921\n",
            "2022-08-02 18:10:23.413911 Epoch [189/250], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9876 Loss3: -0.9931\n",
            "Epoch: 189 MAE: 58.57879011196953 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:10:31.147723 Epoch [190/250], Step [0001/0060], Loss1: -0.9921 Loss2: -0.9880 Loss3: -0.9932\n",
            "2022-08-02 18:11:00.135837 Epoch [190/250], Step [0050/0060], Loss1: -0.9916 Loss2: -0.9870 Loss3: -0.9929\n",
            "2022-08-02 18:11:05.975267 Epoch [190/250], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9878 Loss3: -0.9929\n",
            "Epoch: 190 MAE: 58.52871418369124 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:11:16.085435 Epoch [191/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9842 Loss3: -0.9914\n",
            "2022-08-02 18:11:45.709378 Epoch [191/250], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9849 Loss3: -0.9918\n",
            "2022-08-02 18:11:51.599643 Epoch [191/250], Step [0060/0060], Loss1: -0.9878 Loss2: -0.9822 Loss3: -0.9894\n",
            "Epoch: 191 MAE: 58.496242617066535 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:11:59.271523 Epoch [192/250], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9841 Loss3: -0.9914\n",
            "2022-08-02 18:12:28.093129 Epoch [192/250], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9860 Loss3: -0.9919\n",
            "2022-08-02 18:12:33.916280 Epoch [192/250], Step [0060/0060], Loss1: -0.9919 Loss2: -0.9878 Loss3: -0.9930\n",
            "Epoch: 192 MAE: 58.59583179122763 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:12:41.669367 Epoch [193/250], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9874 Loss3: -0.9926\n",
            "2022-08-02 18:13:10.438792 Epoch [193/250], Step [0050/0060], Loss1: -0.9918 Loss2: -0.9860 Loss3: -0.9931\n",
            "2022-08-02 18:13:16.269856 Epoch [193/250], Step [0060/0060], Loss1: -0.9883 Loss2: -0.9822 Loss3: -0.9900\n",
            "Epoch: 193 MAE: 58.444207221944836 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:13:23.998878 Epoch [194/250], Step [0001/0060], Loss1: -0.9922 Loss2: -0.9886 Loss3: -0.9935\n",
            "2022-08-02 18:13:52.968368 Epoch [194/250], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9826 Loss3: -0.9923\n",
            "2022-08-02 18:13:58.970131 Epoch [194/250], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9872 Loss3: -0.9926\n",
            "Epoch: 194 MAE: 58.51377392180131 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:14:06.816636 Epoch [195/250], Step [0001/0060], Loss1: -0.9869 Loss2: -0.9808 Loss3: -0.9889\n",
            "2022-08-02 18:14:35.663264 Epoch [195/250], Step [0050/0060], Loss1: -0.9916 Loss2: -0.9864 Loss3: -0.9929\n",
            "2022-08-02 18:14:41.518074 Epoch [195/250], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9839 Loss3: -0.9910\n",
            "Epoch: 195 MAE: 58.426595651548546 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:14:51.713912 Epoch [196/250], Step [0001/0060], Loss1: -0.9897 Loss2: -0.9842 Loss3: -0.9911\n",
            "2022-08-02 18:15:21.339034 Epoch [196/250], Step [0050/0060], Loss1: -0.9925 Loss2: -0.9877 Loss3: -0.9936\n",
            "2022-08-02 18:15:27.248331 Epoch [196/250], Step [0060/0060], Loss1: -0.9858 Loss2: -0.9789 Loss3: -0.9885\n",
            "Epoch: 196 MAE: 58.41230166533569 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:15:35.012561 Epoch [197/250], Step [0001/0060], Loss1: -0.9887 Loss2: -0.9840 Loss3: -0.9904\n",
            "2022-08-02 18:16:03.790571 Epoch [197/250], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9858 Loss3: -0.9920\n",
            "2022-08-02 18:16:09.668338 Epoch [197/250], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9869 Loss3: -0.9929\n",
            "Epoch: 197 MAE: 58.547715245366476 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:16:17.395741 Epoch [198/250], Step [0001/0060], Loss1: -0.9904 Loss2: -0.9860 Loss3: -0.9917\n",
            "2022-08-02 18:16:46.285065 Epoch [198/250], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9856 Loss3: -0.9923\n",
            "2022-08-02 18:16:52.082212 Epoch [198/250], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9880 Loss3: -0.9927\n",
            "Epoch: 198 MAE: 58.399251117057325 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:16:59.903943 Epoch [199/250], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9852 Loss3: -0.9912\n",
            "2022-08-02 18:17:28.633857 Epoch [199/250], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9851 Loss3: -0.9921\n",
            "2022-08-02 18:17:34.483560 Epoch [199/250], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9865 Loss3: -0.9921\n",
            "Epoch: 199 MAE: 58.56628904261163 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:17:42.227993 Epoch [200/250], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9823 Loss3: -0.9913\n",
            "2022-08-02 18:18:10.978795 Epoch [200/250], Step [0050/0060], Loss1: -0.9917 Loss2: -0.9873 Loss3: -0.9929\n",
            "2022-08-02 18:18:17.005449 Epoch [200/250], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9863 Loss3: -0.9916\n",
            "Epoch: 200 MAE: 58.51729467846298 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:18:27.348545 Epoch [201/250], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9835 Loss3: -0.9913\n",
            "2022-08-02 18:18:56.823364 Epoch [201/250], Step [0050/0060], Loss1: -0.9889 Loss2: -0.9848 Loss3: -0.9909\n",
            "2022-08-02 18:19:02.651616 Epoch [201/250], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9837 Loss3: -0.9909\n",
            "Epoch: 201 MAE: 58.45746057193425 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:19:10.492113 Epoch [202/250], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9834 Loss3: -0.9912\n",
            "2022-08-02 18:19:39.395640 Epoch [202/250], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9870 Loss3: -0.9920\n",
            "2022-08-02 18:19:45.248093 Epoch [202/250], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9859 Loss3: -0.9920\n",
            "Epoch: 202 MAE: 58.49615125494804 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:19:53.054444 Epoch [203/250], Step [0001/0060], Loss1: -0.9890 Loss2: -0.9846 Loss3: -0.9907\n",
            "2022-08-02 18:20:21.834956 Epoch [203/250], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9850 Loss3: -0.9919\n",
            "2022-08-02 18:20:27.718675 Epoch [203/250], Step [0060/0060], Loss1: -0.9891 Loss2: -0.9850 Loss3: -0.9909\n",
            "Epoch: 203 MAE: 58.505798710464624 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:20:35.496390 Epoch [204/250], Step [0001/0060], Loss1: -0.9872 Loss2: -0.9806 Loss3: -0.9892\n",
            "2022-08-02 18:21:04.319226 Epoch [204/250], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9879 Loss3: -0.9922\n",
            "2022-08-02 18:21:10.165471 Epoch [204/250], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9844 Loss3: -0.9912\n",
            "Epoch: 204 MAE: 58.413953080805896 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:21:17.958035 Epoch [205/250], Step [0001/0060], Loss1: -0.9913 Loss2: -0.9854 Loss3: -0.9927\n",
            "2022-08-02 18:21:46.868658 Epoch [205/250], Step [0050/0060], Loss1: -0.9856 Loss2: -0.9774 Loss3: -0.9877\n",
            "2022-08-02 18:21:52.716264 Epoch [205/250], Step [0060/0060], Loss1: -0.9918 Loss2: -0.9886 Loss3: -0.9930\n",
            "Epoch: 205 MAE: 58.43150141585052 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:22:03.124092 Epoch [206/250], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9856 Loss3: -0.9916\n",
            "2022-08-02 18:22:31.993648 Epoch [206/250], Step [0050/0060], Loss1: -0.9894 Loss2: -0.9832 Loss3: -0.9912\n",
            "2022-08-02 18:22:37.831503 Epoch [206/250], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9871 Loss3: -0.9919\n",
            "Epoch: 206 MAE: 58.5464122854286 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:22:45.615336 Epoch [207/250], Step [0001/0060], Loss1: -0.9885 Loss2: -0.9838 Loss3: -0.9901\n",
            "2022-08-02 18:23:14.566261 Epoch [207/250], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9862 Loss3: -0.9916\n",
            "2022-08-02 18:23:20.458313 Epoch [207/250], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9857 Loss3: -0.9924\n",
            "Epoch: 207 MAE: 58.4626331080092 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:23:28.173810 Epoch [208/250], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9846 Loss3: -0.9916\n",
            "2022-08-02 18:23:57.041324 Epoch [208/250], Step [0050/0060], Loss1: -0.9913 Loss2: -0.9852 Loss3: -0.9924\n",
            "2022-08-02 18:24:02.899051 Epoch [208/250], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9865 Loss3: -0.9924\n",
            "Epoch: 208 MAE: 58.59133147722457 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:24:10.770432 Epoch [209/250], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9849 Loss3: -0.9910\n",
            "2022-08-02 18:24:39.830969 Epoch [209/250], Step [0050/0060], Loss1: -0.9878 Loss2: -0.9826 Loss3: -0.9897\n",
            "2022-08-02 18:24:45.649655 Epoch [209/250], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9877 Loss3: -0.9927\n",
            "Epoch: 209 MAE: 58.514470201649296 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:24:53.544121 Epoch [210/250], Step [0001/0060], Loss1: -0.9897 Loss2: -0.9838 Loss3: -0.9912\n",
            "2022-08-02 18:25:22.388727 Epoch [210/250], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9870 Loss3: -0.9922\n",
            "2022-08-02 18:25:28.311620 Epoch [210/250], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9879 Loss3: -0.9927\n",
            "Epoch: 210 MAE: 58.52935723719236 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:25:38.469811 Epoch [211/250], Step [0001/0060], Loss1: -0.9917 Loss2: -0.9885 Loss3: -0.9931\n",
            "2022-08-02 18:26:08.107742 Epoch [211/250], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9863 Loss3: -0.9917\n",
            "2022-08-02 18:26:13.980130 Epoch [211/250], Step [0060/0060], Loss1: -0.9880 Loss2: -0.9826 Loss3: -0.9898\n",
            "Epoch: 211 MAE: 58.40209869836074 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:26:21.723838 Epoch [212/250], Step [0001/0060], Loss1: -0.9879 Loss2: -0.9813 Loss3: -0.9898\n",
            "2022-08-02 18:26:50.561720 Epoch [212/250], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9851 Loss3: -0.9918\n",
            "2022-08-02 18:26:56.490376 Epoch [212/250], Step [0060/0060], Loss1: -0.9920 Loss2: -0.9877 Loss3: -0.9932\n",
            "Epoch: 212 MAE: 58.51142622044051 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:27:04.182774 Epoch [213/250], Step [0001/0060], Loss1: -0.9918 Loss2: -0.9871 Loss3: -0.9931\n",
            "2022-08-02 18:27:33.006252 Epoch [213/250], Step [0050/0060], Loss1: -0.9885 Loss2: -0.9833 Loss3: -0.9902\n",
            "2022-08-02 18:27:38.885094 Epoch [213/250], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9857 Loss3: -0.9909\n",
            "Epoch: 213 MAE: 58.389363383389295 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:27:46.628994 Epoch [214/250], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9851 Loss3: -0.9925\n",
            "2022-08-02 18:28:15.377020 Epoch [214/250], Step [0050/0060], Loss1: -0.9861 Loss2: -0.9790 Loss3: -0.9880\n",
            "2022-08-02 18:28:21.177717 Epoch [214/250], Step [0060/0060], Loss1: -0.9893 Loss2: -0.9847 Loss3: -0.9909\n",
            "Epoch: 214 MAE: 58.38277481259019 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:28:28.964821 Epoch [215/250], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9857 Loss3: -0.9923\n",
            "2022-08-02 18:28:57.693143 Epoch [215/250], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9859 Loss3: -0.9924\n",
            "2022-08-02 18:29:03.572895 Epoch [215/250], Step [0060/0060], Loss1: -0.9925 Loss2: -0.9892 Loss3: -0.9938\n",
            "Epoch: 215 MAE: 58.44512791588301 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:29:13.954285 Epoch [216/250], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9839 Loss3: -0.9920\n",
            "2022-08-02 18:29:43.078450 Epoch [216/250], Step [0050/0060], Loss1: -0.9857 Loss2: -0.9786 Loss3: -0.9883\n",
            "2022-08-02 18:29:48.901212 Epoch [216/250], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9857 Loss3: -0.9916\n",
            "Epoch: 216 MAE: 58.426365734280814 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:29:56.715700 Epoch [217/250], Step [0001/0060], Loss1: -0.9892 Loss2: -0.9858 Loss3: -0.9908\n",
            "2022-08-02 18:30:25.511709 Epoch [217/250], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9860 Loss3: -0.9917\n",
            "2022-08-02 18:30:31.360643 Epoch [217/250], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9848 Loss3: -0.9914\n",
            "Epoch: 217 MAE: 58.34354198500386 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:30:39.132421 Epoch [218/250], Step [0001/0060], Loss1: -0.9919 Loss2: -0.9872 Loss3: -0.9930\n",
            "2022-08-02 18:31:07.853152 Epoch [218/250], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9844 Loss3: -0.9918\n",
            "2022-08-02 18:31:13.727574 Epoch [218/250], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9873 Loss3: -0.9932\n",
            "Epoch: 218 MAE: 58.595224406418794 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:31:21.403305 Epoch [219/250], Step [0001/0060], Loss1: -0.9884 Loss2: -0.9838 Loss3: -0.9901\n",
            "2022-08-02 18:31:50.392276 Epoch [219/250], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9854 Loss3: -0.9922\n",
            "2022-08-02 18:31:56.249455 Epoch [219/250], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9870 Loss3: -0.9927\n",
            "Epoch: 219 MAE: 58.553663109984186 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:32:04.052311 Epoch [220/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9846 Loss3: -0.9918\n",
            "2022-08-02 18:32:33.054115 Epoch [220/250], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9844 Loss3: -0.9918\n",
            "2022-08-02 18:32:38.909352 Epoch [220/250], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9843 Loss3: -0.9921\n",
            "Epoch: 220 MAE: 58.51393545988028 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:32:49.301312 Epoch [221/250], Step [0001/0060], Loss1: -0.9894 Loss2: -0.9855 Loss3: -0.9909\n",
            "2022-08-02 18:33:18.599209 Epoch [221/250], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9806 Loss3: -0.9904\n",
            "2022-08-02 18:33:24.449447 Epoch [221/250], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9853 Loss3: -0.9926\n",
            "Epoch: 221 MAE: 58.45146665177165 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:33:32.151324 Epoch [222/250], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9861 Loss3: -0.9913\n",
            "2022-08-02 18:34:01.065148 Epoch [222/250], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9864 Loss3: -0.9926\n",
            "2022-08-02 18:34:07.018534 Epoch [222/250], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9868 Loss3: -0.9927\n",
            "Epoch: 222 MAE: 58.55044840585446 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:34:14.765801 Epoch [223/250], Step [0001/0060], Loss1: -0.9897 Loss2: -0.9825 Loss3: -0.9911\n",
            "2022-08-02 18:34:43.552836 Epoch [223/250], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9871 Loss3: -0.9929\n",
            "2022-08-02 18:34:49.436931 Epoch [223/250], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9866 Loss3: -0.9926\n",
            "Epoch: 223 MAE: 58.49818298193323 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:34:57.044013 Epoch [224/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9840 Loss3: -0.9917\n",
            "2022-08-02 18:35:25.703936 Epoch [224/250], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9842 Loss3: -0.9920\n",
            "2022-08-02 18:35:31.549708 Epoch [224/250], Step [0060/0060], Loss1: -0.9875 Loss2: -0.9824 Loss3: -0.9894\n",
            "Epoch: 224 MAE: 58.43441057013176 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:35:39.324379 Epoch [225/250], Step [0001/0060], Loss1: -0.9897 Loss2: -0.9828 Loss3: -0.9910\n",
            "2022-08-02 18:36:08.098202 Epoch [225/250], Step [0050/0060], Loss1: -0.9898 Loss2: -0.9855 Loss3: -0.9911\n",
            "2022-08-02 18:36:13.952140 Epoch [225/250], Step [0060/0060], Loss1: -0.9919 Loss2: -0.9876 Loss3: -0.9931\n",
            "Epoch: 225 MAE: 58.54785615504566 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:36:24.029197 Epoch [226/250], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9859 Loss3: -0.9923\n",
            "2022-08-02 18:36:53.435432 Epoch [226/250], Step [0050/0060], Loss1: -0.9926 Loss2: -0.9894 Loss3: -0.9937\n",
            "2022-08-02 18:36:59.284465 Epoch [226/250], Step [0060/0060], Loss1: -0.9851 Loss2: -0.9786 Loss3: -0.9882\n",
            "Epoch: 226 MAE: 58.480492547031425 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:37:07.107981 Epoch [227/250], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9832 Loss3: -0.9915\n",
            "2022-08-02 18:37:35.831937 Epoch [227/250], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9859 Loss3: -0.9915\n",
            "2022-08-02 18:37:41.708492 Epoch [227/250], Step [0060/0060], Loss1: -0.9923 Loss2: -0.9889 Loss3: -0.9935\n",
            "Epoch: 227 MAE: 58.54319572355155 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:37:49.302996 Epoch [228/250], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9859 Loss3: -0.9921\n",
            "2022-08-02 18:38:17.961072 Epoch [228/250], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9870 Loss3: -0.9922\n",
            "2022-08-02 18:38:23.734150 Epoch [228/250], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9841 Loss3: -0.9913\n",
            "Epoch: 228 MAE: 58.533350868618015 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:38:31.384954 Epoch [229/250], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9824 Loss3: -0.9909\n",
            "2022-08-02 18:38:59.863179 Epoch [229/250], Step [0050/0060], Loss1: -0.9897 Loss2: -0.9842 Loss3: -0.9911\n",
            "2022-08-02 18:39:05.673306 Epoch [229/250], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9858 Loss3: -0.9925\n",
            "Epoch: 229 MAE: 58.537672749003285 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:39:13.433038 Epoch [230/250], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9851 Loss3: -0.9917\n",
            "2022-08-02 18:39:42.164403 Epoch [230/250], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9816 Loss3: -0.9911\n",
            "2022-08-02 18:39:47.997574 Epoch [230/250], Step [0060/0060], Loss1: -0.9889 Loss2: -0.9827 Loss3: -0.9906\n",
            "Epoch: 230 MAE: 58.427092848699935 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:39:58.327151 Epoch [231/250], Step [0001/0060], Loss1: -0.9915 Loss2: -0.9873 Loss3: -0.9928\n",
            "2022-08-02 18:40:27.412760 Epoch [231/250], Step [0050/0060], Loss1: -0.9897 Loss2: -0.9832 Loss3: -0.9913\n",
            "2022-08-02 18:40:33.282504 Epoch [231/250], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9858 Loss3: -0.9915\n",
            "Epoch: 231 MAE: 58.4542814159226 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:40:41.057503 Epoch [232/250], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9873 Loss3: -0.9926\n",
            "2022-08-02 18:41:09.787950 Epoch [232/250], Step [0050/0060], Loss1: -0.9872 Loss2: -0.9813 Loss3: -0.9890\n",
            "2022-08-02 18:41:15.599288 Epoch [232/250], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9871 Loss3: -0.9925\n",
            "Epoch: 232 MAE: 58.44735291599498 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:41:23.264421 Epoch [233/250], Step [0001/0060], Loss1: -0.9897 Loss2: -0.9855 Loss3: -0.9911\n",
            "2022-08-02 18:41:51.808189 Epoch [233/250], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9863 Loss3: -0.9920\n",
            "2022-08-02 18:41:57.621282 Epoch [233/250], Step [0060/0060], Loss1: -0.9891 Loss2: -0.9850 Loss3: -0.9906\n",
            "Epoch: 233 MAE: 58.50691829007443 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:42:05.334520 Epoch [234/250], Step [0001/0060], Loss1: -0.9884 Loss2: -0.9829 Loss3: -0.9900\n",
            "2022-08-02 18:42:34.230320 Epoch [234/250], Step [0050/0060], Loss1: -0.9919 Loss2: -0.9888 Loss3: -0.9931\n",
            "2022-08-02 18:42:40.107648 Epoch [234/250], Step [0060/0060], Loss1: -0.9919 Loss2: -0.9887 Loss3: -0.9931\n",
            "Epoch: 234 MAE: 58.50282466389168 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:42:47.938231 Epoch [235/250], Step [0001/0060], Loss1: -0.9891 Loss2: -0.9833 Loss3: -0.9909\n",
            "2022-08-02 18:43:16.620692 Epoch [235/250], Step [0050/0060], Loss1: -0.9920 Loss2: -0.9889 Loss3: -0.9931\n",
            "2022-08-02 18:43:22.459926 Epoch [235/250], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9864 Loss3: -0.9921\n",
            "Epoch: 235 MAE: 58.46243881909673 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:43:32.797236 Epoch [236/250], Step [0001/0060], Loss1: -0.9894 Loss2: -0.9841 Loss3: -0.9911\n",
            "2022-08-02 18:44:01.932165 Epoch [236/250], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9838 Loss3: -0.9905\n",
            "2022-08-02 18:44:07.766542 Epoch [236/250], Step [0060/0060], Loss1: -0.9910 Loss2: -0.9878 Loss3: -0.9927\n",
            "Epoch: 236 MAE: 58.44142028739076 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:44:15.462894 Epoch [237/250], Step [0001/0060], Loss1: -0.9921 Loss2: -0.9880 Loss3: -0.9933\n",
            "2022-08-02 18:44:44.396925 Epoch [237/250], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9831 Loss3: -0.9907\n",
            "2022-08-02 18:44:50.220128 Epoch [237/250], Step [0060/0060], Loss1: -0.9918 Loss2: -0.9877 Loss3: -0.9931\n",
            "Epoch: 237 MAE: 58.4604332879296 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:44:57.896968 Epoch [238/250], Step [0001/0060], Loss1: -0.9890 Loss2: -0.9852 Loss3: -0.9913\n",
            "2022-08-02 18:45:26.807693 Epoch [238/250], Step [0050/0060], Loss1: -0.9913 Loss2: -0.9872 Loss3: -0.9928\n",
            "2022-08-02 18:45:32.706686 Epoch [238/250], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9853 Loss3: -0.9921\n",
            "Epoch: 238 MAE: 58.43756401137685 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:45:40.573711 Epoch [239/250], Step [0001/0060], Loss1: -0.9915 Loss2: -0.9859 Loss3: -0.9929\n",
            "2022-08-02 18:46:09.395225 Epoch [239/250], Step [0050/0060], Loss1: -0.9879 Loss2: -0.9824 Loss3: -0.9896\n",
            "2022-08-02 18:46:15.291196 Epoch [239/250], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9869 Loss3: -0.9921\n",
            "Epoch: 239 MAE: 58.546796519180766 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:46:23.198862 Epoch [240/250], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9815 Loss3: -0.9911\n",
            "2022-08-02 18:46:51.916265 Epoch [240/250], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9871 Loss3: -0.9928\n",
            "2022-08-02 18:46:57.784836 Epoch [240/250], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9867 Loss3: -0.9926\n",
            "Epoch: 240 MAE: 58.46726327803801 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:47:07.772650 Epoch [241/250], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9861 Loss3: -0.9924\n",
            "2022-08-02 18:47:36.819574 Epoch [241/250], Step [0050/0060], Loss1: -0.9869 Loss2: -0.9813 Loss3: -0.9886\n",
            "2022-08-02 18:47:42.667748 Epoch [241/250], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9844 Loss3: -0.9915\n",
            "Epoch: 241 MAE: 58.410648665189285 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:47:50.457037 Epoch [242/250], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9838 Loss3: -0.9911\n",
            "2022-08-02 18:48:19.426003 Epoch [242/250], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9851 Loss3: -0.9917\n",
            "2022-08-02 18:48:25.283413 Epoch [242/250], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9889 Loss3: -0.9932\n",
            "Epoch: 242 MAE: 58.50892145528931 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:48:32.933771 Epoch [243/250], Step [0001/0060], Loss1: -0.9919 Loss2: -0.9886 Loss3: -0.9931\n",
            "2022-08-02 18:49:01.702163 Epoch [243/250], Step [0050/0060], Loss1: -0.9912 Loss2: -0.9867 Loss3: -0.9926\n",
            "2022-08-02 18:49:07.534588 Epoch [243/250], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9859 Loss3: -0.9925\n",
            "Epoch: 243 MAE: 58.61269848661403 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:49:15.284991 Epoch [244/250], Step [0001/0060], Loss1: -0.9881 Loss2: -0.9843 Loss3: -0.9901\n",
            "2022-08-02 18:49:44.092356 Epoch [244/250], Step [0050/0060], Loss1: -0.9917 Loss2: -0.9867 Loss3: -0.9931\n",
            "2022-08-02 18:49:50.015778 Epoch [244/250], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9852 Loss3: -0.9917\n",
            "Epoch: 244 MAE: 58.52675335395715 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:49:57.745473 Epoch [245/250], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9837 Loss3: -0.9916\n",
            "2022-08-02 18:50:26.564930 Epoch [245/250], Step [0050/0060], Loss1: -0.9876 Loss2: -0.9828 Loss3: -0.9895\n",
            "2022-08-02 18:50:32.469166 Epoch [245/250], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9878 Loss3: -0.9927\n",
            "Epoch: 245 MAE: 58.376691500259355 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:50:42.606367 Epoch [246/250], Step [0001/0060], Loss1: -0.9887 Loss2: -0.9825 Loss3: -0.9904\n",
            "2022-08-02 18:51:12.027444 Epoch [246/250], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9859 Loss3: -0.9925\n",
            "2022-08-02 18:51:17.804167 Epoch [246/250], Step [0060/0060], Loss1: -0.9918 Loss2: -0.9866 Loss3: -0.9930\n",
            "Epoch: 246 MAE: 58.50478380533383 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:51:25.558023 Epoch [247/250], Step [0001/0060], Loss1: -0.9913 Loss2: -0.9866 Loss3: -0.9927\n",
            "2022-08-02 18:51:54.488754 Epoch [247/250], Step [0050/0060], Loss1: -0.9918 Loss2: -0.9871 Loss3: -0.9932\n",
            "2022-08-02 18:52:00.387786 Epoch [247/250], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9863 Loss3: -0.9922\n",
            "Epoch: 247 MAE: 58.44048265712621 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:52:08.252705 Epoch [248/250], Step [0001/0060], Loss1: -0.9904 Loss2: -0.9870 Loss3: -0.9918\n",
            "2022-08-02 18:52:37.254221 Epoch [248/250], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9864 Loss3: -0.9923\n",
            "2022-08-02 18:52:43.091114 Epoch [248/250], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9863 Loss3: -0.9917\n",
            "Epoch: 248 MAE: 58.63641068603693 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n",
            "2022-08-02 18:52:50.727872 Epoch [249/250], Step [0001/0060], Loss1: -0.9892 Loss2: -0.9824 Loss3: -0.9907\n",
            "2022-08-02 18:53:19.483189 Epoch [249/250], Step [0050/0060], Loss1: -0.9881 Loss2: -0.9833 Loss3: -0.9899\n",
            "2022-08-02 18:53:25.383746 Epoch [249/250], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9872 Loss3: -0.9926\n",
            "Epoch: 249 MAE: 58.54337352513371 ####  bestMAE: 58.265671346796104 bestEpoch: 151\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from urllib.request import ProxyBasicAuthHandler\n",
        "import torch.nn.functional as nnf\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "train_accu = []\n",
        "train_losses = []\n",
        "train_accu1 = []\n",
        "train_accu2 = []\n",
        "train_accu3 = []\n",
        "train_losses1 = []\n",
        "train_losses2 = []\n",
        "train_losses3 = []\n",
        "val_accu = []\n",
        "val_losses = []\n",
        "\n",
        "# PSNR metrics\n",
        "def psnr(target, ref):\n",
        "         \n",
        "    # assume RGB image\n",
        "    target_data = torch.tensor(target, dtype=float)\n",
        "    ref_data = torch.tensor(ref, dtype=float) \n",
        "    diff = ref_data - target_data\n",
        "    \n",
        "    diff = diff.flatten()\n",
        "    \n",
        "    rmse = math.sqrt(torch.mean(diff ** 2.))\n",
        "\n",
        "    return 20 * math.log10(255. / rmse)\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    running_loss = 0\n",
        "    running_loss1 = 0\n",
        "    running_loss2 = 0\n",
        "    running_loss3 = 0\n",
        "    total = 0\n",
        "    total1 = 0\n",
        "    total2 = 0\n",
        "    total3 = 0\n",
        "    correct = 0\n",
        "    correct1 = 0\n",
        "    correct2 = 0\n",
        "    correct3 = 0\n",
        "\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = fun_ssim(gts, pre_res[0]) \n",
        "            loss2    = fun_ssim(gts, pre_res[1])\n",
        "            loss3    = fun_ssim(gts, pre_res[2])\n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "\n",
        "            #loss graph\n",
        "            running_loss1 += loss1.item()\n",
        "            running_loss2 += loss2.item()\n",
        "            running_loss3 += loss3.item()\n",
        "            predicted1 = pre_res[0]\n",
        "            predicted2 = pre_res[1]\n",
        "            predicted3 = pre_res[2]\n",
        "            total1 += images.size(0)\n",
        "            total2 += gts.size(0)\n",
        "            total3 += depths.size(0)\n",
        "            #correct1 += float(torch.sum(predicted1 == gts.data))\n",
        "            #correct2 += float(torch.sum(predicted2 == gts.data))\n",
        "            #correct3 += float(torch.sum(predicted3 == gts.data))\n",
        "            correct1 += predicted1.eq(images).sum().item()\n",
        "            correct2 += predicted2.eq(gts).sum().item()\n",
        "            correct3 += predicted3.eq(depths).sum().item()\n",
        "\n",
        "            running_loss += loss_all.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = torch.sum(gt + loss + predicted)\n",
        "            total += images.size(0)\n",
        "            correct += float(correct1 + correct2 + correct3)\n",
        "            \n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "\n",
        "        train_loss = running_loss/len(train_loader)\n",
        "        train_loss1=running_loss1/len(train_loader)\n",
        "        train_loss2=running_loss2/len(train_loader)\n",
        "        train_loss3=running_loss3/len(train_loader)\n",
        "        accu1= correct1/total1\n",
        "        accu2= correct2/total2\n",
        "        accu3= correct3/total3 \n",
        "        accu = correct/total\n",
        "           \n",
        "        train_accu1.append(round(accu1, 3))\n",
        "        train_accu2.append(round(accu2, 3))\n",
        "        train_accu3.append(round(accu3, 3))\n",
        "        train_losses1.append(float(train_loss1))\n",
        "        train_losses2.append(float(train_loss2))\n",
        "        train_losses3.append(float(train_loss3))\n",
        "        train_accu.append(round(accu, 3))\n",
        "        train_losses.append(float(train_loss))\n",
        "\n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "           \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0.0\n",
        "\n",
        "    correct1 = 0.0\n",
        "    correct2 = 0.0\n",
        "    correct3 = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-4)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            #res     = (res - res.min()) / (res.max() - res.min() + 1e-4)\n",
        "            #mae = np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "            #mae = np.mean((gt - res)**2)\n",
        "            mse = psnr(res, gt)\n",
        "            mae_sum += mse\n",
        "\n",
        "            #loss graph\n",
        "            running_loss += mae_sum\n",
        "            pre1, pre2, predicted = pre_res\n",
        "            #outputs = float(torch.sum(gt + depth + predicted))\n",
        "            total += test_loader.size\n",
        "\n",
        "            #correct1 += float(torch.sum(pre1 == image.data))\n",
        "            #correct2 += float(torch.sum(pre2 == image.data))\n",
        "            #correct3 += float(torch.sum(predicted == image.data))\n",
        "\n",
        "            correct += predicted.eq(image).sum().item()\n",
        "            #correct += float(torch.sum(predicted == image).item())\n",
        "\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "       \n",
        "        val_loss=running_loss/len(test_loader)\n",
        "        accu= 100 * correct/total\n",
        "        val_accu.append(round(accu, 3))\n",
        "        val_losses.append(float(val_loss))\n",
        "\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                #torch.save(model.state_dict(), save_path+'SPNet_epoch_best_Combine_Loss_only_with_RGB_as_depth.pth')\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_psnr_ssim1.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n",
        "\n",
        "plt.plot(train_losses, '-')\n",
        "plt.plot(train_losses1,'-')\n",
        "plt.plot(train_losses2,'-')\n",
        "plt.plot(train_losses3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Combined_loss','Loss1', 'Loss2', 'Loss3'])\n",
        "plt.title('Train Losses')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_accu, '-')\n",
        "plt.plot(train_accu1,'-')\n",
        "plt.plot(train_accu2,'-')\n",
        "plt.plot(train_accu3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Acc')\n",
        "plt.legend(['Combined_Accuracy','Acc1', 'Acc2', 'Acc3'])\n",
        "plt.title('Train Accuracy')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(val_losses,'-')\n",
        "plt.plot(val_accu,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Losses','Accuracy'])\n",
        "plt.title('Test Losses and Accuracy')\n",
        " \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with MS-SSIM Loss"
      ],
      "metadata": {
        "id": "q2V0EtsSkH8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wUek5bsikM12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with L1 loss"
      ],
      "metadata": {
        "id": "ZCz5s8d-kNgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import ProxyBasicAuthHandler\n",
        "import torch.nn.functional as nnf\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "\n",
        "#loss\n",
        "L1Loss = torch.nn.L1Loss()\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "train_accu = []\n",
        "train_losses = []\n",
        "train_accu1 = []\n",
        "train_accu2 = []\n",
        "train_accu3 = []\n",
        "train_losses1 = []\n",
        "train_losses2 = []\n",
        "train_losses3 = []\n",
        "val_accu = []\n",
        "val_losses = []\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    running_loss = 0\n",
        "    running_loss1 = 0\n",
        "    running_loss2 = 0\n",
        "    running_loss3 = 0\n",
        "    total = 0\n",
        "    total1 = 0\n",
        "    total2 = 0\n",
        "    total3 = 0\n",
        "    correct = 0\n",
        "    correct1 = 0\n",
        "    correct2 = 0\n",
        "    correct3 = 0\n",
        "\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = L1Loss(gts, pre_res[0]) \n",
        "            loss2    = L1Loss(gts, pre_res[1])\n",
        "            loss3    = L1Loss(gts, pre_res[2])\n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "\n",
        "            #loss graph\n",
        "            running_loss1 += loss1.item()\n",
        "            running_loss2 += loss2.item()\n",
        "            running_loss3 += loss3.item()\n",
        "            predicted1 = pre_res[0]\n",
        "            predicted2 = pre_res[1]\n",
        "            predicted3 = pre_res[2]\n",
        "            total1 += images.size(0)\n",
        "            total2 += gts.size(0)\n",
        "            total3 += depths.size(0)\n",
        "            #correct1 += float(torch.sum(predicted1 == gts.data))\n",
        "            #correct2 += float(torch.sum(predicted2 == gts.data))\n",
        "            #correct3 += float(torch.sum(predicted3 == gts.data))\n",
        "            correct1 += predicted1.eq(images).sum().item()\n",
        "            correct2 += predicted2.eq(gts).sum().item()\n",
        "            correct3 += predicted3.eq(depths).sum().item()\n",
        "\n",
        "            running_loss += loss_all.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = torch.sum(gt + loss + predicted)\n",
        "            total += images.size(0)\n",
        "            correct += float(correct1 + correct2 + correct3)\n",
        "            \n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "\n",
        "        train_loss = running_loss/len(train_loader)\n",
        "        train_loss1=running_loss1/len(train_loader)\n",
        "        train_loss2=running_loss2/len(train_loader)\n",
        "        train_loss3=running_loss3/len(train_loader)\n",
        "        accu1= correct1/total1\n",
        "        accu2= correct2/total2\n",
        "        accu3= correct3/total3 \n",
        "        accu = correct/total\n",
        "           \n",
        "        train_accu1.append(round(accu1, 3))\n",
        "        train_accu2.append(round(accu2, 3))\n",
        "        train_accu3.append(round(accu3, 3))\n",
        "        train_losses1.append(float(train_loss1))\n",
        "        train_losses2.append(float(train_loss2))\n",
        "        train_losses3.append(float(train_loss3))\n",
        "        train_accu.append(round(accu, 3))\n",
        "        train_losses.append(float(train_loss))\n",
        "\n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "           \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0.0\n",
        "\n",
        "    correct1 = 0.0\n",
        "    correct2 = 0.0\n",
        "    correct3 = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-4)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-4)\n",
        "            mae = np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "            mae = np.mean((gt - res)**2)\n",
        "            mae_sum += mae\n",
        "\n",
        "            #loss graph\n",
        "            running_loss += mae_sum\n",
        "            pre1, pre2, predicted = pre_res\n",
        "            #outputs = float(torch.sum(gt + depth + predicted))\n",
        "            total += test_loader.size\n",
        "\n",
        "            #correct1 += float(torch.sum(pre1 == image.data))\n",
        "            #correct2 += float(torch.sum(pre2 == image.data))\n",
        "            #correct3 += float(torch.sum(predicted == image.data))\n",
        "\n",
        "            correct += predicted.eq(image).sum().item()\n",
        "            #correct += float(torch.sum(predicted == image).item())\n",
        "\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "       \n",
        "        val_loss=running_loss/len(test_loader)\n",
        "        accu= 100 * correct/total\n",
        "        val_accu.append(round(accu, 3))\n",
        "        val_losses.append(float(val_loss))\n",
        "\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                #torch.save(model.state_dict(), save_path+'SPNet_epoch_best_Combine_Loss_only_with_RGB_as_depth.pth')\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_l1_loss.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n",
        "\n",
        "plt.plot(train_losses, '-')\n",
        "plt.plot(train_losses1,'-')\n",
        "plt.plot(train_losses2,'-')\n",
        "plt.plot(train_losses3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Combined_loss','Loss1', 'Loss2', 'Loss3'])\n",
        "plt.title('Train Losses')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_accu, '-')\n",
        "plt.plot(train_accu1,'-')\n",
        "plt.plot(train_accu2,'-')\n",
        "plt.plot(train_accu3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Acc')\n",
        "plt.legend(['Combined_Accuracy','Acc1', 'Acc2', 'Acc3'])\n",
        "plt.title('Train Accuracy')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(val_losses,'-')\n",
        "plt.plot(val_accu,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Losses','Accuracy'])\n",
        "plt.title('Test Losses and Accuracy')\n",
        " \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YJJ1jTonkP8r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "18fb49cda74b49b1bba4a1daa1150d4a",
            "1bd734e645d1461c8ca3eaa9de6b33df",
            "181dc99c9e074f31af80556b0fa351ae",
            "f0dd95ac020747d59eea02979fb6b000",
            "a908d4492b9648869a2dc42523144edf",
            "6873fdf4fd9a45e0826db1685ac9df2b",
            "6a82093eaf1e479db16e71ec28e32671",
            "2df8a1d6d3d448c3a74c2de0befdc799",
            "8c2a4d95688e427dbb441838fefe428a",
            "d472394639104e0daf46e59d69478491",
            "69b927c30c0e4f19a00eeb18281f0b75"
          ]
        },
        "outputId": "15f69e49-341f-4ccb-af44-3c67126adde5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE GPU 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://shanghuagao.oss-cn-beijing.aliyuncs.com/res2net/res2net50_v1b_26w_4s-3cf99910.pth\" to /root/.cache/torch/hub/checkpoints/res2net50_v1b_26w_4s-3cf99910.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/98.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18fb49cda74b49b1bba4a1daa1150d4a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load data...\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/traindataset_only_depth/RGB/depth_00.png', '/content/tmp/traindataset_only_depth/RGB/depth_01.png', '/content/tmp/traindataset_only_depth/RGB/depth_02.png', '/content/tmp/traindataset_only_depth/RGB/depth_10.png', '/content/tmp/traindataset_only_depth/RGB/depth_100.png', '/content/tmp/traindataset_only_depth/RGB/depth_101.png', '/content/tmp/traindataset_only_depth/RGB/depth_102.png', '/content/tmp/traindataset_only_depth/RGB/depth_11.png', '/content/tmp/traindataset_only_depth/RGB/depth_110.png', '/content/tmp/traindataset_only_depth/RGB/depth_111.png', '/content/tmp/traindataset_only_depth/RGB/depth_112.png', '/content/tmp/traindataset_only_depth/RGB/depth_12.png', '/content/tmp/traindataset_only_depth/RGB/depth_120.png', '/content/tmp/traindataset_only_depth/RGB/depth_121.png', '/content/tmp/traindataset_only_depth/RGB/depth_122.png', '/content/tmp/traindataset_only_depth/RGB/depth_130.png', '/content/tmp/traindataset_only_depth/RGB/depth_131.png', '/content/tmp/traindataset_only_depth/RGB/depth_132.png', '/content/tmp/traindataset_only_depth/RGB/depth_140.png', '/content/tmp/traindataset_only_depth/RGB/depth_141.png', '/content/tmp/traindataset_only_depth/RGB/depth_142.png', '/content/tmp/traindataset_only_depth/RGB/depth_150.png', '/content/tmp/traindataset_only_depth/RGB/depth_151.png', '/content/tmp/traindataset_only_depth/RGB/depth_152.png', '/content/tmp/traindataset_only_depth/RGB/depth_160.png', '/content/tmp/traindataset_only_depth/RGB/depth_161.png', '/content/tmp/traindataset_only_depth/RGB/depth_162.png', '/content/tmp/traindataset_only_depth/RGB/depth_170.png', '/content/tmp/traindataset_only_depth/RGB/depth_171.png', '/content/tmp/traindataset_only_depth/RGB/depth_172.png', '/content/tmp/traindataset_only_depth/RGB/depth_180.png', '/content/tmp/traindataset_only_depth/RGB/depth_181.png', '/content/tmp/traindataset_only_depth/RGB/depth_182.png', '/content/tmp/traindataset_only_depth/RGB/depth_190.png', '/content/tmp/traindataset_only_depth/RGB/depth_191.png', '/content/tmp/traindataset_only_depth/RGB/depth_192.png', '/content/tmp/traindataset_only_depth/RGB/depth_20.png', '/content/tmp/traindataset_only_depth/RGB/depth_200.png', '/content/tmp/traindataset_only_depth/RGB/depth_201.png', '/content/tmp/traindataset_only_depth/RGB/depth_202.png', '/content/tmp/traindataset_only_depth/RGB/depth_21.png', '/content/tmp/traindataset_only_depth/RGB/depth_210.png', '/content/tmp/traindataset_only_depth/RGB/depth_211.png', '/content/tmp/traindataset_only_depth/RGB/depth_212.png', '/content/tmp/traindataset_only_depth/RGB/depth_22.png', '/content/tmp/traindataset_only_depth/RGB/depth_220.png', '/content/tmp/traindataset_only_depth/RGB/depth_221.png', '/content/tmp/traindataset_only_depth/RGB/depth_222.png', '/content/tmp/traindataset_only_depth/RGB/depth_230.png', '/content/tmp/traindataset_only_depth/RGB/depth_231.png', '/content/tmp/traindataset_only_depth/RGB/depth_232.png', '/content/tmp/traindataset_only_depth/RGB/depth_240.png', '/content/tmp/traindataset_only_depth/RGB/depth_241.png', '/content/tmp/traindataset_only_depth/RGB/depth_242.png', '/content/tmp/traindataset_only_depth/RGB/depth_250.png', '/content/tmp/traindataset_only_depth/RGB/depth_251.png', '/content/tmp/traindataset_only_depth/RGB/depth_252.png', '/content/tmp/traindataset_only_depth/RGB/depth_260.png', '/content/tmp/traindataset_only_depth/RGB/depth_261.png', '/content/tmp/traindataset_only_depth/RGB/depth_262.png', '/content/tmp/traindataset_only_depth/RGB/depth_270.png', '/content/tmp/traindataset_only_depth/RGB/depth_271.png', '/content/tmp/traindataset_only_depth/RGB/depth_272.png', '/content/tmp/traindataset_only_depth/RGB/depth_280.png', '/content/tmp/traindataset_only_depth/RGB/depth_281.png', '/content/tmp/traindataset_only_depth/RGB/depth_282.png', '/content/tmp/traindataset_only_depth/RGB/depth_290.png', '/content/tmp/traindataset_only_depth/RGB/depth_291.png', '/content/tmp/traindataset_only_depth/RGB/depth_292.png', '/content/tmp/traindataset_only_depth/RGB/depth_30.png', '/content/tmp/traindataset_only_depth/RGB/depth_300.png', '/content/tmp/traindataset_only_depth/RGB/depth_301.png', '/content/tmp/traindataset_only_depth/RGB/depth_302.png', '/content/tmp/traindataset_only_depth/RGB/depth_31.png', '/content/tmp/traindataset_only_depth/RGB/depth_310.png', '/content/tmp/traindataset_only_depth/RGB/depth_311.png', '/content/tmp/traindataset_only_depth/RGB/depth_312.png', '/content/tmp/traindataset_only_depth/RGB/depth_32.png', '/content/tmp/traindataset_only_depth/RGB/depth_320.png', '/content/tmp/traindataset_only_depth/RGB/depth_321.png', '/content/tmp/traindataset_only_depth/RGB/depth_322.png', '/content/tmp/traindataset_only_depth/RGB/depth_330.png', '/content/tmp/traindataset_only_depth/RGB/depth_331.png', '/content/tmp/traindataset_only_depth/RGB/depth_332.png', '/content/tmp/traindataset_only_depth/RGB/depth_340.png', '/content/tmp/traindataset_only_depth/RGB/depth_341.png', '/content/tmp/traindataset_only_depth/RGB/depth_342.png', '/content/tmp/traindataset_only_depth/RGB/depth_350.png', '/content/tmp/traindataset_only_depth/RGB/depth_351.png', '/content/tmp/traindataset_only_depth/RGB/depth_352.png', '/content/tmp/traindataset_only_depth/RGB/depth_360.png', '/content/tmp/traindataset_only_depth/RGB/depth_361.png', '/content/tmp/traindataset_only_depth/RGB/depth_362.png', '/content/tmp/traindataset_only_depth/RGB/depth_370.png', '/content/tmp/traindataset_only_depth/RGB/depth_371.png', '/content/tmp/traindataset_only_depth/RGB/depth_372.png', '/content/tmp/traindataset_only_depth/RGB/depth_380.png', '/content/tmp/traindataset_only_depth/RGB/depth_381.png', '/content/tmp/traindataset_only_depth/RGB/depth_382.png', '/content/tmp/traindataset_only_depth/RGB/depth_390.png', '/content/tmp/traindataset_only_depth/RGB/depth_391.png', '/content/tmp/traindataset_only_depth/RGB/depth_392.png', '/content/tmp/traindataset_only_depth/RGB/depth_40.png', '/content/tmp/traindataset_only_depth/RGB/depth_400.png', '/content/tmp/traindataset_only_depth/RGB/depth_401.png', '/content/tmp/traindataset_only_depth/RGB/depth_402.png', '/content/tmp/traindataset_only_depth/RGB/depth_41.png', '/content/tmp/traindataset_only_depth/RGB/depth_410.png', '/content/tmp/traindataset_only_depth/RGB/depth_411.png', '/content/tmp/traindataset_only_depth/RGB/depth_412.png', '/content/tmp/traindataset_only_depth/RGB/depth_42.png', '/content/tmp/traindataset_only_depth/RGB/depth_420.png', '/content/tmp/traindataset_only_depth/RGB/depth_421.png', '/content/tmp/traindataset_only_depth/RGB/depth_422.png', '/content/tmp/traindataset_only_depth/RGB/depth_430.png', '/content/tmp/traindataset_only_depth/RGB/depth_431.png', '/content/tmp/traindataset_only_depth/RGB/depth_432.png', '/content/tmp/traindataset_only_depth/RGB/depth_440.png', '/content/tmp/traindataset_only_depth/RGB/depth_441.png', '/content/tmp/traindataset_only_depth/RGB/depth_442.png', '/content/tmp/traindataset_only_depth/RGB/depth_450.png', '/content/tmp/traindataset_only_depth/RGB/depth_451.png', '/content/tmp/traindataset_only_depth/RGB/depth_452.png', '/content/tmp/traindataset_only_depth/RGB/depth_460.png', '/content/tmp/traindataset_only_depth/RGB/depth_461.png', '/content/tmp/traindataset_only_depth/RGB/depth_462.png', '/content/tmp/traindataset_only_depth/RGB/depth_470.png', '/content/tmp/traindataset_only_depth/RGB/depth_471.png', '/content/tmp/traindataset_only_depth/RGB/depth_472.png', '/content/tmp/traindataset_only_depth/RGB/depth_480.png', '/content/tmp/traindataset_only_depth/RGB/depth_481.png', '/content/tmp/traindataset_only_depth/RGB/depth_482.png', '/content/tmp/traindataset_only_depth/RGB/depth_490.png', '/content/tmp/traindataset_only_depth/RGB/depth_491.png', '/content/tmp/traindataset_only_depth/RGB/depth_492.png', '/content/tmp/traindataset_only_depth/RGB/depth_50.png', '/content/tmp/traindataset_only_depth/RGB/depth_500.png', '/content/tmp/traindataset_only_depth/RGB/depth_501.png', '/content/tmp/traindataset_only_depth/RGB/depth_502.png', '/content/tmp/traindataset_only_depth/RGB/depth_51.png', '/content/tmp/traindataset_only_depth/RGB/depth_510.png', '/content/tmp/traindataset_only_depth/RGB/depth_511.png', '/content/tmp/traindataset_only_depth/RGB/depth_512.png', '/content/tmp/traindataset_only_depth/RGB/depth_52.png', '/content/tmp/traindataset_only_depth/RGB/depth_520.png', '/content/tmp/traindataset_only_depth/RGB/depth_521.png', '/content/tmp/traindataset_only_depth/RGB/depth_522.png', '/content/tmp/traindataset_only_depth/RGB/depth_530.png', '/content/tmp/traindataset_only_depth/RGB/depth_531.png', '/content/tmp/traindataset_only_depth/RGB/depth_532.png', '/content/tmp/traindataset_only_depth/RGB/depth_540.png', '/content/tmp/traindataset_only_depth/RGB/depth_541.png', '/content/tmp/traindataset_only_depth/RGB/depth_542.png', '/content/tmp/traindataset_only_depth/RGB/depth_550.png', '/content/tmp/traindataset_only_depth/RGB/depth_551.png', '/content/tmp/traindataset_only_depth/RGB/depth_552.png', '/content/tmp/traindataset_only_depth/RGB/depth_560.png', '/content/tmp/traindataset_only_depth/RGB/depth_561.png', '/content/tmp/traindataset_only_depth/RGB/depth_562.png', '/content/tmp/traindataset_only_depth/RGB/depth_570.png', '/content/tmp/traindataset_only_depth/RGB/depth_571.png', '/content/tmp/traindataset_only_depth/RGB/depth_572.png', '/content/tmp/traindataset_only_depth/RGB/depth_580.png', '/content/tmp/traindataset_only_depth/RGB/depth_581.png', '/content/tmp/traindataset_only_depth/RGB/depth_582.png', '/content/tmp/traindataset_only_depth/RGB/depth_590.png', '/content/tmp/traindataset_only_depth/RGB/depth_591.png', '/content/tmp/traindataset_only_depth/RGB/depth_592.png', '/content/tmp/traindataset_only_depth/RGB/depth_60.png', '/content/tmp/traindataset_only_depth/RGB/depth_600.png', '/content/tmp/traindataset_only_depth/RGB/depth_601.png', '/content/tmp/traindataset_only_depth/RGB/depth_602.png', '/content/tmp/traindataset_only_depth/RGB/depth_61.png', '/content/tmp/traindataset_only_depth/RGB/depth_610.png', '/content/tmp/traindataset_only_depth/RGB/depth_611.png', '/content/tmp/traindataset_only_depth/RGB/depth_612.png', '/content/tmp/traindataset_only_depth/RGB/depth_62.png', '/content/tmp/traindataset_only_depth/RGB/depth_620.png', '/content/tmp/traindataset_only_depth/RGB/depth_621.png', '/content/tmp/traindataset_only_depth/RGB/depth_622.png', '/content/tmp/traindataset_only_depth/RGB/depth_630.png', '/content/tmp/traindataset_only_depth/RGB/depth_631.png', '/content/tmp/traindataset_only_depth/RGB/depth_632.png', '/content/tmp/traindataset_only_depth/RGB/depth_640.png', '/content/tmp/traindataset_only_depth/RGB/depth_641.png', '/content/tmp/traindataset_only_depth/RGB/depth_642.png', '/content/tmp/traindataset_only_depth/RGB/depth_650.png', '/content/tmp/traindataset_only_depth/RGB/depth_651.png', '/content/tmp/traindataset_only_depth/RGB/depth_652.png', '/content/tmp/traindataset_only_depth/RGB/depth_660.png', '/content/tmp/traindataset_only_depth/RGB/depth_661.png', '/content/tmp/traindataset_only_depth/RGB/depth_662.png', '/content/tmp/traindataset_only_depth/RGB/depth_670.png', '/content/tmp/traindataset_only_depth/RGB/depth_671.png', '/content/tmp/traindataset_only_depth/RGB/depth_672.png', '/content/tmp/traindataset_only_depth/RGB/depth_680.png', '/content/tmp/traindataset_only_depth/RGB/depth_681.png', '/content/tmp/traindataset_only_depth/RGB/depth_682.png', '/content/tmp/traindataset_only_depth/RGB/depth_690.png', '/content/tmp/traindataset_only_depth/RGB/depth_691.png', '/content/tmp/traindataset_only_depth/RGB/depth_692.png', '/content/tmp/traindataset_only_depth/RGB/depth_70.png', '/content/tmp/traindataset_only_depth/RGB/depth_700.png', '/content/tmp/traindataset_only_depth/RGB/depth_701.png', '/content/tmp/traindataset_only_depth/RGB/depth_702.png', '/content/tmp/traindataset_only_depth/RGB/depth_71.png', '/content/tmp/traindataset_only_depth/RGB/depth_710.png', '/content/tmp/traindataset_only_depth/RGB/depth_711.png', '/content/tmp/traindataset_only_depth/RGB/depth_712.png', '/content/tmp/traindataset_only_depth/RGB/depth_72.png', '/content/tmp/traindataset_only_depth/RGB/depth_720.png', '/content/tmp/traindataset_only_depth/RGB/depth_721.png', '/content/tmp/traindataset_only_depth/RGB/depth_722.png', '/content/tmp/traindataset_only_depth/RGB/depth_730.png', '/content/tmp/traindataset_only_depth/RGB/depth_731.png', '/content/tmp/traindataset_only_depth/RGB/depth_732.png', '/content/tmp/traindataset_only_depth/RGB/depth_740.png', '/content/tmp/traindataset_only_depth/RGB/depth_741.png', '/content/tmp/traindataset_only_depth/RGB/depth_742.png', '/content/tmp/traindataset_only_depth/RGB/depth_750.png', '/content/tmp/traindataset_only_depth/RGB/depth_751.png', '/content/tmp/traindataset_only_depth/RGB/depth_752.png', '/content/tmp/traindataset_only_depth/RGB/depth_760.png', '/content/tmp/traindataset_only_depth/RGB/depth_761.png', '/content/tmp/traindataset_only_depth/RGB/depth_762.png', '/content/tmp/traindataset_only_depth/RGB/depth_770.png', '/content/tmp/traindataset_only_depth/RGB/depth_771.png', '/content/tmp/traindataset_only_depth/RGB/depth_772.png', '/content/tmp/traindataset_only_depth/RGB/depth_780.png', '/content/tmp/traindataset_only_depth/RGB/depth_781.png', '/content/tmp/traindataset_only_depth/RGB/depth_782.png', '/content/tmp/traindataset_only_depth/RGB/depth_790.png', '/content/tmp/traindataset_only_depth/RGB/depth_791.png', '/content/tmp/traindataset_only_depth/RGB/depth_792.png', '/content/tmp/traindataset_only_depth/RGB/depth_80.png', '/content/tmp/traindataset_only_depth/RGB/depth_81.png', '/content/tmp/traindataset_only_depth/RGB/depth_82.png', '/content/tmp/traindataset_only_depth/RGB/depth_90.png', '/content/tmp/traindataset_only_depth/RGB/depth_91.png', '/content/tmp/traindataset_only_depth/RGB/depth_92.png'] ['/content/tmp/traindataset_only_depth/GT/GT_00.png', '/content/tmp/traindataset_only_depth/GT/GT_01.png', '/content/tmp/traindataset_only_depth/GT/GT_02.png', '/content/tmp/traindataset_only_depth/GT/GT_10.png', '/content/tmp/traindataset_only_depth/GT/GT_100.png', '/content/tmp/traindataset_only_depth/GT/GT_101.png', '/content/tmp/traindataset_only_depth/GT/GT_102.png', '/content/tmp/traindataset_only_depth/GT/GT_11.png', '/content/tmp/traindataset_only_depth/GT/GT_110.png', '/content/tmp/traindataset_only_depth/GT/GT_111.png', '/content/tmp/traindataset_only_depth/GT/GT_112.png', '/content/tmp/traindataset_only_depth/GT/GT_12.png', '/content/tmp/traindataset_only_depth/GT/GT_120.png', '/content/tmp/traindataset_only_depth/GT/GT_121.png', '/content/tmp/traindataset_only_depth/GT/GT_122.png', '/content/tmp/traindataset_only_depth/GT/GT_130.png', '/content/tmp/traindataset_only_depth/GT/GT_131.png', '/content/tmp/traindataset_only_depth/GT/GT_132.png', '/content/tmp/traindataset_only_depth/GT/GT_140.png', '/content/tmp/traindataset_only_depth/GT/GT_141.png', '/content/tmp/traindataset_only_depth/GT/GT_142.png', '/content/tmp/traindataset_only_depth/GT/GT_150.png', '/content/tmp/traindataset_only_depth/GT/GT_151.png', '/content/tmp/traindataset_only_depth/GT/GT_152.png', '/content/tmp/traindataset_only_depth/GT/GT_160.png', '/content/tmp/traindataset_only_depth/GT/GT_161.png', '/content/tmp/traindataset_only_depth/GT/GT_162.png', '/content/tmp/traindataset_only_depth/GT/GT_170.png', '/content/tmp/traindataset_only_depth/GT/GT_171.png', '/content/tmp/traindataset_only_depth/GT/GT_172.png', '/content/tmp/traindataset_only_depth/GT/GT_180.png', '/content/tmp/traindataset_only_depth/GT/GT_181.png', '/content/tmp/traindataset_only_depth/GT/GT_182.png', '/content/tmp/traindataset_only_depth/GT/GT_190.png', '/content/tmp/traindataset_only_depth/GT/GT_191.png', '/content/tmp/traindataset_only_depth/GT/GT_192.png', '/content/tmp/traindataset_only_depth/GT/GT_20.png', '/content/tmp/traindataset_only_depth/GT/GT_200.png', '/content/tmp/traindataset_only_depth/GT/GT_201.png', '/content/tmp/traindataset_only_depth/GT/GT_202.png', '/content/tmp/traindataset_only_depth/GT/GT_21.png', '/content/tmp/traindataset_only_depth/GT/GT_210.png', '/content/tmp/traindataset_only_depth/GT/GT_211.png', '/content/tmp/traindataset_only_depth/GT/GT_212.png', '/content/tmp/traindataset_only_depth/GT/GT_22.png', '/content/tmp/traindataset_only_depth/GT/GT_220.png', '/content/tmp/traindataset_only_depth/GT/GT_221.png', '/content/tmp/traindataset_only_depth/GT/GT_222.png', '/content/tmp/traindataset_only_depth/GT/GT_230.png', '/content/tmp/traindataset_only_depth/GT/GT_231.png', '/content/tmp/traindataset_only_depth/GT/GT_232.png', '/content/tmp/traindataset_only_depth/GT/GT_240.png', '/content/tmp/traindataset_only_depth/GT/GT_241.png', '/content/tmp/traindataset_only_depth/GT/GT_242.png', '/content/tmp/traindataset_only_depth/GT/GT_250.png', '/content/tmp/traindataset_only_depth/GT/GT_251.png', '/content/tmp/traindataset_only_depth/GT/GT_252.png', '/content/tmp/traindataset_only_depth/GT/GT_260.png', '/content/tmp/traindataset_only_depth/GT/GT_261.png', '/content/tmp/traindataset_only_depth/GT/GT_262.png', '/content/tmp/traindataset_only_depth/GT/GT_270.png', '/content/tmp/traindataset_only_depth/GT/GT_271.png', '/content/tmp/traindataset_only_depth/GT/GT_272.png', '/content/tmp/traindataset_only_depth/GT/GT_280.png', '/content/tmp/traindataset_only_depth/GT/GT_281.png', '/content/tmp/traindataset_only_depth/GT/GT_282.png', '/content/tmp/traindataset_only_depth/GT/GT_290.png', '/content/tmp/traindataset_only_depth/GT/GT_291.png', '/content/tmp/traindataset_only_depth/GT/GT_292.png', '/content/tmp/traindataset_only_depth/GT/GT_30.png', '/content/tmp/traindataset_only_depth/GT/GT_300.png', '/content/tmp/traindataset_only_depth/GT/GT_301.png', '/content/tmp/traindataset_only_depth/GT/GT_302.png', '/content/tmp/traindataset_only_depth/GT/GT_31.png', '/content/tmp/traindataset_only_depth/GT/GT_310.png', '/content/tmp/traindataset_only_depth/GT/GT_311.png', '/content/tmp/traindataset_only_depth/GT/GT_312.png', '/content/tmp/traindataset_only_depth/GT/GT_32.png', '/content/tmp/traindataset_only_depth/GT/GT_320.png', '/content/tmp/traindataset_only_depth/GT/GT_321.png', '/content/tmp/traindataset_only_depth/GT/GT_322.png', '/content/tmp/traindataset_only_depth/GT/GT_330.png', '/content/tmp/traindataset_only_depth/GT/GT_331.png', '/content/tmp/traindataset_only_depth/GT/GT_332.png', '/content/tmp/traindataset_only_depth/GT/GT_340.png', '/content/tmp/traindataset_only_depth/GT/GT_341.png', '/content/tmp/traindataset_only_depth/GT/GT_342.png', '/content/tmp/traindataset_only_depth/GT/GT_350.png', '/content/tmp/traindataset_only_depth/GT/GT_351.png', '/content/tmp/traindataset_only_depth/GT/GT_352.png', '/content/tmp/traindataset_only_depth/GT/GT_360.png', '/content/tmp/traindataset_only_depth/GT/GT_361.png', '/content/tmp/traindataset_only_depth/GT/GT_362.png', '/content/tmp/traindataset_only_depth/GT/GT_370.png', '/content/tmp/traindataset_only_depth/GT/GT_371.png', '/content/tmp/traindataset_only_depth/GT/GT_372.png', '/content/tmp/traindataset_only_depth/GT/GT_380.png', '/content/tmp/traindataset_only_depth/GT/GT_381.png', '/content/tmp/traindataset_only_depth/GT/GT_382.png', '/content/tmp/traindataset_only_depth/GT/GT_390.png', '/content/tmp/traindataset_only_depth/GT/GT_391.png', '/content/tmp/traindataset_only_depth/GT/GT_392.png', '/content/tmp/traindataset_only_depth/GT/GT_40.png', '/content/tmp/traindataset_only_depth/GT/GT_400.png', '/content/tmp/traindataset_only_depth/GT/GT_401.png', '/content/tmp/traindataset_only_depth/GT/GT_402.png', '/content/tmp/traindataset_only_depth/GT/GT_41.png', '/content/tmp/traindataset_only_depth/GT/GT_410.png', '/content/tmp/traindataset_only_depth/GT/GT_411.png', '/content/tmp/traindataset_only_depth/GT/GT_412.png', '/content/tmp/traindataset_only_depth/GT/GT_42.png', '/content/tmp/traindataset_only_depth/GT/GT_420.png', '/content/tmp/traindataset_only_depth/GT/GT_421.png', '/content/tmp/traindataset_only_depth/GT/GT_422.png', '/content/tmp/traindataset_only_depth/GT/GT_430.png', '/content/tmp/traindataset_only_depth/GT/GT_431.png', '/content/tmp/traindataset_only_depth/GT/GT_432.png', '/content/tmp/traindataset_only_depth/GT/GT_440.png', '/content/tmp/traindataset_only_depth/GT/GT_441.png', '/content/tmp/traindataset_only_depth/GT/GT_442.png', '/content/tmp/traindataset_only_depth/GT/GT_450.png', '/content/tmp/traindataset_only_depth/GT/GT_451.png', '/content/tmp/traindataset_only_depth/GT/GT_452.png', '/content/tmp/traindataset_only_depth/GT/GT_460.png', '/content/tmp/traindataset_only_depth/GT/GT_461.png', '/content/tmp/traindataset_only_depth/GT/GT_462.png', '/content/tmp/traindataset_only_depth/GT/GT_470.png', '/content/tmp/traindataset_only_depth/GT/GT_471.png', '/content/tmp/traindataset_only_depth/GT/GT_472.png', '/content/tmp/traindataset_only_depth/GT/GT_480.png', '/content/tmp/traindataset_only_depth/GT/GT_481.png', '/content/tmp/traindataset_only_depth/GT/GT_482.png', '/content/tmp/traindataset_only_depth/GT/GT_490.png', '/content/tmp/traindataset_only_depth/GT/GT_491.png', '/content/tmp/traindataset_only_depth/GT/GT_492.png', '/content/tmp/traindataset_only_depth/GT/GT_50.png', '/content/tmp/traindataset_only_depth/GT/GT_500.png', '/content/tmp/traindataset_only_depth/GT/GT_501.png', '/content/tmp/traindataset_only_depth/GT/GT_502.png', '/content/tmp/traindataset_only_depth/GT/GT_51.png', '/content/tmp/traindataset_only_depth/GT/GT_510.png', '/content/tmp/traindataset_only_depth/GT/GT_511.png', '/content/tmp/traindataset_only_depth/GT/GT_512.png', '/content/tmp/traindataset_only_depth/GT/GT_52.png', '/content/tmp/traindataset_only_depth/GT/GT_520.png', '/content/tmp/traindataset_only_depth/GT/GT_521.png', '/content/tmp/traindataset_only_depth/GT/GT_522.png', '/content/tmp/traindataset_only_depth/GT/GT_530.png', '/content/tmp/traindataset_only_depth/GT/GT_531.png', '/content/tmp/traindataset_only_depth/GT/GT_532.png', '/content/tmp/traindataset_only_depth/GT/GT_540.png', '/content/tmp/traindataset_only_depth/GT/GT_541.png', '/content/tmp/traindataset_only_depth/GT/GT_542.png', '/content/tmp/traindataset_only_depth/GT/GT_550.png', '/content/tmp/traindataset_only_depth/GT/GT_551.png', '/content/tmp/traindataset_only_depth/GT/GT_552.png', '/content/tmp/traindataset_only_depth/GT/GT_560.png', '/content/tmp/traindataset_only_depth/GT/GT_561.png', '/content/tmp/traindataset_only_depth/GT/GT_562.png', '/content/tmp/traindataset_only_depth/GT/GT_570.png', '/content/tmp/traindataset_only_depth/GT/GT_571.png', '/content/tmp/traindataset_only_depth/GT/GT_572.png', '/content/tmp/traindataset_only_depth/GT/GT_580.png', '/content/tmp/traindataset_only_depth/GT/GT_581.png', '/content/tmp/traindataset_only_depth/GT/GT_582.png', '/content/tmp/traindataset_only_depth/GT/GT_590.png', '/content/tmp/traindataset_only_depth/GT/GT_591.png', '/content/tmp/traindataset_only_depth/GT/GT_592.png', '/content/tmp/traindataset_only_depth/GT/GT_60.png', '/content/tmp/traindataset_only_depth/GT/GT_600.png', '/content/tmp/traindataset_only_depth/GT/GT_601.png', '/content/tmp/traindataset_only_depth/GT/GT_602.png', '/content/tmp/traindataset_only_depth/GT/GT_61.png', '/content/tmp/traindataset_only_depth/GT/GT_610.png', '/content/tmp/traindataset_only_depth/GT/GT_611.png', '/content/tmp/traindataset_only_depth/GT/GT_612.png', '/content/tmp/traindataset_only_depth/GT/GT_62.png', '/content/tmp/traindataset_only_depth/GT/GT_620.png', '/content/tmp/traindataset_only_depth/GT/GT_621.png', '/content/tmp/traindataset_only_depth/GT/GT_622.png', '/content/tmp/traindataset_only_depth/GT/GT_630.png', '/content/tmp/traindataset_only_depth/GT/GT_631.png', '/content/tmp/traindataset_only_depth/GT/GT_632.png', '/content/tmp/traindataset_only_depth/GT/GT_640.png', '/content/tmp/traindataset_only_depth/GT/GT_641.png', '/content/tmp/traindataset_only_depth/GT/GT_642.png', '/content/tmp/traindataset_only_depth/GT/GT_650.png', '/content/tmp/traindataset_only_depth/GT/GT_651.png', '/content/tmp/traindataset_only_depth/GT/GT_652.png', '/content/tmp/traindataset_only_depth/GT/GT_660.png', '/content/tmp/traindataset_only_depth/GT/GT_661.png', '/content/tmp/traindataset_only_depth/GT/GT_662.png', '/content/tmp/traindataset_only_depth/GT/GT_670.png', '/content/tmp/traindataset_only_depth/GT/GT_671.png', '/content/tmp/traindataset_only_depth/GT/GT_672.png', '/content/tmp/traindataset_only_depth/GT/GT_680.png', '/content/tmp/traindataset_only_depth/GT/GT_681.png', '/content/tmp/traindataset_only_depth/GT/GT_682.png', '/content/tmp/traindataset_only_depth/GT/GT_690.png', '/content/tmp/traindataset_only_depth/GT/GT_691.png', '/content/tmp/traindataset_only_depth/GT/GT_692.png', '/content/tmp/traindataset_only_depth/GT/GT_70.png', '/content/tmp/traindataset_only_depth/GT/GT_700.png', '/content/tmp/traindataset_only_depth/GT/GT_701.png', '/content/tmp/traindataset_only_depth/GT/GT_702.png', '/content/tmp/traindataset_only_depth/GT/GT_71.png', '/content/tmp/traindataset_only_depth/GT/GT_710.png', '/content/tmp/traindataset_only_depth/GT/GT_711.png', '/content/tmp/traindataset_only_depth/GT/GT_712.png', '/content/tmp/traindataset_only_depth/GT/GT_72.png', '/content/tmp/traindataset_only_depth/GT/GT_720.png', '/content/tmp/traindataset_only_depth/GT/GT_721.png', '/content/tmp/traindataset_only_depth/GT/GT_722.png', '/content/tmp/traindataset_only_depth/GT/GT_730.png', '/content/tmp/traindataset_only_depth/GT/GT_731.png', '/content/tmp/traindataset_only_depth/GT/GT_732.png', '/content/tmp/traindataset_only_depth/GT/GT_740.png', '/content/tmp/traindataset_only_depth/GT/GT_741.png', '/content/tmp/traindataset_only_depth/GT/GT_742.png', '/content/tmp/traindataset_only_depth/GT/GT_750.png', '/content/tmp/traindataset_only_depth/GT/GT_751.png', '/content/tmp/traindataset_only_depth/GT/GT_752.png', '/content/tmp/traindataset_only_depth/GT/GT_760.png', '/content/tmp/traindataset_only_depth/GT/GT_761.png', '/content/tmp/traindataset_only_depth/GT/GT_762.png', '/content/tmp/traindataset_only_depth/GT/GT_770.png', '/content/tmp/traindataset_only_depth/GT/GT_771.png', '/content/tmp/traindataset_only_depth/GT/GT_772.png', '/content/tmp/traindataset_only_depth/GT/GT_780.png', '/content/tmp/traindataset_only_depth/GT/GT_781.png', '/content/tmp/traindataset_only_depth/GT/GT_782.png', '/content/tmp/traindataset_only_depth/GT/GT_790.png', '/content/tmp/traindataset_only_depth/GT/GT_791.png', '/content/tmp/traindataset_only_depth/GT/GT_792.png', '/content/tmp/traindataset_only_depth/GT/GT_80.png', '/content/tmp/traindataset_only_depth/GT/GT_81.png', '/content/tmp/traindataset_only_depth/GT/GT_82.png', '/content/tmp/traindataset_only_depth/GT/GT_90.png', '/content/tmp/traindataset_only_depth/GT/GT_91.png', '/content/tmp/traindataset_only_depth/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7fd7aebd2990>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start train...\n",
            "2022-08-02 12:47:51.223552 Epoch [001/250], Step [0001/0060], Loss1: 0.4579 Loss2: 0.3990 Loss3: 0.3740\n",
            "2022-08-02 12:48:19.816027 Epoch [001/250], Step [0050/0060], Loss1: 0.0897 Loss2: 0.0911 Loss3: 0.0759\n",
            "2022-08-02 12:48:25.632204 Epoch [001/250], Step [0060/0060], Loss1: 0.0814 Loss2: 0.0772 Loss3: 0.0571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 MAE: 0.05019113409613806 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-08-02 12:48:37.049827 Epoch [002/250], Step [0001/0060], Loss1: 0.0957 Loss2: 0.0911 Loss3: 0.0762\n",
            "2022-08-02 12:49:05.852694 Epoch [002/250], Step [0050/0060], Loss1: 0.0662 Loss2: 0.0683 Loss3: 0.0517\n",
            "2022-08-02 12:49:11.671376 Epoch [002/250], Step [0060/0060], Loss1: 0.0668 Loss2: 0.0657 Loss3: 0.0496\n",
            "Epoch: 2 MAE: 0.06390422541234228 ####  bestMAE: 0.05019113409613806 bestEpoch: 0\n",
            "2022-08-02 12:49:19.254047 Epoch [003/250], Step [0001/0060], Loss1: 0.0797 Loss2: 0.0864 Loss3: 0.0612\n",
            "2022-08-02 12:49:47.985156 Epoch [003/250], Step [0050/0060], Loss1: 0.0537 Loss2: 0.0625 Loss3: 0.0444\n",
            "2022-08-02 12:49:53.847816 Epoch [003/250], Step [0060/0060], Loss1: 0.0773 Loss2: 0.0803 Loss3: 0.0565\n",
            "Epoch: 3 MAE: 0.03633431850799492 ####  bestMAE: 0.05019113409613806 bestEpoch: 0\n",
            "best epoch:3\n",
            "2022-08-02 12:50:06.582772 Epoch [004/250], Step [0001/0060], Loss1: 0.0506 Loss2: 0.0601 Loss3: 0.0426\n",
            "2022-08-02 12:50:35.749561 Epoch [004/250], Step [0050/0060], Loss1: 0.0441 Loss2: 0.0464 Loss3: 0.0330\n",
            "2022-08-02 12:50:41.568552 Epoch [004/250], Step [0060/0060], Loss1: 0.0599 Loss2: 0.0762 Loss3: 0.0500\n",
            "Epoch: 4 MAE: 0.027378539155636514 ####  bestMAE: 0.03633431850799492 bestEpoch: 3\n",
            "best epoch:4\n",
            "2022-08-02 12:50:52.012488 Epoch [005/250], Step [0001/0060], Loss1: 0.0605 Loss2: 0.0713 Loss3: 0.0560\n",
            "2022-08-02 12:51:21.370043 Epoch [005/250], Step [0050/0060], Loss1: 0.0476 Loss2: 0.0516 Loss3: 0.0373\n",
            "2022-08-02 12:51:27.180322 Epoch [005/250], Step [0060/0060], Loss1: 0.0476 Loss2: 0.0505 Loss3: 0.0380\n",
            "Epoch: 5 MAE: 0.0259321259541644 ####  bestMAE: 0.027378539155636514 bestEpoch: 4\n",
            "best epoch:5\n",
            "2022-08-02 12:51:39.761640 Epoch [006/250], Step [0001/0060], Loss1: 0.0456 Loss2: 0.0516 Loss3: 0.0369\n",
            "2022-08-02 12:52:09.298678 Epoch [006/250], Step [0050/0060], Loss1: 0.0425 Loss2: 0.0436 Loss3: 0.0347\n",
            "2022-08-02 12:52:15.122513 Epoch [006/250], Step [0060/0060], Loss1: 0.0487 Loss2: 0.0486 Loss3: 0.0321\n",
            "Epoch: 6 MAE: 0.02924603974771878 ####  bestMAE: 0.0259321259541644 bestEpoch: 5\n",
            "2022-08-02 12:52:22.948332 Epoch [007/250], Step [0001/0060], Loss1: 0.0424 Loss2: 0.0487 Loss3: 0.0316\n",
            "2022-08-02 12:52:51.690568 Epoch [007/250], Step [0050/0060], Loss1: 0.0449 Loss2: 0.0526 Loss3: 0.0325\n",
            "2022-08-02 12:52:57.602732 Epoch [007/250], Step [0060/0060], Loss1: 0.0477 Loss2: 0.0490 Loss3: 0.0357\n",
            "Epoch: 7 MAE: 0.01762186870392826 ####  bestMAE: 0.0259321259541644 bestEpoch: 5\n",
            "best epoch:7\n",
            "2022-08-02 12:53:08.070236 Epoch [008/250], Step [0001/0060], Loss1: 0.0424 Loss2: 0.0432 Loss3: 0.0317\n",
            "2022-08-02 12:53:37.301266 Epoch [008/250], Step [0050/0060], Loss1: 0.0379 Loss2: 0.0399 Loss3: 0.0272\n",
            "2022-08-02 12:53:43.124300 Epoch [008/250], Step [0060/0060], Loss1: 0.0368 Loss2: 0.0424 Loss3: 0.0315\n",
            "Epoch: 8 MAE: 0.018972567341748684 ####  bestMAE: 0.01762186870392826 bestEpoch: 7\n",
            "2022-08-02 12:53:50.864040 Epoch [009/250], Step [0001/0060], Loss1: 0.0349 Loss2: 0.0462 Loss3: 0.0296\n",
            "2022-08-02 12:54:19.526902 Epoch [009/250], Step [0050/0060], Loss1: 0.0410 Loss2: 0.0467 Loss3: 0.0338\n",
            "2022-08-02 12:54:25.358849 Epoch [009/250], Step [0060/0060], Loss1: 0.0357 Loss2: 0.0406 Loss3: 0.0282\n",
            "Epoch: 9 MAE: 0.018294831190908713 ####  bestMAE: 0.01762186870392826 bestEpoch: 7\n",
            "2022-08-02 12:54:33.213806 Epoch [010/250], Step [0001/0060], Loss1: 0.0355 Loss2: 0.0407 Loss3: 0.0282\n",
            "2022-08-02 12:55:01.928630 Epoch [010/250], Step [0050/0060], Loss1: 0.0339 Loss2: 0.0410 Loss3: 0.0282\n",
            "2022-08-02 12:55:07.748208 Epoch [010/250], Step [0060/0060], Loss1: 0.0337 Loss2: 0.0382 Loss3: 0.0259\n",
            "Epoch: 10 MAE: 0.0182612534789812 ####  bestMAE: 0.01762186870392826 bestEpoch: 7\n",
            "2022-08-02 12:55:17.787741 Epoch [011/250], Step [0001/0060], Loss1: 0.0384 Loss2: 0.0376 Loss3: 0.0270\n",
            "2022-08-02 12:55:47.046085 Epoch [011/250], Step [0050/0060], Loss1: 0.0323 Loss2: 0.0376 Loss3: 0.0263\n",
            "2022-08-02 12:55:52.942370 Epoch [011/250], Step [0060/0060], Loss1: 0.0348 Loss2: 0.0383 Loss3: 0.0290\n",
            "Epoch: 11 MAE: 0.015166222317410367 ####  bestMAE: 0.01762186870392826 bestEpoch: 7\n",
            "best epoch:11\n",
            "2022-08-02 12:56:03.386407 Epoch [012/250], Step [0001/0060], Loss1: 0.0357 Loss2: 0.0382 Loss3: 0.0272\n",
            "2022-08-02 12:56:32.143140 Epoch [012/250], Step [0050/0060], Loss1: 0.0339 Loss2: 0.0432 Loss3: 0.0304\n",
            "2022-08-02 12:56:37.889784 Epoch [012/250], Step [0060/0060], Loss1: 0.0304 Loss2: 0.0383 Loss3: 0.0258\n",
            "Epoch: 12 MAE: 0.01335638336512068 ####  bestMAE: 0.015166222317410367 bestEpoch: 11\n",
            "best epoch:12\n",
            "2022-08-02 12:56:48.057477 Epoch [013/250], Step [0001/0060], Loss1: 0.0369 Loss2: 0.0437 Loss3: 0.0289\n",
            "2022-08-02 12:57:17.401762 Epoch [013/250], Step [0050/0060], Loss1: 0.0327 Loss2: 0.0373 Loss3: 0.0260\n",
            "2022-08-02 12:57:23.234247 Epoch [013/250], Step [0060/0060], Loss1: 0.0318 Loss2: 0.0406 Loss3: 0.0260\n",
            "Epoch: 13 MAE: 0.01342703595698353 ####  bestMAE: 0.01335638336512068 bestEpoch: 12\n",
            "2022-08-02 12:57:31.005400 Epoch [014/250], Step [0001/0060], Loss1: 0.0311 Loss2: 0.0389 Loss3: 0.0266\n",
            "2022-08-02 12:57:59.808428 Epoch [014/250], Step [0050/0060], Loss1: 0.0302 Loss2: 0.0340 Loss3: 0.0246\n",
            "2022-08-02 12:58:05.614504 Epoch [014/250], Step [0060/0060], Loss1: 0.0338 Loss2: 0.0366 Loss3: 0.0253\n",
            "Epoch: 14 MAE: 0.013379820777724186 ####  bestMAE: 0.01335638336512068 bestEpoch: 12\n",
            "2022-08-02 12:58:13.533376 Epoch [015/250], Step [0001/0060], Loss1: 0.0305 Loss2: 0.0379 Loss3: 0.0245\n",
            "2022-08-02 12:58:42.089712 Epoch [015/250], Step [0050/0060], Loss1: 0.0301 Loss2: 0.0395 Loss3: 0.0264\n",
            "2022-08-02 12:58:47.975639 Epoch [015/250], Step [0060/0060], Loss1: 0.0358 Loss2: 0.0428 Loss3: 0.0279\n",
            "Epoch: 15 MAE: 0.012101794763039502 ####  bestMAE: 0.01335638336512068 bestEpoch: 12\n",
            "best epoch:15\n",
            "2022-08-02 12:59:01.037637 Epoch [016/250], Step [0001/0060], Loss1: 0.0316 Loss2: 0.0390 Loss3: 0.0264\n",
            "2022-08-02 12:59:30.706957 Epoch [016/250], Step [0050/0060], Loss1: 0.0312 Loss2: 0.0365 Loss3: 0.0245\n",
            "2022-08-02 12:59:36.543398 Epoch [016/250], Step [0060/0060], Loss1: 0.0323 Loss2: 0.0378 Loss3: 0.0255\n",
            "Epoch: 16 MAE: 0.013236066230410149 ####  bestMAE: 0.012101794763039502 bestEpoch: 15\n",
            "2022-08-02 12:59:44.331578 Epoch [017/250], Step [0001/0060], Loss1: 0.0296 Loss2: 0.0358 Loss3: 0.0235\n",
            "2022-08-02 13:00:12.984135 Epoch [017/250], Step [0050/0060], Loss1: 0.0290 Loss2: 0.0367 Loss3: 0.0238\n",
            "2022-08-02 13:00:18.812399 Epoch [017/250], Step [0060/0060], Loss1: 0.0337 Loss2: 0.0402 Loss3: 0.0284\n",
            "Epoch: 17 MAE: 0.01101454437547733 ####  bestMAE: 0.012101794763039502 bestEpoch: 15\n",
            "best epoch:17\n",
            "2022-08-02 13:00:29.212111 Epoch [018/250], Step [0001/0060], Loss1: 0.0294 Loss2: 0.0414 Loss3: 0.0258\n",
            "2022-08-02 13:00:58.379560 Epoch [018/250], Step [0050/0060], Loss1: 0.0295 Loss2: 0.0358 Loss3: 0.0237\n",
            "2022-08-02 13:01:04.172938 Epoch [018/250], Step [0060/0060], Loss1: 0.0359 Loss2: 0.0400 Loss3: 0.0276\n",
            "Epoch: 18 MAE: 0.011682811178385264 ####  bestMAE: 0.01101454437547733 bestEpoch: 17\n",
            "2022-08-02 13:01:12.031041 Epoch [019/250], Step [0001/0060], Loss1: 0.0288 Loss2: 0.0356 Loss3: 0.0244\n",
            "2022-08-02 13:01:40.887980 Epoch [019/250], Step [0050/0060], Loss1: 0.0331 Loss2: 0.0359 Loss3: 0.0273\n",
            "2022-08-02 13:01:46.730465 Epoch [019/250], Step [0060/0060], Loss1: 0.0338 Loss2: 0.0354 Loss3: 0.0250\n",
            "Epoch: 19 MAE: 0.012906847588185753 ####  bestMAE: 0.01101454437547733 bestEpoch: 17\n",
            "2022-08-02 13:01:54.510469 Epoch [020/250], Step [0001/0060], Loss1: 0.0283 Loss2: 0.0315 Loss3: 0.0251\n",
            "2022-08-02 13:02:23.162971 Epoch [020/250], Step [0050/0060], Loss1: 0.0301 Loss2: 0.0368 Loss3: 0.0250\n",
            "2022-08-02 13:02:29.110926 Epoch [020/250], Step [0060/0060], Loss1: 0.0264 Loss2: 0.0326 Loss3: 0.0237\n",
            "Epoch: 20 MAE: 0.010998778429532808 ####  bestMAE: 0.01101454437547733 bestEpoch: 17\n",
            "best epoch:20\n",
            "2022-08-02 13:02:42.250663 Epoch [021/250], Step [0001/0060], Loss1: 0.0293 Loss2: 0.0332 Loss3: 0.0235\n",
            "2022-08-02 13:03:11.379785 Epoch [021/250], Step [0050/0060], Loss1: 0.0267 Loss2: 0.0321 Loss3: 0.0219\n",
            "2022-08-02 13:03:17.184401 Epoch [021/250], Step [0060/0060], Loss1: 0.0300 Loss2: 0.0346 Loss3: 0.0232\n",
            "Epoch: 21 MAE: 0.010685938462201092 ####  bestMAE: 0.010998778429532808 bestEpoch: 20\n",
            "best epoch:21\n",
            "2022-08-02 13:03:27.474197 Epoch [022/250], Step [0001/0060], Loss1: 0.0268 Loss2: 0.0309 Loss3: 0.0225\n",
            "2022-08-02 13:03:57.325165 Epoch [022/250], Step [0050/0060], Loss1: 0.0294 Loss2: 0.0327 Loss3: 0.0229\n",
            "2022-08-02 13:04:03.160051 Epoch [022/250], Step [0060/0060], Loss1: 0.0335 Loss2: 0.0412 Loss3: 0.0288\n",
            "Epoch: 22 MAE: 0.0103239627658493 ####  bestMAE: 0.010685938462201092 bestEpoch: 21\n",
            "best epoch:22\n",
            "2022-08-02 13:04:13.561554 Epoch [023/250], Step [0001/0060], Loss1: 0.0282 Loss2: 0.0350 Loss3: 0.0263\n",
            "2022-08-02 13:04:44.170292 Epoch [023/250], Step [0050/0060], Loss1: 0.0272 Loss2: 0.0356 Loss3: 0.0252\n",
            "2022-08-02 13:04:50.001571 Epoch [023/250], Step [0060/0060], Loss1: 0.0297 Loss2: 0.0380 Loss3: 0.0268\n",
            "Epoch: 23 MAE: 0.00984900136522594 ####  bestMAE: 0.0103239627658493 bestEpoch: 22\n",
            "best epoch:23\n",
            "2022-08-02 13:05:00.273237 Epoch [024/250], Step [0001/0060], Loss1: 0.0275 Loss2: 0.0356 Loss3: 0.0277\n",
            "2022-08-02 13:05:29.322536 Epoch [024/250], Step [0050/0060], Loss1: 0.0324 Loss2: 0.0340 Loss3: 0.0240\n",
            "2022-08-02 13:05:35.126113 Epoch [024/250], Step [0060/0060], Loss1: 0.0305 Loss2: 0.0360 Loss3: 0.0243\n",
            "Epoch: 24 MAE: 0.011127149442299492 ####  bestMAE: 0.00984900136522594 bestEpoch: 23\n",
            "2022-08-02 13:05:42.799745 Epoch [025/250], Step [0001/0060], Loss1: 0.0276 Loss2: 0.0341 Loss3: 0.0231\n",
            "2022-08-02 13:06:11.470189 Epoch [025/250], Step [0050/0060], Loss1: 0.0258 Loss2: 0.0303 Loss3: 0.0217\n",
            "2022-08-02 13:06:17.285893 Epoch [025/250], Step [0060/0060], Loss1: 0.0264 Loss2: 0.0323 Loss3: 0.0231\n",
            "Epoch: 25 MAE: 0.010947401805352124 ####  bestMAE: 0.00984900136522594 bestEpoch: 23\n",
            "2022-08-02 13:06:27.490700 Epoch [026/250], Step [0001/0060], Loss1: 0.0258 Loss2: 0.0303 Loss3: 0.0214\n",
            "2022-08-02 13:06:56.676272 Epoch [026/250], Step [0050/0060], Loss1: 0.0282 Loss2: 0.0321 Loss3: 0.0213\n",
            "2022-08-02 13:07:02.431677 Epoch [026/250], Step [0060/0060], Loss1: 0.0257 Loss2: 0.0309 Loss3: 0.0218\n",
            "Epoch: 26 MAE: 0.00963089285447957 ####  bestMAE: 0.00984900136522594 bestEpoch: 23\n",
            "best epoch:26\n",
            "2022-08-02 13:07:12.743189 Epoch [027/250], Step [0001/0060], Loss1: 0.0266 Loss2: 0.0317 Loss3: 0.0227\n",
            "2022-08-02 13:07:42.197435 Epoch [027/250], Step [0050/0060], Loss1: 0.0296 Loss2: 0.0312 Loss3: 0.0246\n",
            "2022-08-02 13:07:48.081073 Epoch [027/250], Step [0060/0060], Loss1: 0.0268 Loss2: 0.0325 Loss3: 0.0227\n",
            "Epoch: 27 MAE: 0.010506209156047257 ####  bestMAE: 0.00963089285447957 bestEpoch: 26\n",
            "2022-08-02 13:07:55.817286 Epoch [028/250], Step [0001/0060], Loss1: 0.0250 Loss2: 0.0306 Loss3: 0.0224\n",
            "2022-08-02 13:08:24.580514 Epoch [028/250], Step [0050/0060], Loss1: 0.0286 Loss2: 0.0332 Loss3: 0.0226\n",
            "2022-08-02 13:08:30.461076 Epoch [028/250], Step [0060/0060], Loss1: 0.0252 Loss2: 0.0333 Loss3: 0.0215\n",
            "Epoch: 28 MAE: 0.011558310069616825 ####  bestMAE: 0.00963089285447957 bestEpoch: 26\n",
            "2022-08-02 13:08:38.237370 Epoch [029/250], Step [0001/0060], Loss1: 0.0281 Loss2: 0.0287 Loss3: 0.0204\n",
            "2022-08-02 13:09:06.949127 Epoch [029/250], Step [0050/0060], Loss1: 0.0275 Loss2: 0.0358 Loss3: 0.0231\n",
            "2022-08-02 13:09:12.754731 Epoch [029/250], Step [0060/0060], Loss1: 0.0264 Loss2: 0.0335 Loss3: 0.0222\n",
            "Epoch: 29 MAE: 0.009226914384357986 ####  bestMAE: 0.00963089285447957 bestEpoch: 26\n",
            "best epoch:29\n",
            "2022-08-02 13:09:23.041089 Epoch [030/250], Step [0001/0060], Loss1: 0.0255 Loss2: 0.0322 Loss3: 0.0231\n",
            "2022-08-02 13:09:52.446013 Epoch [030/250], Step [0050/0060], Loss1: 0.0281 Loss2: 0.0348 Loss3: 0.0255\n",
            "2022-08-02 13:09:58.230128 Epoch [030/250], Step [0060/0060], Loss1: 0.0260 Loss2: 0.0320 Loss3: 0.0213\n",
            "Epoch: 30 MAE: 0.009372564062239632 ####  bestMAE: 0.009226914384357986 bestEpoch: 29\n",
            "2022-08-02 13:10:08.496825 Epoch [031/250], Step [0001/0060], Loss1: 0.0304 Loss2: 0.0345 Loss3: 0.0245\n",
            "2022-08-02 13:10:37.562820 Epoch [031/250], Step [0050/0060], Loss1: 0.0268 Loss2: 0.0359 Loss3: 0.0229\n",
            "2022-08-02 13:10:43.405388 Epoch [031/250], Step [0060/0060], Loss1: 0.0258 Loss2: 0.0332 Loss3: 0.0221\n",
            "Epoch: 31 MAE: 0.00946736822111739 ####  bestMAE: 0.009226914384357986 bestEpoch: 29\n",
            "2022-08-02 13:10:51.095407 Epoch [032/250], Step [0001/0060], Loss1: 0.0244 Loss2: 0.0306 Loss3: 0.0215\n",
            "2022-08-02 13:11:19.665089 Epoch [032/250], Step [0050/0060], Loss1: 0.0261 Loss2: 0.0344 Loss3: 0.0218\n",
            "2022-08-02 13:11:25.528153 Epoch [032/250], Step [0060/0060], Loss1: 0.0275 Loss2: 0.0348 Loss3: 0.0232\n",
            "Epoch: 32 MAE: 0.010021348550383533 ####  bestMAE: 0.009226914384357986 bestEpoch: 29\n",
            "2022-08-02 13:11:33.309530 Epoch [033/250], Step [0001/0060], Loss1: 0.0248 Loss2: 0.0338 Loss3: 0.0223\n",
            "2022-08-02 13:12:01.943159 Epoch [033/250], Step [0050/0060], Loss1: 0.0273 Loss2: 0.0348 Loss3: 0.0255\n",
            "2022-08-02 13:12:07.695044 Epoch [033/250], Step [0060/0060], Loss1: 0.0236 Loss2: 0.0285 Loss3: 0.0207\n",
            "Epoch: 33 MAE: 0.009856764463678239 ####  bestMAE: 0.009226914384357986 bestEpoch: 29\n",
            "2022-08-02 13:12:15.493759 Epoch [034/250], Step [0001/0060], Loss1: 0.0308 Loss2: 0.0371 Loss3: 0.0244\n",
            "2022-08-02 13:12:44.114427 Epoch [034/250], Step [0050/0060], Loss1: 0.0239 Loss2: 0.0315 Loss3: 0.0218\n",
            "2022-08-02 13:12:49.938533 Epoch [034/250], Step [0060/0060], Loss1: 0.0263 Loss2: 0.0320 Loss3: 0.0216\n",
            "Epoch: 34 MAE: 0.008388194248139386 ####  bestMAE: 0.009226914384357986 bestEpoch: 29\n",
            "best epoch:34\n",
            "2022-08-02 13:13:00.265997 Epoch [035/250], Step [0001/0060], Loss1: 0.0270 Loss2: 0.0318 Loss3: 0.0228\n",
            "2022-08-02 13:13:29.180882 Epoch [035/250], Step [0050/0060], Loss1: 0.0235 Loss2: 0.0309 Loss3: 0.0209\n",
            "2022-08-02 13:13:34.990892 Epoch [035/250], Step [0060/0060], Loss1: 0.0281 Loss2: 0.0308 Loss3: 0.0237\n",
            "Epoch: 35 MAE: 0.008412668429729011 ####  bestMAE: 0.008388194248139386 bestEpoch: 34\n",
            "2022-08-02 13:13:45.376223 Epoch [036/250], Step [0001/0060], Loss1: 0.0248 Loss2: 0.0317 Loss3: 0.0249\n",
            "2022-08-02 13:14:14.509470 Epoch [036/250], Step [0050/0060], Loss1: 0.0219 Loss2: 0.0277 Loss3: 0.0199\n",
            "2022-08-02 13:14:20.312156 Epoch [036/250], Step [0060/0060], Loss1: 0.0241 Loss2: 0.0281 Loss3: 0.0209\n",
            "Epoch: 36 MAE: 0.010826922332247099 ####  bestMAE: 0.008388194248139386 bestEpoch: 34\n",
            "2022-08-02 13:14:28.065004 Epoch [037/250], Step [0001/0060], Loss1: 0.0295 Loss2: 0.0308 Loss3: 0.0255\n",
            "2022-08-02 13:14:56.789553 Epoch [037/250], Step [0050/0060], Loss1: 0.0256 Loss2: 0.0335 Loss3: 0.0227\n",
            "2022-08-02 13:15:02.642075 Epoch [037/250], Step [0060/0060], Loss1: 0.0260 Loss2: 0.0314 Loss3: 0.0220\n",
            "Epoch: 37 MAE: 0.009686022486892484 ####  bestMAE: 0.008388194248139386 bestEpoch: 34\n",
            "2022-08-02 13:15:10.485186 Epoch [038/250], Step [0001/0060], Loss1: 0.0229 Loss2: 0.0282 Loss3: 0.0201\n",
            "2022-08-02 13:15:39.193524 Epoch [038/250], Step [0050/0060], Loss1: 0.0241 Loss2: 0.0297 Loss3: 0.0215\n",
            "2022-08-02 13:15:44.967816 Epoch [038/250], Step [0060/0060], Loss1: 0.0276 Loss2: 0.0332 Loss3: 0.0233\n",
            "Epoch: 38 MAE: 0.008945059289948808 ####  bestMAE: 0.008388194248139386 bestEpoch: 34\n",
            "2022-08-02 13:15:52.817693 Epoch [039/250], Step [0001/0060], Loss1: 0.0242 Loss2: 0.0290 Loss3: 0.0224\n",
            "2022-08-02 13:16:21.411292 Epoch [039/250], Step [0050/0060], Loss1: 0.0260 Loss2: 0.0287 Loss3: 0.0210\n",
            "2022-08-02 13:16:27.216447 Epoch [039/250], Step [0060/0060], Loss1: 0.0256 Loss2: 0.0318 Loss3: 0.0220\n",
            "Epoch: 39 MAE: 0.010635796963932022 ####  bestMAE: 0.008388194248139386 bestEpoch: 34\n",
            "2022-08-02 13:16:34.991045 Epoch [040/250], Step [0001/0060], Loss1: 0.0239 Loss2: 0.0302 Loss3: 0.0204\n",
            "2022-08-02 13:17:03.616203 Epoch [040/250], Step [0050/0060], Loss1: 0.0261 Loss2: 0.0322 Loss3: 0.0229\n",
            "2022-08-02 13:17:09.410719 Epoch [040/250], Step [0060/0060], Loss1: 0.0251 Loss2: 0.0302 Loss3: 0.0215\n",
            "Epoch: 40 MAE: 0.009019668746207441 ####  bestMAE: 0.008388194248139386 bestEpoch: 34\n",
            "2022-08-02 13:17:19.452355 Epoch [041/250], Step [0001/0060], Loss1: 0.0227 Loss2: 0.0298 Loss3: 0.0207\n",
            "2022-08-02 13:17:48.933017 Epoch [041/250], Step [0050/0060], Loss1: 0.0248 Loss2: 0.0296 Loss3: 0.0235\n",
            "2022-08-02 13:17:54.753672 Epoch [041/250], Step [0060/0060], Loss1: 0.0251 Loss2: 0.0311 Loss3: 0.0233\n",
            "Epoch: 41 MAE: 0.0077464824971107266 ####  bestMAE: 0.008388194248139386 bestEpoch: 34\n",
            "best epoch:41\n",
            "2022-08-02 13:18:05.046270 Epoch [042/250], Step [0001/0060], Loss1: 0.0228 Loss2: 0.0334 Loss3: 0.0249\n",
            "2022-08-02 13:18:34.660261 Epoch [042/250], Step [0050/0060], Loss1: 0.0261 Loss2: 0.0305 Loss3: 0.0226\n",
            "2022-08-02 13:18:40.474731 Epoch [042/250], Step [0060/0060], Loss1: 0.0240 Loss2: 0.0316 Loss3: 0.0210\n",
            "Epoch: 42 MAE: 0.008052939201690375 ####  bestMAE: 0.0077464824971107266 bestEpoch: 41\n",
            "2022-08-02 13:18:48.197023 Epoch [043/250], Step [0001/0060], Loss1: 0.0255 Loss2: 0.0322 Loss3: 0.0228\n",
            "2022-08-02 13:19:16.896849 Epoch [043/250], Step [0050/0060], Loss1: 0.0256 Loss2: 0.0320 Loss3: 0.0218\n",
            "2022-08-02 13:19:22.696782 Epoch [043/250], Step [0060/0060], Loss1: 0.0224 Loss2: 0.0284 Loss3: 0.0199\n",
            "Epoch: 43 MAE: 0.008763261860059131 ####  bestMAE: 0.0077464824971107266 bestEpoch: 41\n",
            "2022-08-02 13:19:30.533015 Epoch [044/250], Step [0001/0060], Loss1: 0.0233 Loss2: 0.0302 Loss3: 0.0197\n",
            "2022-08-02 13:19:59.374642 Epoch [044/250], Step [0050/0060], Loss1: 0.0248 Loss2: 0.0293 Loss3: 0.0214\n",
            "2022-08-02 13:20:05.227737 Epoch [044/250], Step [0060/0060], Loss1: 0.0235 Loss2: 0.0316 Loss3: 0.0204\n",
            "Epoch: 44 MAE: 0.00836658129645955 ####  bestMAE: 0.0077464824971107266 bestEpoch: 41\n",
            "2022-08-02 13:20:13.023651 Epoch [045/250], Step [0001/0060], Loss1: 0.0250 Loss2: 0.0289 Loss3: 0.0209\n",
            "2022-08-02 13:20:41.779615 Epoch [045/250], Step [0050/0060], Loss1: 0.0238 Loss2: 0.0296 Loss3: 0.0218\n",
            "2022-08-02 13:20:47.557346 Epoch [045/250], Step [0060/0060], Loss1: 0.0264 Loss2: 0.0282 Loss3: 0.0220\n",
            "Epoch: 45 MAE: 0.008736964950840625 ####  bestMAE: 0.0077464824971107266 bestEpoch: 41\n",
            "2022-08-02 13:20:57.677153 Epoch [046/250], Step [0001/0060], Loss1: 0.0260 Loss2: 0.0280 Loss3: 0.0203\n",
            "2022-08-02 13:21:26.986486 Epoch [046/250], Step [0050/0060], Loss1: 0.0221 Loss2: 0.0283 Loss3: 0.0200\n",
            "2022-08-02 13:21:32.790943 Epoch [046/250], Step [0060/0060], Loss1: 0.0249 Loss2: 0.0315 Loss3: 0.0212\n",
            "Epoch: 46 MAE: 0.007523822771858365 ####  bestMAE: 0.0077464824971107266 bestEpoch: 41\n",
            "best epoch:46\n",
            "2022-08-02 13:21:43.254954 Epoch [047/250], Step [0001/0060], Loss1: 0.0225 Loss2: 0.0297 Loss3: 0.0204\n",
            "2022-08-02 13:22:12.137969 Epoch [047/250], Step [0050/0060], Loss1: 0.0248 Loss2: 0.0309 Loss3: 0.0219\n",
            "2022-08-02 13:22:17.931974 Epoch [047/250], Step [0060/0060], Loss1: 0.0225 Loss2: 0.0275 Loss3: 0.0207\n",
            "Epoch: 47 MAE: 0.009049628314281266 ####  bestMAE: 0.007523822771858365 bestEpoch: 46\n",
            "2022-08-02 13:22:25.706533 Epoch [048/250], Step [0001/0060], Loss1: 0.0246 Loss2: 0.0316 Loss3: 0.0217\n",
            "2022-08-02 13:22:54.236220 Epoch [048/250], Step [0050/0060], Loss1: 0.0247 Loss2: 0.0279 Loss3: 0.0203\n",
            "2022-08-02 13:23:00.168336 Epoch [048/250], Step [0060/0060], Loss1: 0.0236 Loss2: 0.0300 Loss3: 0.0208\n",
            "Epoch: 48 MAE: 0.0085404444456337 ####  bestMAE: 0.007523822771858365 bestEpoch: 46\n",
            "2022-08-02 13:23:07.963381 Epoch [049/250], Step [0001/0060], Loss1: 0.0245 Loss2: 0.0308 Loss3: 0.0219\n",
            "2022-08-02 13:23:36.627335 Epoch [049/250], Step [0050/0060], Loss1: 0.0236 Loss2: 0.0272 Loss3: 0.0203\n",
            "2022-08-02 13:23:42.468986 Epoch [049/250], Step [0060/0060], Loss1: 0.0239 Loss2: 0.0275 Loss3: 0.0205\n",
            "Epoch: 49 MAE: 0.008608241772486104 ####  bestMAE: 0.007523822771858365 bestEpoch: 46\n",
            "2022-08-02 13:23:50.313739 Epoch [050/250], Step [0001/0060], Loss1: 0.0244 Loss2: 0.0294 Loss3: 0.0216\n",
            "2022-08-02 13:24:18.916692 Epoch [050/250], Step [0050/0060], Loss1: 0.0243 Loss2: 0.0318 Loss3: 0.0211\n",
            "2022-08-02 13:24:24.696705 Epoch [050/250], Step [0060/0060], Loss1: 0.0236 Loss2: 0.0278 Loss3: 0.0200\n",
            "Epoch: 50 MAE: 0.008078891924390244 ####  bestMAE: 0.007523822771858365 bestEpoch: 46\n",
            "2022-08-02 13:24:34.968237 Epoch [051/250], Step [0001/0060], Loss1: 0.0248 Loss2: 0.0301 Loss3: 0.0208\n",
            "2022-08-02 13:25:03.956460 Epoch [051/250], Step [0050/0060], Loss1: 0.0220 Loss2: 0.0264 Loss3: 0.0191\n",
            "2022-08-02 13:25:09.833333 Epoch [051/250], Step [0060/0060], Loss1: 0.0236 Loss2: 0.0287 Loss3: 0.0208\n",
            "Epoch: 51 MAE: 0.00870262309613209 ####  bestMAE: 0.007523822771858365 bestEpoch: 46\n",
            "2022-08-02 13:25:17.582275 Epoch [052/250], Step [0001/0060], Loss1: 0.0218 Loss2: 0.0281 Loss3: 0.0195\n",
            "2022-08-02 13:25:46.356272 Epoch [052/250], Step [0050/0060], Loss1: 0.0237 Loss2: 0.0289 Loss3: 0.0203\n",
            "2022-08-02 13:25:52.185184 Epoch [052/250], Step [0060/0060], Loss1: 0.0241 Loss2: 0.0298 Loss3: 0.0219\n",
            "Epoch: 52 MAE: 0.008170409593731165 ####  bestMAE: 0.007523822771858365 bestEpoch: 46\n",
            "2022-08-02 13:25:59.993191 Epoch [053/250], Step [0001/0060], Loss1: 0.0225 Loss2: 0.0279 Loss3: 0.0200\n",
            "2022-08-02 13:26:28.826912 Epoch [053/250], Step [0050/0060], Loss1: 0.0250 Loss2: 0.0311 Loss3: 0.0226\n",
            "2022-08-02 13:26:34.784902 Epoch [053/250], Step [0060/0060], Loss1: 0.0231 Loss2: 0.0295 Loss3: 0.0210\n",
            "Epoch: 53 MAE: 0.0084330840036273 ####  bestMAE: 0.007523822771858365 bestEpoch: 46\n",
            "2022-08-02 13:26:42.544276 Epoch [054/250], Step [0001/0060], Loss1: 0.0224 Loss2: 0.0279 Loss3: 0.0208\n",
            "2022-08-02 13:27:11.278842 Epoch [054/250], Step [0050/0060], Loss1: 0.0222 Loss2: 0.0265 Loss3: 0.0200\n",
            "2022-08-02 13:27:17.189535 Epoch [054/250], Step [0060/0060], Loss1: 0.0231 Loss2: 0.0269 Loss3: 0.0200\n",
            "Epoch: 54 MAE: 0.008038040390977311 ####  bestMAE: 0.007523822771858365 bestEpoch: 46\n",
            "2022-08-02 13:27:24.974956 Epoch [055/250], Step [0001/0060], Loss1: 0.0220 Loss2: 0.0284 Loss3: 0.0200\n",
            "2022-08-02 13:27:53.863697 Epoch [055/250], Step [0050/0060], Loss1: 0.0259 Loss2: 0.0300 Loss3: 0.0231\n",
            "2022-08-02 13:27:59.694186 Epoch [055/250], Step [0060/0060], Loss1: 0.0226 Loss2: 0.0279 Loss3: 0.0204\n",
            "Epoch: 55 MAE: 0.00769651202958018 ####  bestMAE: 0.007523822771858365 bestEpoch: 46\n",
            "2022-08-02 13:28:09.977718 Epoch [056/250], Step [0001/0060], Loss1: 0.0238 Loss2: 0.0277 Loss3: 0.0208\n",
            "2022-08-02 13:28:39.348417 Epoch [056/250], Step [0050/0060], Loss1: 0.0227 Loss2: 0.0267 Loss3: 0.0203\n",
            "2022-08-02 13:28:45.130248 Epoch [056/250], Step [0060/0060], Loss1: 0.0245 Loss2: 0.0309 Loss3: 0.0219\n",
            "Epoch: 56 MAE: 0.007820762749317856 ####  bestMAE: 0.007523822771858365 bestEpoch: 46\n",
            "2022-08-02 13:28:52.930416 Epoch [057/250], Step [0001/0060], Loss1: 0.0231 Loss2: 0.0292 Loss3: 0.0217\n",
            "2022-08-02 13:29:21.504926 Epoch [057/250], Step [0050/0060], Loss1: 0.0227 Loss2: 0.0284 Loss3: 0.0198\n",
            "2022-08-02 13:29:27.315134 Epoch [057/250], Step [0060/0060], Loss1: 0.0241 Loss2: 0.0303 Loss3: 0.0213\n",
            "Epoch: 57 MAE: 0.007175290886874473 ####  bestMAE: 0.007523822771858365 bestEpoch: 46\n",
            "best epoch:57\n",
            "2022-08-02 13:29:37.634858 Epoch [058/250], Step [0001/0060], Loss1: 0.0220 Loss2: 0.0279 Loss3: 0.0200\n",
            "2022-08-02 13:30:06.607236 Epoch [058/250], Step [0050/0060], Loss1: 0.0224 Loss2: 0.0297 Loss3: 0.0207\n",
            "2022-08-02 13:30:12.537684 Epoch [058/250], Step [0060/0060], Loss1: 0.0221 Loss2: 0.0270 Loss3: 0.0202\n",
            "Epoch: 58 MAE: 0.007944897696789768 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:30:20.370120 Epoch [059/250], Step [0001/0060], Loss1: 0.0211 Loss2: 0.0263 Loss3: 0.0188\n",
            "2022-08-02 13:30:49.055015 Epoch [059/250], Step [0050/0060], Loss1: 0.0254 Loss2: 0.0314 Loss3: 0.0226\n",
            "2022-08-02 13:30:54.868333 Epoch [059/250], Step [0060/0060], Loss1: 0.0221 Loss2: 0.0280 Loss3: 0.0201\n",
            "Epoch: 59 MAE: 0.008673285370663045 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:31:02.697406 Epoch [060/250], Step [0001/0060], Loss1: 0.0240 Loss2: 0.0302 Loss3: 0.0214\n",
            "2022-08-02 13:31:31.443132 Epoch [060/250], Step [0050/0060], Loss1: 0.0218 Loss2: 0.0297 Loss3: 0.0200\n",
            "2022-08-02 13:31:37.251668 Epoch [060/250], Step [0060/0060], Loss1: 0.0232 Loss2: 0.0299 Loss3: 0.0207\n",
            "Epoch: 60 MAE: 0.00800168558600403 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:31:47.422668 Epoch [061/250], Step [0001/0060], Loss1: 0.0226 Loss2: 0.0275 Loss3: 0.0199\n",
            "2022-08-02 13:32:16.508600 Epoch [061/250], Step [0050/0060], Loss1: 0.0222 Loss2: 0.0288 Loss3: 0.0197\n",
            "2022-08-02 13:32:22.310998 Epoch [061/250], Step [0060/0060], Loss1: 0.0219 Loss2: 0.0268 Loss3: 0.0196\n",
            "Epoch: 61 MAE: 0.008619441022534691 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:32:30.112523 Epoch [062/250], Step [0001/0060], Loss1: 0.0207 Loss2: 0.0248 Loss3: 0.0185\n",
            "2022-08-02 13:32:58.669564 Epoch [062/250], Step [0050/0060], Loss1: 0.0212 Loss2: 0.0277 Loss3: 0.0191\n",
            "2022-08-02 13:33:04.468559 Epoch [062/250], Step [0060/0060], Loss1: 0.0212 Loss2: 0.0259 Loss3: 0.0190\n",
            "Epoch: 62 MAE: 0.008246926302533774 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:33:12.265665 Epoch [063/250], Step [0001/0060], Loss1: 0.0204 Loss2: 0.0252 Loss3: 0.0186\n",
            "2022-08-02 13:33:40.802527 Epoch [063/250], Step [0050/0060], Loss1: 0.0223 Loss2: 0.0276 Loss3: 0.0198\n",
            "2022-08-02 13:33:46.601516 Epoch [063/250], Step [0060/0060], Loss1: 0.0214 Loss2: 0.0275 Loss3: 0.0189\n",
            "Epoch: 63 MAE: 0.008536431361876783 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:33:54.357209 Epoch [064/250], Step [0001/0060], Loss1: 0.0214 Loss2: 0.0266 Loss3: 0.0194\n",
            "2022-08-02 13:34:23.049286 Epoch [064/250], Step [0050/0060], Loss1: 0.0223 Loss2: 0.0294 Loss3: 0.0200\n",
            "2022-08-02 13:34:28.887569 Epoch [064/250], Step [0060/0060], Loss1: 0.0204 Loss2: 0.0250 Loss3: 0.0183\n",
            "Epoch: 64 MAE: 0.00834299237393434 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:34:36.590909 Epoch [065/250], Step [0001/0060], Loss1: 0.0220 Loss2: 0.0277 Loss3: 0.0197\n",
            "2022-08-02 13:35:05.102802 Epoch [065/250], Step [0050/0060], Loss1: 0.0235 Loss2: 0.0292 Loss3: 0.0209\n",
            "2022-08-02 13:35:10.973688 Epoch [065/250], Step [0060/0060], Loss1: 0.0224 Loss2: 0.0272 Loss3: 0.0200\n",
            "Epoch: 65 MAE: 0.008709868497496087 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:35:21.292492 Epoch [066/250], Step [0001/0060], Loss1: 0.0214 Loss2: 0.0281 Loss3: 0.0190\n",
            "2022-08-02 13:35:50.512321 Epoch [066/250], Step [0050/0060], Loss1: 0.0209 Loss2: 0.0255 Loss3: 0.0189\n",
            "2022-08-02 13:35:56.358483 Epoch [066/250], Step [0060/0060], Loss1: 0.0222 Loss2: 0.0283 Loss3: 0.0199\n",
            "Epoch: 66 MAE: 0.008371973705906716 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:36:04.151810 Epoch [067/250], Step [0001/0060], Loss1: 0.0226 Loss2: 0.0292 Loss3: 0.0200\n",
            "2022-08-02 13:36:32.873284 Epoch [067/250], Step [0050/0060], Loss1: 0.0212 Loss2: 0.0260 Loss3: 0.0187\n",
            "2022-08-02 13:36:38.687390 Epoch [067/250], Step [0060/0060], Loss1: 0.0211 Loss2: 0.0246 Loss3: 0.0190\n",
            "Epoch: 67 MAE: 0.008330511010532815 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:36:46.469014 Epoch [068/250], Step [0001/0060], Loss1: 0.0223 Loss2: 0.0271 Loss3: 0.0201\n",
            "2022-08-02 13:37:15.142313 Epoch [068/250], Step [0050/0060], Loss1: 0.0206 Loss2: 0.0255 Loss3: 0.0182\n",
            "2022-08-02 13:37:20.941352 Epoch [068/250], Step [0060/0060], Loss1: 0.0215 Loss2: 0.0268 Loss3: 0.0193\n",
            "Epoch: 68 MAE: 0.008514620962419681 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:37:28.620715 Epoch [069/250], Step [0001/0060], Loss1: 0.0204 Loss2: 0.0264 Loss3: 0.0181\n",
            "2022-08-02 13:37:57.200407 Epoch [069/250], Step [0050/0060], Loss1: 0.0221 Loss2: 0.0295 Loss3: 0.0197\n",
            "2022-08-02 13:38:03.055492 Epoch [069/250], Step [0060/0060], Loss1: 0.0229 Loss2: 0.0286 Loss3: 0.0205\n",
            "Epoch: 69 MAE: 0.0077781106034914655 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:38:10.828587 Epoch [070/250], Step [0001/0060], Loss1: 0.0201 Loss2: 0.0231 Loss3: 0.0182\n",
            "2022-08-02 13:38:39.434369 Epoch [070/250], Step [0050/0060], Loss1: 0.0217 Loss2: 0.0284 Loss3: 0.0197\n",
            "2022-08-02 13:38:45.255317 Epoch [070/250], Step [0060/0060], Loss1: 0.0203 Loss2: 0.0241 Loss3: 0.0182\n",
            "Epoch: 70 MAE: 0.008078824418286482 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:38:55.425019 Epoch [071/250], Step [0001/0060], Loss1: 0.0206 Loss2: 0.0253 Loss3: 0.0183\n",
            "2022-08-02 13:39:24.614131 Epoch [071/250], Step [0050/0060], Loss1: 0.0212 Loss2: 0.0300 Loss3: 0.0195\n",
            "2022-08-02 13:39:30.469425 Epoch [071/250], Step [0060/0060], Loss1: 0.0220 Loss2: 0.0274 Loss3: 0.0194\n",
            "Epoch: 71 MAE: 0.008267036979160612 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:39:38.287298 Epoch [072/250], Step [0001/0060], Loss1: 0.0214 Loss2: 0.0258 Loss3: 0.0192\n",
            "2022-08-02 13:40:06.976528 Epoch [072/250], Step [0050/0060], Loss1: 0.0204 Loss2: 0.0255 Loss3: 0.0185\n",
            "2022-08-02 13:40:12.774997 Epoch [072/250], Step [0060/0060], Loss1: 0.0221 Loss2: 0.0277 Loss3: 0.0199\n",
            "Epoch: 72 MAE: 0.008373178445571472 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:40:20.542460 Epoch [073/250], Step [0001/0060], Loss1: 0.0222 Loss2: 0.0275 Loss3: 0.0197\n",
            "2022-08-02 13:40:49.070409 Epoch [073/250], Step [0050/0060], Loss1: 0.0212 Loss2: 0.0256 Loss3: 0.0191\n",
            "2022-08-02 13:40:54.829586 Epoch [073/250], Step [0060/0060], Loss1: 0.0201 Loss2: 0.0267 Loss3: 0.0181\n",
            "Epoch: 73 MAE: 0.008556629715871716 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:41:02.582513 Epoch [074/250], Step [0001/0060], Loss1: 0.0223 Loss2: 0.0294 Loss3: 0.0201\n",
            "2022-08-02 13:41:31.169111 Epoch [074/250], Step [0050/0060], Loss1: 0.0217 Loss2: 0.0278 Loss3: 0.0194\n",
            "2022-08-02 13:41:36.969413 Epoch [074/250], Step [0060/0060], Loss1: 0.0224 Loss2: 0.0292 Loss3: 0.0195\n",
            "Epoch: 74 MAE: 0.007855028793629672 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:41:44.656260 Epoch [075/250], Step [0001/0060], Loss1: 0.0216 Loss2: 0.0285 Loss3: 0.0195\n",
            "2022-08-02 13:42:13.275348 Epoch [075/250], Step [0050/0060], Loss1: 0.0217 Loss2: 0.0282 Loss3: 0.0195\n",
            "2022-08-02 13:42:19.089946 Epoch [075/250], Step [0060/0060], Loss1: 0.0209 Loss2: 0.0248 Loss3: 0.0184\n",
            "Epoch: 75 MAE: 0.007784801934446607 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:42:29.282783 Epoch [076/250], Step [0001/0060], Loss1: 0.0226 Loss2: 0.0287 Loss3: 0.0197\n",
            "2022-08-02 13:42:58.378381 Epoch [076/250], Step [0050/0060], Loss1: 0.0202 Loss2: 0.0244 Loss3: 0.0182\n",
            "2022-08-02 13:43:04.151689 Epoch [076/250], Step [0060/0060], Loss1: 0.0208 Loss2: 0.0256 Loss3: 0.0185\n",
            "Epoch: 76 MAE: 0.008735904351822914 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:43:11.898065 Epoch [077/250], Step [0001/0060], Loss1: 0.0203 Loss2: 0.0246 Loss3: 0.0183\n",
            "2022-08-02 13:43:40.297893 Epoch [077/250], Step [0050/0060], Loss1: 0.0203 Loss2: 0.0249 Loss3: 0.0182\n",
            "2022-08-02 13:43:46.125938 Epoch [077/250], Step [0060/0060], Loss1: 0.0218 Loss2: 0.0296 Loss3: 0.0199\n",
            "Epoch: 77 MAE: 0.008241634727233932 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:43:53.848540 Epoch [078/250], Step [0001/0060], Loss1: 0.0209 Loss2: 0.0252 Loss3: 0.0188\n",
            "2022-08-02 13:44:22.647246 Epoch [078/250], Step [0050/0060], Loss1: 0.0208 Loss2: 0.0259 Loss3: 0.0185\n",
            "2022-08-02 13:44:28.470145 Epoch [078/250], Step [0060/0060], Loss1: 0.0219 Loss2: 0.0285 Loss3: 0.0197\n",
            "Epoch: 78 MAE: 0.008016204609284325 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:44:36.356942 Epoch [079/250], Step [0001/0060], Loss1: 0.0210 Loss2: 0.0253 Loss3: 0.0184\n",
            "2022-08-02 13:45:05.057452 Epoch [079/250], Step [0050/0060], Loss1: 0.0210 Loss2: 0.0277 Loss3: 0.0189\n",
            "2022-08-02 13:45:10.858449 Epoch [079/250], Step [0060/0060], Loss1: 0.0220 Loss2: 0.0287 Loss3: 0.0202\n",
            "Epoch: 79 MAE: 0.008527665155097133 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:45:18.736849 Epoch [080/250], Step [0001/0060], Loss1: 0.0208 Loss2: 0.0263 Loss3: 0.0188\n",
            "2022-08-02 13:45:47.486932 Epoch [080/250], Step [0050/0060], Loss1: 0.0214 Loss2: 0.0274 Loss3: 0.0193\n",
            "2022-08-02 13:45:53.398785 Epoch [080/250], Step [0060/0060], Loss1: 0.0206 Loss2: 0.0255 Loss3: 0.0185\n",
            "Epoch: 80 MAE: 0.00830143919983317 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:46:03.581278 Epoch [081/250], Step [0001/0060], Loss1: 0.0223 Loss2: 0.0276 Loss3: 0.0192\n",
            "2022-08-02 13:46:32.755178 Epoch [081/250], Step [0050/0060], Loss1: 0.0209 Loss2: 0.0273 Loss3: 0.0189\n",
            "2022-08-02 13:46:38.579541 Epoch [081/250], Step [0060/0060], Loss1: 0.0211 Loss2: 0.0267 Loss3: 0.0189\n",
            "Epoch: 81 MAE: 0.008138991123627103 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:46:46.258001 Epoch [082/250], Step [0001/0060], Loss1: 0.0224 Loss2: 0.0304 Loss3: 0.0201\n",
            "2022-08-02 13:47:14.916815 Epoch [082/250], Step [0050/0060], Loss1: 0.0232 Loss2: 0.0299 Loss3: 0.0208\n",
            "2022-08-02 13:47:20.767609 Epoch [082/250], Step [0060/0060], Loss1: 0.0203 Loss2: 0.0241 Loss3: 0.0178\n",
            "Epoch: 82 MAE: 0.008534736694797637 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:47:28.583442 Epoch [083/250], Step [0001/0060], Loss1: 0.0212 Loss2: 0.0283 Loss3: 0.0191\n",
            "2022-08-02 13:47:57.462989 Epoch [083/250], Step [0050/0060], Loss1: 0.0204 Loss2: 0.0251 Loss3: 0.0186\n",
            "2022-08-02 13:48:03.368815 Epoch [083/250], Step [0060/0060], Loss1: 0.0242 Loss2: 0.0302 Loss3: 0.0215\n",
            "Epoch: 83 MAE: 0.008024641549185155 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:48:11.166864 Epoch [084/250], Step [0001/0060], Loss1: 0.0223 Loss2: 0.0314 Loss3: 0.0195\n",
            "2022-08-02 13:48:39.911054 Epoch [084/250], Step [0050/0060], Loss1: 0.0215 Loss2: 0.0259 Loss3: 0.0195\n",
            "2022-08-02 13:48:45.698235 Epoch [084/250], Step [0060/0060], Loss1: 0.0216 Loss2: 0.0295 Loss3: 0.0196\n",
            "Epoch: 84 MAE: 0.00798257826901381 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:48:53.472268 Epoch [085/250], Step [0001/0060], Loss1: 0.0229 Loss2: 0.0300 Loss3: 0.0206\n",
            "2022-08-02 13:49:22.027990 Epoch [085/250], Step [0050/0060], Loss1: 0.0211 Loss2: 0.0268 Loss3: 0.0192\n",
            "2022-08-02 13:49:27.973104 Epoch [085/250], Step [0060/0060], Loss1: 0.0228 Loss2: 0.0301 Loss3: 0.0203\n",
            "Epoch: 85 MAE: 0.0077595725389463565 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:49:38.514849 Epoch [086/250], Step [0001/0060], Loss1: 0.0230 Loss2: 0.0292 Loss3: 0.0206\n",
            "2022-08-02 13:50:07.191778 Epoch [086/250], Step [0050/0060], Loss1: 0.0218 Loss2: 0.0266 Loss3: 0.0191\n",
            "2022-08-02 13:50:13.032653 Epoch [086/250], Step [0060/0060], Loss1: 0.0205 Loss2: 0.0261 Loss3: 0.0186\n",
            "Epoch: 86 MAE: 0.008256609921181013 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:50:20.745061 Epoch [087/250], Step [0001/0060], Loss1: 0.0228 Loss2: 0.0297 Loss3: 0.0203\n",
            "2022-08-02 13:50:49.365054 Epoch [087/250], Step [0050/0060], Loss1: 0.0207 Loss2: 0.0257 Loss3: 0.0187\n",
            "2022-08-02 13:50:55.180102 Epoch [087/250], Step [0060/0060], Loss1: 0.0225 Loss2: 0.0281 Loss3: 0.0195\n",
            "Epoch: 87 MAE: 0.008197800211963199 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:51:02.942652 Epoch [088/250], Step [0001/0060], Loss1: 0.0190 Loss2: 0.0232 Loss3: 0.0171\n",
            "2022-08-02 13:51:31.465205 Epoch [088/250], Step [0050/0060], Loss1: 0.0216 Loss2: 0.0279 Loss3: 0.0197\n",
            "2022-08-02 13:51:37.251825 Epoch [088/250], Step [0060/0060], Loss1: 0.0196 Loss2: 0.0252 Loss3: 0.0175\n",
            "Epoch: 88 MAE: 0.008393241927796414 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:51:45.049403 Epoch [089/250], Step [0001/0060], Loss1: 0.0205 Loss2: 0.0258 Loss3: 0.0186\n",
            "2022-08-02 13:52:13.778269 Epoch [089/250], Step [0050/0060], Loss1: 0.0203 Loss2: 0.0257 Loss3: 0.0181\n",
            "2022-08-02 13:52:19.583583 Epoch [089/250], Step [0060/0060], Loss1: 0.0222 Loss2: 0.0282 Loss3: 0.0198\n",
            "Epoch: 89 MAE: 0.008198184774272026 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:52:27.335509 Epoch [090/250], Step [0001/0060], Loss1: 0.0214 Loss2: 0.0271 Loss3: 0.0195\n",
            "2022-08-02 13:52:55.874694 Epoch [090/250], Step [0050/0060], Loss1: 0.0234 Loss2: 0.0301 Loss3: 0.0212\n",
            "2022-08-02 13:53:01.670970 Epoch [090/250], Step [0060/0060], Loss1: 0.0225 Loss2: 0.0301 Loss3: 0.0199\n",
            "Epoch: 90 MAE: 0.008167877704614685 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:53:12.157171 Epoch [091/250], Step [0001/0060], Loss1: 0.0200 Loss2: 0.0253 Loss3: 0.0179\n",
            "2022-08-02 13:53:40.832732 Epoch [091/250], Step [0050/0060], Loss1: 0.0211 Loss2: 0.0249 Loss3: 0.0187\n",
            "2022-08-02 13:53:46.600368 Epoch [091/250], Step [0060/0060], Loss1: 0.0220 Loss2: 0.0282 Loss3: 0.0197\n",
            "Epoch: 91 MAE: 0.008323003072291613 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:53:54.376683 Epoch [092/250], Step [0001/0060], Loss1: 0.0214 Loss2: 0.0258 Loss3: 0.0190\n",
            "2022-08-02 13:54:23.032146 Epoch [092/250], Step [0050/0060], Loss1: 0.0205 Loss2: 0.0245 Loss3: 0.0182\n",
            "2022-08-02 13:54:28.846805 Epoch [092/250], Step [0060/0060], Loss1: 0.0209 Loss2: 0.0274 Loss3: 0.0187\n",
            "Epoch: 92 MAE: 0.008330377484006541 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:54:36.737257 Epoch [093/250], Step [0001/0060], Loss1: 0.0220 Loss2: 0.0285 Loss3: 0.0202\n",
            "2022-08-02 13:55:05.298490 Epoch [093/250], Step [0050/0060], Loss1: 0.0202 Loss2: 0.0253 Loss3: 0.0180\n",
            "2022-08-02 13:55:11.074480 Epoch [093/250], Step [0060/0060], Loss1: 0.0213 Loss2: 0.0265 Loss3: 0.0194\n",
            "Epoch: 93 MAE: 0.008603336570400095 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:55:18.886156 Epoch [094/250], Step [0001/0060], Loss1: 0.0200 Loss2: 0.0245 Loss3: 0.0180\n",
            "2022-08-02 13:55:47.397975 Epoch [094/250], Step [0050/0060], Loss1: 0.0213 Loss2: 0.0281 Loss3: 0.0191\n",
            "2022-08-02 13:55:53.164434 Epoch [094/250], Step [0060/0060], Loss1: 0.0216 Loss2: 0.0270 Loss3: 0.0192\n",
            "Epoch: 94 MAE: 0.008146622735593054 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:56:00.972854 Epoch [095/250], Step [0001/0060], Loss1: 0.0221 Loss2: 0.0288 Loss3: 0.0200\n",
            "2022-08-02 13:56:29.645369 Epoch [095/250], Step [0050/0060], Loss1: 0.0213 Loss2: 0.0270 Loss3: 0.0192\n",
            "2022-08-02 13:56:35.472686 Epoch [095/250], Step [0060/0060], Loss1: 0.0224 Loss2: 0.0279 Loss3: 0.0198\n",
            "Epoch: 95 MAE: 0.008082387207578572 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:56:45.597032 Epoch [096/250], Step [0001/0060], Loss1: 0.0214 Loss2: 0.0296 Loss3: 0.0194\n",
            "2022-08-02 13:57:14.867354 Epoch [096/250], Step [0050/0060], Loss1: 0.0193 Loss2: 0.0242 Loss3: 0.0174\n",
            "2022-08-02 13:57:20.632954 Epoch [096/250], Step [0060/0060], Loss1: 0.0219 Loss2: 0.0284 Loss3: 0.0200\n",
            "Epoch: 96 MAE: 0.008422858717422637 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:57:28.446692 Epoch [097/250], Step [0001/0060], Loss1: 0.0216 Loss2: 0.0268 Loss3: 0.0197\n",
            "2022-08-02 13:57:56.821659 Epoch [097/250], Step [0050/0060], Loss1: 0.0207 Loss2: 0.0291 Loss3: 0.0190\n",
            "2022-08-02 13:58:02.594577 Epoch [097/250], Step [0060/0060], Loss1: 0.0205 Loss2: 0.0248 Loss3: 0.0186\n",
            "Epoch: 97 MAE: 0.008267360340271677 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:58:10.378263 Epoch [098/250], Step [0001/0060], Loss1: 0.0211 Loss2: 0.0265 Loss3: 0.0191\n",
            "2022-08-02 13:58:39.042811 Epoch [098/250], Step [0050/0060], Loss1: 0.0225 Loss2: 0.0271 Loss3: 0.0201\n",
            "2022-08-02 13:58:44.862804 Epoch [098/250], Step [0060/0060], Loss1: 0.0221 Loss2: 0.0291 Loss3: 0.0199\n",
            "Epoch: 98 MAE: 0.008596279761857457 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:58:52.661309 Epoch [099/250], Step [0001/0060], Loss1: 0.0227 Loss2: 0.0271 Loss3: 0.0201\n",
            "2022-08-02 13:59:21.030902 Epoch [099/250], Step [0050/0060], Loss1: 0.0228 Loss2: 0.0271 Loss3: 0.0198\n",
            "2022-08-02 13:59:26.758684 Epoch [099/250], Step [0060/0060], Loss1: 0.0218 Loss2: 0.0278 Loss3: 0.0196\n",
            "Epoch: 99 MAE: 0.00821573342684479 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 13:59:34.577898 Epoch [100/250], Step [0001/0060], Loss1: 0.0217 Loss2: 0.0277 Loss3: 0.0194\n",
            "2022-08-02 14:00:03.150263 Epoch [100/250], Step [0050/0060], Loss1: 0.0215 Loss2: 0.0269 Loss3: 0.0193\n",
            "2022-08-02 14:00:09.028231 Epoch [100/250], Step [0060/0060], Loss1: 0.0206 Loss2: 0.0254 Loss3: 0.0184\n",
            "Epoch: 100 MAE: 0.008007662614718788 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:00:19.476872 Epoch [101/250], Step [0001/0060], Loss1: 0.0229 Loss2: 0.0293 Loss3: 0.0204\n",
            "2022-08-02 14:00:48.317782 Epoch [101/250], Step [0050/0060], Loss1: 0.0214 Loss2: 0.0278 Loss3: 0.0194\n",
            "2022-08-02 14:00:54.147537 Epoch [101/250], Step [0060/0060], Loss1: 0.0207 Loss2: 0.0261 Loss3: 0.0186\n",
            "Epoch: 101 MAE: 0.008155447571346211 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:01:01.815684 Epoch [102/250], Step [0001/0060], Loss1: 0.0220 Loss2: 0.0273 Loss3: 0.0197\n",
            "2022-08-02 14:01:30.436446 Epoch [102/250], Step [0050/0060], Loss1: 0.0224 Loss2: 0.0301 Loss3: 0.0199\n",
            "2022-08-02 14:01:36.277097 Epoch [102/250], Step [0060/0060], Loss1: 0.0209 Loss2: 0.0280 Loss3: 0.0193\n",
            "Epoch: 102 MAE: 0.008842918630098067 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:01:44.126967 Epoch [103/250], Step [0001/0060], Loss1: 0.0215 Loss2: 0.0255 Loss3: 0.0195\n",
            "2022-08-02 14:02:12.567242 Epoch [103/250], Step [0050/0060], Loss1: 0.0209 Loss2: 0.0259 Loss3: 0.0186\n",
            "2022-08-02 14:02:18.391603 Epoch [103/250], Step [0060/0060], Loss1: 0.0214 Loss2: 0.0266 Loss3: 0.0193\n",
            "Epoch: 103 MAE: 0.00851677856334145 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:02:26.208150 Epoch [104/250], Step [0001/0060], Loss1: 0.0207 Loss2: 0.0257 Loss3: 0.0186\n",
            "2022-08-02 14:02:54.742149 Epoch [104/250], Step [0050/0060], Loss1: 0.0232 Loss2: 0.0294 Loss3: 0.0207\n",
            "2022-08-02 14:03:00.632552 Epoch [104/250], Step [0060/0060], Loss1: 0.0201 Loss2: 0.0240 Loss3: 0.0183\n",
            "Epoch: 104 MAE: 0.008073075844477567 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:03:08.512732 Epoch [105/250], Step [0001/0060], Loss1: 0.0234 Loss2: 0.0303 Loss3: 0.0212\n",
            "2022-08-02 14:03:37.119361 Epoch [105/250], Step [0050/0060], Loss1: 0.0188 Loss2: 0.0232 Loss3: 0.0170\n",
            "2022-08-02 14:03:43.043701 Epoch [105/250], Step [0060/0060], Loss1: 0.0214 Loss2: 0.0259 Loss3: 0.0190\n",
            "Epoch: 105 MAE: 0.00837496178786433 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:03:53.458330 Epoch [106/250], Step [0001/0060], Loss1: 0.0211 Loss2: 0.0283 Loss3: 0.0193\n",
            "2022-08-02 14:04:22.639714 Epoch [106/250], Step [0050/0060], Loss1: 0.0230 Loss2: 0.0284 Loss3: 0.0209\n",
            "2022-08-02 14:04:28.461048 Epoch [106/250], Step [0060/0060], Loss1: 0.0202 Loss2: 0.0252 Loss3: 0.0180\n",
            "Epoch: 106 MAE: 0.0082750850105806 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:04:36.225971 Epoch [107/250], Step [0001/0060], Loss1: 0.0198 Loss2: 0.0269 Loss3: 0.0178\n",
            "2022-08-02 14:05:05.034120 Epoch [107/250], Step [0050/0060], Loss1: 0.0197 Loss2: 0.0237 Loss3: 0.0179\n",
            "2022-08-02 14:05:10.908446 Epoch [107/250], Step [0060/0060], Loss1: 0.0214 Loss2: 0.0258 Loss3: 0.0191\n",
            "Epoch: 107 MAE: 0.0085142505399528 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:05:18.798234 Epoch [108/250], Step [0001/0060], Loss1: 0.0207 Loss2: 0.0265 Loss3: 0.0186\n",
            "2022-08-02 14:05:47.564490 Epoch [108/250], Step [0050/0060], Loss1: 0.0225 Loss2: 0.0293 Loss3: 0.0202\n",
            "2022-08-02 14:05:53.438115 Epoch [108/250], Step [0060/0060], Loss1: 0.0234 Loss2: 0.0294 Loss3: 0.0210\n",
            "Epoch: 108 MAE: 0.008415579507570891 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:06:01.224656 Epoch [109/250], Step [0001/0060], Loss1: 0.0202 Loss2: 0.0263 Loss3: 0.0183\n",
            "2022-08-02 14:06:29.950570 Epoch [109/250], Step [0050/0060], Loss1: 0.0208 Loss2: 0.0278 Loss3: 0.0185\n",
            "2022-08-02 14:06:35.764552 Epoch [109/250], Step [0060/0060], Loss1: 0.0213 Loss2: 0.0275 Loss3: 0.0193\n",
            "Epoch: 109 MAE: 0.008465731923010141 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:06:43.589532 Epoch [110/250], Step [0001/0060], Loss1: 0.0201 Loss2: 0.0247 Loss3: 0.0181\n",
            "2022-08-02 14:07:12.278700 Epoch [110/250], Step [0050/0060], Loss1: 0.0208 Loss2: 0.0270 Loss3: 0.0185\n",
            "2022-08-02 14:07:18.081126 Epoch [110/250], Step [0060/0060], Loss1: 0.0220 Loss2: 0.0301 Loss3: 0.0201\n",
            "Epoch: 110 MAE: 0.008581392378324554 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:07:31.442614 Epoch [111/250], Step [0001/0060], Loss1: 0.0214 Loss2: 0.0277 Loss3: 0.0194\n",
            "2022-08-02 14:08:00.766288 Epoch [111/250], Step [0050/0060], Loss1: 0.0219 Loss2: 0.0247 Loss3: 0.0192\n",
            "2022-08-02 14:08:06.659959 Epoch [111/250], Step [0060/0060], Loss1: 0.0207 Loss2: 0.0240 Loss3: 0.0184\n",
            "Epoch: 111 MAE: 0.008520527395404993 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:08:14.520095 Epoch [112/250], Step [0001/0060], Loss1: 0.0211 Loss2: 0.0269 Loss3: 0.0189\n",
            "2022-08-02 14:08:43.373248 Epoch [112/250], Step [0050/0060], Loss1: 0.0221 Loss2: 0.0267 Loss3: 0.0195\n",
            "2022-08-02 14:08:49.257207 Epoch [112/250], Step [0060/0060], Loss1: 0.0210 Loss2: 0.0244 Loss3: 0.0187\n",
            "Epoch: 112 MAE: 0.00843074375260917 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:08:57.137351 Epoch [113/250], Step [0001/0060], Loss1: 0.0193 Loss2: 0.0234 Loss3: 0.0174\n",
            "2022-08-02 14:09:25.937646 Epoch [113/250], Step [0050/0060], Loss1: 0.0204 Loss2: 0.0254 Loss3: 0.0180\n",
            "2022-08-02 14:09:31.883693 Epoch [113/250], Step [0060/0060], Loss1: 0.0209 Loss2: 0.0265 Loss3: 0.0190\n",
            "Epoch: 113 MAE: 0.0088201453317962 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:09:39.697410 Epoch [114/250], Step [0001/0060], Loss1: 0.0206 Loss2: 0.0261 Loss3: 0.0187\n",
            "2022-08-02 14:10:08.318709 Epoch [114/250], Step [0050/0060], Loss1: 0.0223 Loss2: 0.0284 Loss3: 0.0198\n",
            "2022-08-02 14:10:14.123634 Epoch [114/250], Step [0060/0060], Loss1: 0.0219 Loss2: 0.0269 Loss3: 0.0200\n",
            "Epoch: 114 MAE: 0.008335588995130762 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:10:22.054795 Epoch [115/250], Step [0001/0060], Loss1: 0.0214 Loss2: 0.0248 Loss3: 0.0189\n",
            "2022-08-02 14:10:50.772891 Epoch [115/250], Step [0050/0060], Loss1: 0.0220 Loss2: 0.0272 Loss3: 0.0198\n",
            "2022-08-02 14:10:56.631085 Epoch [115/250], Step [0060/0060], Loss1: 0.0223 Loss2: 0.0277 Loss3: 0.0198\n",
            "Epoch: 115 MAE: 0.008319997176941898 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:11:06.850856 Epoch [116/250], Step [0001/0060], Loss1: 0.0211 Loss2: 0.0261 Loss3: 0.0190\n",
            "2022-08-02 14:11:35.795791 Epoch [116/250], Step [0050/0060], Loss1: 0.0218 Loss2: 0.0283 Loss3: 0.0196\n",
            "2022-08-02 14:11:41.647770 Epoch [116/250], Step [0060/0060], Loss1: 0.0207 Loss2: 0.0243 Loss3: 0.0187\n",
            "Epoch: 116 MAE: 0.008751496347406554 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:11:49.460112 Epoch [117/250], Step [0001/0060], Loss1: 0.0202 Loss2: 0.0259 Loss3: 0.0179\n",
            "2022-08-02 14:12:18.218668 Epoch [117/250], Step [0050/0060], Loss1: 0.0190 Loss2: 0.0223 Loss3: 0.0172\n",
            "2022-08-02 14:12:24.042913 Epoch [117/250], Step [0060/0060], Loss1: 0.0212 Loss2: 0.0273 Loss3: 0.0191\n",
            "Epoch: 117 MAE: 0.008471315637940452 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:12:31.920604 Epoch [118/250], Step [0001/0060], Loss1: 0.0206 Loss2: 0.0266 Loss3: 0.0185\n",
            "2022-08-02 14:13:00.646772 Epoch [118/250], Step [0050/0060], Loss1: 0.0208 Loss2: 0.0250 Loss3: 0.0190\n",
            "2022-08-02 14:13:06.533534 Epoch [118/250], Step [0060/0060], Loss1: 0.0206 Loss2: 0.0269 Loss3: 0.0188\n",
            "Epoch: 118 MAE: 0.007942981663204375 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:13:14.489587 Epoch [119/250], Step [0001/0060], Loss1: 0.0215 Loss2: 0.0276 Loss3: 0.0194\n",
            "2022-08-02 14:13:43.232601 Epoch [119/250], Step [0050/0060], Loss1: 0.0203 Loss2: 0.0247 Loss3: 0.0183\n",
            "2022-08-02 14:13:49.086567 Epoch [119/250], Step [0060/0060], Loss1: 0.0204 Loss2: 0.0264 Loss3: 0.0185\n",
            "Epoch: 119 MAE: 0.00814440298736805 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:13:56.820635 Epoch [120/250], Step [0001/0060], Loss1: 0.0201 Loss2: 0.0249 Loss3: 0.0181\n",
            "2022-08-02 14:14:25.536230 Epoch [120/250], Step [0050/0060], Loss1: 0.0209 Loss2: 0.0267 Loss3: 0.0191\n",
            "2022-08-02 14:14:31.374462 Epoch [120/250], Step [0060/0060], Loss1: 0.0215 Loss2: 0.0253 Loss3: 0.0193\n",
            "Epoch: 120 MAE: 0.008503001501103715 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:14:41.570112 Epoch [121/250], Step [0001/0060], Loss1: 0.0209 Loss2: 0.0265 Loss3: 0.0187\n",
            "2022-08-02 14:15:10.682665 Epoch [121/250], Step [0050/0060], Loss1: 0.0189 Loss2: 0.0233 Loss3: 0.0170\n",
            "2022-08-02 14:15:16.471135 Epoch [121/250], Step [0060/0060], Loss1: 0.0217 Loss2: 0.0283 Loss3: 0.0196\n",
            "Epoch: 121 MAE: 0.008321605741031586 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:15:24.253188 Epoch [122/250], Step [0001/0060], Loss1: 0.0197 Loss2: 0.0256 Loss3: 0.0178\n",
            "2022-08-02 14:15:53.071372 Epoch [122/250], Step [0050/0060], Loss1: 0.0230 Loss2: 0.0284 Loss3: 0.0206\n",
            "2022-08-02 14:15:58.938436 Epoch [122/250], Step [0060/0060], Loss1: 0.0203 Loss2: 0.0257 Loss3: 0.0183\n",
            "Epoch: 122 MAE: 0.008437075460004427 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:16:06.774720 Epoch [123/250], Step [0001/0060], Loss1: 0.0208 Loss2: 0.0266 Loss3: 0.0186\n",
            "2022-08-02 14:16:35.487482 Epoch [123/250], Step [0050/0060], Loss1: 0.0214 Loss2: 0.0277 Loss3: 0.0195\n",
            "2022-08-02 14:16:41.251062 Epoch [123/250], Step [0060/0060], Loss1: 0.0209 Loss2: 0.0266 Loss3: 0.0188\n",
            "Epoch: 123 MAE: 0.00816334040820717 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:16:49.089504 Epoch [124/250], Step [0001/0060], Loss1: 0.0210 Loss2: 0.0264 Loss3: 0.0190\n",
            "2022-08-02 14:17:17.805365 Epoch [124/250], Step [0050/0060], Loss1: 0.0196 Loss2: 0.0227 Loss3: 0.0177\n",
            "2022-08-02 14:17:23.658871 Epoch [124/250], Step [0060/0060], Loss1: 0.0202 Loss2: 0.0252 Loss3: 0.0180\n",
            "Epoch: 124 MAE: 0.008188395842259366 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:17:31.475722 Epoch [125/250], Step [0001/0060], Loss1: 0.0189 Loss2: 0.0226 Loss3: 0.0170\n",
            "2022-08-02 14:18:00.202673 Epoch [125/250], Step [0050/0060], Loss1: 0.0211 Loss2: 0.0270 Loss3: 0.0190\n",
            "2022-08-02 14:18:05.998569 Epoch [125/250], Step [0060/0060], Loss1: 0.0210 Loss2: 0.0279 Loss3: 0.0191\n",
            "Epoch: 125 MAE: 0.008245911885289446 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:18:16.534215 Epoch [126/250], Step [0001/0060], Loss1: 0.0220 Loss2: 0.0267 Loss3: 0.0197\n",
            "2022-08-02 14:18:45.698831 Epoch [126/250], Step [0050/0060], Loss1: 0.0199 Loss2: 0.0251 Loss3: 0.0180\n",
            "2022-08-02 14:18:51.544436 Epoch [126/250], Step [0060/0060], Loss1: 0.0200 Loss2: 0.0256 Loss3: 0.0183\n",
            "Epoch: 126 MAE: 0.008326501977289952 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:18:59.325743 Epoch [127/250], Step [0001/0060], Loss1: 0.0230 Loss2: 0.0283 Loss3: 0.0203\n",
            "2022-08-02 14:19:27.939554 Epoch [127/250], Step [0050/0060], Loss1: 0.0207 Loss2: 0.0257 Loss3: 0.0188\n",
            "2022-08-02 14:19:33.772110 Epoch [127/250], Step [0060/0060], Loss1: 0.0209 Loss2: 0.0254 Loss3: 0.0185\n",
            "Epoch: 127 MAE: 0.008250737296683448 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:19:41.659647 Epoch [128/250], Step [0001/0060], Loss1: 0.0199 Loss2: 0.0249 Loss3: 0.0180\n",
            "2022-08-02 14:20:10.472102 Epoch [128/250], Step [0050/0060], Loss1: 0.0220 Loss2: 0.0278 Loss3: 0.0199\n",
            "2022-08-02 14:20:16.366043 Epoch [128/250], Step [0060/0060], Loss1: 0.0219 Loss2: 0.0295 Loss3: 0.0198\n",
            "Epoch: 128 MAE: 0.00841246841711894 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:20:24.259476 Epoch [129/250], Step [0001/0060], Loss1: 0.0205 Loss2: 0.0266 Loss3: 0.0183\n",
            "2022-08-02 14:20:53.130144 Epoch [129/250], Step [0050/0060], Loss1: 0.0211 Loss2: 0.0273 Loss3: 0.0189\n",
            "2022-08-02 14:20:58.979198 Epoch [129/250], Step [0060/0060], Loss1: 0.0208 Loss2: 0.0266 Loss3: 0.0185\n",
            "Epoch: 129 MAE: 0.008234971831183113 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:21:06.826664 Epoch [130/250], Step [0001/0060], Loss1: 0.0210 Loss2: 0.0270 Loss3: 0.0188\n",
            "2022-08-02 14:21:35.501104 Epoch [130/250], Step [0050/0060], Loss1: 0.0199 Loss2: 0.0257 Loss3: 0.0181\n",
            "2022-08-02 14:21:41.294433 Epoch [130/250], Step [0060/0060], Loss1: 0.0205 Loss2: 0.0257 Loss3: 0.0184\n",
            "Epoch: 130 MAE: 0.008338457845624477 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:21:51.542389 Epoch [131/250], Step [0001/0060], Loss1: 0.0202 Loss2: 0.0240 Loss3: 0.0181\n",
            "2022-08-02 14:22:20.555720 Epoch [131/250], Step [0050/0060], Loss1: 0.0211 Loss2: 0.0253 Loss3: 0.0191\n",
            "2022-08-02 14:22:26.388930 Epoch [131/250], Step [0060/0060], Loss1: 0.0197 Loss2: 0.0246 Loss3: 0.0176\n",
            "Epoch: 131 MAE: 0.008545005930558083 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:22:34.176659 Epoch [132/250], Step [0001/0060], Loss1: 0.0195 Loss2: 0.0234 Loss3: 0.0175\n",
            "2022-08-02 14:23:02.790717 Epoch [132/250], Step [0050/0060], Loss1: 0.0214 Loss2: 0.0275 Loss3: 0.0196\n",
            "2022-08-02 14:23:08.684883 Epoch [132/250], Step [0060/0060], Loss1: 0.0206 Loss2: 0.0259 Loss3: 0.0187\n",
            "Epoch: 132 MAE: 0.008297856867549911 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:23:16.432030 Epoch [133/250], Step [0001/0060], Loss1: 0.0213 Loss2: 0.0278 Loss3: 0.0192\n",
            "2022-08-02 14:23:45.123455 Epoch [133/250], Step [0050/0060], Loss1: 0.0219 Loss2: 0.0278 Loss3: 0.0197\n",
            "2022-08-02 14:23:50.914504 Epoch [133/250], Step [0060/0060], Loss1: 0.0204 Loss2: 0.0266 Loss3: 0.0185\n",
            "Epoch: 133 MAE: 0.00818383603888963 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:23:58.714551 Epoch [134/250], Step [0001/0060], Loss1: 0.0220 Loss2: 0.0270 Loss3: 0.0196\n",
            "2022-08-02 14:24:27.320374 Epoch [134/250], Step [0050/0060], Loss1: 0.0203 Loss2: 0.0254 Loss3: 0.0183\n",
            "2022-08-02 14:24:33.131585 Epoch [134/250], Step [0060/0060], Loss1: 0.0220 Loss2: 0.0279 Loss3: 0.0200\n",
            "Epoch: 134 MAE: 0.008454390151041841 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:24:40.889314 Epoch [135/250], Step [0001/0060], Loss1: 0.0201 Loss2: 0.0256 Loss3: 0.0183\n",
            "2022-08-02 14:25:09.598780 Epoch [135/250], Step [0050/0060], Loss1: 0.0214 Loss2: 0.0256 Loss3: 0.0201\n",
            "2022-08-02 14:25:15.435203 Epoch [135/250], Step [0060/0060], Loss1: 0.0219 Loss2: 0.0291 Loss3: 0.0197\n",
            "Epoch: 135 MAE: 0.00854676893897473 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:25:25.772092 Epoch [136/250], Step [0001/0060], Loss1: 0.0225 Loss2: 0.0275 Loss3: 0.0202\n",
            "2022-08-02 14:25:54.689341 Epoch [136/250], Step [0050/0060], Loss1: 0.0228 Loss2: 0.0283 Loss3: 0.0203\n",
            "2022-08-02 14:26:00.562192 Epoch [136/250], Step [0060/0060], Loss1: 0.0214 Loss2: 0.0275 Loss3: 0.0192\n",
            "Epoch: 136 MAE: 0.008368488682049608 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:26:08.451346 Epoch [137/250], Step [0001/0060], Loss1: 0.0213 Loss2: 0.0286 Loss3: 0.0194\n",
            "2022-08-02 14:26:37.437233 Epoch [137/250], Step [0050/0060], Loss1: 0.0216 Loss2: 0.0287 Loss3: 0.0193\n",
            "2022-08-02 14:26:43.401276 Epoch [137/250], Step [0060/0060], Loss1: 0.0211 Loss2: 0.0276 Loss3: 0.0192\n",
            "Epoch: 137 MAE: 0.008817819353666097 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:26:51.166244 Epoch [138/250], Step [0001/0060], Loss1: 0.0200 Loss2: 0.0261 Loss3: 0.0182\n",
            "2022-08-02 14:27:19.827269 Epoch [138/250], Step [0050/0060], Loss1: 0.0218 Loss2: 0.0286 Loss3: 0.0198\n",
            "2022-08-02 14:27:25.635630 Epoch [138/250], Step [0060/0060], Loss1: 0.0206 Loss2: 0.0247 Loss3: 0.0184\n",
            "Epoch: 138 MAE: 0.008431436567907296 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:27:33.543935 Epoch [139/250], Step [0001/0060], Loss1: 0.0190 Loss2: 0.0247 Loss3: 0.0172\n",
            "2022-08-02 14:28:02.092658 Epoch [139/250], Step [0050/0060], Loss1: 0.0205 Loss2: 0.0266 Loss3: 0.0184\n",
            "2022-08-02 14:28:07.937902 Epoch [139/250], Step [0060/0060], Loss1: 0.0212 Loss2: 0.0266 Loss3: 0.0191\n",
            "Epoch: 139 MAE: 0.008522875828757173 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:28:15.719853 Epoch [140/250], Step [0001/0060], Loss1: 0.0224 Loss2: 0.0292 Loss3: 0.0201\n",
            "2022-08-02 14:28:44.522441 Epoch [140/250], Step [0050/0060], Loss1: 0.0197 Loss2: 0.0248 Loss3: 0.0180\n",
            "2022-08-02 14:28:50.369635 Epoch [140/250], Step [0060/0060], Loss1: 0.0208 Loss2: 0.0272 Loss3: 0.0185\n",
            "Epoch: 140 MAE: 0.008513710705474728 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:29:00.812352 Epoch [141/250], Step [0001/0060], Loss1: 0.0220 Loss2: 0.0280 Loss3: 0.0197\n",
            "2022-08-02 14:29:29.849417 Epoch [141/250], Step [0050/0060], Loss1: 0.0211 Loss2: 0.0266 Loss3: 0.0191\n",
            "2022-08-02 14:29:35.705152 Epoch [141/250], Step [0060/0060], Loss1: 0.0202 Loss2: 0.0250 Loss3: 0.0183\n",
            "Epoch: 141 MAE: 0.008474209678492375 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:29:43.447122 Epoch [142/250], Step [0001/0060], Loss1: 0.0227 Loss2: 0.0290 Loss3: 0.0204\n",
            "2022-08-02 14:30:12.234237 Epoch [142/250], Step [0050/0060], Loss1: 0.0216 Loss2: 0.0255 Loss3: 0.0191\n",
            "2022-08-02 14:30:18.031434 Epoch [142/250], Step [0060/0060], Loss1: 0.0206 Loss2: 0.0268 Loss3: 0.0185\n",
            "Epoch: 142 MAE: 0.008544049174007442 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:30:25.835365 Epoch [143/250], Step [0001/0060], Loss1: 0.0218 Loss2: 0.0266 Loss3: 0.0195\n",
            "2022-08-02 14:30:54.278069 Epoch [143/250], Step [0050/0060], Loss1: 0.0200 Loss2: 0.0244 Loss3: 0.0178\n",
            "2022-08-02 14:31:00.082737 Epoch [143/250], Step [0060/0060], Loss1: 0.0181 Loss2: 0.0224 Loss3: 0.0163\n",
            "Epoch: 143 MAE: 0.008494388984723223 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:31:07.917631 Epoch [144/250], Step [0001/0060], Loss1: 0.0204 Loss2: 0.0248 Loss3: 0.0185\n",
            "2022-08-02 14:31:36.918706 Epoch [144/250], Step [0050/0060], Loss1: 0.0214 Loss2: 0.0261 Loss3: 0.0191\n",
            "2022-08-02 14:31:42.752150 Epoch [144/250], Step [0060/0060], Loss1: 0.0198 Loss2: 0.0248 Loss3: 0.0178\n",
            "Epoch: 144 MAE: 0.008697008743645653 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:31:50.588017 Epoch [145/250], Step [0001/0060], Loss1: 0.0204 Loss2: 0.0255 Loss3: 0.0184\n",
            "2022-08-02 14:32:19.215228 Epoch [145/250], Step [0050/0060], Loss1: 0.0191 Loss2: 0.0243 Loss3: 0.0173\n",
            "2022-08-02 14:32:25.092190 Epoch [145/250], Step [0060/0060], Loss1: 0.0209 Loss2: 0.0278 Loss3: 0.0191\n",
            "Epoch: 145 MAE: 0.008497993661356824 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:32:35.455323 Epoch [146/250], Step [0001/0060], Loss1: 0.0202 Loss2: 0.0264 Loss3: 0.0184\n",
            "2022-08-02 14:33:04.525870 Epoch [146/250], Step [0050/0060], Loss1: 0.0218 Loss2: 0.0276 Loss3: 0.0189\n",
            "2022-08-02 14:33:10.363620 Epoch [146/250], Step [0060/0060], Loss1: 0.0212 Loss2: 0.0258 Loss3: 0.0192\n",
            "Epoch: 146 MAE: 0.008493455481671151 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:33:18.240961 Epoch [147/250], Step [0001/0060], Loss1: 0.0204 Loss2: 0.0259 Loss3: 0.0185\n",
            "2022-08-02 14:33:46.904085 Epoch [147/250], Step [0050/0060], Loss1: 0.0206 Loss2: 0.0252 Loss3: 0.0185\n",
            "2022-08-02 14:33:52.768947 Epoch [147/250], Step [0060/0060], Loss1: 0.0209 Loss2: 0.0271 Loss3: 0.0190\n",
            "Epoch: 147 MAE: 0.008724856256906475 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:34:00.683983 Epoch [148/250], Step [0001/0060], Loss1: 0.0198 Loss2: 0.0266 Loss3: 0.0174\n",
            "2022-08-02 14:34:29.417864 Epoch [148/250], Step [0050/0060], Loss1: 0.0210 Loss2: 0.0259 Loss3: 0.0189\n",
            "2022-08-02 14:34:35.312362 Epoch [148/250], Step [0060/0060], Loss1: 0.0193 Loss2: 0.0252 Loss3: 0.0175\n",
            "Epoch: 148 MAE: 0.008425322826951742 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:34:43.149330 Epoch [149/250], Step [0001/0060], Loss1: 0.0205 Loss2: 0.0271 Loss3: 0.0185\n",
            "2022-08-02 14:35:11.670871 Epoch [149/250], Step [0050/0060], Loss1: 0.0215 Loss2: 0.0268 Loss3: 0.0193\n",
            "2022-08-02 14:35:17.494362 Epoch [149/250], Step [0060/0060], Loss1: 0.0216 Loss2: 0.0266 Loss3: 0.0193\n",
            "Epoch: 149 MAE: 0.008673300826182914 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:35:25.254510 Epoch [150/250], Step [0001/0060], Loss1: 0.0205 Loss2: 0.0252 Loss3: 0.0187\n",
            "2022-08-02 14:35:53.968894 Epoch [150/250], Step [0050/0060], Loss1: 0.0204 Loss2: 0.0253 Loss3: 0.0184\n",
            "2022-08-02 14:35:59.762569 Epoch [150/250], Step [0060/0060], Loss1: 0.0199 Loss2: 0.0259 Loss3: 0.0181\n",
            "Epoch: 150 MAE: 0.00869120911709846 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:36:10.037915 Epoch [151/250], Step [0001/0060], Loss1: 0.0214 Loss2: 0.0254 Loss3: 0.0190\n",
            "2022-08-02 14:36:39.583916 Epoch [151/250], Step [0050/0060], Loss1: 0.0252 Loss2: 0.0311 Loss3: 0.0220\n",
            "2022-08-02 14:36:45.443196 Epoch [151/250], Step [0060/0060], Loss1: 0.0204 Loss2: 0.0241 Loss3: 0.0183\n",
            "Epoch: 151 MAE: 0.008911184774386504 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:36:53.269598 Epoch [152/250], Step [0001/0060], Loss1: 0.0205 Loss2: 0.0252 Loss3: 0.0185\n",
            "2022-08-02 14:37:22.126459 Epoch [152/250], Step [0050/0060], Loss1: 0.0204 Loss2: 0.0256 Loss3: 0.0184\n",
            "2022-08-02 14:37:27.965355 Epoch [152/250], Step [0060/0060], Loss1: 0.0197 Loss2: 0.0234 Loss3: 0.0180\n",
            "Epoch: 152 MAE: 0.00898283300921321 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:37:35.791121 Epoch [153/250], Step [0001/0060], Loss1: 0.0210 Loss2: 0.0270 Loss3: 0.0191\n",
            "2022-08-02 14:38:04.676169 Epoch [153/250], Step [0050/0060], Loss1: 0.0221 Loss2: 0.0274 Loss3: 0.0196\n",
            "2022-08-02 14:38:10.531476 Epoch [153/250], Step [0060/0060], Loss1: 0.0185 Loss2: 0.0227 Loss3: 0.0168\n",
            "Epoch: 153 MAE: 0.008761023902999503 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:38:18.485468 Epoch [154/250], Step [0001/0060], Loss1: 0.0216 Loss2: 0.0282 Loss3: 0.0193\n",
            "2022-08-02 14:38:47.368493 Epoch [154/250], Step [0050/0060], Loss1: 0.0205 Loss2: 0.0245 Loss3: 0.0185\n",
            "2022-08-02 14:38:53.174081 Epoch [154/250], Step [0060/0060], Loss1: 0.0223 Loss2: 0.0268 Loss3: 0.0195\n",
            "Epoch: 154 MAE: 0.00843850729454841 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:39:01.077598 Epoch [155/250], Step [0001/0060], Loss1: 0.0212 Loss2: 0.0264 Loss3: 0.0189\n",
            "2022-08-02 14:39:29.952489 Epoch [155/250], Step [0050/0060], Loss1: 0.0207 Loss2: 0.0266 Loss3: 0.0188\n",
            "2022-08-02 14:39:35.902513 Epoch [155/250], Step [0060/0060], Loss1: 0.0214 Loss2: 0.0287 Loss3: 0.0194\n",
            "Epoch: 155 MAE: 0.008327183882809348 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:39:46.302035 Epoch [156/250], Step [0001/0060], Loss1: 0.0201 Loss2: 0.0278 Loss3: 0.0182\n",
            "2022-08-02 14:40:15.686724 Epoch [156/250], Step [0050/0060], Loss1: 0.0216 Loss2: 0.0270 Loss3: 0.0194\n",
            "2022-08-02 14:40:21.512678 Epoch [156/250], Step [0060/0060], Loss1: 0.0193 Loss2: 0.0247 Loss3: 0.0175\n",
            "Epoch: 156 MAE: 0.00854448229813623 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:40:29.431630 Epoch [157/250], Step [0001/0060], Loss1: 0.0218 Loss2: 0.0266 Loss3: 0.0196\n",
            "2022-08-02 14:40:58.270591 Epoch [157/250], Step [0050/0060], Loss1: 0.0208 Loss2: 0.0253 Loss3: 0.0189\n",
            "2022-08-02 14:41:04.125340 Epoch [157/250], Step [0060/0060], Loss1: 0.0206 Loss2: 0.0264 Loss3: 0.0185\n",
            "Epoch: 157 MAE: 0.008447970854975874 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:41:12.060330 Epoch [158/250], Step [0001/0060], Loss1: 0.0212 Loss2: 0.0267 Loss3: 0.0192\n",
            "2022-08-02 14:41:40.911965 Epoch [158/250], Step [0050/0060], Loss1: 0.0208 Loss2: 0.0253 Loss3: 0.0188\n",
            "2022-08-02 14:41:46.712191 Epoch [158/250], Step [0060/0060], Loss1: 0.0218 Loss2: 0.0268 Loss3: 0.0196\n",
            "Epoch: 158 MAE: 0.008620378694364004 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:41:54.566291 Epoch [159/250], Step [0001/0060], Loss1: 0.0211 Loss2: 0.0254 Loss3: 0.0190\n",
            "2022-08-02 14:42:23.373126 Epoch [159/250], Step [0050/0060], Loss1: 0.0197 Loss2: 0.0251 Loss3: 0.0179\n",
            "2022-08-02 14:42:29.278490 Epoch [159/250], Step [0060/0060], Loss1: 0.0196 Loss2: 0.0244 Loss3: 0.0177\n",
            "Epoch: 159 MAE: 0.008745160412102465 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:42:37.058862 Epoch [160/250], Step [0001/0060], Loss1: 0.0222 Loss2: 0.0274 Loss3: 0.0199\n",
            "2022-08-02 14:43:05.753580 Epoch [160/250], Step [0050/0060], Loss1: 0.0194 Loss2: 0.0241 Loss3: 0.0175\n",
            "2022-08-02 14:43:11.623402 Epoch [160/250], Step [0060/0060], Loss1: 0.0199 Loss2: 0.0260 Loss3: 0.0179\n",
            "Epoch: 160 MAE: 0.008845575774709383 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:43:22.221048 Epoch [161/250], Step [0001/0060], Loss1: 0.0203 Loss2: 0.0264 Loss3: 0.0182\n",
            "2022-08-02 14:43:51.378634 Epoch [161/250], Step [0050/0060], Loss1: 0.0212 Loss2: 0.0282 Loss3: 0.0195\n",
            "2022-08-02 14:43:57.251751 Epoch [161/250], Step [0060/0060], Loss1: 0.0196 Loss2: 0.0233 Loss3: 0.0175\n",
            "Epoch: 161 MAE: 0.008483326639093104 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:44:04.982044 Epoch [162/250], Step [0001/0060], Loss1: 0.0217 Loss2: 0.0287 Loss3: 0.0197\n",
            "2022-08-02 14:44:33.660870 Epoch [162/250], Step [0050/0060], Loss1: 0.0205 Loss2: 0.0248 Loss3: 0.0185\n",
            "2022-08-02 14:44:39.514664 Epoch [162/250], Step [0060/0060], Loss1: 0.0232 Loss2: 0.0280 Loss3: 0.0200\n",
            "Epoch: 162 MAE: 0.008693658185028841 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:44:47.219146 Epoch [163/250], Step [0001/0060], Loss1: 0.0219 Loss2: 0.0271 Loss3: 0.0198\n",
            "2022-08-02 14:45:15.905969 Epoch [163/250], Step [0050/0060], Loss1: 0.0200 Loss2: 0.0260 Loss3: 0.0181\n",
            "2022-08-02 14:45:21.823792 Epoch [163/250], Step [0060/0060], Loss1: 0.0226 Loss2: 0.0267 Loss3: 0.0202\n",
            "Epoch: 163 MAE: 0.008810181392445451 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:45:29.551789 Epoch [164/250], Step [0001/0060], Loss1: 0.0196 Loss2: 0.0241 Loss3: 0.0178\n",
            "2022-08-02 14:45:58.426720 Epoch [164/250], Step [0050/0060], Loss1: 0.0215 Loss2: 0.0266 Loss3: 0.0194\n",
            "2022-08-02 14:46:04.241642 Epoch [164/250], Step [0060/0060], Loss1: 0.0193 Loss2: 0.0235 Loss3: 0.0176\n",
            "Epoch: 164 MAE: 0.008537402162180534 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:46:12.011444 Epoch [165/250], Step [0001/0060], Loss1: 0.0207 Loss2: 0.0271 Loss3: 0.0189\n",
            "2022-08-02 14:46:40.778037 Epoch [165/250], Step [0050/0060], Loss1: 0.0223 Loss2: 0.0284 Loss3: 0.0205\n",
            "2022-08-02 14:46:46.615850 Epoch [165/250], Step [0060/0060], Loss1: 0.0205 Loss2: 0.0278 Loss3: 0.0185\n",
            "Epoch: 165 MAE: 0.008571841694887668 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:46:57.103187 Epoch [166/250], Step [0001/0060], Loss1: 0.0213 Loss2: 0.0265 Loss3: 0.0192\n",
            "2022-08-02 14:47:26.463500 Epoch [166/250], Step [0050/0060], Loss1: 0.0195 Loss2: 0.0243 Loss3: 0.0177\n",
            "2022-08-02 14:47:32.256646 Epoch [166/250], Step [0060/0060], Loss1: 0.0206 Loss2: 0.0270 Loss3: 0.0187\n",
            "Epoch: 166 MAE: 0.008909375125926638 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:47:40.081758 Epoch [167/250], Step [0001/0060], Loss1: 0.0226 Loss2: 0.0266 Loss3: 0.0200\n",
            "2022-08-02 14:48:08.618626 Epoch [167/250], Step [0050/0060], Loss1: 0.0219 Loss2: 0.0282 Loss3: 0.0198\n",
            "2022-08-02 14:48:14.417738 Epoch [167/250], Step [0060/0060], Loss1: 0.0214 Loss2: 0.0258 Loss3: 0.0191\n",
            "Epoch: 167 MAE: 0.00857527188158461 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:48:22.349392 Epoch [168/250], Step [0001/0060], Loss1: 0.0195 Loss2: 0.0243 Loss3: 0.0176\n",
            "2022-08-02 14:48:51.098510 Epoch [168/250], Step [0050/0060], Loss1: 0.0218 Loss2: 0.0282 Loss3: 0.0195\n",
            "2022-08-02 14:48:57.020882 Epoch [168/250], Step [0060/0060], Loss1: 0.0205 Loss2: 0.0254 Loss3: 0.0189\n",
            "Epoch: 168 MAE: 0.008724431935993452 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:49:04.838387 Epoch [169/250], Step [0001/0060], Loss1: 0.0208 Loss2: 0.0258 Loss3: 0.0185\n",
            "2022-08-02 14:49:33.869253 Epoch [169/250], Step [0050/0060], Loss1: 0.0221 Loss2: 0.0274 Loss3: 0.0199\n",
            "2022-08-02 14:49:39.708547 Epoch [169/250], Step [0060/0060], Loss1: 0.0209 Loss2: 0.0254 Loss3: 0.0186\n",
            "Epoch: 169 MAE: 0.008264045497136456 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:49:47.607951 Epoch [170/250], Step [0001/0060], Loss1: 0.0215 Loss2: 0.0281 Loss3: 0.0196\n",
            "2022-08-02 14:50:16.403058 Epoch [170/250], Step [0050/0060], Loss1: 0.0232 Loss2: 0.0303 Loss3: 0.0209\n",
            "2022-08-02 14:50:22.229656 Epoch [170/250], Step [0060/0060], Loss1: 0.0194 Loss2: 0.0240 Loss3: 0.0177\n",
            "Epoch: 170 MAE: 0.008331190343827956 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:50:32.850768 Epoch [171/250], Step [0001/0060], Loss1: 0.0218 Loss2: 0.0277 Loss3: 0.0195\n",
            "2022-08-02 14:51:02.534356 Epoch [171/250], Step [0050/0060], Loss1: 0.0210 Loss2: 0.0267 Loss3: 0.0191\n",
            "2022-08-02 14:51:08.304830 Epoch [171/250], Step [0060/0060], Loss1: 0.0198 Loss2: 0.0248 Loss3: 0.0180\n",
            "Epoch: 171 MAE: 0.008682434609721578 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:51:16.204889 Epoch [172/250], Step [0001/0060], Loss1: 0.0209 Loss2: 0.0258 Loss3: 0.0189\n",
            "2022-08-02 14:51:44.938165 Epoch [172/250], Step [0050/0060], Loss1: 0.0200 Loss2: 0.0242 Loss3: 0.0180\n",
            "2022-08-02 14:51:50.862922 Epoch [172/250], Step [0060/0060], Loss1: 0.0210 Loss2: 0.0256 Loss3: 0.0186\n",
            "Epoch: 172 MAE: 0.008220757476039349 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:51:58.899308 Epoch [173/250], Step [0001/0060], Loss1: 0.0217 Loss2: 0.0278 Loss3: 0.0197\n",
            "2022-08-02 14:52:27.460649 Epoch [173/250], Step [0050/0060], Loss1: 0.0214 Loss2: 0.0278 Loss3: 0.0192\n",
            "2022-08-02 14:52:33.309689 Epoch [173/250], Step [0060/0060], Loss1: 0.0199 Loss2: 0.0244 Loss3: 0.0179\n",
            "Epoch: 173 MAE: 0.008479161058656044 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:52:41.279701 Epoch [174/250], Step [0001/0060], Loss1: 0.0228 Loss2: 0.0281 Loss3: 0.0204\n",
            "2022-08-02 14:53:10.128232 Epoch [174/250], Step [0050/0060], Loss1: 0.0201 Loss2: 0.0245 Loss3: 0.0180\n",
            "2022-08-02 14:53:16.015965 Epoch [174/250], Step [0060/0060], Loss1: 0.0195 Loss2: 0.0241 Loss3: 0.0176\n",
            "Epoch: 174 MAE: 0.00900137240421914 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:53:24.108172 Epoch [175/250], Step [0001/0060], Loss1: 0.0210 Loss2: 0.0265 Loss3: 0.0189\n",
            "2022-08-02 14:53:53.043123 Epoch [175/250], Step [0050/0060], Loss1: 0.0211 Loss2: 0.0258 Loss3: 0.0191\n",
            "2022-08-02 14:53:58.931913 Epoch [175/250], Step [0060/0060], Loss1: 0.0216 Loss2: 0.0290 Loss3: 0.0194\n",
            "Epoch: 175 MAE: 0.00851157775503539 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:54:09.451232 Epoch [176/250], Step [0001/0060], Loss1: 0.0195 Loss2: 0.0250 Loss3: 0.0177\n",
            "2022-08-02 14:54:39.233214 Epoch [176/250], Step [0050/0060], Loss1: 0.0210 Loss2: 0.0259 Loss3: 0.0187\n",
            "2022-08-02 14:54:45.056818 Epoch [176/250], Step [0060/0060], Loss1: 0.0188 Loss2: 0.0226 Loss3: 0.0170\n",
            "Epoch: 176 MAE: 0.008834641855505724 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:54:53.001046 Epoch [177/250], Step [0001/0060], Loss1: 0.0226 Loss2: 0.0283 Loss3: 0.0203\n",
            "2022-08-02 14:55:21.889865 Epoch [177/250], Step [0050/0060], Loss1: 0.0209 Loss2: 0.0250 Loss3: 0.0188\n",
            "2022-08-02 14:55:27.688825 Epoch [177/250], Step [0060/0060], Loss1: 0.0201 Loss2: 0.0245 Loss3: 0.0180\n",
            "Epoch: 177 MAE: 0.008536024041296471 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:55:35.580582 Epoch [178/250], Step [0001/0060], Loss1: 0.0219 Loss2: 0.0287 Loss3: 0.0197\n",
            "2022-08-02 14:56:04.347022 Epoch [178/250], Step [0050/0060], Loss1: 0.0221 Loss2: 0.0283 Loss3: 0.0200\n",
            "2022-08-02 14:56:10.226505 Epoch [178/250], Step [0060/0060], Loss1: 0.0205 Loss2: 0.0256 Loss3: 0.0185\n",
            "Epoch: 178 MAE: 0.008604099382720297 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:56:18.104272 Epoch [179/250], Step [0001/0060], Loss1: 0.0203 Loss2: 0.0262 Loss3: 0.0184\n",
            "2022-08-02 14:56:46.745743 Epoch [179/250], Step [0050/0060], Loss1: 0.0208 Loss2: 0.0254 Loss3: 0.0186\n",
            "2022-08-02 14:56:52.562464 Epoch [179/250], Step [0060/0060], Loss1: 0.0199 Loss2: 0.0242 Loss3: 0.0180\n",
            "Epoch: 179 MAE: 0.008630761248429143 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:57:00.473223 Epoch [180/250], Step [0001/0060], Loss1: 0.0213 Loss2: 0.0255 Loss3: 0.0190\n",
            "2022-08-02 14:57:29.327346 Epoch [180/250], Step [0050/0060], Loss1: 0.0198 Loss2: 0.0247 Loss3: 0.0178\n",
            "2022-08-02 14:57:35.180222 Epoch [180/250], Step [0060/0060], Loss1: 0.0201 Loss2: 0.0244 Loss3: 0.0180\n",
            "Epoch: 180 MAE: 0.008525470382578317 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:57:45.521397 Epoch [181/250], Step [0001/0060], Loss1: 0.0204 Loss2: 0.0255 Loss3: 0.0182\n",
            "2022-08-02 14:58:14.944568 Epoch [181/250], Step [0050/0060], Loss1: 0.0203 Loss2: 0.0253 Loss3: 0.0184\n",
            "2022-08-02 14:58:20.782905 Epoch [181/250], Step [0060/0060], Loss1: 0.0219 Loss2: 0.0278 Loss3: 0.0201\n",
            "Epoch: 181 MAE: 0.00863682103919841 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:58:28.622783 Epoch [182/250], Step [0001/0060], Loss1: 0.0197 Loss2: 0.0245 Loss3: 0.0179\n",
            "2022-08-02 14:58:57.483797 Epoch [182/250], Step [0050/0060], Loss1: 0.0229 Loss2: 0.0277 Loss3: 0.0203\n",
            "2022-08-02 14:59:03.354084 Epoch [182/250], Step [0060/0060], Loss1: 0.0204 Loss2: 0.0245 Loss3: 0.0184\n",
            "Epoch: 182 MAE: 0.008548493031412363 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:59:11.289128 Epoch [183/250], Step [0001/0060], Loss1: 0.0193 Loss2: 0.0235 Loss3: 0.0174\n",
            "2022-08-02 14:59:40.316761 Epoch [183/250], Step [0050/0060], Loss1: 0.0209 Loss2: 0.0259 Loss3: 0.0182\n",
            "2022-08-02 14:59:46.091661 Epoch [183/250], Step [0060/0060], Loss1: 0.0218 Loss2: 0.0274 Loss3: 0.0198\n",
            "Epoch: 183 MAE: 0.008545694466207236 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 14:59:53.939934 Epoch [184/250], Step [0001/0060], Loss1: 0.0208 Loss2: 0.0267 Loss3: 0.0186\n",
            "2022-08-02 15:00:22.807556 Epoch [184/250], Step [0050/0060], Loss1: 0.0218 Loss2: 0.0270 Loss3: 0.0192\n",
            "2022-08-02 15:00:28.663976 Epoch [184/250], Step [0060/0060], Loss1: 0.0213 Loss2: 0.0247 Loss3: 0.0188\n",
            "Epoch: 184 MAE: 0.00899089313304377 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:00:36.572943 Epoch [185/250], Step [0001/0060], Loss1: 0.0224 Loss2: 0.0270 Loss3: 0.0202\n",
            "2022-08-02 15:01:05.300406 Epoch [185/250], Step [0050/0060], Loss1: 0.0211 Loss2: 0.0261 Loss3: 0.0190\n",
            "2022-08-02 15:01:11.130403 Epoch [185/250], Step [0060/0060], Loss1: 0.0197 Loss2: 0.0249 Loss3: 0.0179\n",
            "Epoch: 185 MAE: 0.008546491604416616 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:01:21.755535 Epoch [186/250], Step [0001/0060], Loss1: 0.0199 Loss2: 0.0237 Loss3: 0.0181\n",
            "2022-08-02 15:01:50.899588 Epoch [186/250], Step [0050/0060], Loss1: 0.0205 Loss2: 0.0268 Loss3: 0.0184\n",
            "2022-08-02 15:01:56.879705 Epoch [186/250], Step [0060/0060], Loss1: 0.0217 Loss2: 0.0289 Loss3: 0.0196\n",
            "Epoch: 186 MAE: 0.008760309164663629 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:02:04.747926 Epoch [187/250], Step [0001/0060], Loss1: 0.0205 Loss2: 0.0260 Loss3: 0.0188\n",
            "2022-08-02 15:02:33.395993 Epoch [187/250], Step [0050/0060], Loss1: 0.0210 Loss2: 0.0268 Loss3: 0.0191\n",
            "2022-08-02 15:02:39.243600 Epoch [187/250], Step [0060/0060], Loss1: 0.0221 Loss2: 0.0285 Loss3: 0.0198\n",
            "Epoch: 187 MAE: 0.008439612656181294 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:02:47.457039 Epoch [188/250], Step [0001/0060], Loss1: 0.0186 Loss2: 0.0230 Loss3: 0.0168\n",
            "2022-08-02 15:03:16.362103 Epoch [188/250], Step [0050/0060], Loss1: 0.0213 Loss2: 0.0248 Loss3: 0.0190\n",
            "2022-08-02 15:03:22.223082 Epoch [188/250], Step [0060/0060], Loss1: 0.0208 Loss2: 0.0256 Loss3: 0.0189\n",
            "Epoch: 188 MAE: 0.00891973770090512 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:03:30.074088 Epoch [189/250], Step [0001/0060], Loss1: 0.0220 Loss2: 0.0271 Loss3: 0.0199\n",
            "2022-08-02 15:03:58.753239 Epoch [189/250], Step [0050/0060], Loss1: 0.0220 Loss2: 0.0290 Loss3: 0.0197\n",
            "2022-08-02 15:04:04.584205 Epoch [189/250], Step [0060/0060], Loss1: 0.0214 Loss2: 0.0280 Loss3: 0.0195\n",
            "Epoch: 189 MAE: 0.008699231529756197 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:04:12.787167 Epoch [190/250], Step [0001/0060], Loss1: 0.0206 Loss2: 0.0263 Loss3: 0.0188\n",
            "2022-08-02 15:04:41.670062 Epoch [190/250], Step [0050/0060], Loss1: 0.0204 Loss2: 0.0257 Loss3: 0.0182\n",
            "2022-08-02 15:04:47.523584 Epoch [190/250], Step [0060/0060], Loss1: 0.0207 Loss2: 0.0255 Loss3: 0.0185\n",
            "Epoch: 190 MAE: 0.008501574981011568 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:04:58.539871 Epoch [191/250], Step [0001/0060], Loss1: 0.0212 Loss2: 0.0266 Loss3: 0.0189\n",
            "2022-08-02 15:05:27.985433 Epoch [191/250], Step [0050/0060], Loss1: 0.0224 Loss2: 0.0296 Loss3: 0.0206\n",
            "2022-08-02 15:05:33.890981 Epoch [191/250], Step [0060/0060], Loss1: 0.0196 Loss2: 0.0250 Loss3: 0.0179\n",
            "Epoch: 191 MAE: 0.00871685870169174 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:05:41.762391 Epoch [192/250], Step [0001/0060], Loss1: 0.0224 Loss2: 0.0276 Loss3: 0.0201\n",
            "2022-08-02 15:06:10.566903 Epoch [192/250], Step [0050/0060], Loss1: 0.0202 Loss2: 0.0247 Loss3: 0.0183\n",
            "2022-08-02 15:06:16.421986 Epoch [192/250], Step [0060/0060], Loss1: 0.0219 Loss2: 0.0278 Loss3: 0.0199\n",
            "Epoch: 192 MAE: 0.008767924301089748 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:06:24.284100 Epoch [193/250], Step [0001/0060], Loss1: 0.0204 Loss2: 0.0255 Loss3: 0.0184\n",
            "2022-08-02 15:06:53.076070 Epoch [193/250], Step [0050/0060], Loss1: 0.0219 Loss2: 0.0264 Loss3: 0.0194\n",
            "2022-08-02 15:06:58.975862 Epoch [193/250], Step [0060/0060], Loss1: 0.0227 Loss2: 0.0280 Loss3: 0.0205\n",
            "Epoch: 193 MAE: 0.008448797551589825 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:07:06.907333 Epoch [194/250], Step [0001/0060], Loss1: 0.0206 Loss2: 0.0246 Loss3: 0.0182\n",
            "2022-08-02 15:07:35.913557 Epoch [194/250], Step [0050/0060], Loss1: 0.0217 Loss2: 0.0284 Loss3: 0.0197\n",
            "2022-08-02 15:07:41.766431 Epoch [194/250], Step [0060/0060], Loss1: 0.0206 Loss2: 0.0255 Loss3: 0.0186\n",
            "Epoch: 194 MAE: 0.008992004592622083 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:07:49.625414 Epoch [195/250], Step [0001/0060], Loss1: 0.0201 Loss2: 0.0260 Loss3: 0.0181\n",
            "2022-08-02 15:08:18.223808 Epoch [195/250], Step [0050/0060], Loss1: 0.0211 Loss2: 0.0255 Loss3: 0.0188\n",
            "2022-08-02 15:08:24.061007 Epoch [195/250], Step [0060/0060], Loss1: 0.0197 Loss2: 0.0247 Loss3: 0.0177\n",
            "Epoch: 195 MAE: 0.008824925123166943 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:08:34.646266 Epoch [196/250], Step [0001/0060], Loss1: 0.0198 Loss2: 0.0249 Loss3: 0.0179\n",
            "2022-08-02 15:09:04.025058 Epoch [196/250], Step [0050/0060], Loss1: 0.0218 Loss2: 0.0267 Loss3: 0.0198\n",
            "2022-08-02 15:09:09.883605 Epoch [196/250], Step [0060/0060], Loss1: 0.0190 Loss2: 0.0233 Loss3: 0.0172\n",
            "Epoch: 196 MAE: 0.008575650648997417 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:09:17.785489 Epoch [197/250], Step [0001/0060], Loss1: 0.0197 Loss2: 0.0245 Loss3: 0.0179\n",
            "2022-08-02 15:09:46.500303 Epoch [197/250], Step [0050/0060], Loss1: 0.0201 Loss2: 0.0243 Loss3: 0.0180\n",
            "2022-08-02 15:09:52.323839 Epoch [197/250], Step [0060/0060], Loss1: 0.0202 Loss2: 0.0249 Loss3: 0.0182\n",
            "Epoch: 197 MAE: 0.008621013257652521 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:10:00.136371 Epoch [198/250], Step [0001/0060], Loss1: 0.0209 Loss2: 0.0279 Loss3: 0.0190\n",
            "2022-08-02 15:10:29.136893 Epoch [198/250], Step [0050/0060], Loss1: 0.0221 Loss2: 0.0290 Loss3: 0.0198\n",
            "2022-08-02 15:10:34.961567 Epoch [198/250], Step [0060/0060], Loss1: 0.0204 Loss2: 0.0247 Loss3: 0.0183\n",
            "Epoch: 198 MAE: 0.008440517705850421 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:10:42.914842 Epoch [199/250], Step [0001/0060], Loss1: 0.0211 Loss2: 0.0261 Loss3: 0.0190\n",
            "2022-08-02 15:11:11.666839 Epoch [199/250], Step [0050/0060], Loss1: 0.0207 Loss2: 0.0249 Loss3: 0.0189\n",
            "2022-08-02 15:11:17.491162 Epoch [199/250], Step [0060/0060], Loss1: 0.0207 Loss2: 0.0267 Loss3: 0.0187\n",
            "Epoch: 199 MAE: 0.008610615055889838 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:11:25.355545 Epoch [200/250], Step [0001/0060], Loss1: 0.0193 Loss2: 0.0248 Loss3: 0.0178\n",
            "2022-08-02 15:11:54.184448 Epoch [200/250], Step [0050/0060], Loss1: 0.0211 Loss2: 0.0244 Loss3: 0.0191\n",
            "2022-08-02 15:11:59.997882 Epoch [200/250], Step [0060/0060], Loss1: 0.0215 Loss2: 0.0278 Loss3: 0.0195\n",
            "Epoch: 200 MAE: 0.008733478685220083 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:12:10.556028 Epoch [201/250], Step [0001/0060], Loss1: 0.0206 Loss2: 0.0251 Loss3: 0.0187\n",
            "2022-08-02 15:12:39.754132 Epoch [201/250], Step [0050/0060], Loss1: 0.0211 Loss2: 0.0269 Loss3: 0.0191\n",
            "2022-08-02 15:12:45.692786 Epoch [201/250], Step [0060/0060], Loss1: 0.0212 Loss2: 0.0270 Loss3: 0.0190\n",
            "Epoch: 201 MAE: 0.008689992639812686 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:12:53.597260 Epoch [202/250], Step [0001/0060], Loss1: 0.0190 Loss2: 0.0224 Loss3: 0.0173\n",
            "2022-08-02 15:13:22.361854 Epoch [202/250], Step [0050/0060], Loss1: 0.0201 Loss2: 0.0253 Loss3: 0.0181\n",
            "2022-08-02 15:13:28.184881 Epoch [202/250], Step [0060/0060], Loss1: 0.0206 Loss2: 0.0269 Loss3: 0.0189\n",
            "Epoch: 202 MAE: 0.008864363818059839 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:13:36.111421 Epoch [203/250], Step [0001/0060], Loss1: 0.0230 Loss2: 0.0288 Loss3: 0.0209\n",
            "2022-08-02 15:14:04.834728 Epoch [203/250], Step [0050/0060], Loss1: 0.0200 Loss2: 0.0250 Loss3: 0.0182\n",
            "2022-08-02 15:14:10.756353 Epoch [203/250], Step [0060/0060], Loss1: 0.0200 Loss2: 0.0251 Loss3: 0.0183\n",
            "Epoch: 203 MAE: 0.008593575770242346 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:14:18.703413 Epoch [204/250], Step [0001/0060], Loss1: 0.0221 Loss2: 0.0268 Loss3: 0.0199\n",
            "2022-08-02 15:14:47.463810 Epoch [204/250], Step [0050/0060], Loss1: 0.0207 Loss2: 0.0268 Loss3: 0.0189\n",
            "2022-08-02 15:14:53.298844 Epoch [204/250], Step [0060/0060], Loss1: 0.0202 Loss2: 0.0249 Loss3: 0.0184\n",
            "Epoch: 204 MAE: 0.00858613783641467 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:15:01.269338 Epoch [205/250], Step [0001/0060], Loss1: 0.0207 Loss2: 0.0252 Loss3: 0.0186\n",
            "2022-08-02 15:15:30.138392 Epoch [205/250], Step [0050/0060], Loss1: 0.0209 Loss2: 0.0263 Loss3: 0.0187\n",
            "2022-08-02 15:15:36.004516 Epoch [205/250], Step [0060/0060], Loss1: 0.0206 Loss2: 0.0248 Loss3: 0.0185\n",
            "Epoch: 205 MAE: 0.008730364379487814 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:15:46.511845 Epoch [206/250], Step [0001/0060], Loss1: 0.0206 Loss2: 0.0250 Loss3: 0.0184\n",
            "2022-08-02 15:16:15.732393 Epoch [206/250], Step [0050/0060], Loss1: 0.0210 Loss2: 0.0256 Loss3: 0.0189\n",
            "2022-08-02 15:16:21.544101 Epoch [206/250], Step [0060/0060], Loss1: 0.0219 Loss2: 0.0283 Loss3: 0.0197\n",
            "Epoch: 206 MAE: 0.008621467950029505 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:16:29.451495 Epoch [207/250], Step [0001/0060], Loss1: 0.0200 Loss2: 0.0253 Loss3: 0.0181\n",
            "2022-08-02 15:16:58.389327 Epoch [207/250], Step [0050/0060], Loss1: 0.0201 Loss2: 0.0244 Loss3: 0.0181\n",
            "2022-08-02 15:17:04.285673 Epoch [207/250], Step [0060/0060], Loss1: 0.0196 Loss2: 0.0241 Loss3: 0.0176\n",
            "Epoch: 207 MAE: 0.008625673595815897 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:17:12.171979 Epoch [208/250], Step [0001/0060], Loss1: 0.0208 Loss2: 0.0274 Loss3: 0.0184\n",
            "2022-08-02 15:17:41.064027 Epoch [208/250], Step [0050/0060], Loss1: 0.0218 Loss2: 0.0297 Loss3: 0.0198\n",
            "2022-08-02 15:17:46.997234 Epoch [208/250], Step [0060/0060], Loss1: 0.0214 Loss2: 0.0268 Loss3: 0.0192\n",
            "Epoch: 208 MAE: 0.008316632116302139 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:17:54.925162 Epoch [209/250], Step [0001/0060], Loss1: 0.0207 Loss2: 0.0256 Loss3: 0.0186\n",
            "2022-08-02 15:18:23.409785 Epoch [209/250], Step [0050/0060], Loss1: 0.0201 Loss2: 0.0255 Loss3: 0.0178\n",
            "2022-08-02 15:18:29.219318 Epoch [209/250], Step [0060/0060], Loss1: 0.0222 Loss2: 0.0300 Loss3: 0.0201\n",
            "Epoch: 209 MAE: 0.008691822821717887 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:18:37.151893 Epoch [210/250], Step [0001/0060], Loss1: 0.0192 Loss2: 0.0228 Loss3: 0.0174\n",
            "2022-08-02 15:19:05.845200 Epoch [210/250], Step [0050/0060], Loss1: 0.0196 Loss2: 0.0249 Loss3: 0.0177\n",
            "2022-08-02 15:19:11.862513 Epoch [210/250], Step [0060/0060], Loss1: 0.0207 Loss2: 0.0274 Loss3: 0.0189\n",
            "Epoch: 210 MAE: 0.00872761977925187 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:19:24.543492 Epoch [211/250], Step [0001/0060], Loss1: 0.0205 Loss2: 0.0253 Loss3: 0.0187\n",
            "2022-08-02 15:19:53.909889 Epoch [211/250], Step [0050/0060], Loss1: 0.0233 Loss2: 0.0300 Loss3: 0.0210\n",
            "2022-08-02 15:19:59.720914 Epoch [211/250], Step [0060/0060], Loss1: 0.0209 Loss2: 0.0267 Loss3: 0.0190\n",
            "Epoch: 211 MAE: 0.0085919546480808 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:20:07.578397 Epoch [212/250], Step [0001/0060], Loss1: 0.0199 Loss2: 0.0241 Loss3: 0.0179\n",
            "2022-08-02 15:20:36.623661 Epoch [212/250], Step [0050/0060], Loss1: 0.0207 Loss2: 0.0263 Loss3: 0.0188\n",
            "2022-08-02 15:20:42.415860 Epoch [212/250], Step [0060/0060], Loss1: 0.0206 Loss2: 0.0250 Loss3: 0.0186\n",
            "Epoch: 212 MAE: 0.008547556113510851 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:20:50.314352 Epoch [213/250], Step [0001/0060], Loss1: 0.0207 Loss2: 0.0252 Loss3: 0.0185\n",
            "2022-08-02 15:21:18.927646 Epoch [213/250], Step [0050/0060], Loss1: 0.0207 Loss2: 0.0257 Loss3: 0.0188\n",
            "2022-08-02 15:21:24.785662 Epoch [213/250], Step [0060/0060], Loss1: 0.0213 Loss2: 0.0262 Loss3: 0.0192\n",
            "Epoch: 213 MAE: 0.0085435364181028 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:21:32.813975 Epoch [214/250], Step [0001/0060], Loss1: 0.0216 Loss2: 0.0260 Loss3: 0.0195\n",
            "2022-08-02 15:22:01.618115 Epoch [214/250], Step [0050/0060], Loss1: 0.0195 Loss2: 0.0237 Loss3: 0.0176\n",
            "2022-08-02 15:22:07.448450 Epoch [214/250], Step [0060/0060], Loss1: 0.0204 Loss2: 0.0266 Loss3: 0.0185\n",
            "Epoch: 214 MAE: 0.008647299789276624 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:22:15.311010 Epoch [215/250], Step [0001/0060], Loss1: 0.0200 Loss2: 0.0250 Loss3: 0.0181\n",
            "2022-08-02 15:22:44.119328 Epoch [215/250], Step [0050/0060], Loss1: 0.0204 Loss2: 0.0263 Loss3: 0.0185\n",
            "2022-08-02 15:22:50.021883 Epoch [215/250], Step [0060/0060], Loss1: 0.0222 Loss2: 0.0264 Loss3: 0.0197\n",
            "Epoch: 215 MAE: 0.008497427594626234 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:23:00.603848 Epoch [216/250], Step [0001/0060], Loss1: 0.0211 Loss2: 0.0266 Loss3: 0.0192\n",
            "2022-08-02 15:23:29.665093 Epoch [216/250], Step [0050/0060], Loss1: 0.0221 Loss2: 0.0286 Loss3: 0.0200\n",
            "2022-08-02 15:23:35.559026 Epoch [216/250], Step [0060/0060], Loss1: 0.0216 Loss2: 0.0268 Loss3: 0.0196\n",
            "Epoch: 216 MAE: 0.008891484944061154 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:23:43.496378 Epoch [217/250], Step [0001/0060], Loss1: 0.0209 Loss2: 0.0267 Loss3: 0.0190\n",
            "2022-08-02 15:24:12.153461 Epoch [217/250], Step [0050/0060], Loss1: 0.0199 Loss2: 0.0255 Loss3: 0.0180\n",
            "2022-08-02 15:24:17.968912 Epoch [217/250], Step [0060/0060], Loss1: 0.0204 Loss2: 0.0259 Loss3: 0.0184\n",
            "Epoch: 217 MAE: 0.008355294295128376 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:24:25.878449 Epoch [218/250], Step [0001/0060], Loss1: 0.0214 Loss2: 0.0286 Loss3: 0.0195\n",
            "2022-08-02 15:24:54.669121 Epoch [218/250], Step [0050/0060], Loss1: 0.0212 Loss2: 0.0250 Loss3: 0.0192\n",
            "2022-08-02 15:25:00.482198 Epoch [218/250], Step [0060/0060], Loss1: 0.0214 Loss2: 0.0278 Loss3: 0.0191\n",
            "Epoch: 218 MAE: 0.008466934726115257 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:25:08.357877 Epoch [219/250], Step [0001/0060], Loss1: 0.0199 Loss2: 0.0244 Loss3: 0.0179\n",
            "2022-08-02 15:25:37.162246 Epoch [219/250], Step [0050/0060], Loss1: 0.0214 Loss2: 0.0270 Loss3: 0.0196\n",
            "2022-08-02 15:25:43.007345 Epoch [219/250], Step [0060/0060], Loss1: 0.0210 Loss2: 0.0264 Loss3: 0.0190\n",
            "Epoch: 219 MAE: 0.008754923887964752 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:25:50.934506 Epoch [220/250], Step [0001/0060], Loss1: 0.0209 Loss2: 0.0263 Loss3: 0.0187\n",
            "2022-08-02 15:26:19.903701 Epoch [220/250], Step [0050/0060], Loss1: 0.0210 Loss2: 0.0252 Loss3: 0.0189\n",
            "2022-08-02 15:26:25.737858 Epoch [220/250], Step [0060/0060], Loss1: 0.0199 Loss2: 0.0247 Loss3: 0.0179\n",
            "Epoch: 220 MAE: 0.008426841725373552 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:26:36.033232 Epoch [221/250], Step [0001/0060], Loss1: 0.0197 Loss2: 0.0244 Loss3: 0.0180\n",
            "2022-08-02 15:27:05.183297 Epoch [221/250], Step [0050/0060], Loss1: 0.0192 Loss2: 0.0244 Loss3: 0.0174\n",
            "2022-08-02 15:27:11.066434 Epoch [221/250], Step [0060/0060], Loss1: 0.0208 Loss2: 0.0248 Loss3: 0.0188\n",
            "Epoch: 221 MAE: 0.008544426503783417 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:27:18.879453 Epoch [222/250], Step [0001/0060], Loss1: 0.0192 Loss2: 0.0235 Loss3: 0.0172\n",
            "2022-08-02 15:27:47.593916 Epoch [222/250], Step [0050/0060], Loss1: 0.0209 Loss2: 0.0268 Loss3: 0.0188\n",
            "2022-08-02 15:27:53.414494 Epoch [222/250], Step [0060/0060], Loss1: 0.0205 Loss2: 0.0262 Loss3: 0.0186\n",
            "Epoch: 222 MAE: 0.008531550492440898 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:28:01.354092 Epoch [223/250], Step [0001/0060], Loss1: 0.0196 Loss2: 0.0249 Loss3: 0.0175\n",
            "2022-08-02 15:28:29.987607 Epoch [223/250], Step [0050/0060], Loss1: 0.0234 Loss2: 0.0314 Loss3: 0.0209\n",
            "2022-08-02 15:28:35.813961 Epoch [223/250], Step [0060/0060], Loss1: 0.0210 Loss2: 0.0261 Loss3: 0.0187\n",
            "Epoch: 223 MAE: 0.008473514823154324 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:28:43.642592 Epoch [224/250], Step [0001/0060], Loss1: 0.0206 Loss2: 0.0273 Loss3: 0.0186\n",
            "2022-08-02 15:29:12.329769 Epoch [224/250], Step [0050/0060], Loss1: 0.0219 Loss2: 0.0266 Loss3: 0.0196\n",
            "2022-08-02 15:29:18.116458 Epoch [224/250], Step [0060/0060], Loss1: 0.0203 Loss2: 0.0264 Loss3: 0.0181\n",
            "Epoch: 224 MAE: 0.008716875095925634 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:29:25.953733 Epoch [225/250], Step [0001/0060], Loss1: 0.0220 Loss2: 0.0278 Loss3: 0.0196\n",
            "2022-08-02 15:29:54.654662 Epoch [225/250], Step [0050/0060], Loss1: 0.0199 Loss2: 0.0244 Loss3: 0.0180\n",
            "2022-08-02 15:30:00.470619 Epoch [225/250], Step [0060/0060], Loss1: 0.0205 Loss2: 0.0256 Loss3: 0.0184\n",
            "Epoch: 225 MAE: 0.008662509665425335 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:30:10.998193 Epoch [226/250], Step [0001/0060], Loss1: 0.0224 Loss2: 0.0286 Loss3: 0.0202\n",
            "2022-08-02 15:30:40.519079 Epoch [226/250], Step [0050/0060], Loss1: 0.0202 Loss2: 0.0268 Loss3: 0.0183\n",
            "2022-08-02 15:30:46.482013 Epoch [226/250], Step [0060/0060], Loss1: 0.0217 Loss2: 0.0265 Loss3: 0.0195\n",
            "Epoch: 226 MAE: 0.008470468843976656 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:30:54.423409 Epoch [227/250], Step [0001/0060], Loss1: 0.0197 Loss2: 0.0251 Loss3: 0.0177\n",
            "2022-08-02 15:31:23.173181 Epoch [227/250], Step [0050/0060], Loss1: 0.0212 Loss2: 0.0274 Loss3: 0.0191\n",
            "2022-08-02 15:31:28.993299 Epoch [227/250], Step [0060/0060], Loss1: 0.0199 Loss2: 0.0260 Loss3: 0.0179\n",
            "Epoch: 227 MAE: 0.008703679666810092 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:31:36.807954 Epoch [228/250], Step [0001/0060], Loss1: 0.0195 Loss2: 0.0258 Loss3: 0.0178\n",
            "2022-08-02 15:32:05.469412 Epoch [228/250], Step [0050/0060], Loss1: 0.0204 Loss2: 0.0262 Loss3: 0.0184\n",
            "2022-08-02 15:32:11.291799 Epoch [228/250], Step [0060/0060], Loss1: 0.0203 Loss2: 0.0260 Loss3: 0.0186\n",
            "Epoch: 228 MAE: 0.008529731948372154 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:32:19.184747 Epoch [229/250], Step [0001/0060], Loss1: 0.0203 Loss2: 0.0258 Loss3: 0.0187\n",
            "2022-08-02 15:32:47.856011 Epoch [229/250], Step [0050/0060], Loss1: 0.0219 Loss2: 0.0277 Loss3: 0.0199\n",
            "2022-08-02 15:32:53.683572 Epoch [229/250], Step [0060/0060], Loss1: 0.0204 Loss2: 0.0251 Loss3: 0.0183\n",
            "Epoch: 229 MAE: 0.00840412629103022 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:33:01.627809 Epoch [230/250], Step [0001/0060], Loss1: 0.0199 Loss2: 0.0255 Loss3: 0.0182\n",
            "2022-08-02 15:33:30.402937 Epoch [230/250], Step [0050/0060], Loss1: 0.0225 Loss2: 0.0281 Loss3: 0.0201\n",
            "2022-08-02 15:33:36.249077 Epoch [230/250], Step [0060/0060], Loss1: 0.0216 Loss2: 0.0257 Loss3: 0.0193\n",
            "Epoch: 230 MAE: 0.00875495480639594 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:33:46.717747 Epoch [231/250], Step [0001/0060], Loss1: 0.0221 Loss2: 0.0262 Loss3: 0.0199\n",
            "2022-08-02 15:34:16.633400 Epoch [231/250], Step [0050/0060], Loss1: 0.0220 Loss2: 0.0261 Loss3: 0.0195\n",
            "2022-08-02 15:34:22.551135 Epoch [231/250], Step [0060/0060], Loss1: 0.0209 Loss2: 0.0258 Loss3: 0.0188\n",
            "Epoch: 231 MAE: 0.008661616689688156 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:34:30.374845 Epoch [232/250], Step [0001/0060], Loss1: 0.0211 Loss2: 0.0271 Loss3: 0.0190\n",
            "2022-08-02 15:34:58.962097 Epoch [232/250], Step [0050/0060], Loss1: 0.0212 Loss2: 0.0268 Loss3: 0.0190\n",
            "2022-08-02 15:35:04.761994 Epoch [232/250], Step [0060/0060], Loss1: 0.0206 Loss2: 0.0255 Loss3: 0.0187\n",
            "Epoch: 232 MAE: 0.008564591141683715 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:35:12.560734 Epoch [233/250], Step [0001/0060], Loss1: 0.0192 Loss2: 0.0244 Loss3: 0.0175\n",
            "2022-08-02 15:35:41.251583 Epoch [233/250], Step [0050/0060], Loss1: 0.0192 Loss2: 0.0263 Loss3: 0.0173\n",
            "2022-08-02 15:35:47.120566 Epoch [233/250], Step [0060/0060], Loss1: 0.0212 Loss2: 0.0267 Loss3: 0.0193\n",
            "Epoch: 233 MAE: 0.008356699620240502 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:35:55.011190 Epoch [234/250], Step [0001/0060], Loss1: 0.0197 Loss2: 0.0256 Loss3: 0.0179\n",
            "2022-08-02 15:36:23.536627 Epoch [234/250], Step [0050/0060], Loss1: 0.0198 Loss2: 0.0239 Loss3: 0.0176\n",
            "2022-08-02 15:36:29.328437 Epoch [234/250], Step [0060/0060], Loss1: 0.0205 Loss2: 0.0267 Loss3: 0.0185\n",
            "Epoch: 234 MAE: 0.008575489877590112 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:36:37.170048 Epoch [235/250], Step [0001/0060], Loss1: 0.0205 Loss2: 0.0255 Loss3: 0.0186\n",
            "2022-08-02 15:37:05.892257 Epoch [235/250], Step [0050/0060], Loss1: 0.0199 Loss2: 0.0265 Loss3: 0.0180\n",
            "2022-08-02 15:37:11.717616 Epoch [235/250], Step [0060/0060], Loss1: 0.0219 Loss2: 0.0289 Loss3: 0.0203\n",
            "Epoch: 235 MAE: 0.008506333492400627 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:37:22.124606 Epoch [236/250], Step [0001/0060], Loss1: 0.0203 Loss2: 0.0259 Loss3: 0.0185\n",
            "2022-08-02 15:37:51.272400 Epoch [236/250], Step [0050/0060], Loss1: 0.0197 Loss2: 0.0241 Loss3: 0.0177\n",
            "2022-08-02 15:37:57.106507 Epoch [236/250], Step [0060/0060], Loss1: 0.0204 Loss2: 0.0253 Loss3: 0.0185\n",
            "Epoch: 236 MAE: 0.008678224277756517 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:38:04.910211 Epoch [237/250], Step [0001/0060], Loss1: 0.0207 Loss2: 0.0248 Loss3: 0.0185\n",
            "2022-08-02 15:38:33.330774 Epoch [237/250], Step [0050/0060], Loss1: 0.0228 Loss2: 0.0290 Loss3: 0.0206\n",
            "2022-08-02 15:38:39.110596 Epoch [237/250], Step [0060/0060], Loss1: 0.0218 Loss2: 0.0257 Loss3: 0.0195\n",
            "Epoch: 237 MAE: 0.008463330382096863 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:38:46.954385 Epoch [238/250], Step [0001/0060], Loss1: 0.0203 Loss2: 0.0251 Loss3: 0.0185\n",
            "2022-08-02 15:39:15.544493 Epoch [238/250], Step [0050/0060], Loss1: 0.0194 Loss2: 0.0251 Loss3: 0.0175\n",
            "2022-08-02 15:39:21.360705 Epoch [238/250], Step [0060/0060], Loss1: 0.0213 Loss2: 0.0274 Loss3: 0.0193\n",
            "Epoch: 238 MAE: 0.008750723408801215 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:39:29.207213 Epoch [239/250], Step [0001/0060], Loss1: 0.0205 Loss2: 0.0243 Loss3: 0.0184\n",
            "2022-08-02 15:39:57.823086 Epoch [239/250], Step [0050/0060], Loss1: 0.0228 Loss2: 0.0270 Loss3: 0.0202\n",
            "2022-08-02 15:40:03.596368 Epoch [239/250], Step [0060/0060], Loss1: 0.0201 Loss2: 0.0236 Loss3: 0.0183\n",
            "Epoch: 239 MAE: 0.00867798396696647 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:40:11.542510 Epoch [240/250], Step [0001/0060], Loss1: 0.0218 Loss2: 0.0281 Loss3: 0.0197\n",
            "2022-08-02 15:40:40.038027 Epoch [240/250], Step [0050/0060], Loss1: 0.0192 Loss2: 0.0234 Loss3: 0.0175\n",
            "2022-08-02 15:40:45.896567 Epoch [240/250], Step [0060/0060], Loss1: 0.0222 Loss2: 0.0286 Loss3: 0.0201\n",
            "Epoch: 240 MAE: 0.008972067563306717 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:40:56.341775 Epoch [241/250], Step [0001/0060], Loss1: 0.0204 Loss2: 0.0259 Loss3: 0.0185\n",
            "2022-08-02 15:41:25.721567 Epoch [241/250], Step [0050/0060], Loss1: 0.0204 Loss2: 0.0254 Loss3: 0.0185\n",
            "2022-08-02 15:41:31.513984 Epoch [241/250], Step [0060/0060], Loss1: 0.0200 Loss2: 0.0256 Loss3: 0.0183\n",
            "Epoch: 241 MAE: 0.008689639291593007 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:41:39.265530 Epoch [242/250], Step [0001/0060], Loss1: 0.0212 Loss2: 0.0269 Loss3: 0.0192\n",
            "2022-08-02 15:42:07.927378 Epoch [242/250], Step [0050/0060], Loss1: 0.0215 Loss2: 0.0281 Loss3: 0.0195\n",
            "2022-08-02 15:42:13.715703 Epoch [242/250], Step [0060/0060], Loss1: 0.0190 Loss2: 0.0235 Loss3: 0.0171\n",
            "Epoch: 242 MAE: 0.008736434156104686 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:42:21.659602 Epoch [243/250], Step [0001/0060], Loss1: 0.0202 Loss2: 0.0268 Loss3: 0.0185\n",
            "2022-08-02 15:42:50.261166 Epoch [243/250], Step [0050/0060], Loss1: 0.0218 Loss2: 0.0281 Loss3: 0.0197\n",
            "2022-08-02 15:42:56.018088 Epoch [243/250], Step [0060/0060], Loss1: 0.0208 Loss2: 0.0280 Loss3: 0.0189\n",
            "Epoch: 243 MAE: 0.008520829528274517 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:43:03.844865 Epoch [244/250], Step [0001/0060], Loss1: 0.0214 Loss2: 0.0246 Loss3: 0.0189\n",
            "2022-08-02 15:43:32.409494 Epoch [244/250], Step [0050/0060], Loss1: 0.0212 Loss2: 0.0280 Loss3: 0.0192\n",
            "2022-08-02 15:43:38.213280 Epoch [244/250], Step [0060/0060], Loss1: 0.0218 Loss2: 0.0276 Loss3: 0.0196\n",
            "Epoch: 244 MAE: 0.008154609122328342 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:43:46.055978 Epoch [245/250], Step [0001/0060], Loss1: 0.0195 Loss2: 0.0245 Loss3: 0.0176\n",
            "2022-08-02 15:44:14.709555 Epoch [245/250], Step [0050/0060], Loss1: 0.0217 Loss2: 0.0287 Loss3: 0.0195\n",
            "2022-08-02 15:44:20.620844 Epoch [245/250], Step [0060/0060], Loss1: 0.0210 Loss2: 0.0264 Loss3: 0.0191\n",
            "Epoch: 245 MAE: 0.00867116931707613 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:44:31.082682 Epoch [246/250], Step [0001/0060], Loss1: 0.0226 Loss2: 0.0280 Loss3: 0.0202\n",
            "2022-08-02 15:45:00.087075 Epoch [246/250], Step [0050/0060], Loss1: 0.0210 Loss2: 0.0263 Loss3: 0.0187\n",
            "2022-08-02 15:45:05.912403 Epoch [246/250], Step [0060/0060], Loss1: 0.0202 Loss2: 0.0246 Loss3: 0.0183\n",
            "Epoch: 246 MAE: 0.008775216120753496 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:45:13.772978 Epoch [247/250], Step [0001/0060], Loss1: 0.0199 Loss2: 0.0252 Loss3: 0.0180\n",
            "2022-08-02 15:45:42.397219 Epoch [247/250], Step [0050/0060], Loss1: 0.0198 Loss2: 0.0248 Loss3: 0.0181\n",
            "2022-08-02 15:45:48.230427 Epoch [247/250], Step [0060/0060], Loss1: 0.0225 Loss2: 0.0301 Loss3: 0.0204\n",
            "Epoch: 247 MAE: 0.008533906952906695 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:45:56.097756 Epoch [248/250], Step [0001/0060], Loss1: 0.0212 Loss2: 0.0261 Loss3: 0.0183\n",
            "2022-08-02 15:46:24.800995 Epoch [248/250], Step [0050/0060], Loss1: 0.0216 Loss2: 0.0261 Loss3: 0.0192\n",
            "2022-08-02 15:46:30.605519 Epoch [248/250], Step [0060/0060], Loss1: 0.0201 Loss2: 0.0256 Loss3: 0.0181\n",
            "Epoch: 248 MAE: 0.008636643821817069 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n",
            "2022-08-02 15:46:38.541544 Epoch [249/250], Step [0001/0060], Loss1: 0.0209 Loss2: 0.0250 Loss3: 0.0192\n",
            "2022-08-02 15:47:07.081330 Epoch [249/250], Step [0050/0060], Loss1: 0.0211 Loss2: 0.0281 Loss3: 0.0190\n",
            "2022-08-02 15:47:13.026377 Epoch [249/250], Step [0060/0060], Loss1: 0.0192 Loss2: 0.0253 Loss3: 0.0172\n",
            "Epoch: 249 MAE: 0.008659458453101771 ####  bestMAE: 0.007175290886874473 bestEpoch: 57\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with L2 Loss\n",
        "\n"
      ],
      "metadata": {
        "id": "VYonp-XUkQbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import ProxyBasicAuthHandler\n",
        "import torch.nn.functional as nnf\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "\n",
        "#loss\n",
        "L2Loss = torch.nn.MSELoss()\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "train_accu = []\n",
        "train_losses = []\n",
        "train_accu1 = []\n",
        "train_accu2 = []\n",
        "train_accu3 = []\n",
        "train_losses1 = []\n",
        "train_losses2 = []\n",
        "train_losses3 = []\n",
        "val_accu = []\n",
        "val_losses = []\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    running_loss = 0\n",
        "    running_loss1 = 0\n",
        "    running_loss2 = 0\n",
        "    running_loss3 = 0\n",
        "    total = 0\n",
        "    total1 = 0\n",
        "    total2 = 0\n",
        "    total3 = 0\n",
        "    correct = 0\n",
        "    correct1 = 0\n",
        "    correct2 = 0\n",
        "    correct3 = 0\n",
        "\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = L2Loss(gts, pre_res[0]) \n",
        "            loss2    = L2Loss(gts, pre_res[1])\n",
        "            loss3    = L2Loss(gts, pre_res[2])\n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "\n",
        "            #loss graph\n",
        "            running_loss1 += loss1.item()\n",
        "            running_loss2 += loss2.item()\n",
        "            running_loss3 += loss3.item()\n",
        "            predicted1 = pre_res[0]\n",
        "            predicted2 = pre_res[1]\n",
        "            predicted3 = pre_res[2]\n",
        "            total1 += images.size(0)\n",
        "            total2 += gts.size(0)\n",
        "            total3 += depths.size(0)\n",
        "            #correct1 += float(torch.sum(predicted1 == gts.data))\n",
        "            #correct2 += float(torch.sum(predicted2 == gts.data))\n",
        "            #correct3 += float(torch.sum(predicted3 == gts.data))\n",
        "            correct1 += predicted1.eq(images).sum().item()\n",
        "            correct2 += predicted2.eq(gts).sum().item()\n",
        "            correct3 += predicted3.eq(depths).sum().item()\n",
        "\n",
        "            running_loss += loss_all.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = torch.sum(gt + loss + predicted)\n",
        "            total += images.size(0)\n",
        "            correct += float(correct1 + correct2 + correct3)\n",
        "            \n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "\n",
        "        train_loss = running_loss/len(train_loader)\n",
        "        train_loss1=running_loss1/len(train_loader)\n",
        "        train_loss2=running_loss2/len(train_loader)\n",
        "        train_loss3=running_loss3/len(train_loader)\n",
        "        accu1= correct1/total1\n",
        "        accu2= correct2/total2\n",
        "        accu3= correct3/total3 \n",
        "        accu = correct/total\n",
        "           \n",
        "        train_accu1.append(round(accu1, 3))\n",
        "        train_accu2.append(round(accu2, 3))\n",
        "        train_accu3.append(round(accu3, 3))\n",
        "        train_losses1.append(float(train_loss1))\n",
        "        train_losses2.append(float(train_loss2))\n",
        "        train_losses3.append(float(train_loss3))\n",
        "        train_accu.append(round(accu, 3))\n",
        "        train_losses.append(float(train_loss))\n",
        "\n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "           \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0.0\n",
        "\n",
        "    correct1 = 0.0\n",
        "    correct2 = 0.0\n",
        "    correct3 = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-4)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-4)\n",
        "            mae = np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "            mae = np.mean((gt - res)**2)\n",
        "            mae_sum += mae\n",
        "\n",
        "            #loss graph\n",
        "            running_loss += mae_sum\n",
        "            pre1, pre2, predicted = pre_res\n",
        "            #outputs = float(torch.sum(gt + depth + predicted))\n",
        "            total += test_loader.size\n",
        "\n",
        "            #correct1 += float(torch.sum(pre1 == image.data))\n",
        "            #correct2 += float(torch.sum(pre2 == image.data))\n",
        "            #correct3 += float(torch.sum(predicted == image.data))\n",
        "\n",
        "            correct += predicted.eq(image).sum().item()\n",
        "            #correct += float(torch.sum(predicted == image).item())\n",
        "\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "       \n",
        "        val_loss=running_loss/len(test_loader)\n",
        "        accu= 100 * correct/total\n",
        "        val_accu.append(round(accu, 3))\n",
        "        val_losses.append(float(val_loss))\n",
        "\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                #torch.save(model.state_dict(), save_path+'SPNet_epoch_best_Combine_Loss_only_with_RGB_as_depth.pth')\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_l2_loss.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n",
        "\n",
        "plt.plot(train_losses, '-')\n",
        "plt.plot(train_losses1,'-')\n",
        "plt.plot(train_losses2,'-')\n",
        "plt.plot(train_losses3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Combined_loss','Loss1', 'Loss2', 'Loss3'])\n",
        "plt.title('Train Losses')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_accu, '-')\n",
        "plt.plot(train_accu1,'-')\n",
        "plt.plot(train_accu2,'-')\n",
        "plt.plot(train_accu3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Acc')\n",
        "plt.legend(['Combined_Accuracy','Acc1', 'Acc2', 'Acc3'])\n",
        "plt.title('Train Accuracy')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(val_losses,'-')\n",
        "plt.plot(val_accu,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Losses','Accuracy'])\n",
        "plt.title('Test Losses and Accuracy')\n",
        " \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dGQ1tZ3AkT_j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "923f0c14-461d-495c-9ce8-7a887b4b9ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USE GPU 0\n",
            "load data...\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/traindataset_only_depth/RGB/depth_00.png', '/content/tmp/traindataset_only_depth/RGB/depth_01.png', '/content/tmp/traindataset_only_depth/RGB/depth_02.png', '/content/tmp/traindataset_only_depth/RGB/depth_10.png', '/content/tmp/traindataset_only_depth/RGB/depth_100.png', '/content/tmp/traindataset_only_depth/RGB/depth_101.png', '/content/tmp/traindataset_only_depth/RGB/depth_102.png', '/content/tmp/traindataset_only_depth/RGB/depth_11.png', '/content/tmp/traindataset_only_depth/RGB/depth_110.png', '/content/tmp/traindataset_only_depth/RGB/depth_111.png', '/content/tmp/traindataset_only_depth/RGB/depth_112.png', '/content/tmp/traindataset_only_depth/RGB/depth_12.png', '/content/tmp/traindataset_only_depth/RGB/depth_120.png', '/content/tmp/traindataset_only_depth/RGB/depth_121.png', '/content/tmp/traindataset_only_depth/RGB/depth_122.png', '/content/tmp/traindataset_only_depth/RGB/depth_130.png', '/content/tmp/traindataset_only_depth/RGB/depth_131.png', '/content/tmp/traindataset_only_depth/RGB/depth_132.png', '/content/tmp/traindataset_only_depth/RGB/depth_140.png', '/content/tmp/traindataset_only_depth/RGB/depth_141.png', '/content/tmp/traindataset_only_depth/RGB/depth_142.png', '/content/tmp/traindataset_only_depth/RGB/depth_150.png', '/content/tmp/traindataset_only_depth/RGB/depth_151.png', '/content/tmp/traindataset_only_depth/RGB/depth_152.png', '/content/tmp/traindataset_only_depth/RGB/depth_160.png', '/content/tmp/traindataset_only_depth/RGB/depth_161.png', '/content/tmp/traindataset_only_depth/RGB/depth_162.png', '/content/tmp/traindataset_only_depth/RGB/depth_170.png', '/content/tmp/traindataset_only_depth/RGB/depth_171.png', '/content/tmp/traindataset_only_depth/RGB/depth_172.png', '/content/tmp/traindataset_only_depth/RGB/depth_180.png', '/content/tmp/traindataset_only_depth/RGB/depth_181.png', '/content/tmp/traindataset_only_depth/RGB/depth_182.png', '/content/tmp/traindataset_only_depth/RGB/depth_190.png', '/content/tmp/traindataset_only_depth/RGB/depth_191.png', '/content/tmp/traindataset_only_depth/RGB/depth_192.png', '/content/tmp/traindataset_only_depth/RGB/depth_20.png', '/content/tmp/traindataset_only_depth/RGB/depth_200.png', '/content/tmp/traindataset_only_depth/RGB/depth_201.png', '/content/tmp/traindataset_only_depth/RGB/depth_202.png', '/content/tmp/traindataset_only_depth/RGB/depth_21.png', '/content/tmp/traindataset_only_depth/RGB/depth_210.png', '/content/tmp/traindataset_only_depth/RGB/depth_211.png', '/content/tmp/traindataset_only_depth/RGB/depth_212.png', '/content/tmp/traindataset_only_depth/RGB/depth_22.png', '/content/tmp/traindataset_only_depth/RGB/depth_220.png', '/content/tmp/traindataset_only_depth/RGB/depth_221.png', '/content/tmp/traindataset_only_depth/RGB/depth_222.png', '/content/tmp/traindataset_only_depth/RGB/depth_230.png', '/content/tmp/traindataset_only_depth/RGB/depth_231.png', '/content/tmp/traindataset_only_depth/RGB/depth_232.png', '/content/tmp/traindataset_only_depth/RGB/depth_240.png', '/content/tmp/traindataset_only_depth/RGB/depth_241.png', '/content/tmp/traindataset_only_depth/RGB/depth_242.png', '/content/tmp/traindataset_only_depth/RGB/depth_250.png', '/content/tmp/traindataset_only_depth/RGB/depth_251.png', '/content/tmp/traindataset_only_depth/RGB/depth_252.png', '/content/tmp/traindataset_only_depth/RGB/depth_260.png', '/content/tmp/traindataset_only_depth/RGB/depth_261.png', '/content/tmp/traindataset_only_depth/RGB/depth_262.png', '/content/tmp/traindataset_only_depth/RGB/depth_270.png', '/content/tmp/traindataset_only_depth/RGB/depth_271.png', '/content/tmp/traindataset_only_depth/RGB/depth_272.png', '/content/tmp/traindataset_only_depth/RGB/depth_280.png', '/content/tmp/traindataset_only_depth/RGB/depth_281.png', '/content/tmp/traindataset_only_depth/RGB/depth_282.png', '/content/tmp/traindataset_only_depth/RGB/depth_290.png', '/content/tmp/traindataset_only_depth/RGB/depth_291.png', '/content/tmp/traindataset_only_depth/RGB/depth_292.png', '/content/tmp/traindataset_only_depth/RGB/depth_30.png', '/content/tmp/traindataset_only_depth/RGB/depth_300.png', '/content/tmp/traindataset_only_depth/RGB/depth_301.png', '/content/tmp/traindataset_only_depth/RGB/depth_302.png', '/content/tmp/traindataset_only_depth/RGB/depth_31.png', '/content/tmp/traindataset_only_depth/RGB/depth_310.png', '/content/tmp/traindataset_only_depth/RGB/depth_311.png', '/content/tmp/traindataset_only_depth/RGB/depth_312.png', '/content/tmp/traindataset_only_depth/RGB/depth_32.png', '/content/tmp/traindataset_only_depth/RGB/depth_320.png', '/content/tmp/traindataset_only_depth/RGB/depth_321.png', '/content/tmp/traindataset_only_depth/RGB/depth_322.png', '/content/tmp/traindataset_only_depth/RGB/depth_330.png', '/content/tmp/traindataset_only_depth/RGB/depth_331.png', '/content/tmp/traindataset_only_depth/RGB/depth_332.png', '/content/tmp/traindataset_only_depth/RGB/depth_340.png', '/content/tmp/traindataset_only_depth/RGB/depth_341.png', '/content/tmp/traindataset_only_depth/RGB/depth_342.png', '/content/tmp/traindataset_only_depth/RGB/depth_350.png', '/content/tmp/traindataset_only_depth/RGB/depth_351.png', '/content/tmp/traindataset_only_depth/RGB/depth_352.png', '/content/tmp/traindataset_only_depth/RGB/depth_360.png', '/content/tmp/traindataset_only_depth/RGB/depth_361.png', '/content/tmp/traindataset_only_depth/RGB/depth_362.png', '/content/tmp/traindataset_only_depth/RGB/depth_370.png', '/content/tmp/traindataset_only_depth/RGB/depth_371.png', '/content/tmp/traindataset_only_depth/RGB/depth_372.png', '/content/tmp/traindataset_only_depth/RGB/depth_380.png', '/content/tmp/traindataset_only_depth/RGB/depth_381.png', '/content/tmp/traindataset_only_depth/RGB/depth_382.png', '/content/tmp/traindataset_only_depth/RGB/depth_390.png', '/content/tmp/traindataset_only_depth/RGB/depth_391.png', '/content/tmp/traindataset_only_depth/RGB/depth_392.png', '/content/tmp/traindataset_only_depth/RGB/depth_40.png', '/content/tmp/traindataset_only_depth/RGB/depth_400.png', '/content/tmp/traindataset_only_depth/RGB/depth_401.png', '/content/tmp/traindataset_only_depth/RGB/depth_402.png', '/content/tmp/traindataset_only_depth/RGB/depth_41.png', '/content/tmp/traindataset_only_depth/RGB/depth_410.png', '/content/tmp/traindataset_only_depth/RGB/depth_411.png', '/content/tmp/traindataset_only_depth/RGB/depth_412.png', '/content/tmp/traindataset_only_depth/RGB/depth_42.png', '/content/tmp/traindataset_only_depth/RGB/depth_420.png', '/content/tmp/traindataset_only_depth/RGB/depth_421.png', '/content/tmp/traindataset_only_depth/RGB/depth_422.png', '/content/tmp/traindataset_only_depth/RGB/depth_430.png', '/content/tmp/traindataset_only_depth/RGB/depth_431.png', '/content/tmp/traindataset_only_depth/RGB/depth_432.png', '/content/tmp/traindataset_only_depth/RGB/depth_440.png', '/content/tmp/traindataset_only_depth/RGB/depth_441.png', '/content/tmp/traindataset_only_depth/RGB/depth_442.png', '/content/tmp/traindataset_only_depth/RGB/depth_450.png', '/content/tmp/traindataset_only_depth/RGB/depth_451.png', '/content/tmp/traindataset_only_depth/RGB/depth_452.png', '/content/tmp/traindataset_only_depth/RGB/depth_460.png', '/content/tmp/traindataset_only_depth/RGB/depth_461.png', '/content/tmp/traindataset_only_depth/RGB/depth_462.png', '/content/tmp/traindataset_only_depth/RGB/depth_470.png', '/content/tmp/traindataset_only_depth/RGB/depth_471.png', '/content/tmp/traindataset_only_depth/RGB/depth_472.png', '/content/tmp/traindataset_only_depth/RGB/depth_480.png', '/content/tmp/traindataset_only_depth/RGB/depth_481.png', '/content/tmp/traindataset_only_depth/RGB/depth_482.png', '/content/tmp/traindataset_only_depth/RGB/depth_490.png', '/content/tmp/traindataset_only_depth/RGB/depth_491.png', '/content/tmp/traindataset_only_depth/RGB/depth_492.png', '/content/tmp/traindataset_only_depth/RGB/depth_50.png', '/content/tmp/traindataset_only_depth/RGB/depth_500.png', '/content/tmp/traindataset_only_depth/RGB/depth_501.png', '/content/tmp/traindataset_only_depth/RGB/depth_502.png', '/content/tmp/traindataset_only_depth/RGB/depth_51.png', '/content/tmp/traindataset_only_depth/RGB/depth_510.png', '/content/tmp/traindataset_only_depth/RGB/depth_511.png', '/content/tmp/traindataset_only_depth/RGB/depth_512.png', '/content/tmp/traindataset_only_depth/RGB/depth_52.png', '/content/tmp/traindataset_only_depth/RGB/depth_520.png', '/content/tmp/traindataset_only_depth/RGB/depth_521.png', '/content/tmp/traindataset_only_depth/RGB/depth_522.png', '/content/tmp/traindataset_only_depth/RGB/depth_530.png', '/content/tmp/traindataset_only_depth/RGB/depth_531.png', '/content/tmp/traindataset_only_depth/RGB/depth_532.png', '/content/tmp/traindataset_only_depth/RGB/depth_540.png', '/content/tmp/traindataset_only_depth/RGB/depth_541.png', '/content/tmp/traindataset_only_depth/RGB/depth_542.png', '/content/tmp/traindataset_only_depth/RGB/depth_550.png', '/content/tmp/traindataset_only_depth/RGB/depth_551.png', '/content/tmp/traindataset_only_depth/RGB/depth_552.png', '/content/tmp/traindataset_only_depth/RGB/depth_560.png', '/content/tmp/traindataset_only_depth/RGB/depth_561.png', '/content/tmp/traindataset_only_depth/RGB/depth_562.png', '/content/tmp/traindataset_only_depth/RGB/depth_570.png', '/content/tmp/traindataset_only_depth/RGB/depth_571.png', '/content/tmp/traindataset_only_depth/RGB/depth_572.png', '/content/tmp/traindataset_only_depth/RGB/depth_580.png', '/content/tmp/traindataset_only_depth/RGB/depth_581.png', '/content/tmp/traindataset_only_depth/RGB/depth_582.png', '/content/tmp/traindataset_only_depth/RGB/depth_590.png', '/content/tmp/traindataset_only_depth/RGB/depth_591.png', '/content/tmp/traindataset_only_depth/RGB/depth_592.png', '/content/tmp/traindataset_only_depth/RGB/depth_60.png', '/content/tmp/traindataset_only_depth/RGB/depth_600.png', '/content/tmp/traindataset_only_depth/RGB/depth_601.png', '/content/tmp/traindataset_only_depth/RGB/depth_602.png', '/content/tmp/traindataset_only_depth/RGB/depth_61.png', '/content/tmp/traindataset_only_depth/RGB/depth_610.png', '/content/tmp/traindataset_only_depth/RGB/depth_611.png', '/content/tmp/traindataset_only_depth/RGB/depth_612.png', '/content/tmp/traindataset_only_depth/RGB/depth_62.png', '/content/tmp/traindataset_only_depth/RGB/depth_620.png', '/content/tmp/traindataset_only_depth/RGB/depth_621.png', '/content/tmp/traindataset_only_depth/RGB/depth_622.png', '/content/tmp/traindataset_only_depth/RGB/depth_630.png', '/content/tmp/traindataset_only_depth/RGB/depth_631.png', '/content/tmp/traindataset_only_depth/RGB/depth_632.png', '/content/tmp/traindataset_only_depth/RGB/depth_640.png', '/content/tmp/traindataset_only_depth/RGB/depth_641.png', '/content/tmp/traindataset_only_depth/RGB/depth_642.png', '/content/tmp/traindataset_only_depth/RGB/depth_650.png', '/content/tmp/traindataset_only_depth/RGB/depth_651.png', '/content/tmp/traindataset_only_depth/RGB/depth_652.png', '/content/tmp/traindataset_only_depth/RGB/depth_660.png', '/content/tmp/traindataset_only_depth/RGB/depth_661.png', '/content/tmp/traindataset_only_depth/RGB/depth_662.png', '/content/tmp/traindataset_only_depth/RGB/depth_670.png', '/content/tmp/traindataset_only_depth/RGB/depth_671.png', '/content/tmp/traindataset_only_depth/RGB/depth_672.png', '/content/tmp/traindataset_only_depth/RGB/depth_680.png', '/content/tmp/traindataset_only_depth/RGB/depth_681.png', '/content/tmp/traindataset_only_depth/RGB/depth_682.png', '/content/tmp/traindataset_only_depth/RGB/depth_690.png', '/content/tmp/traindataset_only_depth/RGB/depth_691.png', '/content/tmp/traindataset_only_depth/RGB/depth_692.png', '/content/tmp/traindataset_only_depth/RGB/depth_70.png', '/content/tmp/traindataset_only_depth/RGB/depth_700.png', '/content/tmp/traindataset_only_depth/RGB/depth_701.png', '/content/tmp/traindataset_only_depth/RGB/depth_702.png', '/content/tmp/traindataset_only_depth/RGB/depth_71.png', '/content/tmp/traindataset_only_depth/RGB/depth_710.png', '/content/tmp/traindataset_only_depth/RGB/depth_711.png', '/content/tmp/traindataset_only_depth/RGB/depth_712.png', '/content/tmp/traindataset_only_depth/RGB/depth_72.png', '/content/tmp/traindataset_only_depth/RGB/depth_720.png', '/content/tmp/traindataset_only_depth/RGB/depth_721.png', '/content/tmp/traindataset_only_depth/RGB/depth_722.png', '/content/tmp/traindataset_only_depth/RGB/depth_730.png', '/content/tmp/traindataset_only_depth/RGB/depth_731.png', '/content/tmp/traindataset_only_depth/RGB/depth_732.png', '/content/tmp/traindataset_only_depth/RGB/depth_740.png', '/content/tmp/traindataset_only_depth/RGB/depth_741.png', '/content/tmp/traindataset_only_depth/RGB/depth_742.png', '/content/tmp/traindataset_only_depth/RGB/depth_750.png', '/content/tmp/traindataset_only_depth/RGB/depth_751.png', '/content/tmp/traindataset_only_depth/RGB/depth_752.png', '/content/tmp/traindataset_only_depth/RGB/depth_760.png', '/content/tmp/traindataset_only_depth/RGB/depth_761.png', '/content/tmp/traindataset_only_depth/RGB/depth_762.png', '/content/tmp/traindataset_only_depth/RGB/depth_770.png', '/content/tmp/traindataset_only_depth/RGB/depth_771.png', '/content/tmp/traindataset_only_depth/RGB/depth_772.png', '/content/tmp/traindataset_only_depth/RGB/depth_780.png', '/content/tmp/traindataset_only_depth/RGB/depth_781.png', '/content/tmp/traindataset_only_depth/RGB/depth_782.png', '/content/tmp/traindataset_only_depth/RGB/depth_790.png', '/content/tmp/traindataset_only_depth/RGB/depth_791.png', '/content/tmp/traindataset_only_depth/RGB/depth_792.png', '/content/tmp/traindataset_only_depth/RGB/depth_80.png', '/content/tmp/traindataset_only_depth/RGB/depth_81.png', '/content/tmp/traindataset_only_depth/RGB/depth_82.png', '/content/tmp/traindataset_only_depth/RGB/depth_90.png', '/content/tmp/traindataset_only_depth/RGB/depth_91.png', '/content/tmp/traindataset_only_depth/RGB/depth_92.png'] ['/content/tmp/traindataset_only_depth/GT/GT_00.png', '/content/tmp/traindataset_only_depth/GT/GT_01.png', '/content/tmp/traindataset_only_depth/GT/GT_02.png', '/content/tmp/traindataset_only_depth/GT/GT_10.png', '/content/tmp/traindataset_only_depth/GT/GT_100.png', '/content/tmp/traindataset_only_depth/GT/GT_101.png', '/content/tmp/traindataset_only_depth/GT/GT_102.png', '/content/tmp/traindataset_only_depth/GT/GT_11.png', '/content/tmp/traindataset_only_depth/GT/GT_110.png', '/content/tmp/traindataset_only_depth/GT/GT_111.png', '/content/tmp/traindataset_only_depth/GT/GT_112.png', '/content/tmp/traindataset_only_depth/GT/GT_12.png', '/content/tmp/traindataset_only_depth/GT/GT_120.png', '/content/tmp/traindataset_only_depth/GT/GT_121.png', '/content/tmp/traindataset_only_depth/GT/GT_122.png', '/content/tmp/traindataset_only_depth/GT/GT_130.png', '/content/tmp/traindataset_only_depth/GT/GT_131.png', '/content/tmp/traindataset_only_depth/GT/GT_132.png', '/content/tmp/traindataset_only_depth/GT/GT_140.png', '/content/tmp/traindataset_only_depth/GT/GT_141.png', '/content/tmp/traindataset_only_depth/GT/GT_142.png', '/content/tmp/traindataset_only_depth/GT/GT_150.png', '/content/tmp/traindataset_only_depth/GT/GT_151.png', '/content/tmp/traindataset_only_depth/GT/GT_152.png', '/content/tmp/traindataset_only_depth/GT/GT_160.png', '/content/tmp/traindataset_only_depth/GT/GT_161.png', '/content/tmp/traindataset_only_depth/GT/GT_162.png', '/content/tmp/traindataset_only_depth/GT/GT_170.png', '/content/tmp/traindataset_only_depth/GT/GT_171.png', '/content/tmp/traindataset_only_depth/GT/GT_172.png', '/content/tmp/traindataset_only_depth/GT/GT_180.png', '/content/tmp/traindataset_only_depth/GT/GT_181.png', '/content/tmp/traindataset_only_depth/GT/GT_182.png', '/content/tmp/traindataset_only_depth/GT/GT_190.png', '/content/tmp/traindataset_only_depth/GT/GT_191.png', '/content/tmp/traindataset_only_depth/GT/GT_192.png', '/content/tmp/traindataset_only_depth/GT/GT_20.png', '/content/tmp/traindataset_only_depth/GT/GT_200.png', '/content/tmp/traindataset_only_depth/GT/GT_201.png', '/content/tmp/traindataset_only_depth/GT/GT_202.png', '/content/tmp/traindataset_only_depth/GT/GT_21.png', '/content/tmp/traindataset_only_depth/GT/GT_210.png', '/content/tmp/traindataset_only_depth/GT/GT_211.png', '/content/tmp/traindataset_only_depth/GT/GT_212.png', '/content/tmp/traindataset_only_depth/GT/GT_22.png', '/content/tmp/traindataset_only_depth/GT/GT_220.png', '/content/tmp/traindataset_only_depth/GT/GT_221.png', '/content/tmp/traindataset_only_depth/GT/GT_222.png', '/content/tmp/traindataset_only_depth/GT/GT_230.png', '/content/tmp/traindataset_only_depth/GT/GT_231.png', '/content/tmp/traindataset_only_depth/GT/GT_232.png', '/content/tmp/traindataset_only_depth/GT/GT_240.png', '/content/tmp/traindataset_only_depth/GT/GT_241.png', '/content/tmp/traindataset_only_depth/GT/GT_242.png', '/content/tmp/traindataset_only_depth/GT/GT_250.png', '/content/tmp/traindataset_only_depth/GT/GT_251.png', '/content/tmp/traindataset_only_depth/GT/GT_252.png', '/content/tmp/traindataset_only_depth/GT/GT_260.png', '/content/tmp/traindataset_only_depth/GT/GT_261.png', '/content/tmp/traindataset_only_depth/GT/GT_262.png', '/content/tmp/traindataset_only_depth/GT/GT_270.png', '/content/tmp/traindataset_only_depth/GT/GT_271.png', '/content/tmp/traindataset_only_depth/GT/GT_272.png', '/content/tmp/traindataset_only_depth/GT/GT_280.png', '/content/tmp/traindataset_only_depth/GT/GT_281.png', '/content/tmp/traindataset_only_depth/GT/GT_282.png', '/content/tmp/traindataset_only_depth/GT/GT_290.png', '/content/tmp/traindataset_only_depth/GT/GT_291.png', '/content/tmp/traindataset_only_depth/GT/GT_292.png', '/content/tmp/traindataset_only_depth/GT/GT_30.png', '/content/tmp/traindataset_only_depth/GT/GT_300.png', '/content/tmp/traindataset_only_depth/GT/GT_301.png', '/content/tmp/traindataset_only_depth/GT/GT_302.png', '/content/tmp/traindataset_only_depth/GT/GT_31.png', '/content/tmp/traindataset_only_depth/GT/GT_310.png', '/content/tmp/traindataset_only_depth/GT/GT_311.png', '/content/tmp/traindataset_only_depth/GT/GT_312.png', '/content/tmp/traindataset_only_depth/GT/GT_32.png', '/content/tmp/traindataset_only_depth/GT/GT_320.png', '/content/tmp/traindataset_only_depth/GT/GT_321.png', '/content/tmp/traindataset_only_depth/GT/GT_322.png', '/content/tmp/traindataset_only_depth/GT/GT_330.png', '/content/tmp/traindataset_only_depth/GT/GT_331.png', '/content/tmp/traindataset_only_depth/GT/GT_332.png', '/content/tmp/traindataset_only_depth/GT/GT_340.png', '/content/tmp/traindataset_only_depth/GT/GT_341.png', '/content/tmp/traindataset_only_depth/GT/GT_342.png', '/content/tmp/traindataset_only_depth/GT/GT_350.png', '/content/tmp/traindataset_only_depth/GT/GT_351.png', '/content/tmp/traindataset_only_depth/GT/GT_352.png', '/content/tmp/traindataset_only_depth/GT/GT_360.png', '/content/tmp/traindataset_only_depth/GT/GT_361.png', '/content/tmp/traindataset_only_depth/GT/GT_362.png', '/content/tmp/traindataset_only_depth/GT/GT_370.png', '/content/tmp/traindataset_only_depth/GT/GT_371.png', '/content/tmp/traindataset_only_depth/GT/GT_372.png', '/content/tmp/traindataset_only_depth/GT/GT_380.png', '/content/tmp/traindataset_only_depth/GT/GT_381.png', '/content/tmp/traindataset_only_depth/GT/GT_382.png', '/content/tmp/traindataset_only_depth/GT/GT_390.png', '/content/tmp/traindataset_only_depth/GT/GT_391.png', '/content/tmp/traindataset_only_depth/GT/GT_392.png', '/content/tmp/traindataset_only_depth/GT/GT_40.png', '/content/tmp/traindataset_only_depth/GT/GT_400.png', '/content/tmp/traindataset_only_depth/GT/GT_401.png', '/content/tmp/traindataset_only_depth/GT/GT_402.png', '/content/tmp/traindataset_only_depth/GT/GT_41.png', '/content/tmp/traindataset_only_depth/GT/GT_410.png', '/content/tmp/traindataset_only_depth/GT/GT_411.png', '/content/tmp/traindataset_only_depth/GT/GT_412.png', '/content/tmp/traindataset_only_depth/GT/GT_42.png', '/content/tmp/traindataset_only_depth/GT/GT_420.png', '/content/tmp/traindataset_only_depth/GT/GT_421.png', '/content/tmp/traindataset_only_depth/GT/GT_422.png', '/content/tmp/traindataset_only_depth/GT/GT_430.png', '/content/tmp/traindataset_only_depth/GT/GT_431.png', '/content/tmp/traindataset_only_depth/GT/GT_432.png', '/content/tmp/traindataset_only_depth/GT/GT_440.png', '/content/tmp/traindataset_only_depth/GT/GT_441.png', '/content/tmp/traindataset_only_depth/GT/GT_442.png', '/content/tmp/traindataset_only_depth/GT/GT_450.png', '/content/tmp/traindataset_only_depth/GT/GT_451.png', '/content/tmp/traindataset_only_depth/GT/GT_452.png', '/content/tmp/traindataset_only_depth/GT/GT_460.png', '/content/tmp/traindataset_only_depth/GT/GT_461.png', '/content/tmp/traindataset_only_depth/GT/GT_462.png', '/content/tmp/traindataset_only_depth/GT/GT_470.png', '/content/tmp/traindataset_only_depth/GT/GT_471.png', '/content/tmp/traindataset_only_depth/GT/GT_472.png', '/content/tmp/traindataset_only_depth/GT/GT_480.png', '/content/tmp/traindataset_only_depth/GT/GT_481.png', '/content/tmp/traindataset_only_depth/GT/GT_482.png', '/content/tmp/traindataset_only_depth/GT/GT_490.png', '/content/tmp/traindataset_only_depth/GT/GT_491.png', '/content/tmp/traindataset_only_depth/GT/GT_492.png', '/content/tmp/traindataset_only_depth/GT/GT_50.png', '/content/tmp/traindataset_only_depth/GT/GT_500.png', '/content/tmp/traindataset_only_depth/GT/GT_501.png', '/content/tmp/traindataset_only_depth/GT/GT_502.png', '/content/tmp/traindataset_only_depth/GT/GT_51.png', '/content/tmp/traindataset_only_depth/GT/GT_510.png', '/content/tmp/traindataset_only_depth/GT/GT_511.png', '/content/tmp/traindataset_only_depth/GT/GT_512.png', '/content/tmp/traindataset_only_depth/GT/GT_52.png', '/content/tmp/traindataset_only_depth/GT/GT_520.png', '/content/tmp/traindataset_only_depth/GT/GT_521.png', '/content/tmp/traindataset_only_depth/GT/GT_522.png', '/content/tmp/traindataset_only_depth/GT/GT_530.png', '/content/tmp/traindataset_only_depth/GT/GT_531.png', '/content/tmp/traindataset_only_depth/GT/GT_532.png', '/content/tmp/traindataset_only_depth/GT/GT_540.png', '/content/tmp/traindataset_only_depth/GT/GT_541.png', '/content/tmp/traindataset_only_depth/GT/GT_542.png', '/content/tmp/traindataset_only_depth/GT/GT_550.png', '/content/tmp/traindataset_only_depth/GT/GT_551.png', '/content/tmp/traindataset_only_depth/GT/GT_552.png', '/content/tmp/traindataset_only_depth/GT/GT_560.png', '/content/tmp/traindataset_only_depth/GT/GT_561.png', '/content/tmp/traindataset_only_depth/GT/GT_562.png', '/content/tmp/traindataset_only_depth/GT/GT_570.png', '/content/tmp/traindataset_only_depth/GT/GT_571.png', '/content/tmp/traindataset_only_depth/GT/GT_572.png', '/content/tmp/traindataset_only_depth/GT/GT_580.png', '/content/tmp/traindataset_only_depth/GT/GT_581.png', '/content/tmp/traindataset_only_depth/GT/GT_582.png', '/content/tmp/traindataset_only_depth/GT/GT_590.png', '/content/tmp/traindataset_only_depth/GT/GT_591.png', '/content/tmp/traindataset_only_depth/GT/GT_592.png', '/content/tmp/traindataset_only_depth/GT/GT_60.png', '/content/tmp/traindataset_only_depth/GT/GT_600.png', '/content/tmp/traindataset_only_depth/GT/GT_601.png', '/content/tmp/traindataset_only_depth/GT/GT_602.png', '/content/tmp/traindataset_only_depth/GT/GT_61.png', '/content/tmp/traindataset_only_depth/GT/GT_610.png', '/content/tmp/traindataset_only_depth/GT/GT_611.png', '/content/tmp/traindataset_only_depth/GT/GT_612.png', '/content/tmp/traindataset_only_depth/GT/GT_62.png', '/content/tmp/traindataset_only_depth/GT/GT_620.png', '/content/tmp/traindataset_only_depth/GT/GT_621.png', '/content/tmp/traindataset_only_depth/GT/GT_622.png', '/content/tmp/traindataset_only_depth/GT/GT_630.png', '/content/tmp/traindataset_only_depth/GT/GT_631.png', '/content/tmp/traindataset_only_depth/GT/GT_632.png', '/content/tmp/traindataset_only_depth/GT/GT_640.png', '/content/tmp/traindataset_only_depth/GT/GT_641.png', '/content/tmp/traindataset_only_depth/GT/GT_642.png', '/content/tmp/traindataset_only_depth/GT/GT_650.png', '/content/tmp/traindataset_only_depth/GT/GT_651.png', '/content/tmp/traindataset_only_depth/GT/GT_652.png', '/content/tmp/traindataset_only_depth/GT/GT_660.png', '/content/tmp/traindataset_only_depth/GT/GT_661.png', '/content/tmp/traindataset_only_depth/GT/GT_662.png', '/content/tmp/traindataset_only_depth/GT/GT_670.png', '/content/tmp/traindataset_only_depth/GT/GT_671.png', '/content/tmp/traindataset_only_depth/GT/GT_672.png', '/content/tmp/traindataset_only_depth/GT/GT_680.png', '/content/tmp/traindataset_only_depth/GT/GT_681.png', '/content/tmp/traindataset_only_depth/GT/GT_682.png', '/content/tmp/traindataset_only_depth/GT/GT_690.png', '/content/tmp/traindataset_only_depth/GT/GT_691.png', '/content/tmp/traindataset_only_depth/GT/GT_692.png', '/content/tmp/traindataset_only_depth/GT/GT_70.png', '/content/tmp/traindataset_only_depth/GT/GT_700.png', '/content/tmp/traindataset_only_depth/GT/GT_701.png', '/content/tmp/traindataset_only_depth/GT/GT_702.png', '/content/tmp/traindataset_only_depth/GT/GT_71.png', '/content/tmp/traindataset_only_depth/GT/GT_710.png', '/content/tmp/traindataset_only_depth/GT/GT_711.png', '/content/tmp/traindataset_only_depth/GT/GT_712.png', '/content/tmp/traindataset_only_depth/GT/GT_72.png', '/content/tmp/traindataset_only_depth/GT/GT_720.png', '/content/tmp/traindataset_only_depth/GT/GT_721.png', '/content/tmp/traindataset_only_depth/GT/GT_722.png', '/content/tmp/traindataset_only_depth/GT/GT_730.png', '/content/tmp/traindataset_only_depth/GT/GT_731.png', '/content/tmp/traindataset_only_depth/GT/GT_732.png', '/content/tmp/traindataset_only_depth/GT/GT_740.png', '/content/tmp/traindataset_only_depth/GT/GT_741.png', '/content/tmp/traindataset_only_depth/GT/GT_742.png', '/content/tmp/traindataset_only_depth/GT/GT_750.png', '/content/tmp/traindataset_only_depth/GT/GT_751.png', '/content/tmp/traindataset_only_depth/GT/GT_752.png', '/content/tmp/traindataset_only_depth/GT/GT_760.png', '/content/tmp/traindataset_only_depth/GT/GT_761.png', '/content/tmp/traindataset_only_depth/GT/GT_762.png', '/content/tmp/traindataset_only_depth/GT/GT_770.png', '/content/tmp/traindataset_only_depth/GT/GT_771.png', '/content/tmp/traindataset_only_depth/GT/GT_772.png', '/content/tmp/traindataset_only_depth/GT/GT_780.png', '/content/tmp/traindataset_only_depth/GT/GT_781.png', '/content/tmp/traindataset_only_depth/GT/GT_782.png', '/content/tmp/traindataset_only_depth/GT/GT_790.png', '/content/tmp/traindataset_only_depth/GT/GT_791.png', '/content/tmp/traindataset_only_depth/GT/GT_792.png', '/content/tmp/traindataset_only_depth/GT/GT_80.png', '/content/tmp/traindataset_only_depth/GT/GT_81.png', '/content/tmp/traindataset_only_depth/GT/GT_82.png', '/content/tmp/traindataset_only_depth/GT/GT_90.png', '/content/tmp/traindataset_only_depth/GT/GT_91.png', '/content/tmp/traindataset_only_depth/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7f7697f2e950>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start train...\n",
            "2022-08-03 09:34:11.968933 Epoch [001/250], Step [0001/0060], Loss1: 0.2390 Loss2: 0.4752 Loss3: 0.2007\n",
            "2022-08-03 09:34:41.537669 Epoch [001/250], Step [0050/0060], Loss1: 0.0249 Loss2: 0.0266 Loss3: 0.0205\n",
            "2022-08-03 09:34:47.352131 Epoch [001/250], Step [0060/0060], Loss1: 0.0190 Loss2: 0.0157 Loss3: 0.0133\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 MAE: 0.06798010898960961 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-08-03 09:34:58.878753 Epoch [002/250], Step [0001/0060], Loss1: 0.0216 Loss2: 0.0196 Loss3: 0.0160\n",
            "2022-08-03 09:35:28.064026 Epoch [002/250], Step [0050/0060], Loss1: 0.0218 Loss2: 0.0158 Loss3: 0.0150\n",
            "2022-08-03 09:35:34.106289 Epoch [002/250], Step [0060/0060], Loss1: 0.0127 Loss2: 0.0108 Loss3: 0.0085\n",
            "Epoch: 2 MAE: 0.04814220033586025 ####  bestMAE: 0.06798010898960961 bestEpoch: 0\n",
            "best epoch:2\n",
            "2022-08-03 09:35:44.361906 Epoch [003/250], Step [0001/0060], Loss1: 0.0127 Loss2: 0.0108 Loss3: 0.0072\n",
            "2022-08-03 09:36:13.569524 Epoch [003/250], Step [0050/0060], Loss1: 0.0117 Loss2: 0.0093 Loss3: 0.0061\n",
            "2022-08-03 09:36:19.517365 Epoch [003/250], Step [0060/0060], Loss1: 0.0167 Loss2: 0.0165 Loss3: 0.0116\n",
            "Epoch: 3 MAE: 0.04410130728686613 ####  bestMAE: 0.04814220033586025 bestEpoch: 2\n",
            "best epoch:3\n",
            "2022-08-03 09:36:29.873108 Epoch [004/250], Step [0001/0060], Loss1: 0.0124 Loss2: 0.0105 Loss3: 0.0069\n",
            "2022-08-03 09:36:58.909551 Epoch [004/250], Step [0050/0060], Loss1: 0.0083 Loss2: 0.0081 Loss3: 0.0057\n",
            "2022-08-03 09:37:05.069680 Epoch [004/250], Step [0060/0060], Loss1: 0.0076 Loss2: 0.0097 Loss3: 0.0052\n",
            "Epoch: 4 MAE: 0.03608790161235938 ####  bestMAE: 0.04410130728686613 bestEpoch: 3\n",
            "best epoch:4\n",
            "2022-08-03 09:37:15.681562 Epoch [005/250], Step [0001/0060], Loss1: 0.0126 Loss2: 0.0141 Loss3: 0.0084\n",
            "2022-08-03 09:37:45.060580 Epoch [005/250], Step [0050/0060], Loss1: 0.0071 Loss2: 0.0079 Loss3: 0.0048\n",
            "2022-08-03 09:37:50.975612 Epoch [005/250], Step [0060/0060], Loss1: 0.0088 Loss2: 0.0097 Loss3: 0.0048\n",
            "Epoch: 5 MAE: 0.03466459425787131 ####  bestMAE: 0.03608790161235938 bestEpoch: 4\n",
            "best epoch:5\n",
            "2022-08-03 09:38:04.346602 Epoch [006/250], Step [0001/0060], Loss1: 0.0083 Loss2: 0.0080 Loss3: 0.0047\n",
            "2022-08-03 09:38:33.811551 Epoch [006/250], Step [0050/0060], Loss1: 0.0063 Loss2: 0.0069 Loss3: 0.0043\n",
            "2022-08-03 09:38:39.796093 Epoch [006/250], Step [0060/0060], Loss1: 0.0072 Loss2: 0.0065 Loss3: 0.0043\n",
            "Epoch: 6 MAE: 0.033307728638488146 ####  bestMAE: 0.03466459425787131 bestEpoch: 5\n",
            "best epoch:6\n",
            "2022-08-03 09:38:50.474288 Epoch [007/250], Step [0001/0060], Loss1: 0.0065 Loss2: 0.0078 Loss3: 0.0040\n",
            "2022-08-03 09:39:20.287740 Epoch [007/250], Step [0050/0060], Loss1: 0.0064 Loss2: 0.0068 Loss3: 0.0036\n",
            "2022-08-03 09:39:26.407861 Epoch [007/250], Step [0060/0060], Loss1: 0.0045 Loss2: 0.0056 Loss3: 0.0029\n",
            "Epoch: 7 MAE: 0.02491565669576327 ####  bestMAE: 0.033307728638488146 bestEpoch: 6\n",
            "best epoch:7\n",
            "2022-08-03 09:39:36.889133 Epoch [008/250], Step [0001/0060], Loss1: 0.0061 Loss2: 0.0059 Loss3: 0.0034\n",
            "2022-08-03 09:40:06.953579 Epoch [008/250], Step [0050/0060], Loss1: 0.0048 Loss2: 0.0060 Loss3: 0.0031\n",
            "2022-08-03 09:40:13.257751 Epoch [008/250], Step [0060/0060], Loss1: 0.0047 Loss2: 0.0054 Loss3: 0.0030\n",
            "Epoch: 8 MAE: 0.026688846626452038 ####  bestMAE: 0.02491565669576327 bestEpoch: 7\n",
            "2022-08-03 09:40:21.174778 Epoch [009/250], Step [0001/0060], Loss1: 0.0042 Loss2: 0.0052 Loss3: 0.0031\n",
            "2022-08-03 09:40:50.185323 Epoch [009/250], Step [0050/0060], Loss1: 0.0044 Loss2: 0.0062 Loss3: 0.0030\n",
            "2022-08-03 09:40:56.055426 Epoch [009/250], Step [0060/0060], Loss1: 0.0043 Loss2: 0.0062 Loss3: 0.0030\n",
            "Epoch: 9 MAE: 0.025562111539618362 ####  bestMAE: 0.02491565669576327 bestEpoch: 7\n",
            "2022-08-03 09:41:03.651012 Epoch [010/250], Step [0001/0060], Loss1: 0.0040 Loss2: 0.0053 Loss3: 0.0026\n",
            "2022-08-03 09:41:32.691388 Epoch [010/250], Step [0050/0060], Loss1: 0.0044 Loss2: 0.0054 Loss3: 0.0027\n",
            "2022-08-03 09:41:38.661301 Epoch [010/250], Step [0060/0060], Loss1: 0.0043 Loss2: 0.0058 Loss3: 0.0029\n",
            "Epoch: 10 MAE: 0.027952642579163824 ####  bestMAE: 0.02491565669576327 bestEpoch: 7\n",
            "2022-08-03 09:41:48.789316 Epoch [011/250], Step [0001/0060], Loss1: 0.0045 Loss2: 0.0057 Loss3: 0.0026\n",
            "2022-08-03 09:42:18.522112 Epoch [011/250], Step [0050/0060], Loss1: 0.0071 Loss2: 0.0068 Loss3: 0.0030\n",
            "2022-08-03 09:42:24.508170 Epoch [011/250], Step [0060/0060], Loss1: 0.0038 Loss2: 0.0050 Loss3: 0.0031\n",
            "Epoch: 11 MAE: 0.02252412908193138 ####  bestMAE: 0.02491565669576327 bestEpoch: 7\n",
            "best epoch:11\n",
            "2022-08-03 09:42:34.880041 Epoch [012/250], Step [0001/0060], Loss1: 0.0045 Loss2: 0.0048 Loss3: 0.0030\n",
            "2022-08-03 09:43:03.893301 Epoch [012/250], Step [0050/0060], Loss1: 0.0040 Loss2: 0.0043 Loss3: 0.0024\n",
            "2022-08-03 09:43:09.921489 Epoch [012/250], Step [0060/0060], Loss1: 0.0043 Loss2: 0.0058 Loss3: 0.0026\n",
            "Epoch: 12 MAE: 0.022695766362760748 ####  bestMAE: 0.02252412908193138 bestEpoch: 11\n",
            "2022-08-03 09:43:17.773391 Epoch [013/250], Step [0001/0060], Loss1: 0.0038 Loss2: 0.0046 Loss3: 0.0023\n",
            "2022-08-03 09:43:46.410328 Epoch [013/250], Step [0050/0060], Loss1: 0.0038 Loss2: 0.0051 Loss3: 0.0022\n",
            "2022-08-03 09:43:52.467524 Epoch [013/250], Step [0060/0060], Loss1: 0.0033 Loss2: 0.0051 Loss3: 0.0022\n",
            "Epoch: 13 MAE: 0.02218297135735315 ####  bestMAE: 0.02252412908193138 bestEpoch: 11\n",
            "best epoch:13\n",
            "2022-08-03 09:44:02.553303 Epoch [014/250], Step [0001/0060], Loss1: 0.0042 Loss2: 0.0044 Loss3: 0.0023\n",
            "2022-08-03 09:44:31.783757 Epoch [014/250], Step [0050/0060], Loss1: 0.0038 Loss2: 0.0042 Loss3: 0.0022\n",
            "2022-08-03 09:44:37.621434 Epoch [014/250], Step [0060/0060], Loss1: 0.0036 Loss2: 0.0046 Loss3: 0.0023\n",
            "Epoch: 14 MAE: 0.01950162962552101 ####  bestMAE: 0.02218297135735315 bestEpoch: 13\n",
            "best epoch:14\n",
            "2022-08-03 09:44:47.816039 Epoch [015/250], Step [0001/0060], Loss1: 0.0038 Loss2: 0.0042 Loss3: 0.0022\n",
            "2022-08-03 09:45:17.224640 Epoch [015/250], Step [0050/0060], Loss1: 0.0033 Loss2: 0.0041 Loss3: 0.0020\n",
            "2022-08-03 09:45:22.934056 Epoch [015/250], Step [0060/0060], Loss1: 0.0034 Loss2: 0.0042 Loss3: 0.0021\n",
            "Epoch: 15 MAE: 0.018017151806917455 ####  bestMAE: 0.01950162962552101 bestEpoch: 14\n",
            "best epoch:15\n",
            "2022-08-03 09:45:35.437944 Epoch [016/250], Step [0001/0060], Loss1: 0.0052 Loss2: 0.0064 Loss3: 0.0035\n",
            "2022-08-03 09:46:04.924801 Epoch [016/250], Step [0050/0060], Loss1: 0.0031 Loss2: 0.0038 Loss3: 0.0021\n",
            "2022-08-03 09:46:10.726012 Epoch [016/250], Step [0060/0060], Loss1: 0.0029 Loss2: 0.0042 Loss3: 0.0021\n",
            "Epoch: 16 MAE: 0.019555823064394413 ####  bestMAE: 0.018017151806917455 bestEpoch: 15\n",
            "2022-08-03 09:46:18.444836 Epoch [017/250], Step [0001/0060], Loss1: 0.0033 Loss2: 0.0038 Loss3: 0.0021\n",
            "2022-08-03 09:46:47.422977 Epoch [017/250], Step [0050/0060], Loss1: 0.0033 Loss2: 0.0044 Loss3: 0.0023\n",
            "2022-08-03 09:46:53.237239 Epoch [017/250], Step [0060/0060], Loss1: 0.0033 Loss2: 0.0041 Loss3: 0.0023\n",
            "Epoch: 17 MAE: 0.018302754321623416 ####  bestMAE: 0.018017151806917455 bestEpoch: 15\n",
            "2022-08-03 09:47:00.724244 Epoch [018/250], Step [0001/0060], Loss1: 0.0031 Loss2: 0.0035 Loss3: 0.0019\n",
            "2022-08-03 09:47:29.664202 Epoch [018/250], Step [0050/0060], Loss1: 0.0030 Loss2: 0.0050 Loss3: 0.0021\n",
            "2022-08-03 09:47:35.646150 Epoch [018/250], Step [0060/0060], Loss1: 0.0033 Loss2: 0.0045 Loss3: 0.0021\n",
            "Epoch: 18 MAE: 0.016912269975162215 ####  bestMAE: 0.018017151806917455 bestEpoch: 15\n",
            "best epoch:18\n",
            "2022-08-03 09:47:45.834903 Epoch [019/250], Step [0001/0060], Loss1: 0.0032 Loss2: 0.0040 Loss3: 0.0021\n",
            "2022-08-03 09:48:15.132840 Epoch [019/250], Step [0050/0060], Loss1: 0.0030 Loss2: 0.0035 Loss3: 0.0020\n",
            "2022-08-03 09:48:20.902905 Epoch [019/250], Step [0060/0060], Loss1: 0.0028 Loss2: 0.0043 Loss3: 0.0018\n",
            "Epoch: 19 MAE: 0.016364507576716796 ####  bestMAE: 0.016912269975162215 bestEpoch: 18\n",
            "best epoch:19\n",
            "2022-08-03 09:48:31.224404 Epoch [020/250], Step [0001/0060], Loss1: 0.0030 Loss2: 0.0037 Loss3: 0.0019\n",
            "2022-08-03 09:49:00.188102 Epoch [020/250], Step [0050/0060], Loss1: 0.0031 Loss2: 0.0041 Loss3: 0.0021\n",
            "2022-08-03 09:49:06.210120 Epoch [020/250], Step [0060/0060], Loss1: 0.0029 Loss2: 0.0033 Loss3: 0.0019\n",
            "Epoch: 20 MAE: 0.017336220909205693 ####  bestMAE: 0.016364507576716796 bestEpoch: 19\n",
            "2022-08-03 09:49:16.619264 Epoch [021/250], Step [0001/0060], Loss1: 0.0031 Loss2: 0.0038 Loss3: 0.0019\n",
            "2022-08-03 09:49:46.123182 Epoch [021/250], Step [0050/0060], Loss1: 0.0033 Loss2: 0.0046 Loss3: 0.0019\n",
            "2022-08-03 09:49:52.026426 Epoch [021/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0037 Loss3: 0.0019\n",
            "Epoch: 21 MAE: 0.015646951066123113 ####  bestMAE: 0.016364507576716796 bestEpoch: 19\n",
            "best epoch:21\n",
            "2022-08-03 09:50:01.852483 Epoch [022/250], Step [0001/0060], Loss1: 0.0029 Loss2: 0.0036 Loss3: 0.0019\n",
            "2022-08-03 09:50:31.142868 Epoch [022/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0037 Loss3: 0.0020\n",
            "2022-08-03 09:50:37.272144 Epoch [022/250], Step [0060/0060], Loss1: 0.0027 Loss2: 0.0042 Loss3: 0.0018\n",
            "Epoch: 22 MAE: 0.015210534896819837 ####  bestMAE: 0.015646951066123113 bestEpoch: 21\n",
            "best epoch:22\n",
            "2022-08-03 09:50:47.587353 Epoch [023/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0041 Loss3: 0.0017\n",
            "2022-08-03 09:51:16.752212 Epoch [023/250], Step [0050/0060], Loss1: 0.0041 Loss2: 0.0049 Loss3: 0.0021\n",
            "2022-08-03 09:51:22.668428 Epoch [023/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0033 Loss3: 0.0017\n",
            "Epoch: 23 MAE: 0.015357969543113121 ####  bestMAE: 0.015210534896819837 bestEpoch: 22\n",
            "2022-08-03 09:51:30.272894 Epoch [024/250], Step [0001/0060], Loss1: 0.0026 Loss2: 0.0032 Loss3: 0.0017\n",
            "2022-08-03 09:51:58.815948 Epoch [024/250], Step [0050/0060], Loss1: 0.0028 Loss2: 0.0039 Loss3: 0.0023\n",
            "2022-08-03 09:52:04.506092 Epoch [024/250], Step [0060/0060], Loss1: 0.0029 Loss2: 0.0043 Loss3: 0.0020\n",
            "Epoch: 24 MAE: 0.015062566129638561 ####  bestMAE: 0.015210534896819837 bestEpoch: 22\n",
            "best epoch:24\n",
            "2022-08-03 09:52:14.942696 Epoch [025/250], Step [0001/0060], Loss1: 0.0027 Loss2: 0.0036 Loss3: 0.0018\n",
            "2022-08-03 09:52:44.385978 Epoch [025/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0040 Loss3: 0.0018\n",
            "2022-08-03 09:52:50.176301 Epoch [025/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0032 Loss3: 0.0017\n",
            "Epoch: 25 MAE: 0.014970717508168448 ####  bestMAE: 0.015062566129638561 bestEpoch: 24\n",
            "best epoch:25\n",
            "2022-08-03 09:53:02.724559 Epoch [026/250], Step [0001/0060], Loss1: 0.0027 Loss2: 0.0039 Loss3: 0.0019\n",
            "2022-08-03 09:53:32.785969 Epoch [026/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0035 Loss3: 0.0017\n",
            "2022-08-03 09:53:38.740751 Epoch [026/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0041 Loss3: 0.0019\n",
            "Epoch: 26 MAE: 0.014765761452653105 ####  bestMAE: 0.014970717508168448 bestEpoch: 25\n",
            "best epoch:26\n",
            "2022-08-03 09:53:49.211137 Epoch [027/250], Step [0001/0060], Loss1: 0.0032 Loss2: 0.0050 Loss3: 0.0023\n",
            "2022-08-03 09:54:17.840066 Epoch [027/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0035 Loss3: 0.0018\n",
            "2022-08-03 09:54:23.800161 Epoch [027/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0039 Loss3: 0.0018\n",
            "Epoch: 27 MAE: 0.014556159368819661 ####  bestMAE: 0.014765761452653105 bestEpoch: 26\n",
            "best epoch:27\n",
            "2022-08-03 09:54:33.737822 Epoch [028/250], Step [0001/0060], Loss1: 0.0027 Loss2: 0.0048 Loss3: 0.0019\n",
            "2022-08-03 09:55:03.797585 Epoch [028/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0030 Loss3: 0.0014\n",
            "2022-08-03 09:55:09.775979 Epoch [028/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0036 Loss3: 0.0015\n",
            "Epoch: 28 MAE: 0.015166894828398076 ####  bestMAE: 0.014556159368819661 bestEpoch: 27\n",
            "2022-08-03 09:55:17.534711 Epoch [029/250], Step [0001/0060], Loss1: 0.0031 Loss2: 0.0042 Loss3: 0.0019\n",
            "2022-08-03 09:55:46.131544 Epoch [029/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0035 Loss3: 0.0016\n",
            "2022-08-03 09:55:51.841672 Epoch [029/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0039 Loss3: 0.0017\n",
            "Epoch: 29 MAE: 0.014660931295818753 ####  bestMAE: 0.014556159368819661 bestEpoch: 27\n",
            "2022-08-03 09:55:59.595924 Epoch [030/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0033 Loss3: 0.0016\n",
            "2022-08-03 09:56:28.575956 Epoch [030/250], Step [0050/0060], Loss1: 0.0018 Loss2: 0.0026 Loss3: 0.0016\n",
            "2022-08-03 09:56:34.416850 Epoch [030/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0031 Loss3: 0.0016\n",
            "Epoch: 30 MAE: 0.013950378042719667 ####  bestMAE: 0.014556159368819661 bestEpoch: 27\n",
            "best epoch:30\n",
            "2022-08-03 09:56:47.153731 Epoch [031/250], Step [0001/0060], Loss1: 0.0026 Loss2: 0.0035 Loss3: 0.0017\n",
            "2022-08-03 09:57:18.269313 Epoch [031/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0034 Loss3: 0.0015\n",
            "2022-08-03 09:57:24.310813 Epoch [031/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0032 Loss3: 0.0016\n",
            "Epoch: 31 MAE: 0.013564014873866524 ####  bestMAE: 0.013950378042719667 bestEpoch: 30\n",
            "best epoch:31\n",
            "2022-08-03 09:57:34.721509 Epoch [032/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0029 Loss3: 0.0015\n",
            "2022-08-03 09:58:04.610944 Epoch [032/250], Step [0050/0060], Loss1: 0.0028 Loss2: 0.0040 Loss3: 0.0017\n",
            "2022-08-03 09:58:10.379279 Epoch [032/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0038 Loss3: 0.0018\n",
            "Epoch: 32 MAE: 0.014605580045590325 ####  bestMAE: 0.013564014873866524 bestEpoch: 31\n",
            "2022-08-03 09:58:18.219032 Epoch [033/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0032 Loss3: 0.0016\n",
            "2022-08-03 09:58:47.753083 Epoch [033/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0032 Loss3: 0.0016\n",
            "2022-08-03 09:58:53.652976 Epoch [033/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0027 Loss3: 0.0015\n",
            "Epoch: 33 MAE: 0.0134245189025052 ####  bestMAE: 0.013564014873866524 bestEpoch: 31\n",
            "best epoch:33\n",
            "2022-08-03 09:59:03.773917 Epoch [034/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0029 Loss3: 0.0015\n",
            "2022-08-03 09:59:33.380659 Epoch [034/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0032 Loss3: 0.0016\n",
            "2022-08-03 09:59:39.350736 Epoch [034/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0032 Loss3: 0.0017\n",
            "Epoch: 34 MAE: 0.014628945014602135 ####  bestMAE: 0.0134245189025052 bestEpoch: 33\n",
            "2022-08-03 09:59:47.622379 Epoch [035/250], Step [0001/0060], Loss1: 0.0026 Loss2: 0.0037 Loss3: 0.0019\n",
            "2022-08-03 10:00:16.768842 Epoch [035/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0038 Loss3: 0.0017\n",
            "2022-08-03 10:00:22.683342 Epoch [035/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0033 Loss3: 0.0017\n",
            "Epoch: 35 MAE: 0.013429706406203053 ####  bestMAE: 0.0134245189025052 bestEpoch: 33\n",
            "2022-08-03 10:00:32.958853 Epoch [036/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0035 Loss3: 0.0017\n",
            "2022-08-03 10:01:02.835897 Epoch [036/250], Step [0050/0060], Loss1: 0.0018 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 10:01:08.509639 Epoch [036/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0037 Loss3: 0.0017\n",
            "Epoch: 36 MAE: 0.014147414737159298 ####  bestMAE: 0.0134245189025052 bestEpoch: 33\n",
            "2022-08-03 10:01:16.015519 Epoch [037/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0039 Loss3: 0.0017\n",
            "2022-08-03 10:01:44.986006 Epoch [037/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0031 Loss3: 0.0017\n",
            "2022-08-03 10:01:50.984355 Epoch [037/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0047 Loss3: 0.0017\n",
            "Epoch: 37 MAE: 0.01337906928171241 ####  bestMAE: 0.0134245189025052 bestEpoch: 33\n",
            "best epoch:37\n",
            "2022-08-03 10:02:01.277555 Epoch [038/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0032 Loss3: 0.0017\n",
            "2022-08-03 10:02:31.464610 Epoch [038/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0031 Loss3: 0.0015\n",
            "2022-08-03 10:02:37.356102 Epoch [038/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0034 Loss3: 0.0015\n",
            "Epoch: 38 MAE: 0.013791006760642169 ####  bestMAE: 0.01337906928171241 bestEpoch: 37\n",
            "2022-08-03 10:02:45.268099 Epoch [039/250], Step [0001/0060], Loss1: 0.0019 Loss2: 0.0031 Loss3: 0.0014\n",
            "2022-08-03 10:03:14.545880 Epoch [039/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0028 Loss3: 0.0015\n",
            "2022-08-03 10:03:20.552755 Epoch [039/250], Step [0060/0060], Loss1: 0.0021 Loss2: 0.0033 Loss3: 0.0016\n",
            "Epoch: 39 MAE: 0.012888283387476962 ####  bestMAE: 0.01337906928171241 bestEpoch: 37\n",
            "best epoch:39\n",
            "2022-08-03 10:03:31.086659 Epoch [040/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0037 Loss3: 0.0016\n",
            "2022-08-03 10:04:00.616467 Epoch [040/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0032 Loss3: 0.0018\n",
            "2022-08-03 10:04:06.420889 Epoch [040/250], Step [0060/0060], Loss1: 0.0019 Loss2: 0.0032 Loss3: 0.0016\n",
            "Epoch: 40 MAE: 0.011704076621090137 ####  bestMAE: 0.012888283387476962 bestEpoch: 39\n",
            "best epoch:40\n",
            "2022-08-03 10:04:19.843478 Epoch [041/250], Step [0001/0060], Loss1: 0.0018 Loss2: 0.0027 Loss3: 0.0014\n",
            "2022-08-03 10:04:49.485059 Epoch [041/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0028 Loss3: 0.0015\n",
            "2022-08-03 10:04:55.677004 Epoch [041/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0027 Loss3: 0.0016\n",
            "Epoch: 41 MAE: 0.014462256271924292 ####  bestMAE: 0.011704076621090137 bestEpoch: 40\n",
            "2022-08-03 10:05:03.702819 Epoch [042/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0034 Loss3: 0.0018\n",
            "2022-08-03 10:05:32.902792 Epoch [042/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0028 Loss3: 0.0016\n",
            "2022-08-03 10:05:38.921739 Epoch [042/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0026 Loss3: 0.0014\n",
            "Epoch: 42 MAE: 0.012561804415392024 ####  bestMAE: 0.011704076621090137 bestEpoch: 40\n",
            "2022-08-03 10:05:46.920057 Epoch [043/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0034 Loss3: 0.0015\n",
            "2022-08-03 10:06:17.127256 Epoch [043/250], Step [0050/0060], Loss1: 0.0018 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 10:06:23.004877 Epoch [043/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0031 Loss3: 0.0015\n",
            "Epoch: 43 MAE: 0.014072958586944474 ####  bestMAE: 0.011704076621090137 bestEpoch: 40\n",
            "2022-08-03 10:06:30.928461 Epoch [044/250], Step [0001/0060], Loss1: 0.0021 Loss2: 0.0028 Loss3: 0.0016\n",
            "2022-08-03 10:07:00.696171 Epoch [044/250], Step [0050/0060], Loss1: 0.0019 Loss2: 0.0029 Loss3: 0.0014\n",
            "2022-08-03 10:07:06.690596 Epoch [044/250], Step [0060/0060], Loss1: 0.0019 Loss2: 0.0025 Loss3: 0.0015\n",
            "Epoch: 44 MAE: 0.01261862554395246 ####  bestMAE: 0.011704076621090137 bestEpoch: 40\n",
            "2022-08-03 10:07:14.624843 Epoch [045/250], Step [0001/0060], Loss1: 0.0018 Loss2: 0.0024 Loss3: 0.0014\n",
            "2022-08-03 10:07:43.540842 Epoch [045/250], Step [0050/0060], Loss1: 0.0019 Loss2: 0.0026 Loss3: 0.0014\n",
            "2022-08-03 10:07:49.574941 Epoch [045/250], Step [0060/0060], Loss1: 0.0017 Loss2: 0.0025 Loss3: 0.0013\n",
            "Epoch: 45 MAE: 0.012745795357558463 ####  bestMAE: 0.011704076621090137 bestEpoch: 40\n",
            "2022-08-03 10:07:59.959578 Epoch [046/250], Step [0001/0060], Loss1: 0.0018 Loss2: 0.0031 Loss3: 0.0014\n",
            "2022-08-03 10:08:29.757366 Epoch [046/250], Step [0050/0060], Loss1: 0.0019 Loss2: 0.0027 Loss3: 0.0013\n",
            "2022-08-03 10:08:35.583474 Epoch [046/250], Step [0060/0060], Loss1: 0.0019 Loss2: 0.0035 Loss3: 0.0015\n",
            "Epoch: 46 MAE: 0.011863434576385078 ####  bestMAE: 0.011704076621090137 bestEpoch: 40\n",
            "2022-08-03 10:08:43.460820 Epoch [047/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0032 Loss3: 0.0015\n",
            "2022-08-03 10:09:13.100818 Epoch [047/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0028 Loss3: 0.0015\n",
            "2022-08-03 10:09:19.284159 Epoch [047/250], Step [0060/0060], Loss1: 0.0021 Loss2: 0.0029 Loss3: 0.0014\n",
            "Epoch: 47 MAE: 0.011583696112095837 ####  bestMAE: 0.011704076621090137 bestEpoch: 40\n",
            "best epoch:47\n",
            "2022-08-03 10:09:29.677913 Epoch [048/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0029 Loss3: 0.0015\n",
            "2022-08-03 10:09:59.025283 Epoch [048/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0028 Loss3: 0.0014\n",
            "2022-08-03 10:10:04.887951 Epoch [048/250], Step [0060/0060], Loss1: 0.0019 Loss2: 0.0032 Loss3: 0.0015\n",
            "Epoch: 48 MAE: 0.013005086767768103 ####  bestMAE: 0.011583696112095837 bestEpoch: 47\n",
            "2022-08-03 10:10:12.910580 Epoch [049/250], Step [0001/0060], Loss1: 0.0019 Loss2: 0.0027 Loss3: 0.0014\n",
            "2022-08-03 10:10:42.199853 Epoch [049/250], Step [0050/0060], Loss1: 0.0019 Loss2: 0.0027 Loss3: 0.0014\n",
            "2022-08-03 10:10:48.047439 Epoch [049/250], Step [0060/0060], Loss1: 0.0019 Loss2: 0.0027 Loss3: 0.0014\n",
            "Epoch: 49 MAE: 0.01148100754630471 ####  bestMAE: 0.011583696112095837 bestEpoch: 47\n",
            "best epoch:49\n",
            "2022-08-03 10:10:58.537053 Epoch [050/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0032 Loss3: 0.0017\n",
            "2022-08-03 10:11:27.820884 Epoch [050/250], Step [0050/0060], Loss1: 0.0019 Loss2: 0.0025 Loss3: 0.0014\n",
            "2022-08-03 10:11:33.870455 Epoch [050/250], Step [0060/0060], Loss1: 0.0019 Loss2: 0.0031 Loss3: 0.0014\n",
            "Epoch: 50 MAE: 0.013014251336691872 ####  bestMAE: 0.01148100754630471 bestEpoch: 49\n",
            "2022-08-03 10:11:44.150532 Epoch [051/250], Step [0001/0060], Loss1: 0.0018 Loss2: 0.0030 Loss3: 0.0014\n",
            "2022-08-03 10:12:13.545039 Epoch [051/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0037 Loss3: 0.0015\n",
            "2022-08-03 10:12:19.450460 Epoch [051/250], Step [0060/0060], Loss1: 0.0019 Loss2: 0.0029 Loss3: 0.0015\n",
            "Epoch: 51 MAE: 0.01365467914128824 ####  bestMAE: 0.01148100754630471 bestEpoch: 49\n",
            "2022-08-03 10:12:27.194253 Epoch [052/250], Step [0001/0060], Loss1: 0.0019 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 10:12:56.058578 Epoch [052/250], Step [0050/0060], Loss1: 0.0017 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 10:13:01.864177 Epoch [052/250], Step [0060/0060], Loss1: 0.0021 Loss2: 0.0027 Loss3: 0.0014\n",
            "Epoch: 52 MAE: 0.013030628245028238 ####  bestMAE: 0.01148100754630471 bestEpoch: 49\n",
            "2022-08-03 10:13:09.857652 Epoch [053/250], Step [0001/0060], Loss1: 0.0018 Loss2: 0.0032 Loss3: 0.0014\n",
            "2022-08-03 10:13:39.284232 Epoch [053/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0034 Loss3: 0.0016\n",
            "2022-08-03 10:13:45.432838 Epoch [053/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0027 Loss3: 0.0015\n",
            "Epoch: 53 MAE: 0.012684235164511299 ####  bestMAE: 0.01148100754630471 bestEpoch: 49\n",
            "2022-08-03 10:13:53.534045 Epoch [054/250], Step [0001/0060], Loss1: 0.0018 Loss2: 0.0027 Loss3: 0.0013\n",
            "2022-08-03 10:14:22.443807 Epoch [054/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0029 Loss3: 0.0014\n",
            "2022-08-03 10:14:28.341135 Epoch [054/250], Step [0060/0060], Loss1: 0.0018 Loss2: 0.0026 Loss3: 0.0013\n",
            "Epoch: 54 MAE: 0.01278145109406776 ####  bestMAE: 0.01148100754630471 bestEpoch: 49\n",
            "2022-08-03 10:14:36.288043 Epoch [055/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0032 Loss3: 0.0014\n",
            "2022-08-03 10:15:05.468642 Epoch [055/250], Step [0050/0060], Loss1: 0.0017 Loss2: 0.0027 Loss3: 0.0013\n",
            "2022-08-03 10:15:11.520195 Epoch [055/250], Step [0060/0060], Loss1: 0.0017 Loss2: 0.0025 Loss3: 0.0014\n",
            "Epoch: 55 MAE: 0.012154429751847471 ####  bestMAE: 0.01148100754630471 bestEpoch: 49\n",
            "2022-08-03 10:15:21.927755 Epoch [056/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 10:15:51.329094 Epoch [056/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0029 Loss3: 0.0015\n",
            "2022-08-03 10:15:57.130020 Epoch [056/250], Step [0060/0060], Loss1: 0.0017 Loss2: 0.0025 Loss3: 0.0013\n",
            "Epoch: 56 MAE: 0.01112186120054315 ####  bestMAE: 0.01148100754630471 bestEpoch: 49\n",
            "best epoch:56\n",
            "2022-08-03 10:16:07.619706 Epoch [057/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0028 Loss3: 0.0013\n",
            "2022-08-03 10:16:37.922495 Epoch [057/250], Step [0050/0060], Loss1: 0.0019 Loss2: 0.0025 Loss3: 0.0014\n",
            "2022-08-03 10:16:43.902561 Epoch [057/250], Step [0060/0060], Loss1: 0.0021 Loss2: 0.0027 Loss3: 0.0016\n",
            "Epoch: 57 MAE: 0.012354154760638872 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:16:51.688070 Epoch [058/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0028 Loss3: 0.0014\n",
            "2022-08-03 10:17:20.924316 Epoch [058/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0029 Loss3: 0.0016\n",
            "2022-08-03 10:17:26.995794 Epoch [058/250], Step [0060/0060], Loss1: 0.0018 Loss2: 0.0025 Loss3: 0.0014\n",
            "Epoch: 58 MAE: 0.012244409120212945 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:17:34.587121 Epoch [059/250], Step [0001/0060], Loss1: 0.0018 Loss2: 0.0027 Loss3: 0.0015\n",
            "2022-08-03 10:18:03.515046 Epoch [059/250], Step [0050/0060], Loss1: 0.0017 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 10:18:09.475767 Epoch [059/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0026 Loss3: 0.0013\n",
            "Epoch: 59 MAE: 0.011434084432761348 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:18:16.999280 Epoch [060/250], Step [0001/0060], Loss1: 0.0018 Loss2: 0.0027 Loss3: 0.0014\n",
            "2022-08-03 10:18:45.889856 Epoch [060/250], Step [0050/0060], Loss1: 0.0017 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 10:18:51.622782 Epoch [060/250], Step [0060/0060], Loss1: 0.0017 Loss2: 0.0027 Loss3: 0.0013\n",
            "Epoch: 60 MAE: 0.012119028635973495 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:19:01.500953 Epoch [061/250], Step [0001/0060], Loss1: 0.0018 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 10:19:31.332820 Epoch [061/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 10:19:37.085725 Epoch [061/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0028 Loss3: 0.0013\n",
            "Epoch: 61 MAE: 0.011890299226497375 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:19:45.321109 Epoch [062/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0027 Loss3: 0.0014\n",
            "2022-08-03 10:20:13.952493 Epoch [062/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 10:20:19.945473 Epoch [062/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0027 Loss3: 0.0013\n",
            "Epoch: 62 MAE: 0.011557942300680139 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:20:28.117631 Epoch [063/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 10:20:57.102109 Epoch [063/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 10:21:03.026433 Epoch [063/250], Step [0060/0060], Loss1: 0.0018 Loss2: 0.0025 Loss3: 0.0013\n",
            "Epoch: 63 MAE: 0.011831820262448183 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:21:10.667759 Epoch [064/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 10:21:39.938117 Epoch [064/250], Step [0050/0060], Loss1: 0.0018 Loss2: 0.0028 Loss3: 0.0014\n",
            "2022-08-03 10:21:45.742616 Epoch [064/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0027 Loss3: 0.0013\n",
            "Epoch: 64 MAE: 0.011845825905246394 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:21:53.356004 Epoch [065/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 10:22:22.516467 Epoch [065/250], Step [0050/0060], Loss1: 0.0019 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 10:22:28.636790 Epoch [065/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0012\n",
            "Epoch: 65 MAE: 0.011788079382053443 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:22:38.741732 Epoch [066/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 10:23:08.624383 Epoch [066/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 10:23:14.705773 Epoch [066/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0020 Loss3: 0.0011\n",
            "Epoch: 66 MAE: 0.011828299367889053 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:23:22.588222 Epoch [067/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 10:23:51.674676 Epoch [067/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0027 Loss3: 0.0013\n",
            "2022-08-03 10:23:57.398224 Epoch [067/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "Epoch: 67 MAE: 0.01193527001444073 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:24:05.053791 Epoch [068/250], Step [0001/0060], Loss1: 0.0018 Loss2: 0.0027 Loss3: 0.0014\n",
            "2022-08-03 10:24:33.681219 Epoch [068/250], Step [0050/0060], Loss1: 0.0018 Loss2: 0.0026 Loss3: 0.0014\n",
            "2022-08-03 10:24:39.636044 Epoch [068/250], Step [0060/0060], Loss1: 0.0018 Loss2: 0.0026 Loss3: 0.0014\n",
            "Epoch: 68 MAE: 0.011469463684729167 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:24:47.466966 Epoch [069/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0026 Loss3: 0.0014\n",
            "2022-08-03 10:25:16.635721 Epoch [069/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 10:25:22.608777 Epoch [069/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0028 Loss3: 0.0013\n",
            "Epoch: 69 MAE: 0.011757414085820081 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:25:30.619677 Epoch [070/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0028 Loss3: 0.0012\n",
            "2022-08-03 10:25:59.760537 Epoch [070/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 10:26:05.859847 Epoch [070/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0013\n",
            "Epoch: 70 MAE: 0.011437270354243025 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:26:16.459206 Epoch [071/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0026 Loss3: 0.0013\n",
            "2022-08-03 10:26:45.558906 Epoch [071/250], Step [0050/0060], Loss1: 0.0017 Loss2: 0.0025 Loss3: 0.0012\n",
            "2022-08-03 10:26:51.346565 Epoch [071/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "Epoch: 71 MAE: 0.011943239267797225 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:26:59.033694 Epoch [072/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 10:27:28.429033 Epoch [072/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 10:27:34.408142 Epoch [072/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0027 Loss3: 0.0013\n",
            "Epoch: 72 MAE: 0.011459449424393593 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:27:42.031846 Epoch [073/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0027 Loss3: 0.0014\n",
            "2022-08-03 10:28:10.925268 Epoch [073/250], Step [0050/0060], Loss1: 0.0018 Loss2: 0.0026 Loss3: 0.0014\n",
            "2022-08-03 10:28:16.670232 Epoch [073/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0027 Loss3: 0.0013\n",
            "Epoch: 73 MAE: 0.012092462179088404 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:28:24.562342 Epoch [074/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 10:28:53.485285 Epoch [074/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 10:28:59.261432 Epoch [074/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0020 Loss3: 0.0011\n",
            "Epoch: 74 MAE: 0.011272474716875761 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:29:06.907285 Epoch [075/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 10:29:36.421552 Epoch [075/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 10:29:42.154474 Epoch [075/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0026 Loss3: 0.0013\n",
            "Epoch: 75 MAE: 0.011521761120843983 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:29:52.561230 Epoch [076/250], Step [0001/0060], Loss1: 0.0018 Loss2: 0.0026 Loss3: 0.0014\n",
            "2022-08-03 10:30:22.193003 Epoch [076/250], Step [0050/0060], Loss1: 0.0017 Loss2: 0.0028 Loss3: 0.0014\n",
            "2022-08-03 10:30:28.208752 Epoch [076/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "Epoch: 76 MAE: 0.011627226735332183 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:30:35.802474 Epoch [077/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0012\n",
            "2022-08-03 10:31:05.472832 Epoch [077/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 10:31:11.362896 Epoch [077/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0026 Loss3: 0.0013\n",
            "Epoch: 77 MAE: 0.0116178817854869 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:31:19.399512 Epoch [078/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 10:31:47.991944 Epoch [078/250], Step [0050/0060], Loss1: 0.0017 Loss2: 0.0027 Loss3: 0.0013\n",
            "2022-08-03 10:31:53.996420 Epoch [078/250], Step [0060/0060], Loss1: 0.0017 Loss2: 0.0027 Loss3: 0.0013\n",
            "Epoch: 78 MAE: 0.011583775200600189 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:32:01.946139 Epoch [079/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 10:32:30.902171 Epoch [079/250], Step [0050/0060], Loss1: 0.0017 Loss2: 0.0026 Loss3: 0.0013\n",
            "2022-08-03 10:32:36.977582 Epoch [079/250], Step [0060/0060], Loss1: 0.0019 Loss2: 0.0028 Loss3: 0.0014\n",
            "Epoch: 79 MAE: 0.011525031607893725 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:32:44.627626 Epoch [080/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 10:33:13.417221 Epoch [080/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 10:33:19.578380 Epoch [080/250], Step [0060/0060], Loss1: 0.0018 Loss2: 0.0026 Loss3: 0.0013\n",
            "Epoch: 80 MAE: 0.011912074605269092 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:33:29.775151 Epoch [081/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0012\n",
            "2022-08-03 10:33:58.782126 Epoch [081/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 10:34:04.481707 Epoch [081/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0022 Loss3: 0.0013\n",
            "Epoch: 81 MAE: 0.011698690923078665 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:34:12.391207 Epoch [082/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0011\n",
            "2022-08-03 10:34:41.612198 Epoch [082/250], Step [0050/0060], Loss1: 0.0013 Loss2: 0.0022 Loss3: 0.0011\n",
            "2022-08-03 10:34:47.408057 Epoch [082/250], Step [0060/0060], Loss1: 0.0017 Loss2: 0.0027 Loss3: 0.0014\n",
            "Epoch: 82 MAE: 0.01203126014609422 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:34:54.971650 Epoch [083/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 10:35:24.432736 Epoch [083/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 10:35:30.372949 Epoch [083/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "Epoch: 83 MAE: 0.011748987833954512 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:35:38.113640 Epoch [084/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0012\n",
            "2022-08-03 10:36:07.461999 Epoch [084/250], Step [0050/0060], Loss1: 0.0018 Loss2: 0.0029 Loss3: 0.0014\n",
            "2022-08-03 10:36:13.325236 Epoch [084/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "Epoch: 84 MAE: 0.01188700215979701 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:36:21.096185 Epoch [085/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 10:36:50.051973 Epoch [085/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 10:36:55.960659 Epoch [085/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0012\n",
            "Epoch: 85 MAE: 0.011700755569137751 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:37:06.132017 Epoch [086/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 10:37:35.387541 Epoch [086/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 10:37:41.223088 Epoch [086/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "Epoch: 86 MAE: 0.01183134386877692 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:37:49.181759 Epoch [087/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0012\n",
            "2022-08-03 10:38:18.324761 Epoch [087/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0026 Loss3: 0.0013\n",
            "2022-08-03 10:38:24.141323 Epoch [087/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "Epoch: 87 MAE: 0.011650736754139265 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:38:32.023278 Epoch [088/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0026 Loss3: 0.0013\n",
            "2022-08-03 10:39:01.178507 Epoch [088/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 10:39:07.028820 Epoch [088/250], Step [0060/0060], Loss1: 0.0018 Loss2: 0.0026 Loss3: 0.0014\n",
            "Epoch: 88 MAE: 0.011967384285988316 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:39:14.959882 Epoch [089/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 10:39:44.119546 Epoch [089/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "2022-08-03 10:39:49.826870 Epoch [089/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0013\n",
            "Epoch: 89 MAE: 0.011479691942296331 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:39:57.780905 Epoch [090/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 10:40:26.584850 Epoch [090/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 10:40:32.509772 Epoch [090/250], Step [0060/0060], Loss1: 0.0017 Loss2: 0.0026 Loss3: 0.0014\n",
            "Epoch: 90 MAE: 0.011565450224138442 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:40:42.562468 Epoch [091/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0011\n",
            "2022-08-03 10:41:12.278498 Epoch [091/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 10:41:18.104351 Epoch [091/250], Step [0060/0060], Loss1: 0.0017 Loss2: 0.0025 Loss3: 0.0013\n",
            "Epoch: 91 MAE: 0.011570693562842078 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:41:26.082107 Epoch [092/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 10:41:55.392564 Epoch [092/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 10:42:01.137310 Epoch [092/250], Step [0060/0060], Loss1: 0.0018 Loss2: 0.0028 Loss3: 0.0014\n",
            "Epoch: 92 MAE: 0.011721652363323502 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:42:08.635264 Epoch [093/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0026 Loss3: 0.0013\n",
            "2022-08-03 10:42:37.446457 Epoch [093/250], Step [0050/0060], Loss1: 0.0017 Loss2: 0.0026 Loss3: 0.0014\n",
            "2022-08-03 10:42:43.166448 Epoch [093/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "Epoch: 93 MAE: 0.011442509065899584 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:42:50.939255 Epoch [094/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 10:43:19.719953 Epoch [094/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0012\n",
            "2022-08-03 10:43:25.511616 Epoch [094/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0013\n",
            "Epoch: 94 MAE: 0.011477149852980224 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:43:33.072521 Epoch [095/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 10:44:01.908690 Epoch [095/250], Step [0050/0060], Loss1: 0.0019 Loss2: 0.0031 Loss3: 0.0015\n",
            "2022-08-03 10:44:07.608832 Epoch [095/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0020 Loss3: 0.0012\n",
            "Epoch: 95 MAE: 0.011385127029839962 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:44:18.293488 Epoch [096/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 10:44:48.049846 Epoch [096/250], Step [0050/0060], Loss1: 0.0017 Loss2: 0.0026 Loss3: 0.0014\n",
            "2022-08-03 10:44:54.165589 Epoch [096/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "Epoch: 96 MAE: 0.011879800168413019 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:45:01.947372 Epoch [097/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 10:45:31.331763 Epoch [097/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 10:45:37.163029 Epoch [097/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "Epoch: 97 MAE: 0.012022041449589389 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:45:45.244420 Epoch [098/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 10:46:14.593453 Epoch [098/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0026 Loss3: 0.0015\n",
            "2022-08-03 10:46:20.586781 Epoch [098/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0013\n",
            "Epoch: 98 MAE: 0.012026222895771738 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:46:28.741611 Epoch [099/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0029 Loss3: 0.0013\n",
            "2022-08-03 10:46:57.658215 Epoch [099/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0028 Loss3: 0.0013\n",
            "2022-08-03 10:47:03.410143 Epoch [099/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0012\n",
            "Epoch: 99 MAE: 0.0115768896075823 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:47:11.438328 Epoch [100/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 10:47:40.859510 Epoch [100/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0019 Loss3: 0.0011\n",
            "2022-08-03 10:47:46.747631 Epoch [100/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0013\n",
            "Epoch: 100 MAE: 0.011955682143923781 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:47:57.193740 Epoch [101/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 10:48:26.755420 Epoch [101/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 10:48:32.536816 Epoch [101/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0027 Loss3: 0.0012\n",
            "Epoch: 101 MAE: 0.012310307524684403 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "2022-08-03 10:48:40.501975 Epoch [102/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 10:49:09.464138 Epoch [102/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 10:49:15.356127 Epoch [102/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0012\n",
            "Epoch: 102 MAE: 0.011089457834642085 ####  bestMAE: 0.01112186120054315 bestEpoch: 56\n",
            "best epoch:102\n",
            "2022-08-03 10:49:25.641893 Epoch [103/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0026 Loss3: 0.0012\n",
            "2022-08-03 10:49:56.289995 Epoch [103/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 10:50:02.311593 Epoch [103/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0012\n",
            "Epoch: 103 MAE: 0.01223708213203483 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 10:50:10.275547 Epoch [104/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 10:50:39.295300 Epoch [104/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 10:50:45.162028 Epoch [104/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0012\n",
            "Epoch: 104 MAE: 0.011834221914233197 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 10:50:52.862996 Epoch [105/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 10:51:21.571045 Epoch [105/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 10:51:27.365364 Epoch [105/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0021 Loss3: 0.0012\n",
            "Epoch: 105 MAE: 0.011736422710652863 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 10:51:37.753104 Epoch [106/250], Step [0001/0060], Loss1: 0.0018 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 10:52:06.622800 Epoch [106/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "2022-08-03 10:52:12.304325 Epoch [106/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0028 Loss3: 0.0013\n",
            "Epoch: 106 MAE: 0.012022830826777315 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 10:52:20.444374 Epoch [107/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0014\n",
            "2022-08-03 10:52:49.361310 Epoch [107/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 10:52:55.263461 Epoch [107/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "Epoch: 107 MAE: 0.012395471504460725 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 10:53:02.886755 Epoch [108/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 10:53:32.029707 Epoch [108/250], Step [0050/0060], Loss1: 0.0017 Loss2: 0.0027 Loss3: 0.0014\n",
            "2022-08-03 10:53:37.677054 Epoch [108/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "Epoch: 108 MAE: 0.012566183641966846 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 10:53:45.812650 Epoch [109/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 10:54:15.276246 Epoch [109/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 10:54:21.207195 Epoch [109/250], Step [0060/0060], Loss1: 0.0017 Loss2: 0.0023 Loss3: 0.0013\n",
            "Epoch: 109 MAE: 0.012245404667087964 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 10:54:29.193014 Epoch [110/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0026 Loss3: 0.0013\n",
            "2022-08-03 10:54:58.891305 Epoch [110/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "2022-08-03 10:55:04.815739 Epoch [110/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0013\n",
            "Epoch: 110 MAE: 0.011788252349351607 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 10:55:14.980801 Epoch [111/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 10:55:44.324225 Epoch [111/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0019 Loss3: 0.0011\n",
            "2022-08-03 10:55:50.266012 Epoch [111/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0026 Loss3: 0.0013\n",
            "Epoch: 111 MAE: 0.011457923238003065 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 10:55:58.359080 Epoch [112/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0019 Loss3: 0.0011\n",
            "2022-08-03 10:56:27.678138 Epoch [112/250], Step [0050/0060], Loss1: 0.0017 Loss2: 0.0025 Loss3: 0.0014\n",
            "2022-08-03 10:56:33.909825 Epoch [112/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0012\n",
            "Epoch: 112 MAE: 0.012262135041907193 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 10:56:41.929158 Epoch [113/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 10:57:10.969584 Epoch [113/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 10:57:17.142395 Epoch [113/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0026 Loss3: 0.0012\n",
            "Epoch: 113 MAE: 0.012142597830721311 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 10:57:24.762346 Epoch [114/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0028 Loss3: 0.0014\n",
            "2022-08-03 10:57:53.496450 Epoch [114/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 10:57:59.642757 Epoch [114/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0026 Loss3: 0.0013\n",
            "Epoch: 114 MAE: 0.012096136475780181 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 10:58:07.304112 Epoch [115/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 10:58:36.148335 Epoch [115/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 10:58:41.882226 Epoch [115/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "Epoch: 115 MAE: 0.012218313047751075 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 10:58:52.374821 Epoch [116/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0020 Loss3: 0.0011\n",
            "2022-08-03 10:59:21.524298 Epoch [116/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 10:59:27.495655 Epoch [116/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "Epoch: 116 MAE: 0.012394372262947616 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 10:59:35.368475 Epoch [117/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0026 Loss3: 0.0013\n",
            "2022-08-03 11:00:04.031524 Epoch [117/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 11:00:10.207259 Epoch [117/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "Epoch: 117 MAE: 0.011862055235911929 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:00:18.081748 Epoch [118/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 11:00:47.149204 Epoch [118/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0011\n",
            "2022-08-03 11:00:53.192182 Epoch [118/250], Step [0060/0060], Loss1: 0.0017 Loss2: 0.0023 Loss3: 0.0013\n",
            "Epoch: 118 MAE: 0.012056919524357432 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:01:01.125280 Epoch [119/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 11:01:30.559781 Epoch [119/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 11:01:36.415134 Epoch [119/250], Step [0060/0060], Loss1: 0.0017 Loss2: 0.0029 Loss3: 0.0013\n",
            "Epoch: 119 MAE: 0.01235169255071216 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:01:44.275975 Epoch [120/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 11:02:13.650731 Epoch [120/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 11:02:19.544956 Epoch [120/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0031 Loss3: 0.0013\n",
            "Epoch: 120 MAE: 0.012188546943463503 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:02:29.702319 Epoch [121/250], Step [0001/0060], Loss1: 0.0018 Loss2: 0.0032 Loss3: 0.0014\n",
            "2022-08-03 11:02:59.450439 Epoch [121/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 11:03:05.419255 Epoch [121/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0013\n",
            "Epoch: 121 MAE: 0.011935411006330497 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:03:13.303712 Epoch [122/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 11:03:42.638171 Epoch [122/250], Step [0050/0060], Loss1: 0.0013 Loss2: 0.0019 Loss3: 0.0011\n",
            "2022-08-03 11:03:48.872253 Epoch [122/250], Step [0060/0060], Loss1: 0.0018 Loss2: 0.0022 Loss3: 0.0013\n",
            "Epoch: 122 MAE: 0.011990314689538782 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:03:57.160980 Epoch [123/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 11:04:26.492275 Epoch [123/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 11:04:32.870574 Epoch [123/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0013\n",
            "Epoch: 123 MAE: 0.01181294485956194 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:04:40.554612 Epoch [124/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 11:05:10.159140 Epoch [124/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "2022-08-03 11:05:16.003980 Epoch [124/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0011\n",
            "Epoch: 124 MAE: 0.01210516525639428 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:05:23.818918 Epoch [125/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0027 Loss3: 0.0013\n",
            "2022-08-03 11:05:53.049625 Epoch [125/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "2022-08-03 11:05:59.007257 Epoch [125/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0013\n",
            "Epoch: 125 MAE: 0.011749341522180845 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:06:09.197918 Epoch [126/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0027 Loss3: 0.0014\n",
            "2022-08-03 11:06:38.314121 Epoch [126/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 11:06:44.028416 Epoch [126/250], Step [0060/0060], Loss1: 0.0013 Loss2: 0.0023 Loss3: 0.0011\n",
            "Epoch: 126 MAE: 0.012006429888840233 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:06:51.889818 Epoch [127/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0012\n",
            "2022-08-03 11:07:21.585140 Epoch [127/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0026 Loss3: 0.0013\n",
            "2022-08-03 11:07:27.446548 Epoch [127/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0013\n",
            "Epoch: 127 MAE: 0.011878905418728079 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:07:35.042735 Epoch [128/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0024 Loss3: 0.0011\n",
            "2022-08-03 11:08:03.860733 Epoch [128/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0027 Loss3: 0.0013\n",
            "2022-08-03 11:08:09.782612 Epoch [128/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0012\n",
            "Epoch: 128 MAE: 0.012112085123561205 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:08:17.640846 Epoch [129/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0012\n",
            "2022-08-03 11:08:47.446640 Epoch [129/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 11:08:53.221605 Epoch [129/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "Epoch: 129 MAE: 0.012042772963583942 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:09:01.334372 Epoch [130/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 11:09:30.679540 Epoch [130/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0020 Loss3: 0.0012\n",
            "2022-08-03 11:09:36.796409 Epoch [130/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "Epoch: 130 MAE: 0.011881109947959581 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:09:47.905681 Epoch [131/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 11:10:16.786214 Epoch [131/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0020 Loss3: 0.0012\n",
            "2022-08-03 11:10:22.451780 Epoch [131/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "Epoch: 131 MAE: 0.012337262439171947 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:10:30.246429 Epoch [132/250], Step [0001/0060], Loss1: 0.0013 Loss2: 0.0019 Loss3: 0.0011\n",
            "2022-08-03 11:10:59.532995 Epoch [132/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 11:11:05.738071 Epoch [132/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0012\n",
            "Epoch: 132 MAE: 0.011921666067330137 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:11:13.842869 Epoch [133/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0026 Loss3: 0.0012\n",
            "2022-08-03 11:11:43.347736 Epoch [133/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0019 Loss3: 0.0011\n",
            "2022-08-03 11:11:49.460495 Epoch [133/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "Epoch: 133 MAE: 0.011735834188700195 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:11:57.222277 Epoch [134/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 11:12:26.183351 Epoch [134/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0020 Loss3: 0.0012\n",
            "2022-08-03 11:12:31.945025 Epoch [134/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "Epoch: 134 MAE: 0.011798179604940943 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:12:39.979595 Epoch [135/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 11:13:08.964942 Epoch [135/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 11:13:15.116757 Epoch [135/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0012\n",
            "Epoch: 135 MAE: 0.011944265725711981 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:13:25.463900 Epoch [136/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 11:13:56.110899 Epoch [136/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "2022-08-03 11:14:02.027062 Epoch [136/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0027 Loss3: 0.0013\n",
            "Epoch: 136 MAE: 0.011945655842917778 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:14:10.210433 Epoch [137/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "2022-08-03 11:14:39.372194 Epoch [137/250], Step [0050/0060], Loss1: 0.0017 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 11:14:45.265778 Epoch [137/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0024 Loss3: 0.0012\n",
            "Epoch: 137 MAE: 0.01193993922973436 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:14:53.091009 Epoch [138/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0027 Loss3: 0.0013\n",
            "2022-08-03 11:15:23.295529 Epoch [138/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0011\n",
            "2022-08-03 11:15:29.506630 Epoch [138/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0020 Loss3: 0.0012\n",
            "Epoch: 138 MAE: 0.012033981640660574 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:15:37.408325 Epoch [139/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0027 Loss3: 0.0012\n",
            "2022-08-03 11:16:06.918940 Epoch [139/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 11:16:12.744722 Epoch [139/250], Step [0060/0060], Loss1: 0.0013 Loss2: 0.0022 Loss3: 0.0011\n",
            "Epoch: 139 MAE: 0.012044190843072202 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:16:20.572095 Epoch [140/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0027 Loss3: 0.0012\n",
            "2022-08-03 11:16:49.887362 Epoch [140/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0026 Loss3: 0.0013\n",
            "2022-08-03 11:16:55.818866 Epoch [140/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0013\n",
            "Epoch: 140 MAE: 0.011883335993699139 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:17:06.185885 Epoch [141/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0029 Loss3: 0.0012\n",
            "2022-08-03 11:17:37.084279 Epoch [141/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "2022-08-03 11:17:43.354477 Epoch [141/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "Epoch: 141 MAE: 0.011887912682834127 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:17:51.239830 Epoch [142/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 11:18:20.195374 Epoch [142/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 11:18:26.284478 Epoch [142/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "Epoch: 142 MAE: 0.011726290068870026 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:18:34.280163 Epoch [143/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0011\n",
            "2022-08-03 11:19:03.273259 Epoch [143/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0026 Loss3: 0.0013\n",
            "2022-08-03 11:19:09.165278 Epoch [143/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0012\n",
            "Epoch: 143 MAE: 0.011989271667386805 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:19:16.989245 Epoch [144/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 11:19:46.800587 Epoch [144/250], Step [0050/0060], Loss1: 0.0013 Loss2: 0.0020 Loss3: 0.0010\n",
            "2022-08-03 11:19:52.711696 Epoch [144/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "Epoch: 144 MAE: 0.011793876103761177 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:20:00.596558 Epoch [145/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0027 Loss3: 0.0013\n",
            "2022-08-03 11:20:29.506427 Epoch [145/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0012\n",
            "2022-08-03 11:20:35.635025 Epoch [145/250], Step [0060/0060], Loss1: 0.0017 Loss2: 0.0028 Loss3: 0.0013\n",
            "Epoch: 145 MAE: 0.012024943620735218 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:20:46.031613 Epoch [146/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0025 Loss3: 0.0014\n",
            "2022-08-03 11:21:15.754170 Epoch [146/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 11:21:21.774926 Epoch [146/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0013\n",
            "Epoch: 146 MAE: 0.012126359201612927 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:21:29.690513 Epoch [147/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0028 Loss3: 0.0013\n",
            "2022-08-03 11:21:59.631524 Epoch [147/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0027 Loss3: 0.0012\n",
            "2022-08-03 11:22:05.891926 Epoch [147/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0027 Loss3: 0.0013\n",
            "Epoch: 147 MAE: 0.012054694372983206 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:22:13.662409 Epoch [148/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0011\n",
            "2022-08-03 11:22:42.957025 Epoch [148/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 11:22:48.987505 Epoch [148/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0024 Loss3: 0.0012\n",
            "Epoch: 148 MAE: 0.012092831795887342 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:22:57.004833 Epoch [149/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 11:23:26.305241 Epoch [149/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "2022-08-03 11:23:32.392007 Epoch [149/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0014\n",
            "Epoch: 149 MAE: 0.012063307081541371 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:23:39.978851 Epoch [150/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 11:24:09.153184 Epoch [150/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0027 Loss3: 0.0013\n",
            "2022-08-03 11:24:14.863539 Epoch [150/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0027 Loss3: 0.0013\n",
            "Epoch: 150 MAE: 0.012015792445117046 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:24:25.069286 Epoch [151/250], Step [0001/0060], Loss1: 0.0013 Loss2: 0.0019 Loss3: 0.0011\n",
            "2022-08-03 11:24:54.600573 Epoch [151/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "2022-08-03 11:25:00.459672 Epoch [151/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0013\n",
            "Epoch: 151 MAE: 0.011812380219381007 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:25:08.363780 Epoch [152/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 11:25:37.677895 Epoch [152/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 11:25:43.722701 Epoch [152/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "Epoch: 152 MAE: 0.012202218278414674 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:25:51.654889 Epoch [153/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0027 Loss3: 0.0013\n",
            "2022-08-03 11:26:21.045039 Epoch [153/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0031 Loss3: 0.0013\n",
            "2022-08-03 11:26:27.027446 Epoch [153/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0012\n",
            "Epoch: 153 MAE: 0.012248555634407297 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:26:35.485722 Epoch [154/250], Step [0001/0060], Loss1: 0.0013 Loss2: 0.0024 Loss3: 0.0011\n",
            "2022-08-03 11:27:04.527943 Epoch [154/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 11:27:10.333240 Epoch [154/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0026 Loss3: 0.0013\n",
            "Epoch: 154 MAE: 0.01199762923790822 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:27:18.589970 Epoch [155/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0011\n",
            "2022-08-03 11:27:47.375227 Epoch [155/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0027 Loss3: 0.0013\n",
            "2022-08-03 11:27:53.176030 Epoch [155/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "Epoch: 155 MAE: 0.011810461502699625 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:28:03.377404 Epoch [156/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0020 Loss3: 0.0011\n",
            "2022-08-03 11:28:32.543695 Epoch [156/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0011\n",
            "2022-08-03 11:28:38.448425 Epoch [156/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0027 Loss3: 0.0013\n",
            "Epoch: 156 MAE: 0.011911556124687195 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:28:46.314391 Epoch [157/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0024 Loss3: 0.0011\n",
            "2022-08-03 11:29:15.708313 Epoch [157/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 11:29:21.748056 Epoch [157/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0019 Loss3: 0.0011\n",
            "Epoch: 157 MAE: 0.01199217490290129 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:29:29.490471 Epoch [158/250], Step [0001/0060], Loss1: 0.0018 Loss2: 0.0027 Loss3: 0.0014\n",
            "2022-08-03 11:29:58.771843 Epoch [158/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 11:30:04.852959 Epoch [158/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "Epoch: 158 MAE: 0.01229443322009747 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:30:12.747022 Epoch [159/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0020 Loss3: 0.0012\n",
            "2022-08-03 11:30:42.068082 Epoch [159/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 11:30:47.994556 Epoch [159/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "Epoch: 159 MAE: 0.011811151272720762 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:30:56.017117 Epoch [160/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0011\n",
            "2022-08-03 11:31:25.192785 Epoch [160/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 11:31:31.344091 Epoch [160/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0026 Loss3: 0.0012\n",
            "Epoch: 160 MAE: 0.011944459270804174 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:31:42.032421 Epoch [161/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0026 Loss3: 0.0013\n",
            "2022-08-03 11:32:11.298597 Epoch [161/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0029 Loss3: 0.0013\n",
            "2022-08-03 11:32:17.418731 Epoch [161/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0019 Loss3: 0.0011\n",
            "Epoch: 161 MAE: 0.011827450238227372 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:32:25.373762 Epoch [162/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 11:32:54.477986 Epoch [162/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 11:33:00.262147 Epoch [162/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0025 Loss3: 0.0011\n",
            "Epoch: 162 MAE: 0.012015830267161604 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:33:08.118969 Epoch [163/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0030 Loss3: 0.0013\n",
            "2022-08-03 11:33:37.768480 Epoch [163/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0018 Loss3: 0.0011\n",
            "2022-08-03 11:33:43.909460 Epoch [163/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0012\n",
            "Epoch: 163 MAE: 0.011851602817870795 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:33:51.980284 Epoch [164/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0031 Loss3: 0.0013\n",
            "2022-08-03 11:34:21.822570 Epoch [164/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0027 Loss3: 0.0013\n",
            "2022-08-03 11:34:27.793031 Epoch [164/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0028 Loss3: 0.0013\n",
            "Epoch: 164 MAE: 0.012028392108659896 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:34:35.524329 Epoch [165/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 11:35:04.731283 Epoch [165/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 11:35:10.535074 Epoch [165/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0012\n",
            "Epoch: 165 MAE: 0.011956558148894045 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:35:21.009464 Epoch [166/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0011\n",
            "2022-08-03 11:35:50.535872 Epoch [166/250], Step [0050/0060], Loss1: 0.0013 Loss2: 0.0021 Loss3: 0.0011\n",
            "2022-08-03 11:35:56.692717 Epoch [166/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0019 Loss3: 0.0011\n",
            "Epoch: 166 MAE: 0.012119718287731446 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:36:04.488890 Epoch [167/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0026 Loss3: 0.0013\n",
            "2022-08-03 11:36:33.433289 Epoch [167/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 11:36:39.434431 Epoch [167/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0012\n",
            "Epoch: 167 MAE: 0.012131839901918457 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:36:47.395805 Epoch [168/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0026 Loss3: 0.0013\n",
            "2022-08-03 11:37:16.601107 Epoch [168/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 11:37:22.699931 Epoch [168/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0011\n",
            "Epoch: 168 MAE: 0.011984078464881769 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:37:30.855655 Epoch [169/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 11:38:00.447950 Epoch [169/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 11:38:06.453805 Epoch [169/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "Epoch: 169 MAE: 0.011774832626716011 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:38:14.388611 Epoch [170/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0011\n",
            "2022-08-03 11:38:43.466408 Epoch [170/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 11:38:49.218735 Epoch [170/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0012\n",
            "Epoch: 170 MAE: 0.01186030726909401 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:38:59.759438 Epoch [171/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 11:39:29.610477 Epoch [171/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0020 Loss3: 0.0012\n",
            "2022-08-03 11:39:35.466347 Epoch [171/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "Epoch: 171 MAE: 0.011986822170752382 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:39:43.334275 Epoch [172/250], Step [0001/0060], Loss1: 0.0013 Loss2: 0.0020 Loss3: 0.0011\n",
            "2022-08-03 11:40:12.679181 Epoch [172/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 11:40:18.916468 Epoch [172/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "Epoch: 172 MAE: 0.012180131113541031 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:40:27.341984 Epoch [173/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 11:40:56.266635 Epoch [173/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 11:41:02.229220 Epoch [173/250], Step [0060/0060], Loss1: 0.0013 Loss2: 0.0018 Loss3: 0.0010\n",
            "Epoch: 173 MAE: 0.011888518922090058 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:41:10.475961 Epoch [174/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 11:41:39.928291 Epoch [174/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 11:41:46.068914 Epoch [174/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "Epoch: 174 MAE: 0.01197435822899616 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:41:54.255267 Epoch [175/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 11:42:23.620589 Epoch [175/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 11:42:29.470962 Epoch [175/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "Epoch: 175 MAE: 0.011817525806171554 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:42:39.498824 Epoch [176/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0026 Loss3: 0.0012\n",
            "2022-08-03 11:43:08.961664 Epoch [176/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 11:43:14.914961 Epoch [176/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0028 Loss3: 0.0013\n",
            "Epoch: 176 MAE: 0.011695119108827342 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:43:23.003353 Epoch [177/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 11:43:52.908431 Epoch [177/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0020 Loss3: 0.0012\n",
            "2022-08-03 11:43:58.936606 Epoch [177/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "Epoch: 177 MAE: 0.011793649844115689 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:44:06.659012 Epoch [178/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0028 Loss3: 0.0013\n",
            "2022-08-03 11:44:36.477211 Epoch [178/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 11:44:42.696075 Epoch [178/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0012\n",
            "Epoch: 178 MAE: 0.0118222892328742 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:44:50.380992 Epoch [179/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 11:45:20.223565 Epoch [179/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 11:45:25.986837 Epoch [179/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0025 Loss3: 0.0012\n",
            "Epoch: 179 MAE: 0.01201051931887392 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:45:33.814994 Epoch [180/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0020 Loss3: 0.0012\n",
            "2022-08-03 11:46:03.277452 Epoch [180/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0027 Loss3: 0.0013\n",
            "2022-08-03 11:46:09.118383 Epoch [180/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0026 Loss3: 0.0013\n",
            "Epoch: 180 MAE: 0.011745453974793828 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:46:19.921351 Epoch [181/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 11:46:50.418312 Epoch [181/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0011\n",
            "2022-08-03 11:46:56.401869 Epoch [181/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "Epoch: 181 MAE: 0.01188597260486512 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:47:04.314655 Epoch [182/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 11:47:33.241577 Epoch [182/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 11:47:39.269824 Epoch [182/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "Epoch: 182 MAE: 0.012239790780262815 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:47:47.058346 Epoch [183/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 11:48:16.298506 Epoch [183/250], Step [0050/0060], Loss1: 0.0017 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 11:48:22.171266 Epoch [183/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0012\n",
            "Epoch: 183 MAE: 0.012082080001987162 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:48:30.611582 Epoch [184/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0029 Loss3: 0.0013\n",
            "2022-08-03 11:49:00.130929 Epoch [184/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0020 Loss3: 0.0011\n",
            "2022-08-03 11:49:05.893277 Epoch [184/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "Epoch: 184 MAE: 0.01198884527686806 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:49:13.964675 Epoch [185/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 11:49:42.713834 Epoch [185/250], Step [0050/0060], Loss1: 0.0013 Loss2: 0.0022 Loss3: 0.0011\n",
            "2022-08-03 11:49:48.569320 Epoch [185/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0020 Loss3: 0.0012\n",
            "Epoch: 185 MAE: 0.011761999984700528 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:49:58.905064 Epoch [186/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 11:50:27.976983 Epoch [186/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 11:50:33.801945 Epoch [186/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "Epoch: 186 MAE: 0.011906581051233742 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:50:41.930409 Epoch [187/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 11:51:11.116647 Epoch [187/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 11:51:17.289772 Epoch [187/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "Epoch: 187 MAE: 0.011895398461511211 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:51:25.128589 Epoch [188/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "2022-08-03 11:51:54.170363 Epoch [188/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 11:52:00.044110 Epoch [188/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0012\n",
            "Epoch: 188 MAE: 0.012070002012132179 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:52:08.054210 Epoch [189/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0026 Loss3: 0.0013\n",
            "2022-08-03 11:52:38.084083 Epoch [189/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 11:52:44.138064 Epoch [189/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "Epoch: 189 MAE: 0.012051346467896587 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:52:52.230558 Epoch [190/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 11:53:22.052697 Epoch [190/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0026 Loss3: 0.0013\n",
            "2022-08-03 11:53:28.245496 Epoch [190/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0013\n",
            "Epoch: 190 MAE: 0.011913453613127034 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:53:38.503265 Epoch [191/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 11:54:08.085119 Epoch [191/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0020 Loss3: 0.0012\n",
            "2022-08-03 11:54:14.168596 Epoch [191/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0012\n",
            "Epoch: 191 MAE: 0.011792423491854043 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:54:21.837950 Epoch [192/250], Step [0001/0060], Loss1: 0.0018 Loss2: 0.0029 Loss3: 0.0014\n",
            "2022-08-03 11:54:52.039253 Epoch [192/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0021 Loss3: 0.0011\n",
            "2022-08-03 11:54:58.045693 Epoch [192/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0025 Loss3: 0.0012\n",
            "Epoch: 192 MAE: 0.011994770927620786 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:55:05.842012 Epoch [193/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 11:55:35.093217 Epoch [193/250], Step [0050/0060], Loss1: 0.0017 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 11:55:40.919075 Epoch [193/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0021 Loss3: 0.0012\n",
            "Epoch: 193 MAE: 0.011794990704705318 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:55:48.991471 Epoch [194/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0011\n",
            "2022-08-03 11:56:17.637227 Epoch [194/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0020 Loss3: 0.0011\n",
            "2022-08-03 11:56:23.410345 Epoch [194/250], Step [0060/0060], Loss1: 0.0017 Loss2: 0.0029 Loss3: 0.0013\n",
            "Epoch: 194 MAE: 0.011964526227010148 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:56:31.321631 Epoch [195/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0026 Loss3: 0.0014\n",
            "2022-08-03 11:57:00.253330 Epoch [195/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0019 Loss3: 0.0011\n",
            "2022-08-03 11:57:06.281093 Epoch [195/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0026 Loss3: 0.0012\n",
            "Epoch: 195 MAE: 0.011887680280894514 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:57:16.683595 Epoch [196/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 11:57:46.202460 Epoch [196/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 11:57:52.265133 Epoch [196/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0011\n",
            "Epoch: 196 MAE: 0.01199544771086602 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:58:00.444105 Epoch [197/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0026 Loss3: 0.0013\n",
            "2022-08-03 11:58:29.563459 Epoch [197/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 11:58:35.647306 Epoch [197/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0013\n",
            "Epoch: 197 MAE: 0.012019080752950339 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:58:43.317410 Epoch [198/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 11:59:12.074529 Epoch [198/250], Step [0050/0060], Loss1: 0.0017 Loss2: 0.0026 Loss3: 0.0013\n",
            "2022-08-03 11:59:17.831825 Epoch [198/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "Epoch: 198 MAE: 0.01176768278200475 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 11:59:25.961363 Epoch [199/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0026 Loss3: 0.0014\n",
            "2022-08-03 11:59:55.290424 Epoch [199/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0011\n",
            "2022-08-03 12:00:01.261377 Epoch [199/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "Epoch: 199 MAE: 0.012101440069576105 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:00:09.191085 Epoch [200/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 12:00:38.103019 Epoch [200/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 12:00:44.008175 Epoch [200/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "Epoch: 200 MAE: 0.011857767448952746 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:00:54.295674 Epoch [201/250], Step [0001/0060], Loss1: 0.0013 Loss2: 0.0023 Loss3: 0.0011\n",
            "2022-08-03 12:01:23.555094 Epoch [201/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 12:01:29.327065 Epoch [201/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0012\n",
            "Epoch: 201 MAE: 0.011999386251859721 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:01:37.146149 Epoch [202/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 12:02:06.270340 Epoch [202/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 12:02:12.177966 Epoch [202/250], Step [0060/0060], Loss1: 0.0013 Loss2: 0.0020 Loss3: 0.0011\n",
            "Epoch: 202 MAE: 0.011841989780170105 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:02:20.219817 Epoch [203/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 12:02:49.032508 Epoch [203/250], Step [0050/0060], Loss1: 0.0017 Loss2: 0.0024 Loss3: 0.0014\n",
            "2022-08-03 12:02:55.164237 Epoch [203/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0024 Loss3: 0.0012\n",
            "Epoch: 203 MAE: 0.012051765134351121 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:03:03.167157 Epoch [204/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 12:03:32.360594 Epoch [204/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 12:03:38.322344 Epoch [204/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "Epoch: 204 MAE: 0.01183545184395616 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:03:46.504296 Epoch [205/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0026 Loss3: 0.0012\n",
            "2022-08-03 12:04:15.883707 Epoch [205/250], Step [0050/0060], Loss1: 0.0013 Loss2: 0.0021 Loss3: 0.0011\n",
            "2022-08-03 12:04:22.205164 Epoch [205/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0019 Loss3: 0.0012\n",
            "Epoch: 205 MAE: 0.012028744392510917 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:04:32.345186 Epoch [206/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0026 Loss3: 0.0012\n",
            "2022-08-03 12:05:02.169495 Epoch [206/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 12:05:08.052997 Epoch [206/250], Step [0060/0060], Loss1: 0.0017 Loss2: 0.0025 Loss3: 0.0014\n",
            "Epoch: 206 MAE: 0.01198113334941722 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:05:16.088112 Epoch [207/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 12:05:45.337926 Epoch [207/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0012\n",
            "2022-08-03 12:05:51.595851 Epoch [207/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0013\n",
            "Epoch: 207 MAE: 0.012023208958525506 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:05:59.329352 Epoch [208/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 12:06:28.925535 Epoch [208/250], Step [0050/0060], Loss1: 0.0013 Loss2: 0.0020 Loss3: 0.0011\n",
            "2022-08-03 12:06:34.878742 Epoch [208/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0021 Loss3: 0.0012\n",
            "Epoch: 208 MAE: 0.01181764191844397 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:06:42.517532 Epoch [209/250], Step [0001/0060], Loss1: 0.0018 Loss2: 0.0030 Loss3: 0.0014\n",
            "2022-08-03 12:07:11.652247 Epoch [209/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 12:07:17.783083 Epoch [209/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "Epoch: 209 MAE: 0.011866495375418 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:07:25.575209 Epoch [210/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 12:07:54.641799 Epoch [210/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 12:08:00.483891 Epoch [210/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0013\n",
            "Epoch: 210 MAE: 0.011924443086461416 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:08:10.668773 Epoch [211/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0019 Loss3: 0.0011\n",
            "2022-08-03 12:08:40.430911 Epoch [211/250], Step [0050/0060], Loss1: 0.0013 Loss2: 0.0018 Loss3: 0.0010\n",
            "2022-08-03 12:08:46.152734 Epoch [211/250], Step [0060/0060], Loss1: 0.0017 Loss2: 0.0027 Loss3: 0.0014\n",
            "Epoch: 211 MAE: 0.012045932386720937 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:08:54.204550 Epoch [212/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0027 Loss3: 0.0013\n",
            "2022-08-03 12:09:23.355208 Epoch [212/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 12:09:29.639065 Epoch [212/250], Step [0060/0060], Loss1: 0.0017 Loss2: 0.0024 Loss3: 0.0013\n",
            "Epoch: 212 MAE: 0.01191979856599891 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:09:37.737749 Epoch [213/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 12:10:06.857603 Epoch [213/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 12:10:12.842071 Epoch [213/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0026 Loss3: 0.0013\n",
            "Epoch: 213 MAE: 0.012135507383694252 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:10:20.741230 Epoch [214/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0024 Loss3: 0.0011\n",
            "2022-08-03 12:10:49.683714 Epoch [214/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0020 Loss3: 0.0012\n",
            "2022-08-03 12:10:55.463225 Epoch [214/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "Epoch: 214 MAE: 0.011613454381447463 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:11:03.218041 Epoch [215/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 12:11:32.633846 Epoch [215/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0020 Loss3: 0.0012\n",
            "2022-08-03 12:11:38.491654 Epoch [215/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0012\n",
            "Epoch: 215 MAE: 0.011770340850547192 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:11:48.894661 Epoch [216/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 12:12:18.345337 Epoch [216/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0011\n",
            "2022-08-03 12:12:24.153860 Epoch [216/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0021 Loss3: 0.0013\n",
            "Epoch: 216 MAE: 0.012132116600811954 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:12:32.259754 Epoch [217/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0019 Loss3: 0.0011\n",
            "2022-08-03 12:13:01.606794 Epoch [217/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 12:13:07.773848 Epoch [217/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0020 Loss3: 0.0012\n",
            "Epoch: 217 MAE: 0.012026527283033208 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:13:15.658529 Epoch [218/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "2022-08-03 12:13:44.741130 Epoch [218/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0020 Loss3: 0.0011\n",
            "2022-08-03 12:13:50.679737 Epoch [218/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0013\n",
            "Epoch: 218 MAE: 0.011985856463156995 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:13:58.895042 Epoch [219/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 12:14:28.371783 Epoch [219/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 12:14:34.514328 Epoch [219/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "Epoch: 219 MAE: 0.011740169295715907 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:14:42.465116 Epoch [220/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 12:15:11.054081 Epoch [220/250], Step [0050/0060], Loss1: 0.0017 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 12:15:16.735543 Epoch [220/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0012\n",
            "Epoch: 220 MAE: 0.011997981240884178 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:15:27.131592 Epoch [221/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0018 Loss3: 0.0011\n",
            "2022-08-03 12:15:56.987675 Epoch [221/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 12:16:02.792687 Epoch [221/250], Step [0060/0060], Loss1: 0.0017 Loss2: 0.0027 Loss3: 0.0013\n",
            "Epoch: 221 MAE: 0.01193755619700939 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:16:10.622089 Epoch [222/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0020 Loss3: 0.0011\n",
            "2022-08-03 12:16:40.084529 Epoch [222/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 12:16:45.733673 Epoch [222/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0013\n",
            "Epoch: 222 MAE: 0.011943479563804373 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:16:53.366887 Epoch [223/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 12:17:22.801482 Epoch [223/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0026 Loss3: 0.0012\n",
            "2022-08-03 12:17:28.512983 Epoch [223/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0012\n",
            "Epoch: 223 MAE: 0.011936150062533598 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:17:36.700576 Epoch [224/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 12:18:05.615226 Epoch [224/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 12:18:11.469532 Epoch [224/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0013\n",
            "Epoch: 224 MAE: 0.011827707453261293 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:18:19.173790 Epoch [225/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0026 Loss3: 0.0013\n",
            "2022-08-03 12:18:48.727189 Epoch [225/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 12:18:54.770206 Epoch [225/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "Epoch: 225 MAE: 0.01194882214010235 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:19:05.401614 Epoch [226/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 12:19:34.480025 Epoch [226/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 12:19:40.554621 Epoch [226/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0027 Loss3: 0.0012\n",
            "Epoch: 226 MAE: 0.012151007717918782 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:19:48.234391 Epoch [227/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "2022-08-03 12:20:17.803299 Epoch [227/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 12:20:23.482530 Epoch [227/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0012\n",
            "Epoch: 227 MAE: 0.011961204199386495 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:20:31.201753 Epoch [228/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 12:21:00.352160 Epoch [228/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 12:21:06.277662 Epoch [228/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0024 Loss3: 0.0013\n",
            "Epoch: 228 MAE: 0.011958021234484419 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:21:14.437147 Epoch [229/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 12:21:43.330846 Epoch [229/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 12:21:49.189291 Epoch [229/250], Step [0060/0060], Loss1: 0.0013 Loss2: 0.0020 Loss3: 0.0011\n",
            "Epoch: 229 MAE: 0.011861838732979127 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:21:56.911564 Epoch [230/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0020 Loss3: 0.0011\n",
            "2022-08-03 12:22:26.295290 Epoch [230/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 12:22:32.498012 Epoch [230/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0012\n",
            "Epoch: 230 MAE: 0.011826739513448306 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:22:42.794661 Epoch [231/250], Step [0001/0060], Loss1: 0.0017 Loss2: 0.0028 Loss3: 0.0014\n",
            "2022-08-03 12:23:11.943935 Epoch [231/250], Step [0050/0060], Loss1: 0.0013 Loss2: 0.0020 Loss3: 0.0011\n",
            "2022-08-03 12:23:17.697190 Epoch [231/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0021 Loss3: 0.0012\n",
            "Epoch: 231 MAE: 0.011778468088734718 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:23:25.461127 Epoch [232/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 12:23:54.312374 Epoch [232/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 12:24:00.191252 Epoch [232/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "Epoch: 232 MAE: 0.012211459910585767 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:24:07.811082 Epoch [233/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 12:24:37.539551 Epoch [233/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 12:24:43.447974 Epoch [233/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0021 Loss3: 0.0011\n",
            "Epoch: 233 MAE: 0.012092217256034177 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:24:51.245237 Epoch [234/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 12:25:20.569936 Epoch [234/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 12:25:26.564885 Epoch [234/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0026 Loss3: 0.0013\n",
            "Epoch: 234 MAE: 0.011931199196075637 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:25:34.431740 Epoch [235/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 12:26:04.069305 Epoch [235/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 12:26:10.180222 Epoch [235/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0012\n",
            "Epoch: 235 MAE: 0.011988204467805132 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:26:20.461743 Epoch [236/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 12:26:49.744156 Epoch [236/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0025 Loss3: 0.0012\n",
            "2022-08-03 12:26:55.523455 Epoch [236/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0012\n",
            "Epoch: 236 MAE: 0.012141732025950674 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:27:03.621076 Epoch [237/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 12:27:32.464758 Epoch [237/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 12:27:38.385725 Epoch [237/250], Step [0060/0060], Loss1: 0.0017 Loss2: 0.0030 Loss3: 0.0013\n",
            "Epoch: 237 MAE: 0.012086154227810246 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:27:46.198156 Epoch [238/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 12:28:14.925955 Epoch [238/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 12:28:20.724584 Epoch [238/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "Epoch: 238 MAE: 0.011826658488384314 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:28:28.468657 Epoch [239/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 12:28:56.942175 Epoch [239/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0027 Loss3: 0.0012\n",
            "2022-08-03 12:29:02.902860 Epoch [239/250], Step [0060/0060], Loss1: 0.0013 Loss2: 0.0020 Loss3: 0.0011\n",
            "Epoch: 239 MAE: 0.012003218415119345 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:29:10.936420 Epoch [240/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0013\n",
            "2022-08-03 12:29:40.302087 Epoch [240/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0021 Loss3: 0.0012\n",
            "2022-08-03 12:29:46.595897 Epoch [240/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0030 Loss3: 0.0013\n",
            "Epoch: 240 MAE: 0.011804780279774042 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:29:57.149988 Epoch [241/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 12:30:26.362109 Epoch [241/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0011\n",
            "2022-08-03 12:30:32.250825 Epoch [241/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0020 Loss3: 0.0012\n",
            "Epoch: 241 MAE: 0.01189283159605804 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:30:40.051053 Epoch [242/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0026 Loss3: 0.0013\n",
            "2022-08-03 12:31:09.494789 Epoch [242/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 12:31:15.645180 Epoch [242/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0021 Loss3: 0.0012\n",
            "Epoch: 242 MAE: 0.011746710129377861 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:31:23.506164 Epoch [243/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0020 Loss3: 0.0012\n",
            "2022-08-03 12:31:52.234527 Epoch [243/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0026 Loss3: 0.0012\n",
            "2022-08-03 12:31:58.128108 Epoch [243/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0019 Loss3: 0.0012\n",
            "Epoch: 243 MAE: 0.011913292065617583 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:32:05.972617 Epoch [244/250], Step [0001/0060], Loss1: 0.0014 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 12:32:34.854009 Epoch [244/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0022 Loss3: 0.0012\n",
            "2022-08-03 12:32:40.659832 Epoch [244/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "Epoch: 244 MAE: 0.011869138712802577 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:32:48.956187 Epoch [245/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 12:33:18.312998 Epoch [245/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0020 Loss3: 0.0011\n",
            "2022-08-03 12:33:24.101372 Epoch [245/250], Step [0060/0060], Loss1: 0.0013 Loss2: 0.0021 Loss3: 0.0010\n",
            "Epoch: 245 MAE: 0.012154460167660126 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:33:34.302740 Epoch [246/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 12:34:04.364613 Epoch [246/250], Step [0050/0060], Loss1: 0.0014 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 12:34:10.472672 Epoch [246/250], Step [0060/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0012\n",
            "Epoch: 246 MAE: 0.011838611769711687 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:34:18.534563 Epoch [247/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 12:34:47.781070 Epoch [247/250], Step [0050/0060], Loss1: 0.0015 Loss2: 0.0024 Loss3: 0.0012\n",
            "2022-08-03 12:34:53.674502 Epoch [247/250], Step [0060/0060], Loss1: 0.0014 Loss2: 0.0019 Loss3: 0.0011\n",
            "Epoch: 247 MAE: 0.011960916472451082 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:35:01.977040 Epoch [248/250], Step [0001/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "2022-08-03 12:35:30.955523 Epoch [248/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0023 Loss3: 0.0012\n",
            "2022-08-03 12:35:36.835160 Epoch [248/250], Step [0060/0060], Loss1: 0.0017 Loss2: 0.0031 Loss3: 0.0014\n",
            "Epoch: 248 MAE: 0.011737552124060809 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n",
            "2022-08-03 12:35:44.552438 Epoch [249/250], Step [0001/0060], Loss1: 0.0015 Loss2: 0.0027 Loss3: 0.0012\n",
            "2022-08-03 12:36:13.460633 Epoch [249/250], Step [0050/0060], Loss1: 0.0016 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 12:36:19.379813 Epoch [249/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0025 Loss3: 0.0013\n",
            "Epoch: 249 MAE: 0.011998560493959793 ####  bestMAE: 0.011089457834642085 bestEpoch: 102\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXgc1Z3u8e+vW5t3eZGNjTEGs9p4CchgxkmckAmbuSwZwjJsyYTL5T5Z4EK4kIEEkxtPDOEyLEPG47AviQkE5iYsIZgxNuYJGJkIs9iAMRgLvAjjFVuy1P27f3RJbqkl0y2p1OrS+3keoe7qqjrnqPHbp09VnTJ3R0REoieW7wqIiEg4FPAiIhGlgBcRiSgFvIhIRCngRUQiSgEvIhJRCniJNDN7xswuync9RPLBdB689DRmtiPtaV+gHkgEz/+Huz/cTfX4ELjY3Rd0R3kiXa0o3xUQac3d+zc93lvImlmRuzd2Z91EComGaKRgmNnXzKzGzK42s/XAvWY22MyeNLNaM9scPB6dts0LZnZx8Pg7ZrbEzG4O1v3AzE7qQD1KzexWM/sk+LnVzEqD14YFddhiZp+Z2YtmFgteu9rMPjaz7Wb2jpl9I1geM7NrzOx9M9tkZr83syHBa2Vm9lCwfIuZvWpmI7rgzym9gAJeCs0+wBBgf+ASUv8P3xs8HwPsAv5tL9sfA7wDDANuAu42M8uxDtcC04ApwGTgaOC64LUrgRqgAhgB/DPgZnYo8ANgqrsPAE4APgy2+SFwOjADGAVsBu4MXrsIGATsBwwFLg3aKPKFFPBSaJLA9e5e7+673H2Tu//B3Xe6+3ZgNqmgbM8ad/+NuyeA+4GRpII4F+cBP3f3je5eC9wAXBC81hDsc393b3D3Fz11oCsBlALjzazY3T909/eDbS4FrnX3GnevB2YBZ5pZUbC/ocBB7p5w92Xuvi3H+kovpYCXQlPr7nVNT8ysr5n9h5mtMbNtwGKg3Mzi7Wy/vumBu+8MHvZvZ932jALWpD1fEywD+BWwCviLma02s2uCslYBl5MK741mNt/MmrbZH3giGILZAqwg9YEwAngQeBaYHwwH3WRmxTnWV3opBbwUmtanfV0JHAoc4+4Dga8Gy3MddsnFJ6RCucmYYBnuvt3dr3T3A4FTgSuaxtrd/bfu/uVgWwduDLZfC5zk7uVpP2Xu/nHwLeAGdx8P/B1wCnBhiG2TCFHAS6EbQGpMektwYPL6Lt5/cXCgs+mnCPgdcJ2ZVZjZMOBnwEMAZnaKmR0UjOtvJdUTT5rZoWZ2XHAwti6oczIoYy4w28z2D/ZRYWanBY+/bmYTg28k20gN2SQRyYICXgrdrUAf4FPgZeDPXbz/p0mFcdPPLOAXQBWwHHgDeC1YBnAwsADYAfwV+LW7LyQ1/j4nqOd6YDjwk2Cb24A/khrW2R6045jgtX2Ax0iF+wpgEalhG5EvpAudREQiSj14EZGIUsCLiESUAl5EJKIU8CIiEdWjJhsbNmyYjx07Nt/VEBEpGMuWLfvU3Svaeq1HBfzYsWOpqqrKdzVERAqGma1p7zUN0YiIRJQCXkQkohTwIiIR1aPG4EWkezQ0NFBTU0NdXd0Xryw9QllZGaNHj6a4OPvJRBXwIr1QTU0NAwYMYOzYseR+vxPpbu7Opk2bqKmp4YADDsh6Ow3RiPRCdXV1DB06VOFeIMyMoUOH5vyNSwEv0ksp3AtLR96vSAT8Hc+/x6J3a/NdDRGRHiUSAf/rF97npVWf5rsaIiI9SiQCPmaQTGpee5FCsn79es455xzGjRvHUUcdxcknn8y7777bqX1+5zvf4bHHHstYXlVVxY9+9KNO7bvJfffdxw9+8IN2X581axY333xzl5TVWZE4iyZmhvJdpHC4O2eccQYXXXQR8+fPB+D1119nw4YNHHLIIV1eXmVlJZWVlV2+354uEgFvBkndmUqkQ27401u8/cm2Lt3n+FEDuf6/TWj39YULF1JcXMyll17avGzy5Mm4O1dddRXPPPMMZsZ1113H2WefzQsvvMD1119PeXk5b7zxBmeddRYTJ07ktttuY9euXfznf/4n48aNA2DBggXMmTOHbdu2ccstt3DKKafwwgsvcPPNN/Pkk08ya9YsPvroI1avXs1HH33E5Zdf3ty7f+ihh7j99tvZvXs3xxxzDL/+9a+Jx+Pce++9/PKXv6S8vJzJkydTWlqa1d+hurqaSy+9lJ07dzJu3DjuueceBg8ezO23387cuXMpKipi/PjxzJ8/n0WLFnHZZZcBqQOqixcvZsCAAR19C4CoDNHEDN16UKRwvPnmmxx11FEZyx9//HGqq6t5/fXXWbBgAVdddRXr1q0DUj38uXPnsmLFCh588EHeffddli5dysUXX8wdd9zRvI8PP/yQpUuX8tRTT3HppZe2eWrhypUrefbZZ1m6dCk33HADDQ0NrFixgkceeYSXXnqJ6upq4vE4Dz/8MOvWreP666/npZdeYsmSJbz99ttZt/PCCy/kxhtvZPny5UycOJEbbrgBgDlz5vC3v/2N5cuXM3fuXABuvvlm7rzzTqqrq3nxxRfp06dPTn/TtkSiB68hGpGO21tPu7stWbKEc889l3g8zogRI5gxYwavvvoqAwcOZOrUqYwcORKAcePGcfzxxwMwceJEFi5c2LyPs846i1gsxsEHH8yBBx7IypUrM8qZOXMmpaWllJaWMnz4cDZs2MDzzz/PsmXLmDp1KgC7du1i+PDhvPLKK3zta1+joiI1I+/ZZ5+d1bGCrVu3smXLFmbMmAHARRddxLe//W0AJk2axHnnncfpp5/O6aefDsD06dO54oorOO+88/jWt77F6NGjO/pnbBaNHryGaEQKyoQJE1i2bFlO26QPi8RisebnsViMxsbG5tdany/e1vnj6fuKx+M0Njbi7lx00UVUV1dTXV3NO++8w6xZs3KqY7aeeuopvv/97/Paa68xdepUGhsbueaaa7jrrrvYtWsX06dPb/ODKVehBbyZHWpm1Wk/28zs8pDKUg9epIAcd9xx1NfXM2/evOZly5cvp7y8nEceeYREIkFtbS2LFy/m6KOPzmnfjz76KMlkkvfff5/Vq1dz6KGHZrXdN77xDR577DE2btwIwGeffcaaNWs45phjWLRoEZs2baKhoYFHH300q/0NGjSIwYMH8+KLLwLw4IMPMmPGDJLJJGvXruXrX/86N954I1u3bmXHjh28//77TJw4kauvvpqpU6d2ScCHNkTj7u8AUwDMLA58DDwRRlkxQ2PwIgXEzHjiiSe4/PLLufHGGykrK2Ps2LHceuut7Nixg8mTJ2Nm3HTTTeyzzz45hd2YMWM4+uij2bZtG3PnzqWsrCyr7caPH88vfvELjj/+eJLJJMXFxdx5551MmzaNWbNmceyxx1JeXs6UKVOyrsv999/ffJD1wAMP5N577yWRSHD++eezdetW3J0f/ehHlJeX89Of/pSFCxcSi8WYMGECJ510UtbltMe6IxjN7Hjgenefvrf1KisrvSN3dDr2l8/zlYOHcdOZkztaRZFeZcWKFRx++OH5robkqK33zcyWuXub54B21xj8OcDv2nrBzC4xsyozq6qt7dh0AzrIKiKSKfSAN7MS4FSgzYErd5/n7pXuXtl0lDr3MnSQVUS61+zZs5kyZUqLn9mzZ+e7Wi10x2mSJwGvufuGsAqImaF8F5HudO2113Lttdfmuxp71R1DNOfSzvBMV1EPXkQkU6gBb2b9gG8Cj4dZjnrwIiKZQh2icffPgaFhlgHqwYuItCUiV7KqBy9SSPr37x/Kfk888UTKy8s55ZRTQtl/oYlIwKsHLyJw1VVX8eCDD+a7Gj1GRALeFPAiBa66uppp06YxadIkzjjjDDZv3gzA7bffzvjx45k0aRLnnHMOAIsWLWo+NfFLX/oS27dvB1LTDXR2it0oicRskpqLRqQTnrkG1r/RtfvcZyKcNCenTS688ELuuOMOZsyYwc9+9jNuuOEGbr31VubMmcMHH3xAaWkpW7ZsAfZMrTt9+nR27NiR9XQEvU1EevCai0akkLU1te7ixYuBPVPrPvTQQxQVpfqkTVPr3n777WzZsqV5ubQUib+KpioQ6YQce9rd7amnnmLx4sX86U9/Yvbs2bzxxhtcc801zJw5k6effprp06fz7LPPcthhh+W7qj1OZHrwGoMXKVw9YWrdKIpED15j8CKFZefOnS3uWHTFFVd0ydS6X/nKV1i5ciU7duxg9OjR3H333Zxwwgn5ambeRSLgNQYvUliSyWSby19++eWMZUuWLMlYln4P1nRN3wAkJSJDNDpNUkSktUgEvBm00yEQEem1IhLw6sGLiLQWiYCPGSjeRURaikjAmw6yioi0EpmA12mSIiItRSLgNR+8SGEJY7rg6upqjj32WCZMmMCkSZN45JFHuryMQhOR8+DVgxfp7fr27csDDzzAwQcfzCeffMJRRx3FCSecQHl5eb6rljeR6MHrQieRwtfZ6YIPOeQQDj74YABGjRrF8OHDqa2tzVt7eoJQe/BmVg7cBRxB6kSXf3L3v3Z1ObrQSaTjblx6Iys/69q5XA4bchhXH311Ttt05XTBS5cuZffu3YwbN67L2lSIwu7B3wb82d0PAyYDK8IoxMx0oZNIAevK6YLXrVvHBRdcwL333kssFolBig4LrQdvZoOArwLfAXD33cDuMMrSbJIiHZdrT7u75TJd8LZt25g5cyazZ89m2rRp+a563oX58XYAUAvca2Z/M7O7zKxf65XM7BIzqzKzqo6Ol+mm2yKFrSumC969ezdnnHEGF154IWeeeWaeW9QzhDkGXwQcCfzQ3V8xs9uAa4Cfpq/k7vOAeQCVlZUdiulYTD14kUISxnTBv//971m8eDGbNm3ivvvuA+C+++5jypQpeWpl/oUZ8DVAjbu/Ejx/jFTAdznNRSNSWMKYLvj888/n/PPP73zlIiS0IRp3Xw+sNbNDg0XfAN4OoywDDdGIiLQS9oVOPwQeNrMSYDXw3TAK0WmSIiKZQg14d68GKsMsAzSbpIhIWyJxkqh68CIimSIR8LrQSUQkUyQCXnPRiIhkikjAazZJkUISxnTBa9as4cgjj2TKlClMmDCBuXPndnkZhSYa0wXrQieRXm/kyJH89a9/pbS0lB07dnDEEUdw6qmnMmrUqHxXLW8i0YM39eBFCl5npwsuKSmhtLQUgPr6+nYvpupNotGD1xi8SIet/5d/oX5F104XXHr4Yezzz/+c0zZdMV3w2rVrmTlzJqtWreJXv/pVr+69Q0R68DpNUqSwddV0wfvttx/Lly9n1apV3H///WzYsCE/DeohItKD1xCNSEfl2tPubrlMF9xk1KhRHHHEEbz44ou9embJSPTgddNtkcLWFdMF19TUsGvXLgA2b97MkiVLOPTQQ/dWbORFpgevfBcpHGFMF7x48WKuvPJKzAx358c//jETJ07MYyvzLxIBb6gHL1JIwpgu+Jvf/CbLly/vfOUiJBJDNLGYevAiIq1FIuA1Bi8ikikSAa8xeJHc6dqRwtKR9ysiAa8evEguysrK2LRpk0K+QLg7mzZtar6gK1uROMiqC51EcjN69Ghqamqora3Nd1UkS2VlZS3OPMpGqAFvZh8C24EE0OjuodzdSXPRiOSmuLiYAw44IN/VkJB1Rw/+6+7+aZgFxCz1290xszCLEhEpGBEZg0+FunrxIiJ7hB3wDvzFzJaZ2SVhFdLUg9c4vIjIHmEP0XzZ3T82s+HAc2a20t0Xp68QBP8lAGPGjOlQIdbcg1fAi4g0CbUH7+4fB783Ak8AR7exzjx3r3T3yoqKig6V0zREo3wXEdkjtIA3s35mNqDpMXA88GYYZWmIRkQkU5hDNCOAJ4LhkyLgt+7+5zAKsuaAD2PvIiKFKbSAd/fVwOSw9p8upjF4EZEMkThN0jQGLyKSIRIBn36hk4iIpEQk4HWhk4hIaxEJ+NRvjcGLiOwRiYDXhU4iIpkiEfC60ElEJFNEAj71Wz14EZE9IhLwOsgqItJaJAK++UpWJbyISLNIBLzG4EVEMkUj4INWaAxeRGSPaAS8TpMUEckQiYBvoiF4EZE9IhHwe8bglfAiIk2iFfB5roeISE8SkYBP/dYYvIjIHpEI+Oa5aJJ5roiISA+Sc8Cb2WAzmxRGZTpKPXgRkUxZBbyZvWBmA81sCPAa8BszuyXLbeNm9jcze7IzFd0bXegkIpIp2x78IHffBnwLeMDdjwH+PsttLwNWdKRy2dKFTiIimbIN+CIzGwmcBWTdEzez0cBM4K4O1C1rmg9eRCRTtgH/c+BZ4H13f9XMDgTey2K7W4H/DbR7+NPMLjGzKjOrqq2tzbI6LWk2SRGRTFkFvLs/6u6T3P1/Bs9Xu/s/7G0bMzsF2Ojuy75g3/PcvdLdKysqKrKueDrddFtEJFO2B1kPMbPnzezN4PkkM7vuCzabDpxqZh8C84HjzOyhTtW2HerBi4hkynaI5jfAT4AGAHdfDpyztw3c/SfuPtrdxwbr/pe7n9+JurbLdJqkiEiGbAO+r7svbbWssasr01GaTVJEJFNRlut9ambjCKZ7MbMzgXXZFuLuLwAv5Fq5bFlzOWGVICJSeLIN+O8D84DDzOxj4AMglOGWjojF1IMXEWktq4B399XA35tZPyDm7tvDrVZu9pxFk996iIj0JNmeRXOZmQ0EdgL/amavmdnx4VYte7rQSUQkU7YHWf8pmKrgeGAocAEwJ7Ra5Uhz0YiIZMo24JuOY55Mai6at9KW5Z1mkxQRyZRtwC8zs7+QCvhnzWwAe5l+oLvpQicRkUzZnkXzPWAKsNrddwbTBn83vGrlRhc6iYhkyrYHfyzwjrtvMbPzgeuAreFVKze66baISKZsA/7fgZ1mNhm4EngfeCC0WuVIQzQiIpmyDfhGT3WPTwP+zd3vBAaEV63c6CCriEimbMfgt5vZT0idHvkVM4sBxeFVKzemHryISIZse/BnA/WkzodfD4wGfhVarXKk+eBFRDJle8OP9cDDwKDgRh517t4Dx+AV8CIiTbKdquAsYCnwbVL3ZX0lmFGyR2g+TbLHnJkvIpJ/2Y7BXwtMdfeNAGZWASwAHgurYrlQD15EJFO2Y/CxpnAPbMph29A19eAV7yIie2Tbg/+zmT0L/C54fjbwdDhVyp0udBIRyZTtfPBXmdk/kLqRNsA8d38ivGrlRhc6iYhkyrYHj7v/AfhDtuubWRmwGCgNynnM3a/PuYZZ0IVOIiKZ9hrwZradtoe2DXB3H7iXzeuB49x9h5kVA0vM7Bl3f7nj1W23noB68CIi6fYa8O7e4ekIgqkNdgRPi4OfUCJYFzqJiGQK9UwYM4ubWTWwEXjO3V9pY51LzKzKzKpqa2s7VE7zGLy68CIizUINeHdPuPsUUlMbHG1mR7Sxzjx3r3T3yoqKig6Vo4OsIiKZuuVcdnffAiwETgxj/xa0QgdZRUT2CC3gzazCzMqDx32AbwIrwyhLN90WEcmU9WmSHTASuN/M4qQ+SH7v7k+GUZBOkxQRyRRawLv7cuBLYe0/naExeBGR1nrMfDKdoZtui4hkikTAN43Bi4jIHhEJ+NRvnQcvIrJHRAJeY/AiIq1FIuA1Bi8ikikiAW+YaS4aEZF0kQh4SA3TaIhGRGSPCAW8hmhERNJFJuBNPXgRkRYiE/AxjcGLiLQQoYA3DdGIiKSJWMDnuxYiIj1HZALedJBVRKSF6AQ8mg9eRCRdZAI+FtMYvIhIuugEvJl68CIiaSIU8BqDFxFJF5mA14VOIiIthXnT7f3MbKGZvW1mb5nZZWGVBbrQSUSktTBvut0IXOnur5nZAGCZmT3n7m+HUZgudBIRaSm0Hry7r3P314LH24EVwL5hlacLnUREWuqWMXgzGwt8CXiljdcuMbMqM6uqra3tRBk6yCoiki70gDez/sAfgMvdfVvr1919nrtXuntlRUVFh8vRaZIiIi2FGvBmVkwq3B9298fDLEunSYqItBTmWTQG3A2scPdbwiqnicbgRURaCrMHPx24ADjOzKqDn5PDKkxj8CIiLYV2mqS7LyE1B1i3SI3BK+BFRJpE6EpWSCbzXQsRkZ4jMgGvC51ERFqKTMCbGYp3EZE9IhPwmotGRKSlCAW8TpMUEUkXoYDXaZIiIukiE/CaD15EpKXIBLzG4EVEWopQwOs0SRGRdNEKeF3oJCLSLDIBr7loRERaikzAaz54EZGWohPwMUgo4UVEmkUm4AeWFbN1V0O+qyEi0mNEJuBHlffhky27dKqkiEggUgG/c3eCLTvVixcRgQgF/L7lZQB8vGVXnmsiItIzRCjg+wLwiQJeRAQI96bb95jZRjN7M6wy0o0KevAKeBGRlDB78PcBJ4a4/xaG9CuhtCjGJ1vruqtIEZEeLbSAd/fFwGdh7b81M2Pf8j58vFk9eBER6AFj8GZ2iZlVmVlVbW1tp/Y1qryPDrKKiATyHvDuPs/dK929sqKiolP7GlVepjF4EZFA3gO+K40Z0peN2+vZVqdz4UVEIhXwR44ZDMBrazbnuSYiIvkX5mmSvwP+ChxqZjVm9r2wymoyZUw58ZhR9aECXkSkKKwdu/u5Ye27PX1Lijhi1EBe/bDbTt4REemxIjVEA1A5dgjVa7fwT/e9SpWCXkR6scgF/LQDh1LfmOS/Vm7krhc/yHd1RETyJnIB//eHD2f+JdM49+j9WPjORj6vb8x3lURE8iJyAW9mTDtwKKdN2Zf6xiQvvNO5i6dERApV5AK+ydSxQxjWv5TfLl2jm4CISK8U2YCPx4wfHncQL63axKNVNfmujohIt4tswANcMG1/jjlgCNf/8S1eXr0p39UREelWkQ74WMz4t388ktGD+/Dde1/ljZqt+a6SiEi3iXTAA1QMKOXh/34MQ/qV8L37X2XVxu35rpKISLeIfMADDB9Qxt3fqWR3IsnJty3htgXvUd+YyHe1RERC1SsCHuCwfQby3P+awYlH7MO/LniXo/7PAs6d97LG5kUksqwnnUJYWVnpVVVVoZfz4nu1PPf2Bp57ewPrttYxcd9BnD11P46fMIKK/qWYWeh1EBHpCma2zN0r23ytNwZ8k7qGBPOXfsT8V9eycn1qbH5w32IOGTGAI/YdxJghfRkxsJThA8sYMbCMiv6llBT1mi89IlIAFPBfwN154+OtVH24mfc2bmfFuu2sWLeN+sZki/ViBhNHl9OYSNK/tIjpBw2jOB5jaP8S9hlYxj6DUh8EA8uK9C1ARLrF3gI+tOmCC4mZMWl0OZNGlzcvSyadz3buZsO2OjZuq2fDtjrWbt7JK6s/Y2BZCeu31nHLc++2ub8+xXH2GVTG8AGlrNtaR9KdKfuVM7hvCf1KiyiOp8K/T0mc/Yf0a36+o74Rdxg9uA8DyorpVxqnYkApSYetuxoYPqCU4ri+QYhIdhTw7YjFjGH9SxnWv5QJozJfd3fqGpI4zqfbd7N+Wx3rt9WxYWtd8+ON2+qYMGogAMtrtrKjvpHtdQ0kkqlvTckcvzyZwfABpfQpjhOLGTEzYkbw2ygpilFaFKO0OE5Z8Lu0KEbFgFL2H9KXPiWp56VFcRoSSXYnkhTFjHgsltpP2j7jZljwuK4xSX1DgpKiWHMZjQlnV0OChoTTpzhOn5I4RTHDDIzU7/R6Ny1r8Th4jRbPrXl5+n5S21raNi33Q8Z+W+6H5rL3Xgak2h6PWYtvYenfdNOXJ5JOQyJJcTxGPKZvbdKzKOA7yMzoUxIHYMzQIsYM7ZvzPrbXNVCzeVdz4PcvLSLhzidbdvF5fYLP6xtZv60OMxjUp5gNW+tYt7WO+sYkSffUT5Lmx7sTTl1Dgq27GtjYkKC+MUldQ4La7fU05vppIsGHn5F0pyGR+fczg/QRTgs+GHOV6yapj6esV6ZvSRz31DGnhkSSePBBXhT8bmubLBallrexfXvtaWtxm9u3W1a2e2173bbLb6esNtZOuNOYSNKQcHY3Jhncr5hEMvXhbwZ1DUn6lcZJOuxuTDb/u7Y9O93TwWjumKVeGNa/hD9f/tW2K9MJCvg8GlBWzOEjizOWj6vo36Xl7G5MUrujnvq00C+Op3rjiaTTmPA9HxgefGAk9zwuK071+usbk+xuTFLfmKAoFqNPSZySeIxdDQl27m4kkXTcwUn9T9+UfakQTH8NnJbr0np56/202iZj/WBB8/7TH7dXRqvnTRJJpzHpJJJJGhNOLGYUp/Xom8qC1LeekuAbze7G1De6XOR6CCzXj+mkOzvrE8QMyoL3K5H05ja2Lr+t+udSx/aO6bW1tK1V2/v7tb1ue3XItgbt7LedesVjRlEsRnE8RnGRsfnz3c3ffh0oK4rzeX0jsRiUFsWJx6x5X+n/jzX9v5n01LKkw4CycKI41IA3sxOB24A4cJe7z+nqMnY17mLOHy7m60f9I187aGZX7z4SSopi7FveJ9/VEJFuFlrAm1kcuBP4JlADvGpmf3T3t7uynMSGtZx082usGP03+l25lpFjj6JswAjKSvoTj5cQjxUTi8WJW1xntohIrxJmD/5oYJW7rwYws/nAaUCXBny/kQcx4tTjGfDbvxC7+Da2A7XF4GlZ3vyNq9Uya/162jrpy7yNz4W2luW8bjv12ltdOrvu3upiX7COiISjvk+MExe81eX7DTPg9wXWpj2vAY5pvZKZXQJcAjBmzJicC7FYjAN+ehs1X32CNQseJbljB8mdO0l4EvdkarzLkyTxYOwrNcCbDB5biyRv/k+LZc3jgsEvY88ya/FSy/UypB+QC55a2v6NNsb/Wm2z1+XtjH9aW4vbqEu763a57j3gq8PL0tN5n8xjcV0h7wdZ3X0eMA9SFzp1dD+jZ5zB6BlndFm9REQKXZhXzXwM7Jf2fHSwTEREukGYAf8qcLCZHWBmJcA5wB9DLE9ERNKENkTj7o1m9gPgWVKnSd7j7l1/FEFERNoU6hi8uz8NPB1mGSIi0jbNXCUiElEKeBGRiFLAi4hElAJeRCSietQdncysFljTwc2HAZ92YXUKQW9sM/TOdqvNvUeu7d7f3SvaeqFHBXxnmFlVe7etiqre2Gbone1Wm3uPrkeAgbsAAATmSURBVGy3hmhERCJKAS8iElFRCvh5+a5AHvTGNkPvbLfa3Ht0WbsjMwYvIiItRakHLyIiaRTwIiIRVfABb2Ynmtk7ZrbKzK7Jd33CZGYfmtkbZlZtZlXBsiFm9pyZvRf8HpzvenaGmd1jZhvN7M20ZW220VJuD9775WZ2ZP5q3jnttHuWmX0cvN/VZnZy2ms/Cdr9jpmdkJ9ad46Z7WdmC83sbTN7y8wuC5ZH9v3eS5vDea9Tt7QrzB9S0xC/DxwIlACvA+PzXa8Q2/shMKzVspuAa4LH1wA35ruenWzjV4EjgTe/qI3AycAzpO46OA14Jd/17+J2zwJ+3Ma644P/10uBA4J/A/F8t6EDbR4JHBk8HgC8G7Qtsu/3Xtocyntd6D345ht7u/tuoOnG3r3JacD9weP7gdPzWJdOc/fFwGetFrfXxtOABzzlZaDczEZ2T027Vjvtbs9pwHx3r3f3D4BVpP4tFBR3X+furwWPtwMrSN3LObLv917a3J5OvdeFHvBt3dh7b3+sQufAX8xsWXCzcoAR7r4ueLweGJGfqoWqvTb2hvf/B8FwxD1pw2+Ra7eZjQW+BLxCL3m/W7UZQnivCz3ge5svu/uRwEnA983sq+kveuo7XaTPe+0NbUzz78A4YAqwDvi/+a1OOMysP/AH4HJ335b+WlTf7zbaHMp7XegB36tu7O3uHwe/NwJPkPqqtqHpa2rwe2P+ahia9toY6fff3Te4e8Ldk8Bv2PPVPDLtNrNiUkH3sLs/HiyO9PvdVpvDeq8LPeB7zY29zayfmQ1oegwcD7xJqr0XBatdBPy//NQwVO218Y/AhcHZFdOArWlf7Qteq/HlM0i935Bq9zlmVmpmBwAHA0u7u36dZWYG3A2scPdb0l6K7PvdXptDe6/zfVS5C45Kn0zqSPT7wLX5rk+I7TyQ1NH014G3mtoKDAWeB94DFgBD8l3XTrbzd6S+ojaQGm/8XnttJHU2xZ3Be/8GUJnv+ndxux8M2rU8+Ic+Mm39a4N2vwOclO/6d7DNXyY1/LIcqA5+To7y+72XNofyXmuqAhGRiCr0IRoREWmHAl5EJKIU8CIiEaWAFxGJKAW8iEhEKeBFuoCZfc3Mnsx3PUTSKeBFRCJKAS+9ipmdb2ZLgzm3/8PM4ma2w8z+NZif+3kzqwjWnWJmLwcTQD2RNi/5QWa2wMxeN7PXzGxcsPv+ZvaYma00s4eDqxZF8kYBL72GmR0OnA1Md/cpQAI4D+gHVLn7BGARcH2wyQPA1e4+idRVhk3LHwbudPfJwN+RugIVUjMDXk5qDu8DgemhN0pkL4ryXQGRbvQN4Cjg1aBz3YfURFZJ4JFgnYeAx81sEFDu7ouC5fcDjwbzAe3r7k8AuHsdQLC/pe5eEzyvBsYCS8JvlkjbFPDSmxhwv7v/pMVCs5+2Wq+j83fUpz1OoH9fkmcaopHe5HngTDMbDs33/tyf1L+DM4N1/hFY4u5bgc1m9pVg+QXAIk/dhafGzE4P9lFqZn27tRUiWVIPQ3oNd3/bzK4jdVesGKmZG78PfA4cHby2kdQ4PaSmqp0bBPhq4LvB8guA/zCznwf7+HY3NkMka5pNUno9M9vh7v3zXQ+RrqYhGhGRiFIPXkQkotSDFxGJKAW8iEhEKeBFRCJKAS8iElEKeBGRiPr/AI3I6jrn6egAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOx9d5wd1Xn2c2bmtm3qQqIIgUwHSxgBtiG2gQ8bXENcwI4Vl4ANDg6O43yOSwIuCdjxhwvExiQOuGBFMRhwg5giDLJNkUBCgGRAoIrKanu7ZWbO98fMe+acMzP3zr27d/dqNc/vJ9jdO3fmTDvveZ/nLYxzjhQpUqRIcfDCmOoBpEiRIkWKqUVqCFKkSJHiIEdqCFKkSJHiIEdqCFKkSJHiIEdqCFKkSJHiIEdqCFKkSJHiIEdqCFIcNGCM3cMY+9BUjyNFilYDS/MIUrQyGGPD0q9tAEoAHP/3j3POb5vk8TwEYCmABZzz0mQeO0WKZiH1CFK0NDjnHfQPwHYA75D+JowAY8xq9lgYY4sB/BkADuCdzT6eduymn1+KgxepIUhxQIIx9ibG2E7G2GcZY3sA3MIYm8UY+xVjrJsx1uf/fLj0nYcYY5f6P3+YMbaGMfYNf9uXGWMX1jjsXwF4FMCtABSKiTF2BGPs5/6xexhjN0qfXcYY28QYG2KMPccYe43/d84Ye5W03a2Msa+O4/xmM8ZuYYy94n9+l//3Zxhj75C2yzDG9jPGTq3zsqeYpkgNQYoDGQsAzAZwJICPwXueb/F/XwRgDMCNsd8GzgTwJwBzAXwdwA8YY6zK9n8F4Db/31sYY4cAAGPMBPArANsALAZwGID/9j97L4Br/O92wfMkepp0fj+GR5+dBGA+gG/6f/8RgA9K270VwG7O+VMJx5FiuoNznv5L/x0Q/wBsBfB//J/fBKAMIF9l+2UA+qTfHwJwqf/zhwG8KH3WBo/yWRCzr7MBVADM9X/fDODv/J9fB6AbgBXxvf8FcFXMPjmAV0m/3wrgq42cH4CFAFwAsyK2OxTAEIAu//fbAfzfqb6f6b/W+Zd6BCkOZHRzzov0C2OsjTH2fcbYNsbYIICHAcz0V+xR2EM/cM5H/R87Yrb9EIDfcs73+7//FAE9dASAbZxzO+J7RwDYkux0Qqjn/I4A0Ms579N3wjl/BcDvAbybMTYTwIXwvJoUKQAAqQCV4kCGHvL29wCOA3Am53wPY2wZgKcAVKN7aoIxVgDwPgCmz9cDQA7eJLwUwA4AixhjVoQx2AFgScyuR+F5IoQFAHZKv9dzfjsAzGaMzeSc90cc64cALoX3zv+Rc74r/oxTHGxIPYIU0wmd8HjzfsbYbABXT9B+/xxeyOqJ8OiYZQBOAPAIPO7/cQC7AVzHGGtnjOUZY2f53/1PAJ9hjJ3GPLyKMXak/9l6AB9gjJmMsQsAvLHR8+Oc7wZwD4Dv+qJyhjH2Bum7dwF4DYCr4GkGKVIIpIYgxXTCtwAUAOyHF91z7wTt90MAbuGcb+ec76F/8ITav4S3In8HgFfBC3HdCeBiAOCc/wzAv8CjkobgTciz/f1e5X+v39/PXeM8vxXwdIzNAPYB+BR9wDkfA3AHgKMA/Ly+008x3ZEmlKVIcZCAMfbPAI7lnH+w5sYpDiqkGkGKFAcBfCrpr+F5DSlSKEipoRQppjkYY5fBE5Pv4Zw/PNXjSdF6SKmhFClSpDjIkXoEKVKkSHGQ44DTCObOncsXL1481cNIkSJFigMK69at2885nxf12QFnCBYvXoy1a9dO9TBSpEiR4oACY2xb3GcpNZQiRYoUBzlSQ5AiRYoUBzlSQ5AiRYoUBzkOOI0gCpVKBTt37kSxWKy9cYqDDvl8HocffjgymcxUDyVFipbEtDAEO3fuRGdnJxYvXozqfUVSHGzgnKOnpwc7d+7EUUcdNdXDSZGiJTEtqKFisYg5c+akRiBFCIwxzJkzJ/UWU6SogqYZAr+H62q/R+uzjLGrIrZ5E2NsgDG23v/3z+M43vgGnGLaIn02UqSojmZSQzaAv+ecP8kY6wSwjjF2H+f8OW27Rzjnb2/iOFKkSDEB2LR7EKNlB6cdOWuqh5JigtE0j4Bzvptz/qT/8xCATfCaeqdIkeIAxDfvex5f+uWzUz2MFE3ApGgEjLHFAE4F8FjEx69jjG1gjN3DGDsp5vsfY4ytZYyt7e7ubuJIx4c9e/bgkksuwZIlS3DaaafhrW99K55//vlx7fPDH/4wbr/99tDf165di7/9278d174Jt956K6688sqa2y1btgyXXHLJhBwzxYGHiuOi4qRFKqcjmh41xBjrgNcZ6VOc80Ht4ycBHMk5H2aMvRVeh6Zj9H1wzm8GcDMALF++vCWfRM45LrroInzoQx/Cf//3fwMANmzYgL179+LYY4+d8OMtX74cy5cvn/D9xmHTpk1wHAePPPIIRkZG0N7e3pTj2LYNy5oWwWzTDi73nvMU0w9NfeMYYxl4RuA2znmoPZ5sGDjnv2GMfZcxNpdzvr/RY37pl8/iuVd0ezM+nHhoF65+R6SzIrB69WpkMhlcfvnl4m9Lly4F5xz/8A//gHvuuQeMMXzxi1/ExRdfjIceeghXX301Zs6ciY0bN+J973sfTjnlFHz729/G2NgY7rrrLixZ4vU8v//++3HddddhcHAQ119/Pd7+9rfjoYcewje+8Q386le/wjXXXIPt27fjpZdewvbt2/GpT31KeAs/+clP8J3vfAflchlnnnkmvvvd78I0Tdxyyy249tprMXPmTCxduhS5XK7q+a1cuRIrVqzApk2bcPfdd+MDH/gAAOCJJ57AVVddhZGREeRyOTzwwANoa2vDZz/7Wdx7770wDAOXXXYZPvnJT4o6UXPnzsXatWvxmc98Bg899BCuueYabNmyBS+99BIWLVqEa6+9FitWrMDIyAgA4MYbb8TrX/96AMDXvvY1/OQnP4FhGLjwwgtx2WWX4b3vfS+efPJJAMALL7yAiy++WPx+IKJYcQAA+Yw5xSNR4XIONzUE0xJNMwTMC9X4AYBNnPPrY7ZZAGAv55wzxs6AR1X1NGtMzcQzzzyD0047LfT3n//851i/fj02bNiA/fv34/TTT8cb3uD1FN+wYQM2bdqE2bNn4+ijj8all16Kxx9/HN/+9rdxww034Fvf+hYAYOvWrXj88cexZcsWnHPOOXjxxRdDx9m8eTNWr16NoaEhHHfccbjiiivw4osvYtWqVfj973+PTCaDT3ziE7jttttw/vnn4+qrr8a6deswY8YMnHPOOTj11FOrnt+qVatw3333YfPmzbjhhhvwgQ98AOVyGRdffDFWrVqF008/HYODgygUCrj55puxdetWrF+/HpZlobe3t+b1e+6557BmzRoUCgWMjo7ivvvuQz6fxwsvvID3v//9WLt2Le655x7cfffdeOyxx9DW1obe3l7Mnj0bM2bMwPr167Fs2TLccsst+MhHPpLklrUs/uH2p+G4Lr77l+HnaSrBuecVpJh+aKZHcBa8tngbGWPr/b99HsAiAOCc3wTgPQCuYIzZAMYAXMLH6XvWWrlPNtasWYP3v//9ME0ThxxyCN74xjfiiSeeQFdXF04//XQsXLgQALBkyRK8+c1vBgCccsopWL16tdjH+973PhiGgWOOOQZHH300Nm/eHDrO2972NuRyOeRyOcyfPx979+7FAw88gHXr1uH0008HAIyNjWH+/Pl47LHH8KY3vQnz5nkVaS+++OKqWgat4hctWoTDDjsMH/3oR9Hb24tdu3Zh4cKFYv9dXV0APA/m8ssvFxTP7NmzY/dNeOc734lCoQDAyxS/8sorsX79epimKcZ2//334yMf+Qja2tqU/V566aW45ZZbcP3112PVqlV4/PHHax6vlbF3sAinBWfc1COYvmiaIeCcrwFQNYCbc34jgBubNYbJxEknnRQp6laDTMcYhiF+NwwDtm2Lz/Q4+Ki4eHlfpmnCtm1wzvGhD30I1157rbLtXXfdVdc4V65cic2bN4P6QAwODuKOO+7Aa1/72rr2Y1kWXNcFgFCCl6w5fPOb38QhhxyCDRs2wHVd5PP5qvt997vfjS996Us499xzcdppp2HOnDl1javVwDmH3YKGgHPvX4rph2mRWdwKOPfcc1EqlXDzzTeLvz399NOYOXMmVq1aBcdx0N3djYcffhhnnHFGXfv+2c9+Btd1BY9+3HHHJfreeeedh9tvvx379u0DAPT29mLbtm0488wz8bvf/Q49PT2oVCr42c9+FrsP13XxP//zP9i4cSO2bt2KrVu34u6778bKlStx3HHHYffu3XjiiScAAENDQ7BtG+effz6+//3vC2NG1NDixYuxbt06AMAdd9wROlbFceFyjoGBASxcuBCGYeDHP/4xHMfjzM8//3zccsstGB0dVfabz+fxlre8BVdcccUBTwsBgONyOL7BbCWkHsH0RWoIJgiMMdx55524//77sWTJEpx00kn43Oc+hw984AN49atfjaVLl+Lcc8/F17/+dSxYsKCufS9atAhnnHEGLrzwQtx00001V8iEE088EV/96lfx5je/Ga9+9atx/vnnY/fu3Vi4cCGuueYavO51r8NZZ52FE044IXYfjzzyCA477DAceuih4m9veMMb8Nxzz6GnpwerVq3CJz/5SSxduhTnn38+isUiLr30UixatEic909/+lMAwNVXX42rrroKy5cvh2mqQijnHM/vHULfSBmf+MQn8MMf/hBLly7F5s2bhbdwwQUX4J3vfCeWL1+OZcuW4Rvf+Ib4/l/+5V/CMAxBrx3IcDlgt2CYpqcRtN64UowfB1zz+uXLl3O9Q9mmTZuqTmYpWh+uy/HMKwM4pCuPQ7qSGToZ3/jGNzAwMICvfOUrkZ8fSM/Iu25cg9Gyg/s+/capHoqC93zvD9g9UMTv//HcqR5KigbAGFvHOY+MOU8DtlO0BGg50si65KKLLsKWLVvw4IMPTuiYpgoO5y0rFh9oC8cUyZAaghQC//Iv/xLSC9773vfiC1/4QtOPHUww9U80d95558QOZorhup4xaDW4afjotEVqCFIIfOELX5iUST8KjZuB6QeX8xbVCFKxeLoiFYtTpGgxuC1LDaUewXRFaghStASIGkoXnH7UUAvOuKlGMH2RGoIULYF0egngtmweQRo+Ol2RGoIJxF133QXGWGQJiFro6enBOeecg46OjkQloacD+kfL6BkuAQg8gXSa8TWCFvQIPI1g8o73q6dfwdlfexC203pGcbohNQQTiJUrV+Lss8/GypUr6/5uPp/HV77yFSVJarqjb7SCnpGy+sd0xQmXoyU1gslOKHu5ewQ7+8Yw5ldjTdE8pIZggjA8PIw1a9bgBz/4gehH4DgOPvOZz+Dkk0/Gq1/9atxwww0AvNLNr3/967F06VKcccYZGBoaQnt7O84+++zEWcPTDUIjmOJxtAIctzU9Ak8jmLzjUQhtyU49gmZj+oWP3vOPwJ6NE7vPBacAF15XdZO7774bF1xwAY499ljMmTMH69atw+OPPx4qxxxXuvlgBJcmFjG/tN78N+ngLRs1NLnho66bGoLJwvQzBFOElStX4qqrrgIAXHLJJVi5ciVefvnlUDnmjRs3RpZuPtiRagQBiBrinEdWmp0qTDY1RB5BOTUETcf0MwQ1Vu7NQG9vLx588EFs3LgRjDE4jgPGmJjsU0SDc4AjpYR00ATocsBsHTvgewSTdzxbeASpRtBspBrBBOD222/HihUrsG3bNmzduhU7duzAUUcdhaVLl4bKMceVbj4YwcV/IFyC1CAEeondYiGkk92zWFBDlda6DtMRqSGYAKxcuRIXXXSR8rd3v/vd2L17d6gcczabjSzdDHj1+j/96U/j1ltvxeGHH47nnntuKk5nUhEqLZFGDYlVd6vpBJMuFvvzf6oRNB/TjxqaAshtJQnUPB4Arr9ebdl8+umn49FHHw19Z+vWrRM+tlYGl9b/qUYQgAxAq0UOTbZG4KYawaQh9QhSTB14agCiQBOg02KF5yZfI/AMQKoRNB+pIUgxZZDnlLTWUAC3RT0CV9yjyRlXSg1NHlJDkGLqwFV6aCrw4r4h/GLDK1M6Bh2tqhHQ/D9ZwyKDmFJDzUdqCFJMGeSooamiiH762A58/ucTnIA4TghqKMHK+99Xv4hrfvFss4cEIDAAk6UTBJnFKTXUbKRicYopA5f8AZFPMMncUMVxW27FWY9G8NjLvdg3WGz2kAAE92ayDEGaWTx5SD2CFFMHaT6ZKm3AdjnKjttSdfZp5Z0kj6BsO5NGIbnj1HF29Y9hZ99o4u3tNI9g0pAaggnEeMpQ33fffTjttNNwyimn4LTTTps2jdirgSOcRzDZ0zHV/W8lYVZ4BAnGVHEmry7ReKmhf7rrGXz+zmcSby9KTLRYGepixcFzrwxO9TAmFKkhmECMpwz13Llz8ctf/hIbN27ED3/4Q6xYsaIJI2xB6KvMccxpIyW77kmR5phKi0w2ciG+JMapbLuoTFIGsiuooca+P1y0MVJKnkUfZBa3lkbwiw2v4J03rsFQsTLVQ5kwpIZggjDeMtSnnnoqDj30UADASSedhLGxMZRKpSk7n8mAV2uIuOfxlZhwXI6XukfQP1quvbHyPW8Srdit4RHIk2wSo1a23UnLN+Dj9AicOquqOi2qEQwVbdgun1Z9EqadWPy1x7+Gzb31UzPVcPzs4/HZMz5bdZuJLEN9xx134DWveQ1yudyEnkfrIZxZ3PCeuCc91ztJ0aq7VegHeaJM5BE4LiqTrRE0eKnqLWPdqoaAPJVWC+8dD6adIZgqTFQZ6meffRaf/exn8dvf/nZyT2AKILNBevRQw/uq8+v0MrcKNSRPlEn6Fpdtd9LF4kY9Atet0xC0aGMaGpfdYpnf48G0MwS1Vu7NwESVod65cycuuugi/OhHP8KSJUuaNNoWgmQJJkIjaOTrdoslLcnzZJKJpuy4k9bTd7xisUcN1bF9i5ahdqahR9A0jYAxdgRjbDVj7DnG2LOMsasitmGMse8wxl5kjD3NGHtNs8bTTExEGer+/n687W1vw3XXXYezzjprKk9n0qB6BOPTCBr9Yqt5BHISWZKEsrLtTl7E0zgzix03oFWSwG1Rj6BVS4CMB80Ui20Af885PxHAawH8DWPsRG2bCwEc4//7GIDvNXE8TcNElKG+8cYb8eKLL+LLX/4yli1bhmXLlmHfvn1TdEaTAx7x03j3Ve9itdU0ApUaai1DMN5aQ5zzRMaNQB7RZOcRPLBpL7qH4gM1WrUEyHjQNGqIc74bwG7/5yHG2CYAhwGQi+y/C8CPuPdkPcoYm8kYW+h/94DBRJSh/uIXv4gvfvGLzRlgq0IqL8Gln8ezs3o1BhE11CJ8ryzEJhWLJwvjDR916tQIRBnqSTxH23Fx2Y/W4jNvOQ6feNOrIrcRGkGLNQ4aDyYlfJQxthjAqQAe0z46DMAO6fed/t9STHNQlI/4fdz7a+x7tOpsSWqohnFyXC7+TUZm9ERoBPVQQ0IjmMQwzYrjldqu5oVMx6ihphsCxlgHgDsAfIpz3lA6HmPsY4yxtYyxtd3d3RM7wBRTjiCXYPzVSBuOGmoRHlqeZGt5BLLxajY9JBua8UQN1UMNkR2cTI2AVvnVJvnAI0gNQSIwxjLwjMBtnPOfR2yyC8AR0u+H+39TwDm/mXO+nHO+fN68ec0Z7DRB70gZuwfGpnoYNcH1X8YZNdRwIlqLlTGoRyOQJ8hmr07l3TfqfLgcqIdNcURjmsmkhvzVfpWTnCyP4AdrXsanV61v6jEIzYwaYgB+AGAT5/z6mM1+AeCv/Oih1wIYOND0gVbDULGCgbEDIPWdqz9OUPRo3RRJEDXUGqs7V9EIqk+Acshrs6ktdwI8AqKxkm/v/b88ieGjlSQeAUUNNfmZ+cqvnsPPnwqti5uCZuYRnAVgBYCNjDEya58HsAgAOOc3AfgNgLcCeBHAKICPNHE8KVoIXPtt/JnFUfutjVbTCOrxCGQvJskEOzBWQcl2ML8zP65x1bsQ3tI9jKPnttedWTwVZaiFR5CAGposjYBzDm9d3Tw0M2poDYCqo/ejhf6mWWOYaHDO0TNSxqy2DEyjNcs0cXl53cLQG9cH/Qga36P8v6QYbx7BnU/txLptffjqn5/S0PfjxqP/HAVZ17Bdju09o1g0py12+6/fuxkbdw3gF1eeXfe45PtSz2T+8v4RnPf/fodVH3tt3VFDU5FZnCRZLMgjmJxxFSsuClmzqcdozdmsRVGyXbzSP4ahYnQFxfGUoX788cdF/sDSpUtx5513NjzOA8AOhKmh8XoE4d0mgj1OHvqRF/bjNxv3NPTdKMjXoR6PYOOuAbzh31Zj486B2O37RsvoHamvKB9BnsDrod96R0r+sStweX2raNq22Vnff9zSg98+691DWhBUNQQReQSjZRsv7x9pyvj6xxq7Z/UgNQR1oFbP1vGUoT755JOxdu1arF+/Hvfeey8+/vGPi4zkusZY9zemBnHjbDhqqEFqaLweQcl2UZzA8MZ6oobkCZK6lO2t0q3MdnjD56l6BMm/R2GYRAs1Vn20uRrBfz7yEr55/wsAgmteTSyOihr64R+24V03rmnK+PpGmq/5pYagDlRrpzjeMtRtbW2iOF2xWGyYE5Tr2R8omAg2S3y/weqjjYaPliouxirOhMXxO3VoBLIXM1r2JstqpZFtlzcscDYqFpekFbZHDSU/plx9tJl5EmXHFQZSaARVrpOghqRt+kfLGCzaEzrOjOnNAZPhEUy7onN7/vVfUdo0sWWocyccjwWf/3xVQXIiylA/9thj+OhHP4pt27bhxz/+sTAM9aP1LYHyvvAgIWqiKKKkGG/UUMl2wLk3meSs8fO4vEGPgAzAWLm6IWg0TFYeSj3UOI2R9IFGMos59+5P1mqOYOq4XBTuE3kE1TyCCI2ArqvLAXOChtmVz6BnpIz+0dQjaClUm6xWrlyJSy65BEBQhvr+++/Hxz/+caUM9Z/+9KdQGWr6/Mwzz8Szzz6LJ554Atdeey2Kxfqbkh8gWjH0SkMT5RFMdq0hWpUXyxPDY6uNaarvU6Z5igk8Asd1G/YIGk0oUwxBneGjsiFsZp6H7XKxEKg0GDWURFsgDJdsbNjRX3O7zrw3L0yGIZh2HsGCz3++afsOJhv1Zk9UGWrCCSecgI6ODjzzzDNYvnx5/YM8ACyBPsRGwz9DO6gTE6ERAEDRdjADmYb2ETUeoDGPYLSaR+DwhiNdGk0oo+vj+AXnGgkfBbwyEx255kxXtkINJRCLI6qPUoe7JOe36okduO6eTdh4zVuQz8R7kR2+Ieirs+teI0g9gjrgxkxWE1GG+uWXXxbbbdu2DZs3b8bixYvrHuMBYgeUycT7eXyWoNGooThDULKTNSinOjgTJRgreQQ1Vu/yKllQQ1U9Am/l2wiPXY9G8OFbHsd3H3rRG6NvCFyXw3XrjBriHDnLm6KaGULqXRfVAFT3CBDaph6PYKhYQcXhNZ+ZjOmd+2QkiKaGoA7EUUMTUYZ6zZo1WLp0KZYtW4aLLroI3/3udzF37txGRpl4y4rjtkzf1cAjGJ8Zm6jM4rue2pWoQTlNdBN1HZXw0RrnongEPjU1Vo6PNKtErGSToh5D8Owrg9i0e8gfo3ddyBuoVyxu8+Pnm2kIFGooSR5BRNRQWWgMtU+Q6LlixcVT2/swGPOMkedRbx/uRjDtqKFmIlh1qjd7IspQr1ixAitWrBj/GHlyU7BvqIShYgXHL+iqvfEEg2s/q9px/ZmUDVcf9akSPVa9e6jkNSgvO+jMx1M+ghqaoJr59SSUyWMuJvIIqOS2K1abSVFP+GjZdoVBEiKqVHDOdTkMo/b9dVyOzpyFPlSamksgh9XaCSZ0UWtI8sgq0nnWApWxGC7ZuPj7j+LTbz4Wl78x3JGQxtCXisWthfHXzG8+ZJalFuoV7yYUGjek/Dqe3da5vUha0qih4ZI3odZqDE8x7tWidepBXXkEEdRQLY0AaCxCqp6EspLtiHFQHoFHSXmfJ61A6rgcbb4u0MxcAtuVNAK3NtfvRHhWlQTF6sS2Nk3wZZQdN1YDoOMMpIagtRBQQy1sCZCcXuF1uuoTibBHMD5LEAj59X0vLo9gpOStaGv1AyZPoDhBE1VdtYYUaqi2VhEUS6t/da2Ej1YZFuccJTugHMtaWKY8jtrHnBxqiPIbHCnPoqpHUCVqKIlHQNeiz8/yjltE0HFSsbgOTMbk3OhkM5kIvJbag+SgBLQpOCH9kOP2COK/FXd+rhusUnWxmAxBrdUzrVQnqnmKPI/UCvWUPYLRJB5BjB6yblsv/uXXz0V9RSBp+KjtX1Oa3MhYycdMGjnkuBx5PzejmdRQRSo8SJN0tQk9yiOg8SXRCOh4/b4IHHfPaF/9qVicDPl8Hj09PU2f0ILmKdMDjVJdQ8VKXZ2mIo+tjYPHfppwfzEGkHOOnp4e5PPhiptRrj1hmDyCKuGWFIUDTJxYLF/XWnkEikZQrk1R2ZJGIOOBTfvwH4+8XPX9SVp0rqSJ5yU7fMwkjw55q1k/aqiZTWDkyLGK8Aiq3HeiuCJCfZN4O+SRkQgc9+zIYnGz57ZpIRYffvjh2LlzJ5rdvcyr9W9jKGtieG+2qcdqFHsGirBdDmswX1Nw3T9cQrHiwhzIJxLvAO9B3z1QxKy2DNrHEdddsl3RINzuzaJ/pCxeMHMwD6NOsXi07KB3pIysyWD3qpN+Pp/H4YcfHvqO/NLqGgGt0qqtylWxdoLE4jo0AiWhzE4gFseU3JaT6uKyo1WNIH5MJc0ziTIESSZL2obCR2sZxfGAzt92uDiO63pjLttu6DmPzCMQmcVJqCFVBI4z3rIHN1JuXh4FME0MQSaTwVFHHdX041x/3/P4zgMv4IKTFuCmFUubfrxGcOl1D2JX/xg2ffmCmqVr33/zo/jjSz149HPnYcGMZDXqd/SO4u0/Xo0vvu0EXLrs6IbH+Yct+3HZbV4L65s+eBr+7/9uwKBf1fWpfzofs9rrM7R3PbULn/rFehx7SAd++3enxm5nOy5ue2w7PnDmImXVp0+Ow4Iaip+AZDSiq7UAACAASURBVAFzovII6qo+GlFrKAk1pBsYOseSXc0QyD9XMY4OZVqr1JA81iTeJBnEXMb3CJrYBEaOppJF3/945CXcvnYnHvzMm7TtufI9QM2groWy5hGMxoT8ytep2MSEOmCaUEOThXLE6qbZ6Bsp1xUxQQ9ispUJTQDJ90+TyHijZOQFHlWlJBogLvLCdTn2D5eiP4sQ8KKwdlsfrv7Fs3hia2+k2EcQYnGV/ZUiMnvHi3qihkp1U0MxHoE/+VXj4ZM2pqEooVG/EB9NejL1liSyhp6PrEkeQfMMgTh/x1XCR/cMFLEnopprVB5BPQlldAyqKhp3z+TrNF4qthZSQ1AH6GZPVn/bsu3i1K/ch3+8Y2Pi74g6KAletrKU2JIU9BCPd+LTq2xWXI6c/9LHPfS/2PAK/uxrq8UkrewvIUc7JlEWiiGw1e+NJPEIpOvWjDyCWi9/vZnFdsSkDAQTWrXInKRicVmaECsOFwllqkaQfJFCHkozNQKZGhLho/74o44rFh2ObAiSv3dkePqERxBjCFwOy6dsm3n+QGoI6kLFqd8j6B0px7p+tbDmRU/zePSlnsTfcaUHuRZoYqiH1qAHshoFkQTy+MgjIBog7mXa3juKsYoTmXIftUqLAp1rRTME4TwCCh+t5hE0lxpKUmuIpJ0knlpc+Cj9Xt0jkMdY5ZpIBnGs7ESLxTVen/3DJfF8CS9xksRimT5zXDfyPYrOI0juEVBuykCNqCHH5SLxr9n5PqkhqANRoXC18MH/fAz/77fPN3S8X23YDQB43ZI5ib8jsjcTDFHmhpMiSI8f38Qnv0SeSMfF6i/uoR/0X5yoVS/NM/KLO1is4F3//nts3hPUDCpJ9zDqRQa8iW6ExOIqs5ZCzUyQIairVaXjoi2r8sZjFSd2ERBXaTXwCOLPQaGGqjwu8j5GK3bkO1Nr1fye7/0BNzzoNYqZjKghyvSVqSHXzymIOm61WkNJNG3KWemrETWk0KWpIWgdlBvwCHpGSiI6ph4UKw7ue24vANQVQUPuaqKVSQOTOk2M4/UIolbj9NDHvUxUkyVqvFEewQt7h7FhRz+e2RUYAuEROJpHIE3qMm1Uzeg34hFwzvFS93Ds56pGUDt8NKp6ZZxhlykQGZUkHoGm6VQbE2Gs7ARiseIRBN9/YNNePLW9T9lHz0gZewa8dybb5KghOZfEKzVBz5Gr0ET6d7xtws9PkuquIqFslDyCaMYgiW42UUgNQR3Qa5YngeM2lh6/o3cUQz49UW/FRiAZD1tpgBqisYxXI5DHRy9RrsZDT650NUMg75cMcFRNHpkGoN8JsgZRlRqSaZCEGsFDz3fjvOt/h139Y5Gf05AYSxY11J4LG4KoiYVzLlEa6ljlTmBxSCwWa5FMIrM4Jnz0uns24z8eeSk0HrpPuSZ7BPozEARbBNdJP3ZU1BDNCcneO98zk+pURVJQnE+KWA6khqAuRAlfteBy3lBWpCw+1vMSJBVNAckQ1DG+RryIKMjjI0NZyw0eHLP9Y4fHG8Xbdg95ER9lyRDL1JDjBgZINu4jpWD7iaaGdvaNgfP4ipI0kWRNI1GtoUKERxBNncmGV/cI1IkpCur8ltxLImOphI/qgQIR4jWdQ7OpEVubzCti8g+a+OiTe/WoofqOSYi6Z647ORoJkBqCuiCnoieF4/KG6qTItWvqcYujVsZxoAe9nvII9EBOKDWkeQRxYydqKEoQFQbQkQ2B7xHIiVeiCFrgERSyprLNsOQRJKGGChkzsSEY8A1AnKchG4IkPYvbInJFoq6Posloz1NcBVYZci2oRjyCuBITDuch8Vr2CGhF3Kw8An0yF5O/G593oS+2XDfQEhItwOzwNlHvk+26qUfQihBRQ3VM7I7bqEcgrUrreAkCXrP2tuVGPAJ/x+PNI1A9AlUjiPUISCOIoNqiKlvui6KGJK+OrmshY6rUkEStVDPCNO4ZhUxiQ0C8cNxqn/6ctYya9z1KLAaiV5dxNBggLQiqisXyz9WMoxrSGpV7Ix/e5aogSxTWmEYNNWsiVENAXcj0WdzkrnsEFVc+twSGIOKZ0p8fvcRGsw3BtMgsbiZ29o2ikDExpyMnHvJyXRpBYx6BzD8nfQg4r6/Ub0MewQTV1nEiNYJaUUNVqKEIdz1KIxBUhfTSF7KmiEj6yC2PY6hY2yP4054h8Z2ZbZnEeQTUfzauAihxxRnTSNSYZnabAYN5E3XWNFB23MjVpR7z/vTOfpxy2AwwxqTEwvFrBLpYXKvEhN61jH6mBLlm5xFUdGpIonji2lbSr06EZljPeydDv2fygiDpfseD1COogbO/thpnfe1BAI3lETiNagT+6qwtayZ+CZQXrElisR6vvr1nFP/2v5sb7gwGSB6B7wZH7cp1eUANVeHA5f2SR1CKqMljO0GjFM8j8H7euGsAa7cFUSxRE/bAWAVv+dbD+Ke7nwUAdBUyiQ3jwJhPDcV6BL4hsFgisThrGbAMQ4wDiPMIgvN4ans/3nnj7/Gt+70QzcAjqKYR8MifdegeQUl4YNHPpu4R0M/kpQYlJpoTNaSHgNK1cFw5pyBaXI8qYV5P/o4MXeCnY6bUUAtB5pXl/yeB6/KGoobomO05K/FDYCsrrerf4dILWFcegQgf9R7c3z63B/++ekvdIbJVqaGIiWa4bAsDEeXBuJIhoImqmkcg0wCFjKcRcM5DlFfUhK3f/0aoobhnSKwEE4rFWcuAZXrhxV0Fz8GvpqEAQT7GLb9/2RuL/1nShLLq1JCUR1COpoZ0sTgqoojOQWgEzRKLNWqIPAR5XDqTo0cNyeeWZJxRjIJ+z0SJjVQsnnroKx8RK1wPNdRw1JD3YHTkrESxyUBYhKsGeYXWSPgoGaqgIUp95yiPNUnU0KCUTRw10akTlVqXKEojKEurP4rFrzg8tJqOoob0+z+zDkNA0UJ0jqs378OP/7g1GLtMDSXII8iYBkw/vbjLb6kZdX3kTmsUljxYtFGsOGLCq0oNaXROtTERxsq20KHKcdQQV38PPALvHAyDwTRqe0c6frHhFdz11K6a20UlNtIY9XDbZ18ZwJ6BYkgjiDu3+GMG21PUl04N0fubGoIWgH5zRJidv3qsBeLsG4oaqgTUUNKHQOdeq0F+GOuZxOVrYDuuaIhSr2YQ5RFUixoifQCIFovV8s1e+z/xoioeAZWYCF50MgQjJTvEf0e58fIKkDGgM1+/RkDX8fZ1O/H9h18Sn7vSBJBELPaoIc8QzPCpodEo6kzal2xU/7Blv7gOE+MRuMiY3uQ9VAy8uDiPQKeGaCy0ieUbgno9gtse3YYf/nFrze2UCqIyNcSDsFba5G9uexLfefAFqVRHWCOoJ1oPAGb7VXb1e0b3K6WGWgB6ZyD5RUnyYCZ5weJAk2N7zkr8EiTN/gTUELb6qpuqHHCSFonR+5GOX6kdNUT6AACMlcPXU1+xdktVSuUVmyxekjGkct1yDaOMT7dE9SyW70fOMlDIGonOn3MunilZoJVX8GTQMknCRysucpYBy1Q1gmJMKCJBDo99YmufVGok/hxUjSB+TGXbRd4yUciYwugB6vMm21Z55a2PE/A8AstgdWcWO26Y5ouC6hEEvYu98FFXGdNQ0cZoyQ5Vuq2314K8/ZwOzxCMaRpB6hG0EPSm0fKEkkQnoJvZWNSQA8bq8wjq6QtbadAjkF8c2RCMxyOg60oRIlH6hjxJJ/EI9g1KhiAi8ct2ZY3Aew1kY9ORs2AZLNIjkP+Ws0zkLU/Qr/VMDJXs0GpSj/KhU8+YtemQou0gnzGFR9CV9zWCGgllQ9J5lipupOekox6NIGsZKGRN9I8FSXPVPIJqE6nJGvMIbJcrxlnWjpTttGiqqPBRGm/ZdlFxgz7fUfkXyaihYJtZbb5HoFND7jTxCBhj/8UY28cYeybm8zcxxgYYY+v9f//crLE0Cr3KpfzARiWF6BAeQUIqSUbR9ld7Rm2KQByvLo0gPDkmgTyWsbKTqPxxFOTxEV1TTSwmOsNg0StevSga6QPtWTOyk1jZDigJ4mll+qk9Z8EyoycgmQrIWYaglmpdR3lhIUecyIXiuFgJVo8Wo4zcnBVoBDnLhMG8e/vIC9249jebQseTz5O2TRI1VE8/gpxloC1rKu+P/LztGyrhb257EsMlG67uEWjPuik8gvreHzkXYazsYMnnf4N/X/1iaDulXpDjCg/Q5cFYRFCFT4fqEWr1eAT6+c5pr2EIJqHoHtBcj+BWABfU2OYRzvky/9+XmziWhkChfp1+Z6CKPzkDyXoSRPHgSVGsBKu9pC+B7D3XMjyyIasnoUz3CERLwjoNAU18jIU1gmhqyJu85nbkIj0C2Yuw3WCVPbMtq1FD4aJzeZ8aIo/gktOPwMffuAQZw4hc5cueVy5jiO/XMoZ9UlkJUfpZJPV53w1WgtXvO51HPmOKUsUZiyHj5xLc/9xe/NfvvT7E9z+3VxXb/XF2FTIo227kylaHPJJa/QiylhGmhqQJ/sltffj1xt14fu+QX9MnrBEQTIPBNGpHUOmwXS6egaGSN45vRFQBlikn21EjmErSPeF+0IfjcqXo3LX3bMIftgRl4msuwDSKq6uQAWNhgV+nhpJoD+NB0wwB5/xhAL3N2v9kgFY0nb7LXXaC/qVJInnkTeptZlOsOMhbJkyTCRpDp6p0qM1equ9ffiDrKzERfG+07IhVcL0eAb3YGdNQhHHA6zuw+k/7lO0HxypgzDME0eGR8s9BEl9XIaPVBJI1Am8MbRnvntLE9dZTFmLFa4/0PIIIb0z1CExhwEo1KDZlYtToGJq0AmoorBGUbEfQOnQeeckjyJoGsqaBis1R9itpbu0ZxaU/Wou71r8SGk9HztI8gmRlqGv1I8hZJgpVPAK6H67r5XJERQ0RhEdQZ4kJx3XFc1XtvlQUashV7jeNU66HVJHyT2yH4+aHX8IvNwTXtlbYNu2f2k62ZU20ZcywR+CohuBA9giS4HWMsQ2MsXsYYyfFbcQY+xhjbC1jbG2zG9TLoBe3I2+B+1EENFklooYU+iP+YYya4Eu2i1zGEB7B7et24A3/troqDy2/LDU1AiXJSt2n43KFR1a/J3kSZUfkE0QJuNUgwiQNJl4Comh+sOZl/O3Kp5TtB8Yq6MhZaM+ZkZqGHjpLk0BX3tJKTMsegff3GX78PdFJJB5bphFp8OVrl88YMP0y4bVWbXLwgd4Mhowbl1aC+sv/7ftfwMXffxRAQEPJGkHGNJCxvDHTGKnk9aB2PwsZE1nL8x6SlKHmSakh20EuE/YIoko200q7UuW5NcahEVCmcDVvPJRQpiyQSCwOWm7K4vZoxYuK6hmRPL2EhoAWl4WMiULWCi2k5KABIFmi2ngwlYbgSQBHcs6XArgBwF1xG3LOb+acL+ecL583b96EHHzT7kE88kJ1o0IrmryUedqeDbyDWogSRHX87vluLP3yb/HHLWoXMuER+C/BnoESBsYqVXloJ+GqDQgeSIOFPYLb1+3An319deTEIJ/TWMUR5ZdpXAOjldjKmvpYTYPBMJh4CWgCHiraoVX/YLGCrnwG+YwZXalRFoudwCPoyFmRGoEnDHp/m9HmRdtQAhoZpIzBauYR5Px7BNQ2vv0KNaTyy2QMaR9ReQR7BovY51dUVQyBH+FkmQwZk3mJUf5+t/eOevvX2nsWsqZXksIOPKPqeQTSz7WoIdPTCOK8REG5+N6AUyXIwTQYLLOxqCHAu07yO6MvcNQaTGooK43TdXkQduy44vyHfbqyTzIEtRYDNA+QR5DPmN610qOG/HE0uww3YcoMAed8kHM+7P/8GwAZxtjcyTr+9x7agqv9EgFxIEPgSCuCthwlHyWghiIEUcCbEGhyemHvEADg1xtV171YcZGXPAKdxx0u2aG0dKVmSx0PpD4BvLx/FP2jldAqElAjZkbLjniA6aW/atVTuOBbj2Bn32jV4ztuEBFC4m9eJNfYsF2dr3VRyJrIx1T61OvVlGwHOctALmNo1UfDHsHMgifYCUMgewRReQSyRmAZMIyEHkHECrkkqCHb34f3eSYis1jumEUGzROLvdc4axqeRmDzkCGQS2sDHqWUtQyFIpuo5vW5jCEmuiiUBTWEmhpBo3kEIkO54ijP90vdI9p2aiSgmhPg/V/2CGzJI6CaVNXGr4Pe4w7fI8hnPUNQK2po2noEjLEFjHk+NWPsDH8syZvzjhMl26kp4PZLhoDqiZBHkCh8NMYjWPbl+/CJ254EAMzvygPwumnJKFYc5DKmEMr0pjhX/GQdPvdztam9nrpfDYGLGmTFfuZnG/CLDa8IAyAXXxPfixGLaR/PvjKIPYNFXPajdVWP77iuJwQyJpJpCiL6xrtW8v2xHReWwWINgU4NUfQKrXoBz0tS8wi878z0PQJabdM4LJNF5xFoUUNEDdV6JPpHK8EKTxOLx4RGEC8WVxxX0H+yWCxTQ1nTm9yp58AOMgTaoiGfNYWwrI8lCvJQqnmb5BEcc0in+JveM4HuAU2KVfMIGEPGqJ1ToSMoXucqi7AtWnc4eeL3tLgI2tENqgPYjqsYiLjjxkHXCAoZE7mMGUnPAtNAI2CMrQTwRwDHMcZ2Msb+mjF2OWPscn+T9wB4hjG2AcB3AFzC642xHAdsp3bcN0VayLHO7XV4BFFJU4T7N+31x+H9XX9Ai34bQuERaDzuC3uHxUsunxOhZkKZ5BHQxPrrp3fjd3/qFp7QcIQhUKghOXy07DWV7x4qoZAxsWn3YNUJw3EhqCHap15bX48Dt0yGQsao2piGfi75MfZZKzAEsmEpSzHjM/1Y7n0haijaI5D/ls+YooF8rUlgsFgR4YKxYrFEDekvv9w4RXgEGUMxBJZGDW3rGVX2TyhkPGqoVAkmtmo6lqoR1BaLTzq0KzhWVjcEQeE/+v/TO/vxzhvXKMluAEUNRVN01UDXbrRi1/AIZO2CRwYH2JIhqFV5OKk2J2sEUQlzcoY5UNvDHy+aVoaac/7+Gp/fCODGZh2/FipubUNArrwchSI0gjryCADgNxt347IfrcXD//ccZRt6wPYPl+G4XPDNpYqDXGfOc4tlQc8Pe+weLgn3kpC0wTigPpDbe71WeWMVx6Ot/M+iBOOKw0XtFyWz2HaEMHncgk6s39GPisORtaL7Lbucw2AQq2kAof678gvsHdeoohEEP9sOFxQFCaKAOtFV7CBChEozhKmh6BBOmsT/+e0n4oyjZou2k7WM7+BYBV2FDPYNlYQxERpBRY0ayvs9ElyXC+pJToIr2nEagRGpEVD7Tca8zOBCxkTGMpTInlJCjyCJWHzSoTPE33SPQO/va7suntk1iKd3DmB3f1HZ1jQwLo1grKxqBC/3qIZA79MQ1SvAkTzJco0s/KQ1vjpz3jNXyBr+O67RgNKCAJjG1NBUw9ZCxaIwIDyC4IUljSBJ+Kj8UHz/4ZewbyjcyF52x7dJD2lJ8wjkFeT+4ZIXTqolvNWjEdAD2ZG3ULIdMRH1jZaFJzRUivIIXLRT3P1YRSpL7WKLv9o6YWFn6NzC++FitUcIrxxVEdEyWGw3MKXEhP/i5iwTWdOUPILge/KkmrUMtGdNlGwXjAUCnRUrFnv7O/f4+Tj5sBkSNVTbI+jKZ5QiakHUkN+f2r9vs9qz4FyN9pHpLKI7vIACTSOQvN2S5nHQpExisWxUq4UR69nAcSjbHjU0rzMn/hZ3X2l17fJggtVzREzDaCxqiCg3SSOY3Z4NBTLQdlk/2spxOJi2dnGcQCOoRSfXmrDpvhwxuwAAWNBVgGWw0DWdNtRQq6PiuDUjf+RKkXrUUCKxOOLmGYb6lMkC3bOvDIqfvaghw88j4MoKcu+gt2oa1A2B4hHU4ioDasjlgdHrH62In6M0gorLkbUM5DMGeqVoiWLFwYv7hpExGZbM6/C2rfLS2K63wvfnMGUClvcZbO9pBLmMN2Hr56eWmPDCR3O+ICo3CRfnIQmvlsGEd1XImPClq9jwUVpA0EpcRA3VML5DRRtdBctftXOlxeGoFD7q5Ut4FJIcmlhxvCKGrssVaiijawS2G6IwSCMgrytnmchaTAk4qK4RBPurdpoU9iwj1iOICGHWjbzJGs8spv3RPud35kKLJ7r+ecsX2d2gYby8jaCGahiCWtMCHe/EQ7vwxBf+D048tCvS0MktS4HUI2ga9FAxHa7LxYrYkWiktnqoocjaJuqTIr98G3cNiJ/1zGK5Ns2eAc8QlGw3xKOL8dcYHh230y9d3DvsTTh9o2WRxRtFDTkOh2UYaMtaIUOwpXsYR85pFyvAasbSdTlMI6CGslI5ZXmf33toC/YNFWE7pBGY4tyVcSkagSs8KqKGPKGY6BTDzxL19mEaTBHvCHEeAV07cttF1FACj6Azn/FLV6gLkVFJLDYZE1Upe4bD9XoqrquIxaYwBAwZi/lisXp96FGUPYKMaSjaQa2EOEK18/Q8Au8Yxy/o9MeoTjNRXctEzSotH8Uw0HAeAe2PjndIV16J3AKC56aQNf2EMje0IHGlUvK0LyOa8axJYdnSs0NeU5Sho/d9ssJHD9pWlUQNyBysjKFSUELXlTjCRsVigl4AjX5fdsRMPCl1xqLwURE15O+rYrvYK9FLQ0VbrPLqoYb0xJZe3/sZGKuIFXGUWGz7lE6baQpxFfBc8D2DRRwzv0NMkFUTefwJj669HH1DeKl7BF+7dzNmFDKwXY42wxCTyljFUSgH+XQdF0H4qFQShFbRHbmMQrOYjAmDKOsU3kQZcQ00Q5CYGhqz0ZW3YBmeR1COmAgd14uUIUPQOxJc46B7VuAR5C0jKDHhU0PDRTv2+aTrV8gY4FwtbZDUI6iuEQQewY//+kz877N78MeX1GDAoFlNsCNa0ISpIQbLMBouajhathWP4Mntfcp2trTAs12PLi5kTbEYAqI9gqwVDlpgLDklS13lvHMM1xPTxeIDtsREq0Mk9MRYcL3kdBA1VA81FLFf6Xu9I14+gWUwLD9yFjbuGkDZDlavcmgg8bclx8XegUBQk11dtRRzMq6SKlbu9yd1lwcvUZRGYLsuLJNhXmdOiVoaLTvY0TuKxXPbxeRb0yMwWeARWGbIIFNtHsr4zBhMCjGNjrumMZbsIHwU8O4nTTKdeUvUGmLMW9GLKA7JuMQVnROUkk8N0TtdbRLg3MvW7ipk/Mqi6qo9TA15q0WVGiJxNcicVj2CsEagg86PxGJRZiNrVtcIpN3FTUqu6xk3uv/zOnP44GuPDBn4IGpIMoRkCHRqKCaPYLBYweJ//DX+54kdkWOhe1GUNIL5XTkMFW3tWQlW3hW/EKFObdF5yWPX6SPToDDXyOEIVMQiIrgmUR5BSCOoM2qqXhy0hiBoOxl9genGZ00DrkIN1eERRLww8vF6R8qoOF6XqVMXzULJdrF5z6DHH3MolSWJQ63YLvYMBoZAFhMVjSBh+Ogsf+W5d6gY2iaKGrJ90XZ+Z05MUjnLwL7BIioOx/zOvFihVgv5s10uEspoH/qEoRgCP1qJVuxxKfmAN2kRtUYvUtl2BfXRmbdENyoytHLtFwKt3HXQ3zKG6hFUu+QjZQcuhxCLbUftXDdWoYQy7zypPHEUNeQ4kkZgyeGjTOQRxOkzeb/Ud94PHyW0Za06NIIa74xGrViaga/qEcRqBOrY6Lpc80svKfQnj27DSf98L4p+JVca4pivEZgGw+x2z7jKz7VCDbnegoPKoRNkj4Dm66y2DTXjqfXekeZkSdee6onJoHHRtUub1zcJ9BDGNcWmG5/PGEq7yaDERAKNoEadmv3DJdGA/NRFMwF4lRmLEclClH1b9sVimkBlwbhahuPd63fhL777e2kc3ucU175nIMoQRNMilmFgfmde/G12e1YYp7kdWWEIqglrDvcoOYMFhiDsEQThu47LkTHjSz7r1UeFR2AFNBV9pzNviTBcuo7kEajUkBe6+/3fbcHGnYF+Q89MSCyu4oUNSgUMM6aBissjPQKihrKWgc68qsOI0tWu591YBoNlBj2LM5Yhxhz3fNL5yUYS8CjPkh1fLl3+c9xpBlVk1UlSv69CI1CaHIUFfUDyCLTzkfMvOOf44l3PYKTsYM9AUU169DWCvGWIMGG1GF7gEZVtV5T2luG64Xaz+jbUMrR2Vzl1gqef4zwCy4+aqjd8tl7UNASMsXbGmCH9bjDG2po6qklArWzKwBCYilgsqo8m0gjCf5NXar0jZVG2d+GMPOZ35vD0zgExYeUkt78oFUvbO1jE4jneLZC5TD2EUsbTOwfw5PZ+sQ2dzxyfgkhqCCixa74UHjirLSsmh7kduWAVXosakjyCrBUWi6mGi+1H13gegbfvkCHQsqopsSmKGhJVN10uuNoOiuuWxWJ/dX3dvZtxp9T/tqKt1owEqzby3LoKGdHwRl4UyGIxOUZzO3JqQTNJIyhVXDGpU/hoxjD8McdTQ3lFLA6ud1vWAufxomSS8FG99zRB9/ToGHpvCyB8Xw1Ra0g9prydXKerb7QcqodFWfpRhoAm2LxlCgOl57PYLg/lWOjnmDUNGKy2J07nLH8/ivqiZ4nE8gTTzbiQxCN4AIA88bcBuL85w5k8VCIeRgB4emc/vnX/88IQFLKmzxF6241bLJa+1zNcRtn2wtUYYzh8VgH7hkqCwshLbj89+GXbixo61k/hVx9qeTJUj0uip1wzBQh6psp0E+CVXdCzPOl7lsFwSFfgEVC7PfqZJpiqHoEbFJ0DfI9A0+x1jYDyCIDwytHhajenop/YJBulkiQWe7HrrjA+cvgoIWMEfXeHS2rlUMtgQlQX1UereARkVLvyGT8slStiulx9lMY0uz2LnoiWm7bD/e5kQb4DoPYjkJ9PefUpawQU3QNA5IbECfzyqcWdJmUxL5CeDSDsERCU8NGYcuaWLxaHS3IH3/3cnUGpFa9XtXxdbeERUCmRfh3qlgAAIABJREFUgQgvOp8xxT3QV/syI0CgZ03WZ8yIlb0Oui91eQSsBTwCAHkqDgcA/s/TxiPQJ/RfP70b37r/BbG6KWRM5UEINILa1FDU6kD+Xo/kEQDeyrp3pKyGBpq0Ag5c4cGijaPntQNQqSE1fFQ99nApoJaAYJKe7XPRuzWP4LCZhWiNwOfq53WpHgFhTntOvCRVS2b7hoAWpVnLEDQRoW+kIo4pwkezVJguTA2RAZJXzDkr7BF0Si0d9TaPuljcH5FTYfteEaEeaqirELTAVMNHg4Qyug6z27MqNUQagUt5EkEGNEB5BEGJCXpWleQuETVkIiNlfbflKCw6zhDU1gie8iNyiOYkmDGzjExfxYnFhq8R6CtmebttPaP48OsXAwB6Ryo1PQKl+J/jZbjnrCAyKWQIIsJx6doRtZqxvAY6STsDZmSNIKLxDp2DaZChqLrbcSOJIRhhjL2GfmGMnQZgrHlDmhzoRdwINMHQajifMb1G1g55CNVfGBm1wkd7R0oo246YOGe2eZmPUUKgKPPsTyiz2rLIWkZisZjKEMvp/abBRMPz/cMlGAyCljh0ZiGm6JwLyzQUaoi8Csa8n8mwVTUEXM0sjqSGyCPw+8eahiGouRHNW3FcrmRhUvioqhEEYjEAISICUhGwrEoN0T2UvaOy7QqhGICYuKvRAnSfgjyCYHHRkbOUxjS0v7kdWewfVhPKvPNzfUOnegRB9VGP6yZPbb60QhcJZRlDEYs7cuQRREcOJak19NT2fiya3SYingg6NURQooYENRStEcRRQ4WMib94zWH49JuPBeDRiWphxEAviqKGPKPu6SyBRxAvFhPo2nXmLeQzhu8RoGYDHT3iDIj2COgaG4zqcTXXEiTJI/gUgJ8xxl4BwAAsAHBxU0c1CajEeASUgUkvPnkEQe0P5icaNRY1VHaCF61nuAyOYHUxqy2DvtFKZGgg/Y36zeYzJrryGaXPrl54TcawZggqDheRDh05C8MlGx05C6bJ0D9awaEz8nh0S7gYrO14E65MDZEhmN2W9cLokojFrrfyDcRiMzRh0MpNjvChSVz3VlzOlfwFirqSo4ZksRjwrqmIGoqhhghqXLmLjMbxeucUfa73PrMbW/Z55Te68pZogUnP0IxCRqxGXZcLimx2exZ9o2WR6yKHj3qGTtMI/MY0tK9zjpsvPIcNO/phsGAlWtDE4rYaC5wk1NBT2/tx5tGzQ3+PpYakHVWNGoqIqqEoul9ceRZeNd/LZM+YDL26RlB2/PpH8RqB5T+zwiPQw0c5V95bIOD427IWOvMZZE0DRcZC7/yW7mFcf9/z+Ob7lnllLCI9gviEMsvwS9FPddQQ5/wJAMcDuALA5QBO4JxXrzF8ACBKsAKAUZ9CodVwIWsq1T8twxCFvWohijOWO5v1j1VEbRbAC+UcqzhKQ5zAI3D9cQWfdRUshRqqlvRDK87AEASrWpkWmdWWRWfewoxCBsNlO3QOtIKa3ZaFZTAYLPg+rUCTiMU0scttFkPlNwQn7k2alslEsS49x0E2BOQtyG0ky46LvpEyChlTCMNjFUcckxLKdLGYMFxU6QSZ46XNol7W0bKNK257Ejf9bos4DomfdC9mtmUUsTighnJwXC68CfmZLUoeAVFiVHSOhnH4rAK+/p6l6PI7sFlmkHxGmcUE0gjiDEEtj2D3wBj2DBZx6hEzQ5/p4aMEJbOY8mSk41OOR1Q0TklaLDHm6TWz2rIhj4DyCPKWISKlBrWoIXnxAoSpoUiPwAq0FooEMwwWel8ee6kXv356N3YPeCQK0WEZo7ohkMViI+LziUaSqKG/AdDOOX+Gc/4MgA7G2CeaOqomg/OgBLE+WZFHQBNuQdMEvIcmWVncWmLxWNkR4aNAUBefhFsvs5gp36NJoeCvcAa1CYqgP5B0XrInRKtaoofacxZmtmXQlc+gM5/xRNKI5jeWL/LO7cihLWuJa0SUQKARqGN4fu8Q/vrWJ1CyHc8j0KghACF6CAiagVh+1JDli7j6uOgFDurqGEIQLdsuekbKipg9VpY8gkhqKBiLfDzPm4qghiLu977BkojGyfviNZVVlg3BmEQN0TWgekP7hz2vgJ4nSigLooZUjYBAYxRagv/sAkEZagJpBEnE4qjF6dN+eO2yRbNCn8V5BFGGQPYIyEO0Ijh08gjk1TtpKvJ9GC3bXiVf/1rNKGRCARZeIl4wRj1qKCp8lK5dPmuiM58RTIG+GKDz0usr6dRQXB4B9eyYckMA4DLOeT/9wjnvA3BZ84bUfCjNKDRDIDQC/8WnBJyy8Ai8cgRR3bt0RJYwlvZTrDgo+wllQCDcUiin5xGotyighgyfGor2CPQHklbJoimIE4irXf5quC1r4rCZBRw6My/oE73MRMUJIm0O6cohnzHFi0OhqHHU0CMv7McDm/dh70BJ1NSR8wiAaD45EIu96KrOvBWihhweGBOZ65Wpof3DJSW8dawSnEtXVB6BdO2HSzZ+/+J+fO7nT4vsakI1sbhbivqh65zxi9nRMzWzkMVo2QbnXskTugQkwveNlpWYe8fPI6CxygllsoGin2UjS3/L+5nFhI6ahiAImY30CPxS3EfMKoQ+i9cIwtSQHDVEBiRqxSx7BIRZbVk/aiisEeT9c9UNAYUl1/QItHmCtilkDLz26NlYvng2jCqidtCMJ6wRRHoEsiGYBLE4iUZgMsYYNY1hjJkAsjW+09KQVyL6qpUmzEFBDal1c0yDYVZ7RonmiANNxjnLCBXa6sh7DavlyBZqkPKKX5NdziwmyB5BVyGjlK6WHxb9wRrVo4b8xDAg4Mzbsxa+8q6TUXFdPP5yL4BwLoEjRefM68yjb7QiXsa5GjWk02dUgpuSuXJW2CMwDACaXkkZnzThdeYzIQPFJWqI9BA1fNTB/uEyDpsZZD6XKk5ghNs9fWOuFAorv6yjZQf3PLMbKx/fgQtPXqDQHWTMoqihfYOSIfA9L8tQM4u7Cl44q6dtBNQQbT9UrCiTJlFD9NxccPJCAB5fLdNZWeERBKIynZOXWSznEdQSi73/x2XPdg+XYBlMiSAjmMq1CrwLtYUoJZRFeQTeivkPL+5HLmPitCNnBTqaJOzObs9i855BIawazNsf5zzWI6BQYEsxBGGPQDeQWWEITHzuwhMAAKs37wt5hbohEFFD0iIjKiqKrjHl2rRC+Oi9AFYxxs5jjJ0HYCWAe5o6qiZDfqn0WkPkEQiNIKNyp5bhpar3xRiC3z67B/94x9MAgslYLlsgl7MeLTtq+Gi79+I/t9srRz2vMxfiV8kQ5DImuvKW6ubGhPhxzgVdUpY8gqxGDbXlTMxqz2J+Z15w5lHNvkmcvPyNR+OzFxwvrtFc4RFE5xGQIaA6P3rUEBC9eqSSG3KETzUDRUZP9wh6hkuY054Tk78cNTSnI4d7rvozvPWUhWKf+rWnOPnhkh0S+4BoaqhbKt1BXgdpTDQRzvIpwZGSrZwnbT8wVlGMqtyBDQBeNb8DV557jHcdZWrICoR4wNMIspJGoGQW1xSLZY8g/Pm+Qc/biqKByLAxphZbi8rCLVa8nhBZKWKOVszX3bsZ37r/eQAQvSNkSmdWuxdsQZNqe87yxWLVI5DDRylBUr5uSTQCQbFJ73a16Cb5vZPzZ7zvGaK8uH5tvKJ7DE0uNZTIEHwWwIPwhOLLAWwEEPb/DiDIk39ILBaGIFh5A8GNNA2GOe1ZJeNTxiMv7Md/P7EDJdsRL48sQMohg2MVR9QaAgIq4E97BrFwRh5tWS+KR4ZMDbVl1W5djjJZBN8pSu0IZbFYj6GnyQAIvARdlKXibwCwfPFsvO3VC8XLIGKqiRrSPYJhyRBQ+ChTJyt6QWTjSS8T7dejhqIMgff5qBT9QRNfyXbRO1LG3E5JI6g4yqr/2EM6lQleXiUCwMv7Pe9rsGhHU0NRHsGQt1J+9eEzsGBGXmwvi8WH+XTKvqESHCmzmKJcBsdsxXOtuKpYLCOKGpI9Agrv7fIFTkKbCB+trhGYBovMI+geLin5CjLo+njVZoO/xzV3sgymBA/QinmkZCsZyHkr6B0BeNRq/2g58LTyGSmPwPe6I6ghy1A7qulRQ5EJZVZAscnnqXtL5OmUHRcfvfUJ3PzIS6EFBj1LslcgPAKjRcJHOecuY+wxAEsAvA/AXAB3NHVUTYbiEYQ0AjV8NC+5zJRNqif6yKAHZnd/UUzGBcUj8P7YnjNFSGOQR+C9+C6HSBjTHxrZQMlNVwAoqwZ5UtJj4GkcwcRKbfOCcXbmKExTm3AdHqKr5nfmwBhw1FxvzHEJZapH4K0U48TiGYUgkoYMQVAXKIOdfWq/ZpcHHs6oiBoKqKHuoRJslysewZjkEURBv/bUknLIbzlJ0MXi/1rzMnpGSviHtxyP7iFvpfyDD50u9meZqli8aLaXn7lnsOhlFjM1ksnrBKdpBFJCmYxIQ5AJru07lh6K5UfO9gXOBjwC04isqrtvsISFM/LhDxDcN0My/EB8vS4KyBCZ2/6KebTsoJAN8g10Qzir3St1Qu9mR85C91DJK03iX6u2nLZ48j3TPztmrvibfl3lDmUECkIoaIZAp3hksfjBzfvEuKKuT1T4t/AIpkosZowdyxi7mjG2GcANALYDAOf8HL/f8AELVSMIfnZdHk4oswKPQE79H9V6oRKIY93VPyYmhjZppS08gnwQ00yTVc4yRRgfTar6REXPQ94vEeDyQPCWXUt51RbVhaoii8UF8ggkQ+CPLyQWa1m1AHDknHY8+rnzcObRcwD49WEMFksNlW0uGtPIJSaAgBqaIU20dJ1lD0Yvf+HywAARDSaHj9IkPkcqilesuKHJXkZG8wjokg4WbSXiRn+RV/9pHx7Y5L30+4a8lfK8zpyo9JoxPLGYnj1hCAaKIr8C8IxjIWNisFhRwo6pJ7Me3QJAEYBpjPR/ipdf5NepUovOVReLubRCjdMIankEBlMjiOLqdVlGEF0FBCvm4aLmEWjnT/ks9JwdMiOPsuNiTPIIClIpCSDwjC3TwOmLZ/nXQH2vbZeHmvbIGgHBiIju0akh+XyC8yWPQGIq/P1Qrs1URg1tBnAugLdzzs/mnN+AkIx3YCJKLN7eM6rQPUNF21uZSJmpdMPmiKYhYa+AXqRdfWNiVX74rIJYYQuxOBfUzJEnHBKMj57rJcnoUUOEQsYUDzdN7rIXID84tTwCETUkrVQ6YhK3HJdHjukQrb6MnmvhuFw0WbGF+GuIEhM0YTNNKAUC91pO/tI9FVemhspBJzKaBKkp+ryOnMIr62UtZOgvLGGoWFGpISEWQxyfrn/3UEnJwqb9ymLxoTMLYMwzBC4Psru96+DpQDKdWfb1BZ3LBhAdPpoJNAJ1W4kaqpFHQI9TlEbguBw91QyBVJNJvt5xlTopikcWiwEvlJmeBcoWlkHUKlGQR84OKuHI5bfHfAGZxk738t/esxTLj5yFM4+ao517hEdAhiBbixoKR0PpWlKUR0DbkMA/lYbgLwDsBrCaMfYfvlAc/9YcQJDdN1qVvOHfVuM9N/1B/H2oWBGxwYDqEcxKYAh29o+J43zhbSfgtsvO9Paj9T4GVHGKBOOj5kV7BAS5njy9vHEdyuS6PHLhMstUJ13ZI2jPmjBYmBqSw0erIWuptfx7R8piAqk4nmZhSKJZQA1520R5BKagsjyPQPZ6HIkakhPKyDuhhJ45HTlNB6jiEVBUlebKl2xXmVTJLtLLO1p2xL2PWikT513yAwUypoF5HTnsGSgqRefoOngaQTARkRge6REo1JDqbeneT7RHEL3WkzlrXSPoGSnB5QgZPALdYzlvBIhvCmUZTPEI6P+cq/kG+vkTtUptV4+cExgCWjTRd+RwTgp+WDy3Hbdf8XosnKkuakgsli9fLkYjCHsEaiIooGap0/nScQiOrBGw+lt11otYQ8A5v4tzfgm8rOLV8EpNzGeMfY8x9uamjqrJiKOGKCoECNx/WpWUneDlJ48gSjAW1FBfQA152ayaR5APJhf5hZwlPIJojYCgl08ApK5GUnYpEO0RlBWNgJqyBGNiLCg9IUOOzqmGjGkoNEO31NaybHvJUSaDJBYH1JDBVB6VisWRSN2Zz8CRaDwal6fhBIaP9pm1DLzi52bM6cgq19uM8biAwEgcEsF9y+UndLG4WHFEK9Se4SiPwCs1ULZd5Px7sGBGHnsGVWoI8Ly1QS18NKiDVV0sDihHVX+J2rZ2ZnFwrvqql0Jk4z2C4LvyucVl55tCLPZ+l9+BoKWlKzwdAnH7I/79XzynXXwmym9r/SzksORgvMHvjAUJZfLiTURfyYYggsIhwyWXggmfr7cvXSMwmPcexuVuTCRqRg1xzkc45z/lnL8DwOEAnoIXSXTAQhWLeaTb5WX8Bu0TdY0AUPvJEohL3NU/GkoK8Y4XRA0RdGooYzIcPqtNfFcHNXGRC6oBwYOU0VxJWkHSeQB+9I9GDVGJbUJU4py8gqqGnKVSQ3JiFYWPRmUWGwbzk9SCY1BDc71AnGykqB6PZbDAI8gE0Vi0opvll8YgRCVAEcjwR4mgVgS9JPfJtR0uVsrzNNrMMhkqrtczgM57QVdeUEPyLe/ys8flazkiFUSsNq6ozGIZskFPohEw5p2r/rrQvZ3XWUMsZkypRBpHDZGWQRSkKX2JaB0vakh9Dul8aJKf1Z4V3py+gqeVul4uxDt+sN+8ZYqEMpkGCmoNJQsfrZaAKrqQaYZAFtlbqlUl57yPc34z5/y8Zg1oMqB7BHFhbF5Cl/dzWdEIvJVP70j45gqNoH8sqCAorYT0BjeA6hG87ZSF+Ouzjw4JZTJEBUnNEHjJSOHaJHKlTiEW28HK/rBZBeQzhrKCAqLDNCkBpxYyplqYT/YIyBBQqQogiMIwDeY3nQ9eMMoipWsRVXiOJlCDMUkj8PbxkbMWi230LNITD+2KPwdJEwqH/MXnERA1JFbKWjXOjBF4BBnNI3D9zm0EyhWRabbhchAVpSMb4RHQ/0MagfR9Sl6sphEYzPO49Cmp2z/PmtQQ06OGYjwCk/llyb3f5WvPufe8l+ywWC6ixvzrkzGZCM0NGvIEEWOAqhEE4w1+zmWMwCOQ3tljDunABSctwGuOnCV9LxzvT4YgqqS7ON8oQyAlFraERzAdoZSYcHmstZVr5Jckbpxqyj/8fDe+9MtnFc6UqKHd/cWgPpEUJln2oz9kj0B+eS84eQH+8cLjxe9Rky65o7pGQOnyuvs+Ug5TQyNlW1BBczty2HjNW0TUD6EzbylRQ67rJXZV49UJVA6ZEDIEoTyCgBrKS0I4EFBDliiS54dVSmOj/clZmrTPD772SGVs8gR44sJ4Q0ATZ0feUqg8QKOGtMzisbID23GFEZX1Dm+/TGQSC49gRh4DYxWMlGyFPiGNwI7QCBKHj8ZQQ3rkU9Y0qmoEZGj1SSnwCGqIxQaUuP94j8AQlXGjxl2sOF79IL1LmDAEQbgxedZBSQiVGqpEeLiyR5CzgiZC8uq/K5/BTStOU4IkLCNcdC7QCIJntTMfHT6qaASSpxIVljrRSFJiYtpB9gDKthtvCEyp6Ju0emOMYVZ7Fr97vhu/e74bn3nzcSHX2na5EChrUkMRKztCFA1DtIkeNeS6QWlnxRBEaAS9I2VBcQHhUEkao0zpiDopicXiGI3A4WKsUdSQ7hHofV4Dj0CjhpgqRorCYBkT//upN4hVoHyuxy+oZgi8fbXnLHTmLSUjVRWLA4+AWmB6//xyAjHhgqNlR5w30U+7B4o4YlYgcnYVMhgqVpRWiSNVPIJIsVjrW6BvS/kxuYxR1SNgvn4TEouHy2jPmpFUFaAmlMn3Jy581DSYR8tqUUOEYsWNFIvpfgfhxgYO9z0Cep5IVwg8Alcx6oDmEVjUmMpRDEFUtFmUqKtTQzd98DScd8L80PnSWAiO5BmaEQZmonFQegRK3RY3nhrKWoFYXLLV5KPZUk0V+eUpVVyRqUtRRbJIFkUN5SImYYL8EtCzlxcegSrwCbqFqUWqRsoOMqZXubPseC/RaNlRDEEU9Jo+on1elfESdLG4f6wsBMmKTf2Cg+uS1T0CMgzS+yY0goiCeHqjm5xlKKvP4xZ0YplfIlmemGXeN3QO1M84a6Ejl1GoD91wmoZXeZJWo1QoDwhfL/p9tBzkI9DKcvdAUQ0fzXt1iAYkI0Rx8HrfXO9vYUMY9C2Ijhoig5fV7pkMLnsE2iZyAbwo0HEZ06OG4jWCI2e3xepkXrZwOKEs2iPwDYGURwAARek+6fuXPYKsZYiEMjmYIkq7M41waOiYoIa8Z7UjZ4WenaioIVfSCMxJiBo6KD0CPY8g7iJnzIDDLlVcxaWTJ1GZ6yzZji+y2kHYI1PDUAFVmI16oQnyA9eWMTFSDl66UNQQJwFWfSBHSjbac5bgOinaaU5NQ6BqBGQwE3kEWh5BseJgRiGDkbJXVoOahdDqMid5BFmTiXPskmrD6JnQikYgPIJwWJ+OKO8nCrJHMLs9g7asie5hr6y0vso3feNLk7TjBg3kw2Jk2CMg3QlQV5uU7Ldf8sxGqxiCatRQ3AREBk/PVJdBxfBYBDUkl1KPgkzxyJeiWtTQl991kjROdd/UbCbOIxgTHgETyXrkgQux2KaooQiNgAX/9yrFeu+NKgxHj1uv9xU0lKI+IuEvCmpIo6z1WkvNxEHpESh1Wxw39EASpysXvipr8fMXn34EjvE7Iykege2Kh44eSDleno5FDVaA6hOT2nicHmZVBKTuSUEfYJ0actCetZC1TJQdV8RZz6phCPTELbkQVi3oeQSjZUfkK3iGwBXRT/K5mIbnvtPkRXqAfNxIaogH/W2B6BdOjM2/3lee86qq50CTfUfOwjXvOAn/etEpYkWpT06G4U2WJFRSe01vP3p0i79yLQXlRWQNQr6+dP5yqDIdo6YhILHYjNYIGPPj9aV8g1LM5EzX12Dhpke1DAEZNtljAzzPMAqmT1Ux6XsyyCPQqTHve8Fq3zQYzjvhENz0wdfglMO8WkJ0/ygSzYnQCMhzsQwvWKTs573IHkEUNWQahjJhU7FEIHhWo3QdMkR6z3H5uh2wYjFj7L8YY/sYY8/EfM4YY99hjL3IGHta7ovcbMhUUMVRNQLGglWYHj4qT8p/fuphuPJcbyKR3emy7YqXuijVuxdag3+suDwCHfJLQF5EnFgcxNKrKxPPI/Am17Ltonc0mUfQlc+g7K/eAbmWehJqSI1AkQ3BaNkB536kilZ0ri1joSufESs32QsTK3T/haQGPnTunhjp/b78yHDLRIJhMLx87Vvx936f2zjQZN+es3DMIZ04bkGnuPbRHgEXxp9zqWKtvi15BBVb3PsOJYcj2JYWJb1S7+IRXyzORtyHKI3A8IXgKE8uK4VpZi0zVEqhWHHwd6vWY0fvqAgfdVwXv3r6FeF1yl32oqCUmJDzCGJWuWGqJiwWR9FRjHnnSUUHyfBccPJCYVSi8gh0jQCAaJFpGoYwLLIXH0kNMXUyl7OJg6rBUR6B4Y+lSvjoAewR3ArggiqfXwjgGP/fxwB8r4ljUaA2plGpofasJdLRlYQyO5xRG4ra8YVC8giKFUdJr/eOHdAFenhfFOSVJz3EOjWkho+ykLhEEUI0OVP+Qy2NoEMrPFcPNaSXmBgrO2jPmsiYTMn8lTl9APjXvzgZ//T2EzDTnwBlXl7ElRsM5x0/H7f+YSse3LwXQECL7fYTx9580iFVxyevOONw3IJOvP+MRXjdkiCaSjSDCYUc+oZASnITVVMN3SPwDUEpoIbkSUalhsIeAU0wUV6PPCFntOiXKAPuNbMJ7oEe0rmlexh3PrULj77UIzyCtdv6cOVPn8LjW72eFXIp9SjQ+cg9qoFqtYY0QxCqwFsB59H0X9Y0xD2Iek7pmtE1jNIIgKDYm8k8gw3U9gj0sO2SZAhozokS+KPyCGzJEERFI000mmYIOOcPA+itssm7APyIe3gUwEzG2MIq208Y6AE0mPcQyx5CWzYIXZQbw8iNXAh61A79P/AIHBGBQP+nydE0WOzqUoZchrpd4zn1PAJ6qD2uMthH32gZs9oyggPuGSaPIDrcjyBTMDv7RkX1xKTUkDypjApjZIjS1rmMERKLXzW/E0fOacc5x8/HHVe8HkvmdQTXQjrut99/KpbMa8f/b+/No+So7kP/z62qXmffNdoXBJIQEkgCZMCYxQYM2GBjAnhP7GDn2bETn7zE20sw8TvYyXt23u/Z8TPeYmMnOCZe5AVjVoNAgFgkQBJCCxrty2ikWXutvr8/qm51dfUyPaPuaTFdn3N0NFNTXX2r6lZ973f/p99vB5QzM/v3y5fkRmZMhnBA5653n5MjMJVz2TsXlPruznaOefIfFOqzY8msacjQNeclVdg05PYR2KYhvbiZwZ2jAda1LqgRGFrWWWxoOS8vyGbEJuyEPCGybULHXD0uyvURuM+t2LutlPMW4ITtMyqYR2FkHd6F5qmqJpzVCPJ9BOqzhq0tKcGSEzVURItwm3BinmsJhYVXNnw0twDmVDqLa+kjmAXsc/2+396WhxDidiHEc0KI544dO3bKX6xU0mjQyInuAOtlq8wU7jwCt6qm8EbtKLW6KeQyDXk0AndfAzWxCk1ohfvhVft7BUGOs9hO+nFPyKNDCbqbws7LeWA0ia4JxwRWDHcF0u8+8Tpf+IVl5SunxETQk0cQS5pOw/SReDb80asRKHRNsHpeW84q1v29jSGDty/vZfuRYYbjKbtkRf4LtNKMZxoay9EICpuG1O+xlOlpF2mN2T3N1D067jINqTyCUj4Cr1+iLRp0otm8+6sXbSGNQJk0rEYwuc5ep1zJOKYhNYc1IQq+QPP3z58Lbk7GrGtRUCNwXZNCxRGVtu8IgiK1s5RGoGlZ57w75LtQAyVDz31hx1P5Gs9kNIKpCB99Q0S+NlBEAAAgAElEQVQNSSnvBu4GWLNmzSlfEeWkigR1J+5bEQ1mHZXuPALIf6C9UTtqJdLoKuDl9RGkHG1EuGz944feQdY2nucsVqYhe3Wji+zEMTOS46NJuppCBI9aL2dLQwiOaxrJmoZSOaaJckpMeE1DYykrDjuga05pCHdhsWIrSvcL1/vArp7XhpSwed+gU8Tuib+9PGflVmkcZ7HnxafZGoG7NHmsiGnIm7CkaAzp9I/kmh2UMHYXOFQ28MKCQOT8r/j+h8/PS2SC3DkeMjSOj+S+vNxNXLw2fjXfE2amoJBxPufWCEpMuaCu5QVlQP5zN1hCI8jpHFfgy1SiWjyVIZY0OTGWortAaQwlCAwtu3BxX79Cj4Amcl/YhcrUF3IWuxPKjg7H6W4KOz291d+nc/joAWCO6/fZ9raqo1SwaFC3wkdVH1Fd5GRHBozc2ijFqjeqqB3lVHU7i9UDKeyVulsjUCuagFH86XCvPNQLLuINH3XKUGeTdtTqYmA0iZmRdDeHckxD4zmKIbdL2cmx7IuokHPNS6GooUjQ6pM74vIRXHtOr60dFZ6K7pemd4V37txWhIDn+iwLpC4Ec1ylh6uBMgfm5REU0Ai8pTEU7t87XeUn1Lxxv2x1TdAUMhxzWjigOSvNQi9CISybv1dIFLsuQVe+RciOKnMz5BIEwmPjd0qaFygJ7UbNYa8g8RIJ6iRjBYrAeX4/MVauRpD/XcJegMVSJrv7RwByzI/u7zRsIalKejS5I9gKRg3lBmlkExjFOD4Ca9v6Hf189IfP8cTfXp5jgXhDRw2VwTrgg3b00FpgUEp5aCq+WN2USEC3w0et379+y7n8r5tXujQC3fNQ5l4ur7PYqxF4O2DpQjgPmi6EY28upVZbdYqsn1U7wXDRqKGMU9dILSBURm9XY8iKCrFNQ+M5iiFrXhmOp3OyasvxEbhLTKi2jNGAQcDINQ0t6Gzg429ZVPQ47pem94XaHA6wuLuR5/acAHJNKtWiqGlIs/II3E2ACmUyez87ozkrCJTG511tunszuKtdFteitJJzyruvemFa9nWPj8AVomv5CLJ/c/vGSjqLHT9ZadOQWugUixpSf1c+gvHKcBebp+GAZgmCY1br0UXdDXn7qNwfXRNO5dXmIiG+Cm8DGaUROOHoulbYt2BvO3AihpmR9I8k8gTBG1YjEEL8B3AZ0CmE2A/8AxAAkFL+P+B3wLXATmAM+NNqjcWL8glEgnpOZnFPc5jOxlCOjyB3RVpYI0h4fQT2hPGWFNa17MpA07ITu9RDZH2vlpPZqExDhm4V5lIPb7aQW9ZHcNRunt7dHLKSvNIZhlMmS0sUW1O4m9Mou6z1vRNzFquXYzSoY2jCebkUUpO9uF+ahVZ4q+a28atNB4HCDrxKU8xZrK55oaihUtUt3bVq1ALCu2pW80kIdc1SdiP4wucb0LWSZUvcBA3NmSsqvNjNUI5pqLBGMG74qMtPVnQlnZEus1thjaAhZJAyM45pqGDUlOu8C32X9TmdeMpk17ERhCCv2KL6TkPPdW43hAyr6J4sPNe8LSXV/W8OB+gfSRbVmtT5qtIhMbuxkVsQVDuhrGqCQEp52zh/l8AnqvX9pUiZVgSElf2aDR/1Oi6DhpazOvPaHL3OWsc0FMpPglI/JwqYhsYTBLomwMw3DanPZlfe2QqP7g5ZAF2NYYKGpZEMjE3MNDQYS3HSVWm1WNc0N0E7VFW6Xo5h20fgLRNd+txdgrjAy2Z2W8RZeZejqZwqRV9WnjwCgFiqcPSK+wXu7nVQyDQE2RVlQHP5VHStqI8noGtlZ0+3NwQdu7Y74kaRJwhch80RBGVEDXkb0yiCukYsYzoab7EicJGATjygO4uSQgsJVa5FiOILg6wgGGVOW7RoJI+uaTnCJBLUCdiLssIJZV5BYC8M7ftXbL6ra6Kek1jKxJSuRDx7bv39r17hokUdXLO88sGVbwhncaWIp0ze9a9P0RjSMXSrsctIIu1oCMqpVyh8FEr5CDymIbdTya0RuH7OdRaPpxHYKyJbI3A35AgZetZZbNfbUY5LsHrmglUZUsVYnxxLlWUaCuga7Q1BDp2MOzZq93jG+yxYDjBlN48GdIKGltc4pvRxSmsEDeNEclSacBHTkKbl1hoC68FWCX5u3AJthksjaHA0gtzvVKahgC5yQj2LEdRF2YLgn25a4ZSVdkd6jSbSjCTSOXX0VUKZwt3kqLRpyOUjKBLCGkuZRAPW+RfzEShBcKKERqD8baXmaCSgE09lODw4xsKufG1AfWdAFzmLv0hAx9AFSbPwXHM/d5A1DSpBXkwDVsdSDXXiKRPT1TBHt6ORfvx0H83hgC8ITpVjwwm2HRpCCOulamjCDh/NDfNTUTzuhDIoULTLZaPfeXTEibBwh5nlNDDxaAflmobUZIyGimgEqv1kRrp8BFmNoClkWI5aQ3NMReVoBGAldL12dDhnWzmZxeqcUmYmKwhsjUBRjmnIrX0UWk26BcEUyIHieQR2xIjbNJRImwXNaO5t7uAEFXbsfVkqX41yXkLpa2foWk7v4lK4y4yEAlmN4Mu/3cpTu47T44qoUbWGFI6PIJ0pGfnmrplT6P2s5kp4HB9BOKgTSescOGFV9S0UHVasnIabSEBnNJFmd/9ITrKgG5Xz4NUIstpN4fMsbBpSC7jxNIK0/bls4yawfYtOjbLqvLLrShCoiSvtmvoqxDFbE8Z+yJzIkFznljcM0F3t8B3/dz1LepsAa4IqW2IxQaKqbEL5GoE3j0B9NuEOH9XyTUNdtkPSHcnT3Vy4m5SXGS1hNr6emxdYrrMYrJdEzM7MjNiZxc7Yy9AIcjpuFXj63P2Ep9I0VNhZLJ3QTrA0gkJjdm/LaRdpn4s3ZlzlEgR0Lau1lrh2gQloBG6Cuo6ZsRZG63f2s28glqMBWFE/2f3LNQ25M4sLraTV/G9whGwxjUAjbncMEwKnOqmbbGnt4uMJBTS2Hx4mnsoU1wiEIKDlJuFFAtmFTEGNwA7SsLq5Ccc0NJ5GkPURZE1DmUz2vN1j8HYRrBS1jBqactyOMKv5hRIEypab+5AFDT33RV4kj2AwliKWMnm9f9T5vJrcbkGS81BpVk9gFZlQCvV3VajO3WQ+ZORG5+i2HVclKR4bTjgdstyrtmLdpLzMaA47E1RRlmnIZTbLagSGRyOYmGmoUFx4Q40EQZ6z2NbCYq6ooXgZGoEbb7FChdII3M1aSr14J+IjcKMWQHsHxtg3YK269xwfdf7udRYnbB9Q0syU1EDcTs9ipiHIalvF8ggiAd3RGorZ9rPFC0trBMpkuqCzuGnIO95IQM/Rbgp9BrKJYeo+qrDTYoUQndpTiayzOJ3JOOftHkNDkTDrU6WuNAJ3gpOqsZIyZV7jE3fUUCkfgWqWrmLsVYhlKKA7K/VcjUD9b21774VzWT6rZdzELvXSuXBhO//zXcu5YEG2oFqOs1hKNM1ukCGtbUeH45wzu9XZV1GuRuDeTxNWWYBi/RvcKKddypQ5pqHgBAVBqagtyBUEpWLUK4V6mL1ROUojcMfhx5JmQTNaMUGqBMGYR/CqFaXh9hGUeNFHg3rJPgvFUMd8ctdxZ5s7fF0IcI88aWac8y3LWezSCNyd5LyN4ItFWYUDOpGAdW0WFVnJOz0WSggCtwCZVyBiSI3Z0IXrnaA5PbGFoOAz6wgCKTHA6aKm5nnRqCFVciRV2Fk8FRpBXQmCHI1AtxJG0q7qo9767UFDy7Pru1HVDt0x9urzAUODhMcv4Ck3MbM1wszW4s3Tvd8bDui878L8tovu5vUBu36P6fIRdDZadmD3qs3bR7cYbmfmxWd08sSO/rIaaSunXTKdcezmEa+PoETPAIVRQhCDJ9tzKp3FnrGofrWqx0AynbESCguFGdrXwGvjVkEGMY8gyDqLXT6CEhFXd96wvCyzmxd1zCd39BcsN+0t1JdMZ5xnqmzTkOvFmvb0VVBCPT9qKNdZDIWTwKB8H4H63t4iC6Kb18ymIWjw/F4rR8XxDXn8hm7Ud6p1UixlOr4565xLd3BTQjeRMnNqDeVoBL6P4NRxCwKlPidN6bSIMzw+Am/p3mJFu07GCggCXamQ2e26o+pNbNzqewt9f55pSNMQWHbmtJlhNGnSGgk6YwUrZLDcF0WPK+Hpa39yLut3HsvRSIoRcDSCjKMiR4N6zkq6LI1gnAShXNPQuIc7ZdwvBDe6wHEWN4cN+keSxFNmwQdXNePpaMx12DcU0QiUs9Ftsy6lESy3a+9PFHXMDbuPc8GCdp7bcyInkamQj8ARBGWUoXaXCQ8ammNyDLhMP2q/nM/rWWdxOGULgu4igqAc05BjXooUDTH94JvmA7B5/0nAingDcrrqeVECwtKYdY4OJWiJBMrQCHKPF0uZedVHFcUy8E+V+vIRuE1DdoPsdCaTZxoKujSDUpnFap+hPEFQ2Knk1QjKRdU9KaSOuqOGrPokKiU9W7derTTVQ1KufwCyCU+6JuhsDPKu82aPa8qC3IiqbPioka2RL8rzNbiraRb63sZxSgNXGmXvjXi0GcdZnDSdfeKpwj4CZer54Nr5OduzpqF0zvZmt2nI1U2s0igNbTCW4qyepjxttVBCWdY0VKJelqtmTiEfR76PoLhGEKmARqAWesXMQjljd0UsgXUPii3ksr2rrUXB068f5/z57Y4AGK+nsyKmNAKXJqXwTUMVwGsaCtiZtk6dfSUAAuX5CIA805AQ1gqn0IR04qkn6NRU9spCBHXNKRXszkY0M5LhhDUuFVmjxtQ1AUEww054aokEyhIACnUNE2nTcaCqhBywhGU5x1P7F3uwx2sWUmkuXtTBN9+7iuWzcjOzlTkuljKZaV+zWKpw1FBHY4htd16T5zwcz0cQ0HNLRlca96q+tzXC7LYIewfGnG3Cm1Bmlmka0rKf9zYigqz2GB03akgnZu9TLNpHaZzj5REAzOsYvy6VGm/UFTZc1DRkbzalZOuhIU6OpbjkjE4n0bRsjSCZsXpwuxZBimo5i+tKI3AXQTPshyqVyWYWux1DYNtkS+QRgDINZcsvqKbpgQKCwO0omwiGLgq+UNT355qGsnkEqrhbViOwJnNPmY5igPZokIAuaI1OrKyzimwaTZiM2YlVQUNzfAflvsiMAg9D7t+zx5kKjcDQNa5b0ZsnxFSp4HjKdNT3jCweIRQJ5gtCJdSK+whybeyVxn3MmbYgAHfpCyblI3AaColsFI7To1q4BYHyEeRel4Cm0dMcYn5nA/M7oizsbCiaB1OORqBW5vPKKFCoe8xWhl68XpJuf7eZkazf2Q/ARYs6sj6CcaKGFPG0mVNW3VvmohrUl0ZgZh+wgCacButpj2loYWcDrdEAc9ojOSugQnX4g4aWU3dcrXTUC89ba8j9f7nomlZcI3BVjFSCQErrZ1XcTT3IkzENaZqguynsdAwrFzVhRxNpq/KoE38/fhy8G3XNy0lim4paQ8VQlSdTZm6T83LGrVDhwWN54aPZPIJsgbjKmwjc92RWa9iJ0+9sDDKSSBc0DSXK8BGoZ8idoBV0BIHIWfFDvtDXNMGGz17p+Bf+7OIFRbXJbNRQ8fFkNYIyTEP296h+4aXCvdW+Zkby5M5+zuxppLs57IRth4vcM9UjWYWdxj21hnKdxb5p6JTxOosNTUPKbI0gdeEX9zSx6e+vAnLttYV8BN6VkFubcB8TcqMnJoKhFU8QCurZrlKqMY3E8hcM52kEExcEACvntNAWLS8TWaGEz0gi7TSlUeOF8uoMQfaBLkeLmooSE8VQtehTpswJ3SynZLdCPeTeAmMNQcPyqbiayJRbXXQiBD0awaq5bTSHDeZ2NLDn+FieszjhCh8trwx11rTkCALb/+Uun1EoX8T9MixV9LAcjUCZ2oqZl9xk/RP2PCwZNWT9b0rJvoExJ2w7NI5GoMbrzj8wCziLDU1U5b5DvQmCHNOQcFbtsaTVN6DQKsP90i7mI8j53ch9UL1F57zbykEvJQjczmJ78mSkZZZwGmo4PgLre8vNIVD86/tWT2h/yNpURxNppykNuDWC8lY25VwzFeo4FVFDxVCVZc2M9GgE5d9rpT389VvPzNmuaYLmSICAlq19UxVnsZFN6OpuCtPbEuGlO67mM/+5CSjcj6Ac01A2jyD7PLlNQ4Ydwee07TwFzc7RCEpc92uWz+DelrVlaQSaIwhcUUNFxqfOLWMXH4y6fI0wTlkQTaAMzLGUyVAs5SQSquNa1U+rs9ipL0HgDR+1lyexlFlUlSz0IndTTCNwq76KbPGtiWsExSZ2yJVHoELORMZ6IY16NAJla55TIDW/0jimoaTlLFaq9cRNQ7kaViGiQcMxXdQKTQji6WwGtWKiGb57vnJdwe3N4UBeglOlUXN2RnM4Z647WfLC048gbZbpLM4Kc2+tJFX33z3Hy+mAV4xCmriXcEBn7cLCNYa8OBqBMg3Zpd8L7qtnTUM5WrATNTS+sARrATecSDt+OXXchkkkCZZLnTmL3SUmhGN/jiXTRVchbjWw0MtY2WrVbo6PoMCELJWeXgoVPloIlUeQyUgGx1I0hgynCqLjLLZfymsXdPCzj7+Jc2ZPLs58IoQMy549YvsIHI3AmNiLLPtyKH7N1ANXS0Gga9l+FO4wwVNZ3br5q7cu5gNr50+Js3hma67G6F7U5GgEZpl5BMo0pIkCGoElHNy9PyqhEVTKTOjVCAJa4XpJkJ1/aVsj8AqCUhqBe34fHrIKQypBoI4brZKjGOpMEHg1AvXAjiQKx3uDNRHUfS9WSx0s80s4oOUUrPN+plAUQDmU9BHYpqG+gTGGE2nOntns2KuHbdNQtvOV4Pz54yeDVQIhBA0hgzGPIAhO0DQUKOPlkE1Eqq2z2J04p5iIs7gU7141m0sWdzrXoyrho/Yxe1ty8wfUPRNeH0FqoiUmsj+7fQTLeps5d04rQWNyz4ebQs/dqeAt+FisXpL7O5NpKzfJW2a+lPB2z2/13LbafjklIKsVMQR1KAg0YaloAV24BEGq5ANbKuxT3dxIUKejIZTvLM4xDdn/T3COrpnfXlSVDeqWw3vTPisV/uyZLVb1UVsjaAjqNYumaQwZjCRMS032RA1NOHy0hM1XPaS1jBrShHDKDrsFQaFIs1PB8RFUwSGS1QhyBYGKzc/zEZSZR+D4eUR+Qpkm4M8uWcB3P3R+RTQCdQ4T8c2UQp1vxOXjGi9qSHUaU3M+7Pm/4GcLHFNF6qlbXU3TUF35CFJmhoCuMbstSms06NjsRhNmycmn2d7IUlFD0aBBd1OIjgZV6bNyzuJPXH5G0b+p73++7wRBXePMnibbNGTZGt1NcqaahpBV930wlspJioLJmIaK768esFpGDelaVhC4o4bK6eY2EQzPi7SSNEcCLJ/VnFejP9dH4HEWmxMzDXlNqDmm0wqs5rMlJipzfdxZzQDnzmkdN0NYmWRVNvKirga+eN1SrljaXeJ78serTEP6FGgEdSUIEnbd9Hs+cgENIYPn+6xV9EgiXXIFoSZyodWdoxEEdL7x3lXOZFAvvEJlqCtpy84KgpOcNaPJKpQnrMiFkUQ6p0nOVNMQMhhNphkYSzod0bL1nCZmGiq1slYrcMn4xfCqhS6EU6TNXX6iUitT53uq6CMI6Bq/+cs3523P9RFkt7ujhkqNx91gxckjsK+LW7A4vQRO4Zpl+xFU5rqrJDEl3P/80oXF91WCwDbtqKghIQQffXPxz7k/60aFbE+FRlBXpqGUmSFkaPS2RGgOB5wEj+F4umjmLpReyWc1Ap2uppDzwlNOUfecnqxGUAq1stp2aMgpNqaSm4YTaRrDE0sEqySNIYNjwwmS6YzTCasce6kbvYxVohIE7sS+qcYt8N0rxlLzajJkTWvVeyl4yWoEWdNQNGg1iFFaUDl9tzVNsHJOK5ed1ZUjHBQzWyMsn9XM0t7mYocpe6yVesachLIyFi7q3qgilBMpBZ5tR5v9TItHI/CdxRUimc7kOF2VacjyEZQwDdl/KpVH4L3phTSCyTqLS+F+AM+b22qPV9iZxamcDl5TTUPQYJ9dq6bdXt1MOHy0DLuxevF6G7pMJe4XmrtqbbU0gmqYhooRcFbv2WdBlf9WhQ3HG093U4iuxhBXnz2Df/vTCwo+C40hg9/85ZtZMmPygqCcWkMTIRs+Ov5LXZlh++2mN+UID4W6Dq2OFiCcZ1ddq2pq93VlGvI22VYvkHgqU9KmmF3JF/cReG96sKCzuPKmIfWQLp/VzLvPm+WMV0rL5NXdNLHksUpimYasF4XSCJx2oGWuaLO1horfH3XtY56qnVNJTktTwyoJks7ISXUKK0U1fQTFUNqHu2dxUzjAkaEEI3Zhw/HO8/efvtTpuQ3ZZ6rSbp1KawTe8NFSqBf3sRFLEJRyDntR422OBDhwMkarq8ij+luhHs2Voq40AuUsVuSo8GW02ivWjwDyb1KhDMfJ5hGU4vIl3fzDO5Zx38cvciKfNJGtNVRLZ3Gj68Fvs9VctWIrv8TE+CvrK5f2AHDWKawkTxX3ezCoVyYmvvD3VM9HUAx36XDNszodSaQRYvzzbIkGcp49rQrPAmSvS7XCR0uhnrVjSiOYiGnIvsYtdn/qFleRR3UuvkZQIZLpTE50gzvTr9RELsdHEPGUhw247KqKQnbRU6U5HOBPL16Qs01z+whq7CxWeH0E5YY/CjvztNSDfc3yGbx0x1VOSn4tyDENGcIV9lotH8FUagT5zmJlGhqOpwnq2oRLH6jjVDoJsJzM4omgntlyVvfqWVOCYCIreGVtUNF17tpeWY3A9xFUhKQpcx6gnOiOUqahEnkE3n6rilJlqCvsP8xDtxPKRhLpnFaOU41bEOT5CMrUCCC3IUsxaikEwGMacvkIKp5HoDSCKSyslE0oyyZTqes9kkhPSihlC9FVaJA25fQsngir5rZy1bKesgrUqcTNY5PwEajxKkHgrvar7nm1Ko9C3WkEpkcjKC/Mr5QaGypiGsqq0y5BUCV12Ismso3Ba6oROKUfcmvqQ/k+ArCEdKVNLJXGrREEckxD08FH4M4jsLapBcZIPD0pM1U1/GVQ+TyC2W1R7v7gmrL21TRhRcqdgo9ACQK3aairKYShCeaW0T9hstSZIMjkqFfuCVwys9ixU5dwFhfxEVSiDPVEca9Oa5tQZn13azSYl18xkZeHoRcvune6oHs0guycmQ5RQ0ojKOwjmEyWczUi6KDyeQQTpTFkOLWCJhM+qqKG3KahWa0RNv/DVX6JiUqRMmWOqi6EyJaEKOUjKGUaKhI1VNA0pJG3rRq4V6e11AjUd7e5VjfZAlwTEARvAI3ALXyDuubMs0qbhpx2qlOZR1DQR2Dd0+H45ExD6npVuqxypZ3FE8W98JpM+GhzAdMQVDerGOpMECTTmbxJGy6jYFkp05DqPpRvGsp3FrtrrlQT9zBVyYtaoCZvu6utYHdTiNZogIVFmo8XIhrUJ6Rm14JcZ7FLI5gGpiH3XFbz2TENTdJHoDkaQYUGaVNrjUDNeW+/8/FQ4+20n5WOxql9buvKNJQyM3kZmeGAxmCsdBy0oxEUaVUJhRLK8rUIrUrqsBf36vScWdUvOV2MBkcjyAqC1mjQ6f5WLl+/5dwJd1WbanKdxdlqsZXWCOa1R2kKG3Q0Tqxj3KmgVtlCZFfwjS5BMMeIFP1sMdTjVmkzqep5UCuNQOUSTEQbgOw7YU57lLs/sJqLz+is+NhKUdVlhRDiGiHEdiHETiHEZwv8/cNCiGNCiE32v49WczyJdCbvwVQrzXKcxaXzCHJlqpOWrxXQCKptGrKPP7MlnON0mmoaC2gEk2H1vDbmVNFRVglynMWu1WClnJaKi87o5OU7rp7SKKlcjcDapvoomxk5KR9BNf1lf/3Wxbz9nN6KH7ccGk9REAQNjavOnlF1U5CXqn2bEEIHvgm8DdgPbBRCrJNSbvXs+lMp5SerNQ43SbvWkJtwgSqIXowSD3U27jf3wSzUIKNQM+pqoA6/ck5rVb9nPFS4W9spCoI3AnkJZRUooHa64I4ayjqL8/0+E8Hdo6DSfPKKxZU/aJkoTWkijmLImhCnMlHQTTW/9QJgp5Ryt5QyCdwL3FDF7xsXb2YxZJPKShUHK6URrJzdwr23r2X1vLac7VlncXabEylRZR/B/hMxa2w1FgQtkQCagJ7T3KxTCaYqj6AWuEOhvQllMLEwScVUacdTTSU0glpQzW+dBexz/b7f3ublJiHES0KI+4QQc6o4nrzMYijPNKT+VGjSCiFYu7AjL/qhYNG5KZr8R4esOOZzaywImsIB/vNjb+JPzq/qbT0tcPt/3K1FK+0srgVBx0fgrjWUFQSTmWfqONVqxl4rmiatEUw8v6aS1NpZ/GvgP6SUCSHEx4AfAld4dxJC3A7cDjB37txJf1nKLB41VNJZPImYcKftXpWLzhXiC9ctZdnMZi6YoraUpVhzGoxhKvD2rDCqFD5aC9yNaa49p5eALhyTKMDlZxVvuFKMqdKOp5pT1Qimo2noAOBeCs62tzlIKY9LKRP2r98FVhc6kJTybinlGinlmq6urkkNJpORdh5BYdNQyfBRMfHVXakSE9WuDjCnPcqnrlxc09aN9YbmmIJyM4qnk0agCcGCzgZuv3RRzoJqMpFpTtTQG//y5KB8BBM1l6mFw3Q0DW0EFgshFgghgsCtwDr3DkIIt2v/ncC2ag2mWJPtskxDkzDpFBIE1aq46FN71PQJeuLYp4Wz2DFzZre5TRiTWXBMVZb9VONoBBM0Dema5X+pVf5D1UxDUsq0EOKTwAOADnxfSrlFCHEn8JyUch3wKSHEO4E0MAB8uFrjSRXpraqihsrpUDaRm1Sy6Nw0m/w+2fvsbbdY6X4EtUDXVK/h3KS5z1+7hCuWTNwspI7p/n+6oHwE0YlqBJpG0Jh4FVuJcHMAAB3ESURBVNdKUVUfgZTyd8DvPNv+3vXz54DPVXMMCtVbNV8jGD/MbzKJYO72foqpKjHhM/WoVXG2+mVtM1wriRCCoK7lhXrefumiSR9zumoEqgLpRDWCCxa0M2i3uKwFtXYWTxkp06rGWdQ0VEYewUQe6pZIgKCu0dHgriueLxx8pgfFnMWV7kdQKyxBULl5O1WBE1PNZH0E157Ty7U1SoKDOhIESiPwquohx0cwfh7BRFbyLdEAf/zby3JaRfoawfTF6yzOmoqmx72+4byZXHxGR8WOV61+BLWmyU60m2jUUK2pH0FgFm6y7ZiGxqk+amhiwva73pbcGixTVWvIZ+pRLzY1vwLTKGoI4Ms3nlPR403XRVGz3Wqymk1kqkH9CIK0bRryrNAiZZiGKlXESp+m6rBPvrNYn0Z5BNVguvoIWqNB/u9t50150bhTpX4Ewbjho6VNQ5Vw+mUjJU75UD6nGY6zWFUdLdHMyGfq6m7VgnesnFnrIUyYupml2fDR/DLUUHrlpovKqLDaNM2m9HE5iz2tEqdD1FA10Kapj+CNSt0IgqyzOHfmqTyCUrZcTRMVWdlN51VQvaOmR9BjEpoOeQTVwAnA8BdFpwV1M0uL5xGUU3SuQj4CXyOYtmjC4yOYRpnF1UA9A9Ot6NwblbrzEeSHj44f3XHN8hnMapt4FyYvvkYwfcnPLB6/vHk9ozlRQ7Udh49F/QgCWyPIa0xThkZw5dIerlzac8pjmEypCp83BvlF53yNoBR+uZXTi7oRBG9d2sMTf3s5Pc3hnO1LZzRz06rZeY1lqoFfdG764s0jWNjVwJz2SM3KCp/uaL52fFpRN4IgEtQL9r2NBHX+95+snJIx+Kug6YvTYcrWAK5fMZPrV7zxwginCj9q6PTCX65MIdM1m9In31nsUxrdjxo6rfBn7RTirIJ8QTDtcJzFvimoLPyoodMLf9ZOIf4qaPqiFAFfIygPzdeOTyv8WTuFZJ3FNR6IT8VR2p7vHC4PvwDj6YU/a6cQFVLoO4unH9Ot7HS1UdfLfxROD3xBMIXo/ipo2uI7iyeGX3fr9MKftVOIn0cwffFmFvuUxi/Jfnrhz9opxJ/805dsHoH/SJWD7kfQnVb4s3YK8R1k0xclAFTtKp/SqLWQ/yicHvizdgrxNYLpy7yOKF+96RzetuzUa1LVA34o9elF3ZSYOB3obAyia4Ke5lCth+JTYYQQ3HL+3FoP4w2DX4n39MIXBFPI7LYoL3zxbbREA7Ueio9PTZmuPYvfqPimoSnGFwI+Pm4zaY0H4gP4gsDHx6cG+Dk1pxe+IPDx8ZlymsIGN6+ezZsWddR6KD74PgIfH58aoGmCf755avqA+IyPrxH41AwpJRmZqfUwfKaIjMxgZswJfSadSVdpND5ufEHgc8rE0jEAnjrwFP2x/rI/9/n1n+dD93+IVCaFlJJH9z7KQHxg0uOIp+N528ZSYyU/c3DkIA/2PZj3wnlk7yN87onPMZoadbZJKZ1zHU2NIqVk18ldPLH/iXHHNpYaI2EmyjmNsnnywJNsH9ju/N4f6+fgyEGklAX3T2fSpzQGM2OSNJOT/vynH/k0H3vwY0XH5+V7L3+Py/7zMl4+9nLBv493b8vdN2WmJn1eT+x/gv3D+yf1WbCenXKvRzXR77jjjlqPYULcfffdd9x+++1T9n2ZZBKEIG7GWbdzHa8OvMr8lvkEtMLRP/uG9vHSsZeY1zwPAJlMsntoD/tG9jGjYUbBzyTMBI/te4yAHqAl1OJs33liJ197/mukM2kWtS5ytj+691GOjh2lJ9qDruk5x0pn0qQyKQzNcI6tCz2vAcimo5s49sBvkf91P5FVq9CCQeLpOBLJg30Pcvfmu2mPtKMLnWggSkZmSJgJYukYd264k4AWYF7zPO7Zeg8fe/BjjKRG+Men/5Ftx7extnctGw5tYF7zPDRhrTXMjEk8HSegW9dt+8B2vvzMlzk8dhhDM3jhyAt86ekvsfX4Vt4eWUN86zaCs2c756AJjaHkEI/tewxDM2gNt+acz/7h/Vz/i+sxpcl53edxZOwI9712Hx998KM0GA2s7F7J+gPr+camb9AT7aGnoYd0Js1H//BRfrLtJzzU95B1PYXOd176Dl/Z+BVeO/EaB0YOcE7nOUQDUe7ccCd3briTszvO5pbf3MJDfQ/xvVe+x692/Yqx1BhvmvmmnOvcH+vni09+kR9v/TFf3fhVHt37KFfPv5qh5BAjyREiRoR7tt7D4/sf54IZF5AwE0gkv/r6X9L38K9Z9ObrEEIwlhpD13Lv4VMHn+IvHvoLfvbazxiID7B3aC+3P3g792y7h5OJk1w862LSMo0udMZSYxiawV8//Gn+5en/RSAQ4p5t95AwEyxqseaV2rcYqUyKj9z/Z9y37afceOa7nfsKcGT0COt2rePJg0/ygy0/4Oc7fs66Xet48eiL9Db0IhAcHj3MVzZ+hQMjB1jSvoSuSBdBPcgr/a8wlBiiPdIOwFByiLueuYsXjrzA9175HrF0jAf7HuTNs9/MvuF9DMQH6Ip2senoJm781Y0MJgc5f8b5JMwEAT1AwkxgaAbbB7ZzePQw3dFunjn0DDf/+mbGUmOsnbkWgNcHX+euZ++iK9LF59Z/jm9t+hare1bTFmrj4b0P0xJq4fkjz3Pfa/extnctsXQMQzMQQvDsoWf5xqZv0B/r57NPfJZ1u9bRFe2iJ9pDUA/yyN5H6Ih0EDbCjCRHeHjvw8xqnEVAD7D52Gb6hvqY1TiLg6MHuf4X17Pr5C6umHtF3jO6d2gve4b2FH1vTJQvfelLh+644467C/1NVFMaCSGuAf4PoAPflVJ+xfP3EPAjYDVwHLhFSrmn1DHXrFkjn3vuuUmPKd3fj97czKuHX+bg7pe4eOk1hLpn8Ie+PyAQbD+6hcPHXufzV92FOTTM0ff/GUZLCz/92Jn8uO+/6DkB18++iisuuJXdI3tYEzmLjrln8oX1X8AQBo8feJzR1Cg3n3kzf7fyM7z6zmvZ3DDAT64K8q2OT7LgTz7MA3v/QN9gHxec7CB6cIC/i/8H8zcfZcuiALf0XsulqQV8v2c7G7Y+wECjJKiH+OLcP6fl5T5OXHoOd7x4Fyt2Z5jfMIf//ql7aQm1ED9ykN+dfIpvv/IdUpkUX7vsa8xpmsNN625iUesi3s9a4n17WHDTB0hn0nzkNx/k69+M0z4C6dndPP2xi9j+zP2cu8PkYIvJv18ZoHHEZLABzmpfQsJMcDx2nIWtC3nl8CYu3C65bNal/CD6IocC1qq5MdBIPDZMt2jhoD7E/Ob5fGrVp7hy7pV85rHP8OjeR7gospw7rvs6//zcP/PE/idY2bWSDYc2ALBKzmVsfx9f/G2E4IkRHr1pISv7BN895ziNrZ0s3nKSg+YA/c1w445W5t1wG2dech3xV7ZwV8sTPL7lt6TCBgs6z2Tb8a30DsD8RBMXbxgifPFavjrzRdKZNBLJ+5e+H4Cfbb6HDyx5Pw/1P8mxI68TD0JG13j34nfTGenk2y99G4CZDTM5OHoQwBKORpSwEWZm40wWty3mvtfu48sXf5mQEWJg4wYWRefyu7a9rNu1jpVdK1nQsoBf7vwlAkEqkwIgYkSIpWMIKbmsfS2PnXiW9nSIr//LCOEUHL1kCQdmhfn2jG2YbY1c2LGat3StZcGs5XzykU/SFmrj2pGFPLvlAZ49U3DRnEvoDHey85Ff0NrQxfPdI7wlsoKHRp/jUnMxb/+3rTQmBP/wXo2RziiMjjGvdSFCCI4f28tVa27lI+d8BICB4aMcHjzA9tgeMjLDa/3bWPtPfyCakCT/9U7e0XUZemcnI6kRbvvtbfQN9QFwRusZ9CQjJMM6Lw++yuy9MW56KsPDb5/BS82DdEe7OThygKYx+PzVX+FLG75EKpPi2o5LaXx6Kw+eleC4OYgpTZqCTXzrrd/iM49+hlg6xkhqBE1o3LbkNh7a+xAn4icID8VpjxkMRiR6ZwfH48d575L3kv7+vYhkkoEPXsMTB9YTiqUZFgnet+LDjKRGuP/1+xlLjyEQSCTt4XYG4gMsOx5h3u5R5uidbJwZ48UZMd656J38Yefv+OvHGoksWcpdM1+g/VicpAEdC5diSpPGjdu55FXBY7ct4eXh7ZzXfR7fveq7fOrRT/HkgSdpC7XRFm5j9+BuAC4KLmXJ1mHunXeQpDB578KbedvZN/Ctzd/ixjNu5Nyuc/n8t9/D+c8OclHkbDbefhFPnXyBq+ZdxW1nv29S7z4hxPNSyjUF/1YtQSCE0IHXgLcB+4GNwG1Syq2uff4bsEJK+XEhxK3Au6SUt5Q67mQFQeLwIXZ95UuI3/8RGQwgUyk0CaYGT14/j1eT+2iKwVteztA+DD+4KcCqF9Os2SGt1WgoQ1gLEhqxVMi0BhkBQRMGOoM8My9NrC1CYEYPHT1zeWnr4yyINXD1Y8PW9xsQSsPBi8/gxL6ddAzBjJOeMTYGEbEkQRNSOgRMEIt7+c2sk7zl6RiNcRiKwJGFLSzeMgjAyWadsNQJDyfZ2Qt9KzqImwn0wRjnHAryWkeS7kE4e49lm33wXEHPSdCDIc5+Lc6vLo9y6bNjtNkWkHhzmPBQnOCKM0m+9BqDK+by81VpDixsJhUJMPrqVv7xt41EDlvfPxwG7fZ38drRHVywcC1Hv/kD2gZNEt0t9OsxfnxxmqtfDXNSxJhndLHgxaO8cFaA8FiKxsWLWX35Dex44kEaNvcROGJdkKEInGyAubaVabhRx0iaRFzau6mBkJAKaoQSGXb3wIKj1nV7blmAJQ0Lad+w3dlXz8CGy7q5YvkNbNr5GPqmHTTGoXtIoAeDNF10FoOPvkQmHCKwfAHdZ3YSXr6YZzp6OB4/wcvrf0lLsJne2Wfw9OYHePNNf8GVJ3pJ7T+E3tbJlwf/nV3DfZy3Pc171mfIaPA/Pmhw8YXX8ZnMXLTFF/PCd7/J6MZNpC9azcBV5zP01HrO6E8intpC18E4Oy+YSaq9iaW/38725U0sfmUYDUiFDV5922LaN+6k7USKH7xVozvTwK2tV2D+52/ANIk3h2jq7KHh0ssY+NGPQMKJmVE6DoyRDGkEExnGojoNRpS0IelaZtD/9CAZKQGBYUoOdAg2L9IYDkmu3JyheQx+e75g00KNS7ZkeNsm612xp9dg/qE0uxc38tMrgrzaPMI3Ov4bM186QPLxx0jsP4YxYwb6ucuJP/QIIp3hYBskFs9iTsNM9iSPcsaTffxqreCxFRqLW1q4/L4hlr6e5uDiNro+cBuBxzbCkaN0LlvAiY7Z/Pz1X9Ny1nJSyRhHX91ERzLA1Yc7EbsPOHNiYHYzG94+l337t/Lx+y3f06NrQgRnzeDiX+8jaUhengOvLg7RsmwlV8d6+D+Jddy0yeCskVaOpAZpez3lHC8j4PHLmnl05ig3bwqxfItlXjreGaSj35qMwRtWM/vd17Prk/+MGB7jsVVBhm+8hHuH/8j7nhTM3W+iv2kVLyyJ07U7ydLMTJp2HyS6cQfBNAyd0Unw2CiBoRg7ZmtsnSuIBSSNccl1z0qSQQgmYctcQXcyiHbtZVz2N/8y4fcf1E4QvAm4Q0p5tf375wCklHe59nnA3meDEMIADgNdssSgJisIHvqXP6f7O+t5YJWwXyCScxtSmLt0Fu3OqrmiVZDIpAkOWWryL98CW3o0Lt8iuUIaRLtMvtGYZukRyXljCf7YGaZpv87Kvgy6mR8TfXROhkVanP7BEE/NMbj8ZclIo6SzI866OSGenWXw33doLJwR4NiGBEMNsP3sGBfuTtMYynBiZxQzrpNpS5NaGeP43giz9uk0nxHkYOcQu4+F6A/qBJtg7SaJbr/Q0zrs6IXFRyDYIEguihM5niG1J0IsKomMCcLdGp1vH2ZLLEHv5hAdM1M0LJvNvp+fYPRQgMZZMcaOhsikNBAQaNFIjmQIBExmrDnJxtYgbU9ECZ/MmhS0qElwUZzgSIjYMUiNGKQ1QEgME1ILM5j7dFJNGZpOCJACYWRo6E7SMCOBiJisn2twVDO45vkMR+YHiD4YQoRNjKtPMK95FonDo5jRfrZu6GIoo/H8Io3rNmZomz9GXAjSOyOQEXSeHyTcrRPp1TnwYIyxPuWolMjuNHrUpDViMnY0SPy4db5GVGP0oE5qdLyAOusFWojIrCTHB4OQgkbdJDOmW1JLCgKNaVIjucfWo2mSs1MYuyJIEyIzNNqvOMBWI8iS0SaGX4wysjuNFsiQbMhgnMx+vml2nKbZMUYOhUiOGMSPBwl3aQTCMcaOGrQtHiUd1xluD9B+dhuNMTjwu0GSQwaRrjTRjhgy0o4R1ejflyZ1wEQ3IdklEI1pAq9n723b4jFOJnTk3hDPnilYvk8SjYHUQZggNEm0K0m0O8XwkWZSQ5KmOQkae0bY/2QbQpcIIJPWSHenMI4q86p1LVsWjDG0N4I0BUKXBBrSJIeKJGAKSbQzScMcCPa0khrKcHJriuQJSwBkulJ0tCY5saMBgIbeOIEGk9HDobzrDxBsSmMmNDqWjdE8d4QH2puZ+ahBpC/o7NO1Yoix4wESgxE6V5iMHUgw1BdFD5uYCY2m2XGG90WsMxISIQXxlgzhQS1nvughk4a5Kfo7wwQ3QKBZsHmJRlOfyZwj2TElZiVpuGSIl/Y2s2xDECOaZsZ730LT33y38DUZh1oJgvcA10gpP2r//gHgQinlJ137vGLvs9/+fZe9T7/nWLcDtwPMnTt3dV9f34THc/T1x3j+919h0bJLuX+sj3NTGd6ityBb5jD27EYCq6/BSO5DDGwllenk+LYGWlbNJGjsYNvIXoIIztKiIHTkjBWIhZdC/07SfU/yYkMj550cQIsNk4i1YJph9ORRTr6apOOCDgJLVsLKWzmybwMHfvltlq+5hFDnXIaObWPfsZc5W4sCOE4j0TYPFl0Jr/0eOe9SpNGIiB1BhJugqRdevAdGj0HzbOhdAckR2P8cMjGKnHkhNHSSee1+XmSI87RGDCGgaSayazljr+4netZMEpueQBfDBHpmwPxLoGsJbPp3GNpPJtBBXC4guvZSMs/+G7FX9zD6+hDJ/jh6JETn+99BYOYcaF+AmdaIrf8DwRntpA4PEFowAyN5CIYPYbYuo/+XT9M4XxDoasU0w0Qah5C9KxGRNpKHjpM+MUx48Wy0gGGVpOxeCm0LrJ/7d8DG75DYexi9dyFGVycc2QKaAStuRRoheP1xxMgRZO95iFAjIEm9upH0wd1EZjY4919KiUxLCDYi5qxBRFsACf2vkRkbJaatIDrbQOx7BtlxBsnWi4g/+xjsegzMBKEzlwKQ7h9AX3YZQ7+4l8jieTQu6yB1+CjxwQgM7SeyfDmBhhTxV7czsKEfGroIr1xNavtzhOd00XLj9SQe/jGDzx8mMq+RxsuvRix+C2Lf06S2rGfgyX00L2sjsvpCmHkuvHwfmAliB0fRe+ZiLFzF2I79hHpb0Qe3orV0WfcOgUwMM7b+IcLtoPfMR867BDFjGRx4Hvash7Hj1rUIdzLadDXR1avQXvw3OJJ1xkpTIjMSYQhEtIOU3kv8xWcJtesEFp+NNHXiL79AdG4jZtzkxNNHMBMmDYuaiS6egbbqFtj9GJzYYx0w0gZnv5vYwz/F6GpHIEju6yO65kK2Pfko3W0XYh4ZRUsdp+Oac8jseZ74YBPBxUsIzFtMJpmCzfciEzHih0YRmiA8vxcx73xEIGCdmzovM8PIzhFk01wa1q5Bjx0g2beblJhFdOUyRO9ySMVIPvNrEltfJNDeyOCxuURWnE3zRSsh2Agbvgmtc2HoALKxh1R0JYmXnya8cCaBM89H7noU9j+LCDYiZ13AsYf2kNy9i6ZVC2g+p5ORPz6KOZYmnplPZOUqWuYMEnvlFQZ3h2joidHQk0TMWIK46BOgB4n94G8IRobQI4Y1R0UIupfDyT603iWw8lZkbJCxP9xHZGEP2uxzrGd+ErzhBYGbU/UR+Pj4+NQjpQRBNcNHDwBzXL/PtrcV3Mc2DbVgOY19fHx8fKaIagqCjcBiIcQCIUQQuBVY59lnHfAh++f3AI+U8g/4+Pj4+FSeqpWYkFKmhRCfBB7ACh/9vpRyixDiTuA5KeU64HvAPUKIncAAlrDw8fHx8ZlCqlprSEr5O+B3nm1/7/o5DtxczTH4+Pj4+JTGLzHh4+PjU+f4gsDHx8enzvEFgY+Pj0+d4wsCHx8fnzqnqkXnqoEQ4hgw8dRii06g/DrJ04d6PO96PGeoz/P2z7k85kkpuwr94Q0nCE4FIcRzxTLrpjP1eN71eM5Qn+ftn/Op45uGfHx8fOocXxD4+Pj41Dn1JggKduepA+rxvOvxnKE+z9s/51OkrnwEPj4+Pj751JtG4OPj4+PjwRcEPj4+PnVO3QgCIcQ1QojtQoidQojP1no81UIIsUcI8bIQYpMQ4jl7W7sQ4kEhxA77/7Zaj/NUEUJ8Xwhx1G5upLYVPE9h8f/Z9/4lIcSq2o188hQ55zuEEAfs+71JCHGt62+fs895uxDi6tqM+tQQQswRQjwqhNgqhNgihPi0vX3a3usS51y9ey2lnPb/sMpg7wIWAkFgM7Cs1uOq0rnuATo92/4J+Kz982eBr9Z6nBU4z0uBVcAr450ncC1wP1bT2LXAM7UefwXP+Q7gbwrsu8ye5yFggT3/9VqfwyTOuRdYZf/cBLxmn9u0vdclzrlq97peNIILgJ1Syt1SyiRwL3BDjcc0ldwA/ND++YfAjTUcS0WQUj6O1cPCTbHzvAH4kbR4GmgVQvROzUgrR5FzLsYNwL1SyoSU8nVgJ9Zz8IZCSnlISvmC/fMwsA2YxTS+1yXOuRinfK/rRRDMAva5ft9P6Qv7RkYCfxBCPC+EuN3e1iOlPGT/fBjoqc3Qqk6x85zu9/+Tthnk+y6z37Q7ZyHEfOA84Bnq5F57zhmqdK/rRRDUE5dIKVcBbwc+IYS41P1HaemS0z5muF7OE/gWsAg4FzgE/O/aDqc6CCEagf8C/kpKOeT+23S91wXOuWr3ul4EwQFgjuv32fa2aYeU8oD9/1HgF1gq4hGlHtv/H63dCKtKsfOctvdfSnlESmlKKTPAd8iaBKbNOQshAlgvxJ9IKX9ub57W97rQOVfzXteLINgILBZCLBBCBLF6I6+r8ZgqjhCiQQjRpH4GrgJewTrXD9m7fQj4VW1GWHWKnec64IN2RMlaYNBlVnhD47F/vwvrfoN1zrcKIUJCiAXAYuDZqR7fqSKEEFi9zbdJKb/m+tO0vdfFzrmq97rWHvIp9MRfi+V93wV8odbjqdI5LsSKHtgMbFHnCXQADwM7gIeA9lqPtQLn+h9Y6nEKyyb6kWLniRVB8k373r8MrKn1+Ct4zvfY5/SS/ULode3/BfuctwNvr/X4J3nOl2CZfV4CNtn/rp3O97rEOVftXvslJnx8fHzqnHoxDfn4+Pj4FMEXBD4+Pj51ji8IfHx8fOocXxD4+Pj41Dm+IPDx8fGpc3xB4OMzhQghLhNC/KbW4/DxceMLAh8fH586xxcEPj4FEEK8XwjxrF33/dtCCF0IMSKE+LpdI/5hIUSXve+5Qoin7WJgv3DVxj9DCPGQEGKzEOIFIcQi+/CNQoj7hBCvCiF+YmeS+vjUDF8Q+Ph4EEIsBW4BLpZSnguYwPuABuA5KeXZwB+Bf7A/8iPg76SUK7AyP9X2nwDflFKuBC7CygoGq5rkX2HVkV8IXFz1k/LxKYFR6wH4+JyGXAmsBjbai/UIVlGzDPBTe58fAz8XQrQArVLKP9rbfwj8zK75NEtK+QsAKWUcwD7es1LK/fbvm4D5wPrqn5aPT2F8QeDjk48Afiil/FzORiH+h2e/ydZnSbh+NvGfQ58a45uGfHzyeRh4jxCiG5z+uPOwnpf32Pu8F1gvpRwETggh3mxv/wDwR2l1ltovhLjRPkZICBGd0rPw8SkTfyXi4+NBSrlVCPFFrE5vGla1z08Ao8AF9t+OYvkRwCqD/P/sF/1u4E/t7R8Avi2EuNM+xs1TeBo+PmXjVx/18SkTIcSIlLKx1uPw8ak0vmnIx8fHp87xNQIfHx+fOsfXCHx8fHzqHF8Q+Pj4+NQ5viDw8fHxqXN8QeDj4+NT5/iCwMfHx6fO+f8BbeqiQYHDvc4AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xW5f3/8dcn951BJhA2IQwByx4NQ3GPumrV2lZcWGsd337VDutX+6tVu7613y6LWqutW4urdVWtOFCcICCoDCUgSCCQkJC9c1+/P85JDJCEMO7cJOf9fDzuB/cZ9zmf6z7hfO7rus65jjnnEBGR4IqLdQAiIhJbSgQiIgGnRCAiEnBKBCIiAadEICIScEoEIiIBp0QgcpAws9fN7LuxjkOCR4lA2mRmFS1eETOrbjF9/j5sr90TnZkNMzNnZuH9i7z7MrNv+9/RObGORboPJQJpk3MutekFfA6c3mLeI7GOL6AuAoqBOZ25UyXn7k2JQPaamcWZ2fVmts7MiszscTPr7S9LMrOH/fklZva+mfU3s18DRwK3+zWK2/dyn4PM7FkzKzazXDO7tMWy6Wa2xMzKzGybmf2xvVj8ZRlmdo+Z5ZvZZjP7lZmF/GUjzewNMys1s+1m9lg7cT1hZlv9dRea2bgWy+43szvM7HkzKzezRWZ2SIvlJ5rZGv+ztwO2h+9gKHA0cBlwkpkNaLEsZGb/zz8m5Wa21MyG+MvGmdnL/ne3zcz+X4v4ftViG8eYWV6L6Q1mdp2ZfQhUmlm4xXEvN7NVZnbWLjFeamarWyyfambXmtk/d1lvrpn9ub3ySidyzuml1x5fwAbgBP/994H3gCwgEbgLmOcvuxx4DkgGQsCXgXR/2evAd9vZxzDAAeFWli0E/gIkAZOBQuA4f9m7wIX++1RgZgdiecqPOwXoBywGLveXzQN+ivdDKQk4op2YvwOk+d/DrcDyFsvuB4qA6UAYeAR41F/WBygHvgHEAz8EGvbw/fwMWOy//wi4psWya/15h+IllElAph9bPnCNX5Y0YEaL+H7VYhvHAHm7HPPlwBCghz/vm8Ag/7s5B6gEBrZYthmY5scwEhgKDPTX6+mvFwYKgC/H+u9aL/9YxzoAvbrGi50TwWrg+BbLBgL1/n/w7wDvABNb2cbrezjRDaOVROCfiBqBtBbzfgPc779fCPwc6LPL51qNBegP1Dad3Px55wIL/PcPAncDWXv5HfX048/wp+8H/t5i+anAGv/9HOC9FssMyNvD97MW+IH//ifAihbLPgHOaOUz5wIftLG9jiSC7+yhzMub9gu8BHy/jfVeBC71338VWBXrv2m9vnipaUj2xVDgKb+5pQQvMTTinWAfwjshPGpmW8zs/8wsfj/3Nwgods6Vt5i3ERjsv78EGA2s8Zt/vurPbyuWoXi/wvNblOEuvJoBwP/gnZgXm9lKM/tOa0H5zTG3+E0lZXgnTvB+7TfZ2uJ9FV6NpalMm5oWOO8MuYk2mNksYDjwqD/rH8AEM5vsTw8B1rXy0bbmd9ROMZnZHDNb3uJ7G88X5W1vXw8AF/jvL8A7NnKQUCKQfbEJOMU517PFK8k5t9k5V++c+7lzbixwON6vv6aOzX0d6nYL0NvM0lrMy8ZrhsA5t9Y5dy7eify3wJNmltJOLJvwagR9WsSf7pwb529vq3PuUufcILzmpb+Y2chW4joPOAM4AcjAq9HAHtr6ffl4J07vA2bWcroVF/nbXW5mW4FFLebjl+mQVj63CRjRxjYr8ZrNmgxoZZ3mY+b3UfwNuBLIdM71BD7mi/K2FQPA08BEMxuPdxx0scFBRIlA9sVfgV/7JwbMrK+ZneG/P9bMJvgdr2V4TUYR/3PbaPuk1FKi39GbZGZJeCf8d4Df+PMm4tUCHvb3eYGZ9XXORYASfxuRtmJxzuUD84E/mFm6eZ3fh5jZ0f72vmlmWf52duCdDJvK0FIaXkIpwjuh/m8HytbkeWCcmX3dvCtyrqb1EzH+d/AtvE7iyS1eVwHn+Z//O/BLMxtlnolmlgn8GxhoZj8ws0QzSzOzGf6mlwOnmllvv+P5B3uIOQXvuyj047oYr0bQ5O/Aj83sy34MI5v+RpxzNcCTeDWZxc65zzv+VUm0KRHIvvgz8Cww38zK8TqOm04uA/D+w5fhNRm9wRfNAH8GvmFmO8xsbjvbrwCqW7yOw2vrHoZXO3gKuMk594q//snASjOr8Pcx2zlXvYdY5gAJwCq8k/2TeH0d4HV2LvK39yxeu/f6VuJ8EK+JarO/nffaKdNOnHPb8TpXb8FLJKOAt9tY/Uz/e3jQr61sdc5tBe7F65c5Gfgj8DhegisD7sHrAykHTgROx2umWgsc62/3IWAFXpPWfKDNq6P8mFcBf8DrnN8GTGgZs3PuCeDXeCf7crxaQO8Wm3jA/4yahQ4y5jVNiohEl5llA2uAAc65sljHI19QjUBEos7M4oAf4V0+qyRwkNHdgiISVWaWgteUtBGvGUsOMmoaEhEJODUNiYgEXJdrGurTp48bNmxYrMMQEelSli5dut0517e1ZV0uEQwbNowlS5bEOgwRkS7FzDa2tUxNQyIiAadEICIScEoEIiIB1+X6CESk+6qvrycvL4+amppYh9JlJSUlkZWVRXx8xwf9VSIQkYNGXl4eaWlpDBs2DG9AVtkbzjmKiorIy8tj+PDhHf6cmoZE5KBRU1NDZmamksA+MjMyMzP3ukalRCAiBxUlgf2zL99fYBLBJ1vL+cP8TyiqqI11KCIiB5XAJILcggpuey2X7RV1sQ5FRA5iqampe16pmwlMIogPedWl+sbWHjQlIhJcAUoEXlGVCERkby1fvpyZM2cyceJEzjrrLHbs2AHA3LlzGTt2LBMnTmT27NkAvPHGG0yePJnJkyczZcoUysvLAfjd737HtGnTmDhxIjfddBMAlZWVnHbaaUyaNInx48fz2GPtPiQuagJz+WjYrxE0RDTstkhX8PPnVrJqy4F9hs3YQencdPq4vf7cnDlzuO222zj66KO58cYb+fnPf86tt97KLbfcwmeffUZiYiIlJd7jsn//+99zxx13MGvWLCoqKkhKSmL+/PmsXbuWxYsX45zja1/7GgsXLqSwsJBBgwbx/PPPA1BaWnpAy9tRgakRhONUIxCRvVdaWkpJSQlHH300ABdddBELFy4EYOLEiZx//vk8/PDDhMPe7+pZs2bxox/9iLlz51JSUkI4HGb+/PnMnz+fKVOmMHXqVNasWcPatWuZMGECL7/8Mtdddx1vvvkmGRkZMSljYGoECeGmPgLVCES6gn355d7Znn/+eRYuXMhzzz3Hr3/9az766COuv/56TjvtNF544QVmzZrFSy+9hHOOn/zkJ1x++eW7bWPZsmW88MIL3HDDDRx//PHceOONnV6OwNUIGlQjEJG9kJGRQa9evXjzzTcBeOihhzj66KOJRCJs2rSJY489lt/+9reUlpZSUVHBunXrmDBhAtdddx3Tpk1jzZo1nHTSSdx7771UVFQAsHnzZgoKCtiyZQvJyclccMEFXHvttSxbtiwmZQxMjSAcUo1ARPasqqqKrKys5ukf/ehHPPDAA1xxxRVUVVUxYsQI7rvvPhobG7ngggsoLS3FOcfVV19Nz549+dnPfsaCBQuIi4tj3LhxnHLKKSQmJrJ69WoOO+wwwLtE9eGHHyY3N5drr72WuLg44uPjufPOO2NS5i73zOKcnBy3Lw+mWbutnBP/tJDbzp3C6ZMGRSEyEdlfq1evZsyYMbEOo8tr7Xs0s6XOuZzW1o9a05CZDTGzBWa2ysxWmtn3W1nHzGyumeWa2YdmNjVa8YT9y0cbImoaEhFpKZpNQw3ANc65ZWaWBiw1s5edc6tarHMKMMp/zQDu9P894MJxahoSEWlN1GoEzrl859wy/305sBoYvMtqZwAPOs97QE8zGxiNeJpuKGtQIhAR2UmnXDVkZsOAKcCiXRYNBja1mM5j92SBmV1mZkvMbElhYeE+xaAhJkREWhf1RGBmqcA/gR845/bpNkHn3N3OuRznXE7fvn33KY6whpgQEWlVVBOBmcXjJYFHnHP/amWVzcCQFtNZ/rwDLl5DTIiItCqaVw0ZcA+w2jn3xzZWexaY4189NBModc7lRyOeL/oIVCMQkfY9/fTTmBlr1qyJdSidIpo1glnAhcBxZrbcf51qZleY2RX+Oi8A64Fc4G/A96IVTNNVQ3XqLBaRPZg3bx5HHHEE8+bNi9o+Ghsbo7btvRXNq4becs6Zc26ic26y/3rBOfdX59xf/XWcc+6/nXOHOOcmOOf2/k6xDjIzwnGmGoGItKuiooK33nqLe+65h0cffRTwTto//vGPGT9+PBMnTuS2224D4P333+fwww9n0qRJTJ8+nfLycu6//36uvPLK5u199atf5fXXXwe8O4qvueYaJk2axLvvvssvfvELpk2bxvjx47nssstousE3NzeXE044gUmTJjF16lTWrVvHnDlzePrpp5u3e/755/PMM88ckDIHZogJ8IaZUB+BSBfx4vWw9aMDu80BE+CUW9pd5ZlnnuHkk09m9OjRZGZmsnTpUhYvXsyGDRtYvnw54XCY4uJi6urqOOecc3jssceYNm0aZWVl9OjRo91tV1ZWMmPGDP7whz8AMHbs2OZB5i688EL+/e9/c/rpp3P++edz/fXXc9ZZZ1FTU0MkEuGSSy7hT3/6E2eeeSalpaW88847PPDAAwfkawnMoHPg9RPUNahGICJtmzdvXvNDZmbPns28efN45ZVXuPzyy5uHmu7duzeffPIJAwcOZNq0aQCkp6c3L29LKBTi7LPPbp5esGABM2bMYMKECbz22musXLmS8vJyNm/ezFlnnQVAUlISycnJHH300axdu5bCwkLmzZvH2Wefvcf9dVSgagTxoTgNMSHSVezhl3s0FBcX89prr/HRRx9hZjQ2NmJmzSf7jgiHw0RanGdqamqa3yclJREKhZrnf+9732PJkiUMGTKEm2++ead1WzNnzhwefvhhHn30Ue677769LF3bAlUj8PoI1DQkIq178sknufDCC9m4cSMbNmxg06ZNDB8+nEmTJnHXXXfR0NAAeAnj0EMPJT8/n/fffx+A8vJyGhoaGDZsGMuXL28epnrx4sWt7qvppN+nTx8qKip48sknAUhLSyMrK6u5P6C2tpaqqioAvv3tb3PrrbcCXrPSgRKoRBAfitNYQyLSpnnz5jU3yTQ5++yzyc/PJzs7m4kTJzJp0iT+8Y9/kJCQwGOPPcZVV13FpEmTOPHEE6mpqWHWrFkMHz6csWPHcvXVVzN1autjafbs2ZNLL72U8ePHc9JJJ+1U63jooYeYO3cuEydO5PDDD2fr1q0A9O/fnzFjxnDxxRcf0HIHZhhqgGN+t4CJWT2Ze+6UAxyViBwIGoa6fVVVVUyYMIFly5a1+1jLg2YY6oNRWH0EItJFvfLKK4wZM4arrrrqgD/bOFCdxeE4U9OQiHRJJ5xwAhs3bozKtgNVI0gIx2nQOZGDXFdrrj7Y7Mv3F6hEoKuGRA5uSUlJFBUVKRnsI+ccRUVFJCUl7dXngtU0FFKNQORglpWVRV5eHvv63BHxkmlWVtZefSZQiSA+ZNTUKxGIHKzi4+MZPnx4rMMInEA1DcWrRiAisptAJYJwnG4oExHZVaASQXxIw1CLiOwqUIlAncUiIrsLVCKID+mGMhGRXQUrEcRpiAkRkV0FKhGEQ7qhTERkV4FKBPGhOOrURyAispOAJQLVCEREdhWoRKBhqEVEdheoRBDvD0OtAa1ERL4QrEQQ8orbEFEiEBFpEqhEEG5KBOonEBFpFqhEEB8yAOrVTyAi0ixQiSAc5yeCBiUCEZEmgUoE8WH1EYiI7CpYiSDOK64GnhMR+UKgEkHY7yNQZ7GIyBcClQiaLh9VjUBE5AsBSwR+Z7FqBCIizQKVCMJxTZ3FqhGIiDQJViJorhEoEYiINAlUIkho7iNQ05CISJNAJQINMSEisruAJQINMSEisqtAJYLmpiENMSEi0ixqicDM7jWzAjP7uI3lx5hZqZkt9183RiuWJs03lGmICRGRZuEobvt+4HbgwXbWedM599UoxrCTsIaYEBHZTdRqBM65hUBxtLa/L3RDmYjI7mLdR3CYma0wsxfNbFxbK5nZZWa2xMyWFBYW7vPONMSEiMjuYpkIlgFDnXOTgNuAp9ta0Tl3t3MuxzmX07dv333eYe+UBACKKmr3eRsiIt1NzBKBc67MOVfhv38BiDezPtHcZ1J8iN4pCeSX1kRzNyIiXUrMEoGZDTAz899P92MpivZ+B6QnsVWJQESkWdSuGjKzecAxQB8zywNuAuIBnHN/Bb4B/JeZNQDVwGznXNR7cQdmJKlGICLSQtQSgXPu3D0svx3v8tJONSAjiQ82lXT2bkVEDlqxvmqo0w3MSKK4so6a+sZYhyIiclAIXCIYkNEDgG1lah4SEYEAJoKBGUkA6icQEfEFLhEMaE4E1TGORETk4BC8RJCuGoGISEuBSwQpiWHSk8K6l0BExBe4RADeUBMlVfWxDkNE5KAQyESQnBCmqq4h1mGIiBwUApkIUhJDVNXpPgIREQhoIkhOCFOpRCAiAgQ2EYSoqlXTkIgIBDYRhNU0JCLiC2Qi8PoIVCMQEYGAJgL1EYiIfKFDicDM/mVmp5lZt0gcKQkh6hoienaxiAgdrxH8BTgPWGtmt5jZoVGMKep6JIQA1E8gIkIHE4Fz7hXn3PnAVGAD8IqZvWNmF5tZfDQDjIaURO95POonEBHZiz4CM8sEvg18F/gA+DNeYng5KpFFUbJqBCIizTr0qEozewo4FHgION05l+8veszMlkQruGhJSfBrBLVKBCIiHX1m8Vzn3ILWFjjncg5gPJ2iqUZQqaYhEZEONw2NNbOeTRNm1svMvhelmKIuWX0EIiLNOpoILnXOlTRNOOd2AJdGJ6ToS1EfgYhIs44mgpCZWdOEmYWAhOiEFH3NNQL1EYiIdLiP4D94HcN3+dOX+/O6pBT1EYiINOtoIrgO7+T/X/70y8DfoxJRJ9ANZSIiX+hQInDORYA7/VeXlxCKIxxnVGooahGRDt9HMAr4DTAWSGqa75wbEaW4osrMvGcSqEYgItLhzuL78GoDDcCxwIPAw9EKqjOkJOq5xSIi0PFE0MM59ypgzrmNzrmbgdOiF1b0JSeENBS1iAgd7yyu9YegXmtmVwKbgdTohRV9yQlhPa5SRISO1wi+DyQDVwNfBi4ALopWUJ1BNQIREc8eawT+zWPnOOd+DFQAF0c9qk6QkhimsLw21mGIiMTcHmsEzrlG4IhOiKVTpSeF2VxSrQ5jEQm8jjYNfWBmz5rZhWb29aZXVCOLsvNmDKW4so7bX8uNdSgiIjHV0USQBBQBxwGn+6+vRiuozjB9eG++PnUwf3tzPTsq62IdjohIzHT0zuJu0S+wq3OnZ/OvZZtZ9FkxJ48fEOtwRERioqN3Ft8HuF3nO+e+c8Aj6kQTszJIio9j0WdFSgQiElgdbRr6N/C8/3oVSMe7gqhNZnavmRWY2cdtLDczm2tmuWb2oZlN3ZvAD4TEcIip2b1YtL64s3ctInLQ6FAicM79s8XrEeBbwJ4eUXk/cHI7y08BRvmvy4jRgHYzhmeyemsZpVX1sdi9iEjMdbRGsKtRQL/2VnDOLQTa+6l9BvCg87wH9DSzgfsYzz6bNrwXzsHyvJI9rywi0g11tI+gnJ37CLbiPaNgfwwGNrWYzvPn5bey/8vwag1kZ2fv5253NiDdG0xVVw6JSFB19KqhtGgHsof93w3cDZCTk7Nbp/X+SPUfW1mucYdEJKA61DRkZmeZWUaL6Z5mduZ+7nszMKTFdJY/r1OlJnmJoKJGiUBEgqmjfQQ3OedKmyaccyXATfu572eBOf7VQzOBUufcbs1C0dYjPkScQUWtOotFJJg6Ogx1awmj3c+a2TzgGKCPmeXhJY54AOfcX4EXgFOBXKCKGA1mZ2akJoaprNVIpCISTB1NBEvM7I/AHf70fwNL2/uAc+7cPSx3/nZiLi0pnnI1DYlIQHW0aegqoA54DHgUqOEgOYkfCKmJYTUNiUhgdfSqoUrg+ijHEjOpSWEqdNWQiARUR68aetnMeraY7mVmL0UvrM6VmhjWVUMiElgdbRrq418pBIBzbgd7uLO4K0lNCus+AhEJrI4mgoiZNd/Sa2bDaGU00q4qTTUCEQmwjl419FPgLTN7AzDgSPwhH7oDr7NYiUBEgqmjncX/MbMcvJP/B8DTQHU0A+tMqUlhquoaaYw4QnEW63BERDpVRwed+y7wfbxhIJYDM4F38R5d2eU1jTdUUdtARo/4GEcjItK5OtpH8H1gGrDROXcsMAXoNuM2p/njDW0traGspp7C8lp+/MQKNReJSCB0tI+gxjlXY2aYWaJzbo2ZHRrVyDpRaqJXC/jO/e+T3TuZk8b158mleZw5eTBHjOoT4+hERKKro4kgz7+P4GngZTPbAWyMXlidq2kE0s0l1eSXVhMOef0E28pqYhmWiEin6Ghn8Vn+25vNbAGQAfwnalF1sqY+AoCIgzfXbgegoLw2ViGJiHSajtYImjnn3ohGILHUMhG0pBqBiATBvj6zuFtpahoygxnDewPecwoKVSMQkQDY6xpBd9RUIxjeJ4XLjhpBn7REtpfXqkYgIoGgGgFfJIIxA9M5fkx/7jhvKgMyktRHICKBoBoBEIozzpg8iNMmDGye1y8tkW1lNTjnMNPdxiLSfSkR+P48e8pO0/3Tk6htiFBWo7uNRaR7U9NQG/qlJwFQoH4CEenmlAja0C8tEdC9BCLS/SkRtKG/XyNYs7Uc57rNoxdERHajRNCGgRlJZPSI55f/XsUpf36T/3ycH+uQRESiQomgDUnxIRZeeyy/PHM8dQ0Rrnl8BZGIagYi0v0oEbQjIzmeC2cO5ZIjh1NZ18jmkm7zLB4RkWZKBB0wun8aAGsLymMciYjIgadE0AGj+3mJ4JOtFTGORETkwFMi6ICM5Hj6pyeydptqBCLS/SgRdNDo/ml8qqYhEemGlAg6aHT/NNZuq6BRVw6JSDejRNBBYwamU9sQ4VM1D4lIN6NE0EFH+g+xf3X1Nr7513e4Y0FujCMSETkwNPpoB/VPT2LC4AzufH0dlXWNrNhUyukTB5GdmRzr0ERE9otqBHvh+DH9qKxrZGBGEqE443fzP4l1SCIi+02JYC98ZewAAC4/agRfnzqYV1dvo6ExEuOoRET2jxLBXhg7KJ35PzyKOYcNY+aITKrqGlm5pSzWYYmI7Bclgr00un8acXHGjOG9AVj8WTGNEcc1j69g0fqiGEcnIrL31Fm8j/qlJzG8TwqLNxSTnZnMP5fl0RiJMGNEZqxDExHZK1GtEZjZyWb2iZnlmtn1rSz/tpkVmtly//XdaMZzoE0f1ptF64v4i38p6aLPivUQGxHpcqKWCMwsBNwBnAKMBc41s7GtrPqYc26y//p7tOKJhnOmD8E5WJFXyoi+KeSX1vB5cVWswxIR2SvRrBFMB3Kdc+udc3XAo8AZUdxfp5ua3YuXfngU/3PyofzxW5MBWLS+OMZRiYjsnWgmgsHAphbTef68XZ1tZh+a2ZNmNiSK8UTFoJ49+N4xI5mUlUHvlARe/DhfTzITkS4l1lcNPQcMc85NBF4GHmhtJTO7zMyWmNmSwsLCTg2wo8yMiw8fxoJPCjl17pt85U9vkFtQQVVdA9V1jbEOT0SkTdG8amgz0PIXfpY/r5lzruX1ln8H/q+1DTnn7gbuBsjJyTlof25fedxIQiHjxY+2smlHFRfdu5iSqjoaIo5v5QzhmzlZ/NfDy/ifkw/ljMmtVY5ERDqfResqFzMLA58Cx+MlgPeB85xzK1usM9A5l++/Pwu4zjk3s73t5uTkuCVLlkQl5gPpvfVFXHjPImYMz6RfeiL/WraZtMQw5bUNhOOM+y+ezhH+QHZNCsprSAyHyOgRH6OoRaS7MrOlzrmc1pZFrWnIOdcAXAm8BKwGHnfOrTSzX5jZ1/zVrjazlWa2Arga+Ha04ulsM0dksvRnJ/LQJdP5wzcncfK4AZTXNnD7eVMYmpnMDU9/RF1DhDVby5h997us3VbOmbe/zTWPL4916CISMFGrEURLV6kR7Kq2oZF1BZWMHZTOgk8KuPi+9/nJKV/i7XVFLPy0kD6piWyvqCUcZzz1vVm8+HE+Vx43kuSEL1rvSqvr+fXzq/jJKWPolZIQw9KISFfTXo1AdxZ3ksRwiLGD0gE4ZnRfjvtSP37z4hoARvVLZW1BBf3TE9lWVst5f3uP8toGPi+uondKAieM6c9Ro/vydu52Hl+Sx+QhvSgsryU1KcwlRwyPZbFEpBuI9VVDgWRm/OX8qVwwM5uJWRk8fvlhnDSuP3NnTyG7dzLltQ1MGtKTf3+Yz4PvbuTmZ1cSiThyCyoAeOPTAu58I5c7X1+nS1VFZL+pRhAjSfEhfnXmhObpuy70amyXHz2Ct3O3c+s5U3hm+WZ2VNXxvy+s4fVPC1hX6CWC+au24RzU1NeyKr+M8YMzWt1HaXU91z6xghPH9uebOV3uFg0R6SRKBAeZ82cM5fwZQwH4Zs4Q6hsj3PPWZ9z/zkaKKmoBcA6S4uOobYiwYE3BTolga2kN5TX1ZGcmc/F9i1n2eQmvrN5GWlI8J48fEJMyicjBTU1DB7n4UBxnT83i7dzt5BZUND87+ZjR/Zg4OIPHlmzi9tfWUtvg3bR2zRPLOfdvi3htdQHLPi/hV2eOZ8zAdK54eCkX37eYVXp+gojsQomgCzhxbH8aI47ahggnjRvA7GlDuOTI4Zw7PZvK2gZ+P/9THnp3I/ml1byzrojtFbXc9louqYlhzpk2hCevOJzrT/kSSzfu4Ku3vcmCNQUAvPhRPt/667tc9uAS3f0sEmBKBF3ApKye9EtLBLwrjG45eyLThvVm9vRsPrjxKxw1ui+3vZbLfW9vwDmIM1iVX8aRo/oQH4qjR0KIK44+hDf/5zhG90/jR48vJ7+0mj+/upbVW8uYv2ob/1mZT1lNPTX1+54QDpZLkfN2VDXXfJpqSk02bK/kyn8s457TesYAABI2SURBVJrHV/D4+5soq6lvXrZr/JuKq7jlxTXkl1YDXrPbq6u37VMH/dKNO/h4c+lef25fRCKu1WMRibjdvg8R0H0EXcZPn/qIRxZ9zpIbTqBPauJOy1ZuKeWM29+mIeKYPKQnieE4Fn1WzG/PnsA507J3WnddYQWnzX2T8YMyWLJxBz/76ljue/szMlMSyNtRTVlNPadPHMTNZ4zjscWbeCt3O+k94hmUkURJVT0l1XXccNpYBmYkEWfGf1Zu5f53NvDTU8fw4ydW8PWpWfzXMYe0WoZln+/gyaV5fPeI4Tz83uc0RCJk9IinvKaB0ycNorC8holZPdlQVEluQQUXzhyKmQGQW1BOSVU9OcN6N29v8WfF/GPRRnILK+iTmsgvvjaeJRuLueHpjwH4x6UzmX33u5w6fiA3nT6OgvIavn3f+5RW15MUH2J7RS3ZvZOZd9lMauob+fpf3iEpPo6R/VLpER/i3XVFVNY1MrJfKt+ZNZzfz/+E4so6vjy0F1cdN5Kk+BCZKQlsLavh1dUFXHXcSDbtqKauIcJrawp4bc02vjQgnSNG9uGGZz4GB3+ePbm5r2ZDURWNkQg9kxMoqapndX4Zn24rZ2S/VKZm9yItKUx6UjwfbNrBiD6p1EciPLt8C6u2lJHVO5ltpTXUN0ZITgwxqGcPjhrVlz++/CnvrS+iV3ICFx42lDmHDSXOjCUbdvDz51ZSWdvA3XNyKKmqZ8LgDJbnlVDfEGF43xTeWVfEgPQk3s7dztqCctKT4vlWzhCOObQvAB/mlXLv25+xvrCSH544isE9k8nunUyPhFDzMampb+TlVdsYlpnC+MHpPLN8C/e+/RmDe/bgy0N7ccKY/gzNTGZLaQ0Njd73VNsQYczAdMYOTKdPagKLPyumZ3ICQzOTKa6sIzkhxHvri0mMj2Pi4Ay2V9Tx4sf5nDCmP7UNEfqlJVJYUcuyjTs4fdIgPvi8hNqGRhLDcSQnhJk5IpOEcBzbK2p5O3c7lbWNZPdO5p112zl3ejZDeifzzPLNvLxqG8d9qR8DMpKYPKQnVXWNLNu4g4RwHInhED0SQozom0JaYpiXVm7j4fc2ctghmYzsl8qQXsnNl4fXNjRy6ytrWbutgmGZyZw8fgBlNfX8c9lmEsNxfGXsAI4c1YcP80qZkt2TpPgvvr/6xghbS2v4x+LPyfQvHTeDoZkpbNheSVpSmMxd/v93VHv3ESgRdBHbymp4O3c7X5+a1ery3IJy5q/axuGH9GH55zv43xfW8OZ1x9I/PWm3dW95cQ1/fWMdZvDu9cfzyKKN3PZaLknxcZw1ZTDzFm8iJSFEZV0jo/qlUlXXSFFlLT3iQ9Q3OlISQ1TWNpKZmkB+aQ11DRHMvE7scJxxw2ljeGddEe+tL2JQzx5EnCMlMczKLWXUNUQAr9aSGA5R1xghFGfN8xNCcdQ1eu9PnzSIjB5hGhod/1q2mbrGCP997CEcOaov28pquPaJD0lNCjNhcAYffL6DUJyxo6qeMQPTWZ1fRv/0RIoq6og4R5wZjc6RlhjmH5fOZNygdN5ZV8QVDy8lOSFEzx7eCf2EMf3JLaygpq6RcYPSOfrQvlz75IfUNUQY2S+V2dOGcNfC9RSW1+72vaYmhqmobWienjmiN59sLWdHVT3ZvZPplZLAik0ljOibQnVdI/mlNe0eczPol+bdW5KS4H33dY2R5psPM1MSSPaPRXFlHQBpSWG+PmUwn26r4N31RSSE46hvjOAcDEhPoq4x0rxu0zHbVUI4jvGD0vm8uJrtFbVMHtKTgrIatpTWkJwQorf/owG8ixaOGtWXfumJvLe+mPySairrGokzb2TevB3VjOqXSnV9I3k7qgnHGcP7pLDWvxR6V01la/ob2bXyFYozDGjYi1pZckKIXskJbC6p3m3ZoIwkJmRl8NLKbSQnhKjym0gHpCdRVddAWU3DTusnhOPI6BFPYXkt/dISKWjxd5DdOxmHIxKBzSXVHNo/jc+2Vzb/PfdOScCAoso6wnFGQ8SRmZJAQjiOHvEh0nrE82FeSXOtvmURDxuRyZKNxZw3PZufnzG+w2VvSYkgYBojjm1lNQzq2aPV5SVVdRz52wWMGZjO41ccxsaiSk66dSE3nz6O2dOzuXvhOh57fxO/PGM8h4/ceTykFZtKuPTBJUzN7sW6wgoizvGDE0bz8+dW8sMTR/Onlz9le0UdfdMSOWZ0X7ZX1BIfiqO0up7M1ATmHDaMv7+5ngtmDuXwQ/oQcY6qukZe/6SAgRk9eOqDPDJ6xGNm3L1wPWlJYXBw+MhMEsMhnl2xpTmWLw1I47HLDiMjOZ6lG4uZc89iTpkwkN98fQKn3/YWa7aWc07OEC46fBjPfbiFhFAccw4butMvqpVbSrnm8RWs2VrObedO4fRJg3b7vgrKaqisa2RIrx6EQ3HUNjSyYE0BPRLCbCquIuIcYwamc8uLazhxbH9G9Uulb1oiE7N6UlHbwD+X5nHMoX3pn57EE0s28crqAnomx5MztBepSWHKaxpITQxz6IA0DumbyopNJWwsqmJzSTUrt5Ry/Jj+LN24g+SEEBcdPoxD+qZSU9+40y/J1fllPLtiC+fPyCarVzIASzcW89yKfHomxzNmYDqzRvZha2k1T32wmclDevHB5zs4pG8qGT3i2VhcxTGH9qWwvJZD+6fRKyWB+sYIj76/iXveXM/IfqmcNG4AXxk7gIRwHC+t3IoZLNu4g/mrtlFcWceskX3I6tWDY7/UjwVrCvhseyVnT83i9EmDCMUZm0uqufP1XFZuKeO0CQNJSQyTM7QXfdMSWbO1nOWbSvgwr4SjR/elpj5CUUUt/f2aaM7QXgAsXFtIdV2EC2Zm8866IvqkJvJ5cSXgDevy/If5zByRyZDePahrcGwtq2bhp9vZUVXH6P5pHDGyD6lJYdYVVNA7JYHLHloKwHnTs7nq+JF8urWCrWU13LEgl5TEEFcfN8o75vWNVNY18s667eyorOOIUX05c/Ig8nZUU17TwKLPivjg8xLiQ0ZJdT3n5AzhlAkDKa6sY8mGYpITwuQM60V8KI5nlm9mxaYSpg7txfyV20gIx1FWXU9JdT0zhvemT2oiJ47tT2FFLWu3lbOxqIrH3t/EV8b154cnjqZf2u4/7jpCiUB28/HmUtKT4snO9E4adQ0REsJ712XknCPivF9pzjnMjLXbyimsqGXG8ExCcbZfMZbV1JOWGG5uHgKv3X5jURU19Y3MGNGbtKQvBujzmgO8k+MjizZy4zMref7qI/jSgPR291PfGGHD9kpG9U/br3iDyjlHY8QRDnW9LsfqukbiQ9YlY99bSgQSOM458kvbrhWJBE1MRh8ViSUzUxIQ6SAlAhGRgFMiEBEJOCUCEZGAUyIQEQk4JQIRkYBTIhARCTglAhGRgFMiEBEJOCUCEZGAUyIQEQk4JQIRkYBTIhARCTglAhGRgFMiEBEJOCUCEZGAUyIQEQk4JQIRkYBTIhARCTglAhGRgFMiEBEJOCUCEZGAUyIQEQk4JQIRkYBTIhARCTglgn1VXwN1lbHbV12VN39/OQdVxfu/Hdk7VcXedy+dT3/zu4lqIjCzk83sEzPLNbPrW1meaGaP+csXmdmwaMZzwDgH82bD30+AxobO31ekEe79Cjzyjf0/mSy5F34/Grat3P9YpWMK1sAfDoXFd8c6kmDS3/xuopYIzCwE3AGcAowFzjWzsbusdgmwwzk3EvgT8NtoxXNArXsN1i+AglXw4aOdv6+PnoCtH8GGN2Hty/u+7doKeP03EKmHV395YOKVPXvtl9BYB2/8FmrKYh1NsOhvvlXmolQ9NbPDgJudcyf50z8BcM79psU6L/nrvGtmYWAr0Ne1E1ROTo5bsmTJ3geU+wq89NO9/1xryvMhKQOSM2H7WsjIOjDb7ei+SjdD7+FQWw7VxZA2cN+2XVcJpZtg7Jmw6mnocyiYHdj4ZWfOwfZPYOwZsOoZSM+CxNRYRxUcXf1vfsqFcPiV+/RRM1vqnMtpbVl4v4Jq32BgU4vpPGBGW+s45xrMrBTIBLa3XMnMLgMuA8jOzt63aBLToe+h+/bZXfX9EuR8xztBv30ruMiB2W5H99VvDBx+lddP8P7fgf1I5jnfgRlXeNuvKTlgYUs7smfASb+BwV+GzUtjHU3wdOW/+dR+UdlsNGsE3wBOds5915++EJjhnLuyxTof++vk+dPr/HW2t7ZN2I8agYhIgLVXI4hmZ/FmYEiL6Sx/Xqvr+E1DGUBRFGMSEZFdRDMRvA+MMrPhZpYAzAae3WWdZ4GL/PffAF5rr39AREQOvKj1Efht/lcCLwEh4F7n3Eoz+wWwxDn3LHAP8JCZ5QLFeMlCREQ6UTQ7i3HOvQC8sMu8G1u8rwG+Gc0YRESkfbqzWEQk4JQIREQCTolARCTglAhERAIuajeURYuZFQIb9/HjfdjlruWACGK5g1hmCGa5VeaOGeqc69vagi6XCPaHmS1p68667iyI5Q5imSGY5VaZ95+ahkREAk6JQEQk4IKWCIL6JJAgljuIZYZglltl3k+B6iMQEZHdBa1GICIiu1AiEBEJuMAkAjM72cw+MbNcM7s+1vFEi5ltMLOPzGy5mS3x5/U2s5fNbK3/b69Yx7m/zOxeMyvwH27UNK/Vcppnrn/sPzSzqbGLfN+1UeabzWyzf7yXm9mpLZb9xC/zJ2Z2Umyi3j9mNsTMFpjZKjNbaWbf9+d322PdTpmjd6ydc93+hTcM9jpgBJAArADGxjquKJV1A9Bnl3n/B1zvv78e+G2s4zwA5TwKmAp8vKdyAqcCLwIGzAQWxTr+A1jmm4Eft7LuWP/vPBEY7v/9h2Jdhn0o80Bgqv8+DfjUL1u3PdbtlDlqxzooNYLpQK5zbr1zrg54FDgjxjF1pjOAB/z3DwBnxjCWA8I5txDvGRYttVXOM4AHnec9oKeZDeycSA+cNsrcljOAR51ztc65z4BcvP8HXYpzLt85t8x/Xw6sxnvWebc91u2UuS37fayDkggGA5taTOfR/hfblTlgvpktNbPL/Hn9nXP5/vutQP/YhBZ1bZWzux//K/1mkHtbNPt1uzKb2TBgCrCIgBzrXcoMUTrWQUkEQXKEc24qcArw32Z2VMuFzqtLdvtrhoNSTuBO4BBgMpAP/CG24USHmaUC/wR+4Jwra7msux7rVsoctWMdlESwGRjSYjrLn9ftOOc2+/8WAE/hVRG3NVWP/X8LYhdhVLVVzm57/J1z25xzjc65CPA3vmgS6DZlNrN4vBPiI865f/mzu/Wxbq3M0TzWQUkE7wOjzGy4mSXgPRv52RjHdMCZWYqZpTW9B74CfIxX1ov81S4CnolNhFHXVjmfBeb4V5TMBEpbNCt0abu0f5+Fd7zBK/NsM0s0s+HAKGBxZ8e3v8zM8J5tvto598cWi7rtsW6rzFE91rHuIe/EnvhT8Xrf1wE/jXU8USrjCLyrB1YAK5vKCWQCrwJrgVeA3rGO9QCUdR5e9bger030krbKiXcFyR3+sf8IyIl1/AewzA/5ZfrQPyEMbLH+T/0yfwKcEuv497HMR+A1+3wILPdfp3bnY91OmaN2rDXEhIhIwAWlaUhERNqgRCAiEnBKBCIiAadEICIScEoEIiIBp0Qg0onM7Bgz+3es4xBpSYlARCTglAhEWmFmF5jZYn/c97vMLGRmFWb2J3+M+FfNrK+/7mQze88fDOypFmPjjzSzV8xshZktM7ND/M2nmtmTZrbGzB7x7yQViRklApFdmNkY4BxglnNuMtAInA+kAEucc+OAN4Cb/I88CFznnJuId+dn0/xHgDucc5OAw/HuCgZvNMkf4I0jPwKYFfVCibQjHOsARA5CxwNfBt73f6z3wBvULAI85q/zMPAvM8sAejrn3vDnPwA84Y/5NNg59xSAc64GwN/eYudcnj+9HBgGvBX9Yom0TolAZHcGPOCc+8lOM81+tst6+zo+S22L943o/6HEmJqGRHb3KvANM+sHzc/HHYr3/+Ub/jrnAW8550qBHWZ2pD//QuAN5z1ZKs/MzvS3kWhmyZ1aCpEO0i8RkV0451aZ2Q14T3qLwxvt87+BSmC6v6wArx8BvGGQ/+qf6NcDF/vzLwTuMrNf+Nv4ZicWQ6TDNPqoSAeZWYVzLjXWcYgcaGoaEhEJONUIREQCTjUCEZGAUyIQEQk4JQIRkYBTIhARCTglAhGRgPv/+RhhJc33hZIAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HneuM16wUntF"
      },
      "source": [
        "## Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsPGafxUUsQO",
        "outputId": "968829d8-8f24-4434-8a6b-d0647316f72b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USE GPU 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1500.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1501.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1502.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1510.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1511.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1512.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1520.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1521.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1522.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1530.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1531.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1532.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1540.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1541.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1542.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1550.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1551.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1552.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1560.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1561.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1562.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1570.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1571.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1572.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1580.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1581.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1582.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1590.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1591.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1592.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1600.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1601.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1602.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1610.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1611.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1612.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1620.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1621.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1622.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1630.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1631.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1632.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1640.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1641.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1642.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1650.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1651.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1652.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1660.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1661.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1662.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1670.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1671.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1672.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1680.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1681.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1682.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1690.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1691.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1692.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1700.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1701.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1702.png\n",
            "Test Done!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os, argparse\n",
        "import cv2\n",
        "\n",
        "def test_arguments():\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument('--testsize', type=int, default=352, help='testing size')\n",
        "  parser.add_argument('--gpu_id',   type=str, default='0', help='select gpu id')\n",
        "  parser.add_argument('--test_path',type=str, default='/content/tmp/testdataset_only_depth/',help='test dataset path')\n",
        "  return parser.parse_args(\"\")\n",
        "\n",
        "opt = test_arguments()\n",
        "\n",
        "dataset_path = opt.test_path\n",
        "\n",
        "#set device for test\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        " \n",
        "\n",
        "#load the model\n",
        "model = SPNet(32,50)\n",
        "model.cuda()\n",
        "\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Checkpoint/path_with_same_input/SPNet_best_epoch_perceptual_loss_same_input.pth'))\n",
        "model.eval()\n",
        "\n",
        "#test\n",
        "test_datasets = ['NJU2K','NLPR', 'DES'] \n",
        "\n",
        "test_datasets = ['DES'] \n",
        "\n",
        "\n",
        "for dataset in test_datasets:\n",
        "    save_path = '/content/drive/MyDrive/test_maps/SPNet_new/' + dataset + '/'\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "        \n",
        "    image_root  = str(dataset_path + dataset + '/RGB/')\n",
        "    gt_root     = str(dataset_path + dataset + '/GT/')\n",
        "    depth_root  = str(dataset_path + dataset + '/depth/')\n",
        "    test_loader = test_dataset(image_root, gt_root,depth_root, opt.testsize)\n",
        "    for i in range(test_loader.size):\n",
        "        image, gt,depth, name, image_for_post = test_loader.load_data()\n",
        "        gt      = np.asarray(gt, np.float32)\n",
        "        gt     /= (gt.max() + 1e-8)\n",
        "        image   = image.cuda()\n",
        "        depth   = depth.cuda()\n",
        "        pre_res = model(image,depth)\n",
        "        res     = pre_res[2]     \n",
        "        res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "        res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "        res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "        \n",
        "        print('save img to: ',save_path+name)\n",
        "        cv2.imwrite(save_path+name,res*255)\n",
        "    print('Test Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_GSFjpOi58H"
      },
      "source": [
        "#PNG to Nifti File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAas9xX7zEMG",
        "outputId": "6790641f-611b-410b-c276-f61ff8af075f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.1.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.4 MB 36 kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install SimpleITK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVnG8oPlnt3X"
      },
      "outputs": [],
      "source": [
        "import SimpleITK as sitk\n",
        "import os\n",
        "\n",
        "dirPth = '/content/drive/MyDrive/test_maps/SPNet_new/DES/'\n",
        "file_names = [dirPth + f for f in os.listdir(dirPth) if f.endswith('.png')]\n",
        "\n",
        "#file_names = glob.glob('*.png')\n",
        "reader = sitk.ImageSeriesReader()\n",
        "reader.SetFileNames(file_names)\n",
        "vol = reader.Execute()\n",
        "sitk.WriteImage(vol, dirPth + 'des_psnrMse_ssim_100.nii.gz')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "spnet_with_same_input.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "068e6e83d28b43ae856e8fecb89d4b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a99a99da932477e84d1a2e7943c0427",
            "placeholder": "​",
            "style": "IPY_MODEL_664c0c86ffd74162989a3345327b1e57",
            "value": "100%"
          }
        },
        "09fb191651614417a0fc3521e708b834": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "617f158750ad4178b5359ae4b5bb6b2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "641b4f6ccb7e4990a995898ad31c23be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65bcef97a60a472ca515aebaacad69a3",
            "max": 103197949,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_710076496e4f4dd4a4c0e38e6b8aa53d",
            "value": 103197949
          }
        },
        "653c429900a54f46a0495f6d8548260f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65bcef97a60a472ca515aebaacad69a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "664c0c86ffd74162989a3345327b1e57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "710076496e4f4dd4a4c0e38e6b8aa53d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a99a99da932477e84d1a2e7943c0427": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ab5f00d782d48bebcc25eee1e1e9e38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_617f158750ad4178b5359ae4b5bb6b2e",
            "placeholder": "​",
            "style": "IPY_MODEL_09fb191651614417a0fc3521e708b834",
            "value": " 98.4M/98.4M [03:18&lt;00:00, 397kB/s]"
          }
        },
        "8749833372c34712944b35ab0fa2a15b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_068e6e83d28b43ae856e8fecb89d4b9d",
              "IPY_MODEL_641b4f6ccb7e4990a995898ad31c23be",
              "IPY_MODEL_7ab5f00d782d48bebcc25eee1e1e9e38"
            ],
            "layout": "IPY_MODEL_653c429900a54f46a0495f6d8548260f"
          }
        },
        "18fb49cda74b49b1bba4a1daa1150d4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bd734e645d1461c8ca3eaa9de6b33df",
              "IPY_MODEL_181dc99c9e074f31af80556b0fa351ae",
              "IPY_MODEL_f0dd95ac020747d59eea02979fb6b000"
            ],
            "layout": "IPY_MODEL_a908d4492b9648869a2dc42523144edf"
          }
        },
        "1bd734e645d1461c8ca3eaa9de6b33df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6873fdf4fd9a45e0826db1685ac9df2b",
            "placeholder": "​",
            "style": "IPY_MODEL_6a82093eaf1e479db16e71ec28e32671",
            "value": "100%"
          }
        },
        "181dc99c9e074f31af80556b0fa351ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2df8a1d6d3d448c3a74c2de0befdc799",
            "max": 103197949,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c2a4d95688e427dbb441838fefe428a",
            "value": 103197949
          }
        },
        "f0dd95ac020747d59eea02979fb6b000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d472394639104e0daf46e59d69478491",
            "placeholder": "​",
            "style": "IPY_MODEL_69b927c30c0e4f19a00eeb18281f0b75",
            "value": " 98.4M/98.4M [00:24&lt;00:00, 8.92MB/s]"
          }
        },
        "a908d4492b9648869a2dc42523144edf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6873fdf4fd9a45e0826db1685ac9df2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a82093eaf1e479db16e71ec28e32671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2df8a1d6d3d448c3a74c2de0befdc799": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c2a4d95688e427dbb441838fefe428a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d472394639104e0daf46e59d69478491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69b927c30c0e4f19a00eeb18281f0b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}