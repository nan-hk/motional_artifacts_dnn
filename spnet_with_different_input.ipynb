{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nan-hk/motional_artifacts_dnn/blob/master/spnet_with_different_input.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKPfkuuXJ_IB"
      },
      "source": [
        "# Salient Object Detection Model with Different Modelities Input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4vHYiJEPBRW"
      },
      "source": [
        "##Requirement Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73_3TQiIPG5e",
        "outputId": "b4db104e-01a9-473d-8e88-061236aa8d92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting piqa\n",
            "  Downloading piqa-1.2.2-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from piqa) (0.13.0+cu113)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from piqa) (1.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.0->piqa) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9.0->piqa) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9.0->piqa) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9.0->piqa) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.0->piqa) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.0->piqa) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.0->piqa) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.9.0->piqa) (3.0.4)\n",
            "Installing collected packages: piqa\n",
            "Successfully installed piqa-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install piqa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shxlFTxTQA0w",
        "outputId": "c39f6f3e-9e46-4e51-c0fd-cc8c690a8a5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 35.5 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 92 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 102 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 112 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 122 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 125 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShWXdTv3RNvf"
      },
      "source": [
        "## Different Modalities Dataset\n",
        " \n",
        "\n",
        "1.   RGB as RGB dataset\n",
        "2.   Depth as depth dataset with noise\n",
        "3.   GT as GT dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Grv8GfrReKm",
        "outputId": "fd564cfc-4839-4967-b91b-d5f1fee06aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/traindataset.zip\", 'r') #depth more artifacts\n",
        "zip_ref.extractall(\"/content/tmp\")\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdF4x7UkRzgU"
      },
      "outputs": [],
      "source": [
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/testdataset.zip\", 'r') #depth more artifacts\n",
        "zip_ref.extractall(\"/content/tmp\")\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz5sCv8JQcXM"
      },
      "source": [
        "## Res2Net Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJk30OH8Qg49"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "__all__ = ['Res2Net', 'res2net50_v1b', 'res2net101_v1b']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'res2net50_v1b_26w_4s': 'https://shanghuagao.oss-cn-beijing.aliyuncs.com/res2net/res2net50_v1b_26w_4s-3cf99910.pth',\n",
        "    'res2net101_v1b_26w_4s': 'https://shanghuagao.oss-cn-beijing.aliyuncs.com/res2net/res2net101_v1b_26w_4s-0812c246.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class Bottle2neck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, baseWidth=26, scale = 4, stype='normal'):\n",
        "        \"\"\" Constructor\n",
        "        Args:\n",
        "            inplanes: input channel dimensionality\n",
        "            planes: output channel dimensionality\n",
        "            stride: conv stride. Replaces pooling layer.\n",
        "            downsample: None when stride = 1\n",
        "            baseWidth: basic width of conv3x3\n",
        "            scale: number of scale.\n",
        "            type: 'normal': normal set. 'stage': first block of a new stage.\n",
        "        \"\"\"\n",
        "        super(Bottle2neck, self).__init__()\n",
        "\n",
        "        width = int(math.floor(planes * (baseWidth/64.0)))\n",
        "        self.conv1 = nn.Conv2d(inplanes, width*scale, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(width*scale)\n",
        "        \n",
        "        if scale == 1:\n",
        "          self.nums = 1\n",
        "        else:\n",
        "          self.nums = scale -1\n",
        "        if stype == 'stage':\n",
        "            self.pool = nn.AvgPool2d(kernel_size=3, stride = stride, padding=1)\n",
        "        convs = []\n",
        "        bns = []\n",
        "        for i in range(self.nums):\n",
        "          convs.append(nn.Conv2d(width, width, kernel_size=3, stride = stride, padding=1, bias=False))\n",
        "          bns.append(nn.BatchNorm2d(width))\n",
        "        self.convs = nn.ModuleList(convs)\n",
        "        self.bns = nn.ModuleList(bns)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(width*scale, planes * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stype = stype\n",
        "        self.scale = scale\n",
        "        self.width  = width\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        spx = torch.split(out, self.width, 1)\n",
        "        for i in range(self.nums):\n",
        "          if i==0 or self.stype=='stage':\n",
        "            sp = spx[i]\n",
        "          else:\n",
        "            sp = sp + spx[i]\n",
        "          sp = self.convs[i](sp)\n",
        "          sp = self.relu(self.bns[i](sp))\n",
        "          if i==0:\n",
        "            out = sp\n",
        "          else:\n",
        "            out = torch.cat((out, sp), 1)\n",
        "        if self.scale != 1 and self.stype=='normal':\n",
        "          out = torch.cat((out, spx[self.nums]),1)\n",
        "        elif self.scale != 1 and self.stype=='stage':\n",
        "          out = torch.cat((out, self.pool(spx[self.nums])),1)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Res2Net(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, baseWidth = 26, scale = 4, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(Res2Net, self).__init__()\n",
        "        self.baseWidth = baseWidth\n",
        "        self.scale = scale\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, 3, 1, 1, bias=False)\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.AvgPool2d(kernel_size=stride, stride=stride, \n",
        "                    ceil_mode=True, count_include_pad=False),\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion, \n",
        "                    kernel_size=1, stride=1, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample=downsample, \n",
        "                        stype='stage', baseWidth = self.baseWidth, scale=self.scale))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, baseWidth = self.baseWidth, scale=self.scale))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x0 = self.maxpool(x)\n",
        "        \n",
        "\n",
        "        x1 = self.layer1(x0)\n",
        "        x2 = self.layer2(x1)\n",
        "        x3 = self.layer3(x2)\n",
        "        x4 = self.layer4(x3)\n",
        "\n",
        "        x5 = self.avgpool(x4)\n",
        "        x6 = x5.view(x5.size(0), -1)\n",
        "        x7 = self.fc(x6)\n",
        "\n",
        "        return x7\n",
        "\n",
        "\n",
        "\n",
        "class Res2Net_Ours(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, baseWidth = 26, scale = 4, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(Res2Net_Ours, self).__init__()\n",
        "        \n",
        "        self.baseWidth = baseWidth\n",
        "        self.scale = scale\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, 3, 1, 1, bias=False)\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "       \n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.AvgPool2d(kernel_size=stride, stride=stride, \n",
        "                    ceil_mode=True, count_include_pad=False),\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion, \n",
        "                    kernel_size=1, stride=1, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample=downsample, \n",
        "                        stype='stage', baseWidth = self.baseWidth, scale=self.scale))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, baseWidth = self.baseWidth, scale=self.scale))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x0 = self.maxpool(x)\n",
        "        \n",
        "\n",
        "        x1 = self.layer1(x0)\n",
        "        x2 = self.layer2(x1)\n",
        "        x3 = self.layer3(x2)\n",
        "        x4 = self.layer4(x3)\n",
        "\n",
        "\n",
        "        return x0,x1,x2,x3,x4\n",
        "    \n",
        "    \n",
        "\n",
        "def res2net50_v1b(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b model.\n",
        "    Res2Net-50 refers to the Res2Net-50_v1b_26w_4s.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 4, 6, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net50_v1b_26w_4s'],map_location='cpu'))\n",
        "    return model\n",
        "\n",
        "def res2net101_v1b(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 4, 23, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net101_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def res2net50_v1b_Ours(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b model.\n",
        "    Res2Net-50 refers to the Res2Net-50_v1b_26w_4s.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net_Ours(Bottle2neck, [3, 4, 6, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net50_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "def res2net101_v1b_Ours(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net_Ours(Bottle2neck, [3, 4, 23, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net101_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def res2net50_v1b_26w_4s(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 4, 6, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net50_v1b_26w_4s'],map_location='cpu'))\n",
        "    return model\n",
        "\n",
        "def res2net101_v1b_26w_4s(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 4, 23, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net101_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "def res2net152_v1b_26w_4s(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 8, 36, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net152_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "def Res2Net_model(ind=50):\n",
        "    \n",
        "    if ind == 50:\n",
        "        model_base = res2net50_v1b(pretrained=True)\n",
        "        model      = res2net50_v1b_Ours()\n",
        "\n",
        "    if ind == 101:\n",
        "        model_base = res2net101_v1b(pretrained=True)\n",
        "        model      = res2net101_v1b_Ours()\n",
        "        \n",
        "        \n",
        "    pretrained_dict = model_base.state_dict()\n",
        "    model_dict      = model.state_dict()\n",
        "    \n",
        "    pretrained_dict =  {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "    \n",
        "    model_dict.update(pretrained_dict)\n",
        "    model.load_state_dict(model_dict)\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    images = torch.rand(1, 3, 352, 352)\n",
        "    model = res2net50_v1b_26w_4s(pretrained=False)\n",
        "    model = model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVSgFX16KrRU"
      },
      "source": [
        "## Salient Object Detection Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBFBDRavJhIf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.nn import functional as F\n",
        "\n",
        "def maxpool():\n",
        "    pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "    return pool\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicConv2d(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1):\n",
        "        super(BasicConv2d, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_planes, out_planes,\n",
        "                              kernel_size=kernel_size, stride=stride,\n",
        "                              padding=padding, dilation=dilation, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "#Global Contextual module\n",
        "class GCM(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel):\n",
        "        super(GCM, self).__init__()\n",
        "        self.relu = nn.ReLU(True)\n",
        "        self.branch0 = nn.Sequential(\n",
        "            BasicConv2d(in_channel, out_channel, 1),\n",
        "        )\n",
        "        self.branch1 = nn.Sequential(\n",
        "            BasicConv2d(in_channel, out_channel, 1),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(1, 3), padding=(0, 1)),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(3, 1), padding=(1, 0)),\n",
        "            BasicConv2d(out_channel, out_channel, 3, padding=3, dilation=3)\n",
        "        )\n",
        "        self.branch2 = nn.Sequential(\n",
        "            BasicConv2d(in_channel, out_channel, 1),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(1, 5), padding=(0, 2)),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(5, 1), padding=(2, 0)),\n",
        "            BasicConv2d(out_channel, out_channel, 3, padding=5, dilation=5)\n",
        "        )\n",
        "        self.branch3 = nn.Sequential(\n",
        "            BasicConv2d(in_channel, out_channel, 1),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(1, 7), padding=(0, 3)),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(7, 1), padding=(3, 0)),\n",
        "            BasicConv2d(out_channel, out_channel, 3, padding=7, dilation=7)\n",
        "        )\n",
        "        self.conv_cat = BasicConv2d(4*out_channel, out_channel, 3, padding=1)\n",
        "        self.conv_res = BasicConv2d(in_channel, out_channel, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x0 = self.branch0(x)\n",
        "        x1 = self.branch1(x)\n",
        "        x2 = self.branch2(x)\n",
        "        x3 = self.branch3(x)\n",
        "\n",
        "        x_cat = self.conv_cat(torch.cat((x0, x1, x2, x3), 1))\n",
        "\n",
        "        x = self.relu(x_cat + self.conv_res(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "class CIM0(nn.Module):    \n",
        "    def __init__(self,in_dim, out_dim):\n",
        "        super(CIM0, self).__init__()\n",
        "        \n",
        "        act_fn = nn.ReLU(inplace=True)\n",
        "        \n",
        "\n",
        "        self.layer_10 = nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer_20 = nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1)   \n",
        "        \n",
        "        self.layer_11 = nn.Sequential(nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)        \n",
        "        self.layer_21 = nn.Sequential(nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "        \n",
        "        self.gamma1 = nn.Parameter(torch.zeros(1))\n",
        "        self.gamma2 = nn.Parameter(torch.zeros(1))\n",
        "        \n",
        "\n",
        "        self.layer_ful1 = nn.Sequential(nn.Conv2d(out_dim*2, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "        \n",
        "\n",
        "    def forward(self, rgb, depth):\n",
        "        \n",
        "        ################################\n",
        "        \n",
        "        x_rgb = self.layer_10(rgb)\n",
        "        x_dep = self.layer_20(depth)\n",
        "        \n",
        "        rgb_w = nn.Sigmoid()(x_rgb)\n",
        "        dep_w = nn.Sigmoid()(x_dep)\n",
        "        \n",
        "        ##\n",
        "        x_rgb_w = rgb.mul(dep_w)\n",
        "        x_dep_w = depth.mul(rgb_w)\n",
        "        \n",
        "        x_rgb_r = x_rgb_w + rgb\n",
        "        x_dep_r = x_dep_w + depth\n",
        "        \n",
        "        ## fusion \n",
        "        x_rgb_r = self.layer_11(x_rgb_r)\n",
        "        x_dep_r = self.layer_21(x_dep_r)\n",
        "        \n",
        "        \n",
        "        ful_mul = torch.mul(x_rgb_r, x_dep_r)         \n",
        "        x_in1   = torch.reshape(x_rgb_r,[x_rgb_r.shape[0],1,x_rgb_r.shape[1],x_rgb_r.shape[2],x_rgb_r.shape[3]])\n",
        "        x_in2   = torch.reshape(x_dep_r,[x_dep_r.shape[0],1,x_dep_r.shape[1],x_dep_r.shape[2],x_dep_r.shape[3]])\n",
        "        x_cat   = torch.cat((x_in1, x_in2),dim=1)\n",
        "        ful_max = x_cat.max(dim=1)[0]\n",
        "        ful_out = torch.cat((ful_mul,ful_max),dim=1)\n",
        "        \n",
        "        out1 = self.layer_ful1(ful_out)\n",
        "         \n",
        "        return out1\n",
        "\n",
        "\n",
        "class CIM(nn.Module):    \n",
        "    def __init__(self,in_dim, out_dim):\n",
        "        super(CIM, self).__init__()\n",
        "        \n",
        "        act_fn = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.reduc_1 = nn.Sequential(nn.Conv2d(in_dim, out_dim, kernel_size=1), act_fn)\n",
        "        self.reduc_2 = nn.Sequential(nn.Conv2d(in_dim, out_dim, kernel_size=1), act_fn)\n",
        "        \n",
        "        self.layer_10 = nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer_20 = nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1)   \n",
        "        \n",
        "        self.layer_11 = nn.Sequential(nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)        \n",
        "        self.layer_21 = nn.Sequential(nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "        \n",
        "        self.gamma1 = nn.Parameter(torch.zeros(1))\n",
        "        self.gamma2 = nn.Parameter(torch.zeros(1))\n",
        "        \n",
        "\n",
        "        self.layer_ful1 = nn.Sequential(nn.Conv2d(out_dim*2, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "        self.layer_ful2 = nn.Sequential(nn.Conv2d(out_dim+out_dim//2, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "\n",
        "    def forward(self, rgb, depth, xx):\n",
        "        \n",
        "        ################################\n",
        "        x_rgb = self.reduc_1(rgb)\n",
        "        x_dep = self.reduc_2(depth)\n",
        "        \n",
        "        x_rgb1 = self.layer_10(x_rgb)\n",
        "        x_dep1 = self.layer_20(x_dep)\n",
        "        \n",
        "        rgb_w = nn.Sigmoid()(x_rgb1)\n",
        "        dep_w = nn.Sigmoid()(x_dep1)\n",
        "        \n",
        "        ##\n",
        "        x_rgb_w = x_rgb.mul(dep_w)\n",
        "        x_dep_w = x_dep.mul(rgb_w)\n",
        "        \n",
        "        x_rgb_r = x_rgb_w + x_rgb\n",
        "        x_dep_r = x_dep_w + x_dep\n",
        "        \n",
        "        ## fusion \n",
        "        x_rgb_r = self.layer_11(x_rgb_r)\n",
        "        x_dep_r = self.layer_21(x_dep_r)\n",
        "        \n",
        "        \n",
        "        ful_mul = torch.mul(x_rgb_r, x_dep_r)         \n",
        "        x_in1   = torch.reshape(x_rgb_r,[x_rgb_r.shape[0],1,x_rgb_r.shape[1],x_rgb_r.shape[2],x_rgb_r.shape[3]])\n",
        "        x_in2   = torch.reshape(x_dep_r,[x_dep_r.shape[0],1,x_dep_r.shape[1],x_dep_r.shape[2],x_dep_r.shape[3]])\n",
        "        x_cat   = torch.cat((x_in1, x_in2),dim=1)\n",
        "        ful_max = x_cat.max(dim=1)[0]\n",
        "        ful_out = torch.cat((ful_mul,ful_max),dim=1)\n",
        "        \n",
        "        out1 = self.layer_ful1(ful_out)\n",
        "        out2 = self.layer_ful2(torch.cat([out1,xx],dim=1))\n",
        "         \n",
        "        return out2\n",
        "\n",
        "\n",
        "\n",
        "class MFA(nn.Module):    \n",
        "    def __init__(self,in_dim):\n",
        "        super(MFA, self).__init__()\n",
        "         \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.layer_10 = nn.Conv2d(in_dim, in_dim, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer_20 = nn.Conv2d(in_dim, in_dim, kernel_size=3, stride=1, padding=1)   \n",
        "        self.layer_cat1 = nn.Sequential(nn.Conv2d(in_dim*2, in_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(in_dim),)        \n",
        "        \n",
        "    def forward(self, x_ful, x1, x2):\n",
        "        \n",
        "        ################################\n",
        "    \n",
        "        x_ful_1 = x_ful.mul(x1)\n",
        "        x_ful_2 = x_ful.mul(x2)\n",
        "        \n",
        "     \n",
        "        x_ful_w = self.layer_cat1(torch.cat([x_ful_1, x_ful_2],dim=1))\n",
        "        out     = self.relu(x_ful + x_ful_w)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "    \n",
        "\n",
        "  \n",
        "   \n",
        "###############################################################################\n",
        "\n",
        "class SPNet(nn.Module):\n",
        "    def __init__(self, channel=32,ind=50):\n",
        "        super(SPNet, self).__init__()\n",
        "        \n",
        "       \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.upsample_2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.upsample_4 = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)\n",
        "        self.upsample_8 = nn.Upsample(scale_factor=8, mode='bilinear', align_corners=True)\n",
        "        \n",
        "        #Backbone model\n",
        "        #Backbone model\n",
        "        self.layer_rgb  = Res2Net_model(ind)\n",
        "        self.layer_dep  = Res2Net_model(ind)\n",
        "        \n",
        "        self.layer_dep0 = nn.Conv2d(1, 3, kernel_size=1)\n",
        "        \n",
        "        ###############################################\n",
        "        # funsion encoders #\n",
        "        ###############################################\n",
        "        self.fu_0 = CIM0(64, 64)#\n",
        "        \n",
        "        self.fu_1 = CIM(256, 128) #MixedFusion_Block_IMfusion\n",
        "        self.pool_fu_1 = maxpool()\n",
        "        \n",
        "        self.fu_2 = CIM(512, 256)\n",
        "        self.pool_fu_2 = maxpool()\n",
        "        \n",
        "        self.fu_3 = CIM(1024, 512)\n",
        "        self.pool_fu_3 = maxpool()\n",
        "\n",
        "        self.fu_4 = CIM(2048, 1024)\n",
        "        self.pool_fu_4 = maxpool()\n",
        "        \n",
        "        \n",
        "        ###############################################\n",
        "        # decoders #\n",
        "        ###############################################\n",
        "        \n",
        "        ## rgb\n",
        "        self.rgb_conv_4   = nn.Sequential(BasicConv2d(2048,    256, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_4    = GCM(2048,  channel)\n",
        "        \n",
        "        self.rgb_conv_3   = nn.Sequential(BasicConv2d(1024+32, 256, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_3    = GCM(1024+32,  channel)\n",
        "\n",
        "        self.rgb_conv_2   = nn.Sequential(BasicConv2d(512+32, 128, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_2    = GCM(512+32,  channel)\n",
        "\n",
        "        self.rgb_conv_1   = nn.Sequential(BasicConv2d(256+32, 128, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_1    = GCM(256+32,  channel)\n",
        "\n",
        "        self.rgb_conv_0   = nn.Sequential(BasicConv2d(64+32, 64, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_0    = GCM(64+32,  channel)        \n",
        "        self.rgb_conv_out = nn.Conv2d(channel, 1, 1)\n",
        "        \n",
        "        ## depth\n",
        "        self.dep_conv_4   = nn.Sequential(BasicConv2d(2048, 256, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_4    = GCM(2048,  channel)\n",
        "        \n",
        "        self.dep_conv_3   = nn.Sequential(BasicConv2d(1024+32, 256, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_3    = GCM(1024+32,  channel)\n",
        "\n",
        "        self.dep_conv_2   = nn.Sequential(BasicConv2d(512+32, 128, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_2    = GCM(512+32,  channel)\n",
        "\n",
        "        self.dep_conv_1   = nn.Sequential(BasicConv2d(256+32, 128, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_1    = GCM(256+32,  channel)\n",
        "\n",
        "        self.dep_conv_0   = nn.Sequential(BasicConv2d(64+32, 64, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_0    = GCM(64+32,  channel)        \n",
        "        self.dep_conv_out = nn.Conv2d(channel, 1, 1)\n",
        "        \n",
        "        ## fusion\n",
        "        self.ful_conv_4   = nn.Sequential(BasicConv2d(2048, 256, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_4    = GCM(1024,  channel)\n",
        "        \n",
        "        self.ful_conv_3   = nn.Sequential(BasicConv2d(1024+32*3, 256, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_3    = GCM(512+32,  channel)\n",
        "\n",
        "        self.ful_conv_2   = nn.Sequential(BasicConv2d(512+32*3, 128, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_2    = GCM(256+32,  channel)\n",
        "\n",
        "        self.ful_conv_1   = nn.Sequential(BasicConv2d(256+32*3, 128, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_1    = GCM(128+32,  channel)\n",
        "\n",
        "        self.ful_conv_0   = nn.Sequential(BasicConv2d(128+32*3, 64, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_0    = GCM(64+32,  channel)        \n",
        "        self.ful_conv_out = nn.Conv2d(channel, 1, 1)\n",
        "        \n",
        "        self.ful_layer4   = MFA(channel)\n",
        "        self.ful_layer3   = MFA(channel)\n",
        "        self.ful_layer2   = MFA(channel)\n",
        "        self.ful_layer1   = MFA(channel)\n",
        "        self.ful_layer0   = MFA(channel)\n",
        "        \n",
        "                \n",
        "\n",
        "    def forward(self, imgs, depths):\n",
        "        \n",
        "        img_0, img_1, img_2, img_3, img_4 = self.layer_rgb(imgs)\n",
        "        dep_0, dep_1, dep_2, dep_3, dep_4 = self.layer_dep(self.layer_dep0(depths))\n",
        "        \n",
        "    \n",
        "      \n",
        "        ####################################################\n",
        "        ## fusion\n",
        "        ####################################################\n",
        "        ful_0    = self.fu_0(img_0, dep_0)\n",
        "        ful_1    = self.fu_1(img_1, dep_1, ful_0)\n",
        "        ful_2    = self.fu_2(img_2, dep_2, self.pool_fu_1(ful_1))\n",
        "        ful_3    = self.fu_3(img_3, dep_3, self.pool_fu_2(ful_2))\n",
        "        ful_4    = self.fu_4(img_4, dep_4, self.pool_fu_3(ful_3))\n",
        "        \n",
        "        ####################################################\n",
        "        ## decoder rgb\n",
        "        ####################################################        \n",
        "        #\n",
        "        x_rgb_42    = self.rgb_gcm_4(img_4)\n",
        "        \n",
        "        x_rgb_3_cat = torch.cat([img_3, self.upsample_2(x_rgb_42)], dim=1)\n",
        "        x_rgb_32    = self.rgb_gcm_3(x_rgb_3_cat)\n",
        "        \n",
        "        x_rgb_2_cat = torch.cat([img_2, self.upsample_2(x_rgb_32)], dim=1)\n",
        "        x_rgb_22    = self.rgb_gcm_2(x_rgb_2_cat)        \n",
        "\n",
        "        x_rgb_1_cat = torch.cat([img_1, self.upsample_2(x_rgb_22)], dim=1)\n",
        "        x_rgb_12    = self.rgb_gcm_1(x_rgb_1_cat)     \n",
        "\n",
        "        x_rgb_0_cat = torch.cat([img_0, x_rgb_12], dim=1)\n",
        "        x_rgb_02    = self.rgb_gcm_0(x_rgb_0_cat)     \n",
        "        rgb_out     = self.upsample_4(self.rgb_conv_out(x_rgb_02))\n",
        "        \n",
        "        \n",
        "        ####################################################\n",
        "        ## decoder depth\n",
        "        ####################################################        \n",
        "        #\n",
        "        x_dep_42    = self.dep_gcm_4(dep_4)\n",
        "        \n",
        "        x_dep_3_cat = torch.cat([dep_3, self.upsample_2(x_dep_42)], dim=1)\n",
        "        x_dep_32    = self.dep_gcm_3(x_dep_3_cat)\n",
        "        \n",
        "        x_dep_2_cat = torch.cat([dep_2, self.upsample_2(x_dep_32)], dim=1)\n",
        "        x_dep_22    = self.dep_gcm_2(x_dep_2_cat)        \n",
        "\n",
        "        x_dep_1_cat = torch.cat([dep_1, self.upsample_2(x_dep_22)], dim=1)\n",
        "        x_dep_12    = self.dep_gcm_1(x_dep_1_cat)     \n",
        "\n",
        "        x_dep_0_cat = torch.cat([dep_0, x_dep_12], dim=1)\n",
        "        x_dep_02    = self.dep_gcm_0(x_dep_0_cat)     \n",
        "        dep_out     = self.upsample_4(self.dep_conv_out(x_dep_02))\n",
        "        \n",
        "\n",
        "        ####################################################\n",
        "        ## decoder fusion\n",
        "        ####################################################        \n",
        "        #\n",
        "        x_ful_42    = self.ful_gcm_4(ful_4)\n",
        "        \n",
        "        x_ful_3_cat = torch.cat([ful_3, self.ful_layer3(self.upsample_2(x_ful_42),self.upsample_2(x_rgb_42),self.upsample_2(x_dep_42))], dim=1)\n",
        "        x_ful_32    = self.ful_gcm_3(x_ful_3_cat)\n",
        "        \n",
        "        x_ful_2_cat = torch.cat([ful_2, self.ful_layer2(self.upsample_2(x_ful_32),self.upsample_2(x_rgb_32),self.upsample_2(x_dep_32))], dim=1)\n",
        "        x_ful_22    = self.ful_gcm_2(x_ful_2_cat)        \n",
        "\n",
        "        x_ful_1_cat = torch.cat([ful_1, self.ful_layer1(self.upsample_2(x_ful_22),self.upsample_2(x_rgb_22),self.upsample_2(x_dep_22))], dim=1)\n",
        "        x_ful_12    = self.ful_gcm_1(x_ful_1_cat)     \n",
        "\n",
        "        x_ful_0_cat = torch.cat([ful_0, self.ful_layer0(x_ful_12, x_rgb_12, x_dep_12)], dim=1)\n",
        "        x_ful_02    = self.ful_gcm_0(x_ful_0_cat)     \n",
        "        ful_out     = self.upsample_4(self.ful_conv_out(x_ful_02))\n",
        "\n",
        "\n",
        "        return rgb_out, dep_out, ful_out\n",
        "    \n",
        "    \n",
        "\n",
        "    def _make_agant_layer(self, inplanes, planes):\n",
        "        layers = nn.Sequential(\n",
        "            nn.Conv2d(inplanes, planes, kernel_size=1,\n",
        "                      stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(planes),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        return layers\n",
        "\n",
        "    def _make_transpose(self, block, planes, blocks, stride=1):\n",
        "        upsample = None\n",
        "        if stride != 1:\n",
        "            upsample = nn.Sequential(\n",
        "                nn.ConvTranspose2d(self.inplanes, planes,\n",
        "                                   kernel_size=2, stride=stride,\n",
        "                                   padding=0, bias=False),\n",
        "                nn.BatchNorm2d(planes),\n",
        "            )\n",
        "        elif self.inplanes != planes:\n",
        "            upsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, self.inplanes))\n",
        "\n",
        "        layers.append(block(self.inplanes, planes, stride, upsample))\n",
        "        self.inplanes = planes\n",
        "\n",
        "        return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-uZRV-GLXGz"
      },
      "source": [
        "## Data Preprocessing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbveAVtDLglO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import ImageEnhance\n",
        "\n",
        "#several data augumentation strategies\n",
        "def cv_random_flip(img, label,depth):\n",
        "    flip_flag = random.randint(0, 1)\n",
        "    # flip_flag2= random.randint(0,1)\n",
        "    #left right flip\n",
        "    if flip_flag == 1:\n",
        "        img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        label = label.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        depth = depth.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "    #top bottom flip\n",
        "    # if flip_flag2==1:\n",
        "    #     img = img.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "    #     label = label.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "    #     depth = depth.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "    return img, label, depth\n",
        "def randomCrop(image, label,depth):\n",
        "    border=30\n",
        "    image_width = image.size[0]\n",
        "    image_height = image.size[1]\n",
        "    crop_win_width = np.random.randint(image_width-border , image_width)\n",
        "    crop_win_height = np.random.randint(image_height-border , image_height)\n",
        "    random_region = (\n",
        "        (image_width - crop_win_width) >> 1, (image_height - crop_win_height) >> 1, (image_width + crop_win_width) >> 1,\n",
        "        (image_height + crop_win_height) >> 1)\n",
        "    return image.crop(random_region), label.crop(random_region),depth.crop(random_region)\n",
        "def randomRotation(image,label,depth):\n",
        "    mode=Image.BICUBIC\n",
        "    if random.random()>0.8:\n",
        "        random_angle = np.random.randint(-15, 15)\n",
        "        image=image.rotate(random_angle, mode)\n",
        "        label=label.rotate(random_angle, mode)\n",
        "        depth=depth.rotate(random_angle, mode)\n",
        "    return image,label,depth\n",
        "def colorEnhance(image):\n",
        "    bright_intensity=random.randint(5,15)/10.0\n",
        "    image=ImageEnhance.Brightness(image).enhance(bright_intensity)\n",
        "    contrast_intensity=random.randint(5,15)/10.0\n",
        "    image=ImageEnhance.Contrast(image).enhance(contrast_intensity)\n",
        "    color_intensity=random.randint(0,20)/10.0\n",
        "    image=ImageEnhance.Color(image).enhance(color_intensity)\n",
        "    sharp_intensity=random.randint(0,30)/10.0\n",
        "    image=ImageEnhance.Sharpness(image).enhance(sharp_intensity)\n",
        "    return image\n",
        "def randomGaussian(image, mean=0.1, sigma=0.35):\n",
        "    def gaussianNoisy(im, mean=mean, sigma=sigma):\n",
        "        for _i in range(len(im)):\n",
        "            im[_i] += random.gauss(mean, sigma)\n",
        "        return im\n",
        "    img = np.asarray(image)\n",
        "    width, height = img.shape\n",
        "    img = gaussianNoisy(img[:].flatten(), mean, sigma)\n",
        "    img = img.reshape([width, height])\n",
        "    return Image.fromarray(np.uint8(img))\n",
        "def randomPeper(img):\n",
        "\n",
        "    img=np.array(img)\n",
        "    noiseNum=int(0.0015*img.shape[0]*img.shape[1])\n",
        "    for i in range(noiseNum):\n",
        "\n",
        "        randX=random.randint(0,img.shape[0]-1)  \n",
        "\n",
        "        randY=random.randint(0,img.shape[1]-1)  \n",
        "\n",
        "        if random.randint(0,1)==0:  \n",
        "\n",
        "            img[randX,randY]=0  \n",
        "\n",
        "        else:  \n",
        "\n",
        "            img[randX,randY]=255 \n",
        "    return Image.fromarray(img)  \n",
        "\n",
        "# dataset for training\n",
        "#The current loader is not using the normalized depth maps for training and test. If you use the normalized depth maps\n",
        "#(e.g., 0 represents background and 1 represents foreground.), the performance will be further improved.\n",
        "\n",
        "class SalObjDataset(data.Dataset):\n",
        "    def __init__(self, image_root, gt_root,depth_root, trainsize):\n",
        "        self.trainsize = trainsize\n",
        "        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "        self.gts = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.jpg')\n",
        "                    or f.endswith('.png')]\n",
        "        self.depths=[depth_root + f for f in os.listdir(depth_root) if f.endswith('.bmp')\n",
        "                    or f.endswith('.png')]\n",
        "        self.images = sorted(self.images)\n",
        "        self.gts = sorted(self.gts)\n",
        "        self.depths=sorted(self.depths)\n",
        "        print('SalObjDat', )\n",
        "        self.filter_files()\n",
        "        self.size = len(self.images)\n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        self.gt_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor()])\n",
        "        self.depths_transform = transforms.Compose([transforms.Resize((self.trainsize, self.trainsize)),transforms.ToTensor()])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.rgb_loader(self.images[index])\n",
        "        gt = self.binary_loader(self.gts[index])\n",
        "        depth=self.binary_loader(self.depths[index])\n",
        "        image,gt,depth =cv_random_flip(image,gt,depth)\n",
        "        image,gt,depth=randomCrop(image, gt,depth)\n",
        "        image,gt,depth=randomRotation(image, gt,depth)\n",
        "        image=colorEnhance(image)\n",
        "        # gt=randomGaussian(gt)\n",
        "        gt=randomPeper(gt)\n",
        "        image = self.img_transform(image)\n",
        "        gt = self.gt_transform(gt)\n",
        "        depth=self.depths_transform(depth)\n",
        "        \n",
        "        return image, gt, depth\n",
        "\n",
        "    def filter_files(self):\n",
        "        print('SalObjDataset', self.images, self.gts)\n",
        "        assert len(self.images) == len(self.gts) and len(self.gts)==len(self.images)\n",
        "        images = []\n",
        "        gts = []\n",
        "        depths=[]\n",
        "        for img_path, gt_path,depth_path in zip(self.images, self.gts, self.depths):\n",
        "            img = Image.open(img_path)\n",
        "            gt = Image.open(gt_path)\n",
        "            depth= Image.open(depth_path)\n",
        "            if img.size == gt.size and gt.size==depth.size:\n",
        "                images.append(img_path)\n",
        "                gts.append(gt_path)\n",
        "                depths.append(depth_path)\n",
        "        self.images = images\n",
        "        self.gts = gts\n",
        "        self.depths=depths\n",
        "\n",
        "    def rgb_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def binary_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('L')\n",
        "\n",
        "    def resize(self, img, gt, depth):\n",
        "        assert img.size == gt.size and gt.size==depth.size\n",
        "        w, h = img.size\n",
        "        if h < self.trainsize or w < self.trainsize:\n",
        "            h = max(h, self.trainsize)\n",
        "            w = max(w, self.trainsize)\n",
        "            return img.resize((w, h), Image.BILINEAR), gt.resize((w, h), Image.NEAREST),depth.resize((w, h), Image.NEAREST)\n",
        "        else:\n",
        "            return img, gt, depth\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 0919\n",
        "#\n",
        "\n",
        "class SalObjDataset_var(data.Dataset):\n",
        "    def __init__(self, image_root, gt_root,depth_root, trainsize):\n",
        "        \n",
        "        self.trainsize = trainsize\n",
        "        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.jpg')]\n",
        "        self.gts    = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "        self.depths = [depth_root + f for f in os.listdir(depth_root) if f.endswith('.bmp') or f.endswith('.png')]\n",
        "        self.images = sorted(self.images)\n",
        "        self.gts    = sorted(self.gts)\n",
        "        self.depths = sorted(self.depths)\n",
        "        self.filter_files()\n",
        "        self.size   = len(self.images)\n",
        "        \n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        self.gt_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor()])\n",
        "        self.depths_transform = transforms.Compose([transforms.Resize((self.trainsize, self.trainsize)),transforms.ToTensor()])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        ## read imag, gt, depth\n",
        "        image0 = self.rgb_loader(self.images[index])\n",
        "        gt0    = self.binary_loader(self.gts[index])\n",
        "        depth0 = self.binary_loader(self.depths[index])\n",
        "        \n",
        "        \n",
        "        ##################################################\n",
        "        ## out1\n",
        "        ##################################################\n",
        "        image,gt,depth = cv_random_flip(image0,gt0,depth0)\n",
        "        image,gt,depth = randomCrop(image, gt,depth)\n",
        "        image,gt,depth = randomRotation(image, gt,depth)\n",
        "        image          = colorEnhance(image)\n",
        "        gt             = randomPeper(gt)\n",
        "        image          = self.img_transform(image)\n",
        "        gt             = self.gt_transform(gt)\n",
        "        depth          = self.depths_transform(depth)\n",
        "\n",
        "        ##################################################\n",
        "        ## out1\n",
        "        ##################################################\n",
        "        image2,gt2,depth2 = cv_random_flip(image0,gt0,depth0)\n",
        "        image2,gt2,depth2 = randomCrop(image2, gt2,depth2)\n",
        "        image2,gt2,depth2 = randomRotation(image2, gt2,depth2)\n",
        "        image2          = colorEnhance(image2)\n",
        "        gt2             = randomPeper(gt2)\n",
        "        image2          = self.img_transform(image2)\n",
        "        gt2             = self.gt_transform(gt2)\n",
        "        depth2          = self.depths_transform(depth2)\n",
        "\n",
        "        \n",
        "        return image, gt, depth, image2, gt2, depth2\n",
        "\n",
        "    def filter_files(self):\n",
        "\n",
        "        \n",
        "        assert len(self.images) == len(self.gts) and len(self.gts)==len(self.images)\n",
        "        images = []\n",
        "        gts = []\n",
        "        depths=[]\n",
        "        for img_path, gt_path,depth_path in zip(self.images, self.gts, self.depths):\n",
        "            img = Image.open(img_path)\n",
        "            gt = Image.open(gt_path)\n",
        "            depth= Image.open(depth_path)\n",
        "            if img.size == gt.size and gt.size==depth.size:\n",
        "                images.append(img_path)\n",
        "                gts.append(gt_path)\n",
        "                depths.append(depth_path)\n",
        "        self.images = images\n",
        "        self.gts = gts\n",
        "        self.depths=depths\n",
        "\n",
        "    def rgb_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def binary_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('L')\n",
        "\n",
        "    def resize(self, img, gt, depth):\n",
        "        assert img.size == gt.size and gt.size==depth.size\n",
        "        w, h = img.size\n",
        "        if h < self.trainsize or w < self.trainsize:\n",
        "            h = max(h, self.trainsize)\n",
        "            w = max(w, self.trainsize)\n",
        "            return img.resize((w, h), Image.BILINEAR), gt.resize((w, h), Image.NEAREST),depth.resize((w, h), Image.NEAREST)\n",
        "        else:\n",
        "            return img, gt, depth\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "\n",
        "\n",
        "class SalObjDataset_var_unlabel(data.Dataset):\n",
        "    def __init__(self, image_root, gt_root,depth_root, trainsize):\n",
        "        \n",
        "        self.trainsize = trainsize\n",
        "        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.png')]\n",
        "        self.gts    = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "        self.depths = [depth_root + f for f in os.listdir(depth_root) if f.endswith('.bmp') or f.endswith('.png')]\n",
        "        self.images = sorted(self.images)\n",
        "        self.gts    = sorted(self.gts)\n",
        "        self.depths = sorted(self.depths)\n",
        "        self.filter_files()\n",
        "        self.size   = len(self.images)\n",
        "        \n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        self.gt_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor()])\n",
        "        self.depths_transform = transforms.Compose([transforms.Resize((self.trainsize, self.trainsize)),transforms.ToTensor()])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        ## read imag, gt, depth\n",
        "        image0 = self.rgb_loader(self.images[index])\n",
        "        gt0    = self.binary_loader(self.gts[index])\n",
        "        depth0 = self.binary_loader(self.depths[index])\n",
        "        \n",
        "        \n",
        "        ##################################################\n",
        "        ## out1\n",
        "        ##################################################\n",
        "        image,gt,depth = cv_random_flip(image0,gt0,depth0)\n",
        "        image,gt,depth = randomCrop(image, gt,depth)\n",
        "        image,gt,depth = randomRotation(image, gt,depth)\n",
        "        image          = colorEnhance(image)\n",
        "        gt             = randomPeper(gt)\n",
        "        image          = self.img_transform(image)\n",
        "        gt             = self.gt_transform(gt)\n",
        "        depth          = self.depths_transform(depth)\n",
        "\n",
        "        ##################################################\n",
        "        ## out1\n",
        "        ##################################################\n",
        "        image2,gt2,depth2 = cv_random_flip(image0,gt0,depth0)\n",
        "        image2,gt2,depth2 = randomCrop(image2, gt2,depth2)\n",
        "        image2,gt2,depth2 = randomRotation(image2, gt2,depth2)\n",
        "        image2          = colorEnhance(image2)\n",
        "        gt2             = randomPeper(gt2)\n",
        "        image2          = self.img_transform(image2)\n",
        "        gt2             = self.gt_transform(gt2)\n",
        "        depth2          = self.depths_transform(depth2)\n",
        "\n",
        "        \n",
        "        return image, gt, depth, image2, gt2, depth2\n",
        "\n",
        "    def filter_files(self):\n",
        "\n",
        "        assert len(self.images) == len(self.gts) and len(self.gts)==len(self.images)\n",
        "        images = []\n",
        "        gts = []\n",
        "        depths=[]\n",
        "        for img_path, gt_path,depth_path in zip(self.images, self.gts, self.depths):\n",
        "            img = Image.open(img_path)\n",
        "            gt = Image.open(gt_path)\n",
        "            depth= Image.open(depth_path)\n",
        "            if img.size == gt.size and gt.size==depth.size:\n",
        "                images.append(img_path)\n",
        "                gts.append(gt_path)\n",
        "                depths.append(depth_path)\n",
        "        self.images = images\n",
        "        self.gts = gts\n",
        "        self.depths=depths\n",
        "\n",
        "    def rgb_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def binary_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('L')\n",
        "\n",
        "    def resize(self, img, gt, depth):\n",
        "        assert img.size == gt.size and gt.size==depth.size\n",
        "        w, h = img.size\n",
        "        if h < self.trainsize or w < self.trainsize:\n",
        "            h = max(h, self.trainsize)\n",
        "            w = max(w, self.trainsize)\n",
        "            return img.resize((w, h), Image.BILINEAR), gt.resize((w, h), Image.NEAREST),depth.resize((w, h), Image.NEAREST)\n",
        "        else:\n",
        "            return img, gt, depth\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "#dataloader for training\n",
        "def get_loader(image_root, gt_root,depth_root, batchsize, trainsize, shuffle=True, num_workers=12, pin_memory=False):\n",
        "    print(image_root, gt_root, depth_root)\n",
        "    dataset = SalObjDataset(image_root, gt_root, depth_root,trainsize)\n",
        "    print(dataset)\n",
        "    data_loader = data.DataLoader(dataset=dataset,\n",
        "                                  batch_size=batchsize,\n",
        "                                  shuffle=shuffle,\n",
        "                                  num_workers=num_workers,\n",
        "                                  pin_memory=pin_memory)\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "#dataloader for training2\n",
        "## 09-19-2020\n",
        "def get_loader_var(image_root, gt_root,depth_root, batchsize, trainsize, shuffle=True, num_workers=12, pin_memory=False):\n",
        "\n",
        "    dataset = SalObjDataset_var(image_root, gt_root, depth_root,trainsize)\n",
        "    data_loader = data.DataLoader(dataset=dataset,\n",
        "                                  batch_size=batchsize,\n",
        "                                  shuffle=shuffle,\n",
        "                                  num_workers=num_workers,\n",
        "                                  pin_memory=pin_memory)\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "def get_loader_var_unlabel(image_root, gt_root,depth_root, batchsize, trainsize, shuffle=True, num_workers=12, pin_memory=False):\n",
        "\n",
        "    dataset = SalObjDataset_var_unlabel(image_root, gt_root, depth_root,trainsize)\n",
        "    data_loader = data.DataLoader(dataset=dataset,\n",
        "                                  batch_size=batchsize,\n",
        "                                  shuffle=shuffle,\n",
        "                                  num_workers=num_workers,\n",
        "                                  pin_memory=pin_memory)\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "#test dataset and loader\n",
        "class test_dataset:\n",
        "    def __init__(self, image_root, gt_root,depth_root, testsize):\n",
        "        self.testsize = testsize\n",
        "        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "        self.gts = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.jpg')\n",
        "                       or f.endswith('.png')]\n",
        "        self.depths=[depth_root + f for f in os.listdir(depth_root) if f.endswith('.bmp')\n",
        "                    or f.endswith('.png')]\n",
        "        self.images = sorted(self.images)\n",
        "        self.gts = sorted(self.gts)\n",
        "        self.depths=sorted(self.depths)\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((self.testsize, self.testsize)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        self.gt_transform = transforms.ToTensor()\n",
        "        # self.gt_transform = transforms.Compose([\n",
        "        #     transforms.Resize((self.trainsize, self.trainsize)),\n",
        "        #     transforms.ToTensor()])\n",
        "        self.depths_transform = transforms.Compose([transforms.Resize((self.testsize, self.testsize)),transforms.ToTensor()])\n",
        "        self.size = len(self.images)\n",
        "        self.index = 0\n",
        "\n",
        "    def load_data(self):\n",
        "        image = self.rgb_loader(self.images[self.index])\n",
        "        image = self.transform(image).unsqueeze(0)\n",
        "        gt = self.binary_loader(self.gts[self.index])\n",
        "        depth=self.binary_loader(self.depths[self.index])\n",
        "        depth=self.depths_transform(depth).unsqueeze(0)\n",
        "        name = self.images[self.index].split('/')[-1]\n",
        "        image_for_post=self.rgb_loader(self.images[self.index])\n",
        "        image_for_post=image_for_post.resize(gt.size)\n",
        "        if name.endswith('.jpg'):\n",
        "            name = name.split('.jpg')[0] + '.png'\n",
        "        self.index += 1\n",
        "        self.index = self.index % self.size\n",
        "        return image, gt,depth, name,np.array(image_for_post)\n",
        "\n",
        "    def rgb_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def binary_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('L')\n",
        "    def __len__(self):\n",
        "        return self.size\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTNA4QgLL_Fp"
      },
      "source": [
        "##Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9CzuKgEMD60"
      },
      "outputs": [],
      "source": [
        "def clip_gradient(optimizer, grad_clip):\n",
        "    for group in optimizer.param_groups:\n",
        "        for param in group['params']:\n",
        "            if param.grad is not None:\n",
        "                param.grad.data.clamp_(-grad_clip, grad_clip)\n",
        "\n",
        "\n",
        "def adjust_lr(optimizer, init_lr, epoch, decay_rate=0.1, decay_epoch=30):\n",
        "    decay = decay_rate ** (epoch // decay_epoch)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = decay*init_lr\n",
        "        lr=param_group['lr']\n",
        "    return lr\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrsMhVYLwSy2"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Sep 29 17:21:18 2020\n",
        "\n",
        "@author: taozhou\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "## basic funcs\n",
        "###############################################################################\n",
        "\n",
        "def fun_eval_e(y_pred, y, num, cuda=True):\n",
        "    \n",
        "    if cuda:\n",
        "        score = torch.zeros(num).cuda()\n",
        "    else:\n",
        "        score = torch.zeros(num)\n",
        "    \n",
        "    for i in range(num):\n",
        "        \n",
        "        fm = y_pred - y_pred.mean()\n",
        "        gt = y - y.mean()\n",
        "        align_matrix = 2 * gt * fm / (gt * gt + fm * fm + 1e-20)\n",
        "        enhanced = ((align_matrix + 1) * (align_matrix + 1)) / 4\n",
        "        score[i] = torch.sum(enhanced) / (y.numel() - 1 + 1e-20)        \n",
        "    return score.max()\n",
        "\n",
        "\n",
        "def fun_eval_pr(y_pred, y, num, cuda=True):\n",
        "    \n",
        "    if cuda:\n",
        "        prec, recall = torch.zeros(num).cuda(), torch.zeros(num).cuda()\n",
        "        thlist = torch.linspace(0, 1 - 1e-10, num).cuda()\n",
        "    else:\n",
        "        prec, recall = torch.zeros(num), torch.zeros(num)\n",
        "        thlist = torch.linspace(0, 1 - 1e-10, num)\n",
        "    \n",
        "    for i in range(num):\n",
        "        y_temp = (y_pred >= thlist[i]).float()\n",
        "        tp = (y_temp * y).sum()\n",
        "        prec[i], recall[i] = tp / (y_temp.sum() + 1e-20), tp / (y.sum() + 1e-20)\n",
        "    return prec, recall\n",
        "    \n",
        "\n",
        "def fun_S_object(pred, gt):\n",
        "        \n",
        "    fg = torch.where(gt==0, torch.zeros_like(pred), pred)\n",
        "    bg = torch.where(gt==1, torch.zeros_like(pred), 1-pred)\n",
        "    o_fg = fun_object(fg, gt)\n",
        "    o_bg = fun_object(bg, 1-gt)\n",
        "    u = gt.mean()\n",
        "    Q = u * o_fg + (1-u) * o_bg\n",
        "    return Q\n",
        "\n",
        "\n",
        "def fun_object(pred, gt):\n",
        "    \n",
        "    temp = pred[gt == 1]\n",
        "    x = temp.mean()\n",
        "    sigma_x = temp.std()\n",
        "    score = 2.0 * x / (x * x + 1.0 + sigma_x + 1e-20)\n",
        "        \n",
        "    return score\n",
        "\n",
        "\n",
        "def fun_S_region(pred, gt):\n",
        "    \n",
        "    X, Y = fun_centroid(gt)\n",
        "    gt1, gt2, gt3, gt4, w1, w2, w3, w4 = fun_divideGT(gt, X, Y)\n",
        "    p1, p2, p3, p4 = fun_dividePrediction(pred, X, Y)\n",
        "    Q1 = fun_ssim(p1, gt1)\n",
        "    Q2 = fun_ssim(p2, gt2)\n",
        "    Q3 = fun_ssim(p3, gt3)\n",
        "    Q4 = fun_ssim(p4, gt4)\n",
        "    Q = w1*Q1 + w2*Q2 + w3*Q3 + w4*Q4\n",
        "    \n",
        "    return Q\n",
        "    \n",
        "def fun_centroid(gt, cuda=True):\n",
        "    \n",
        "    rows, cols = gt.size()[-2:]\n",
        "    gt = gt.view(rows, cols)\n",
        "    \n",
        "    if gt.sum() == 0:\n",
        "        \n",
        "        if cuda:\n",
        "            X = torch.eye(1).cuda() * round(cols / 2)\n",
        "            Y = torch.eye(1).cuda() * round(rows / 2)\n",
        "        else:\n",
        "            X = torch.eye(1) * round(cols / 2)\n",
        "            Y = torch.eye(1) * round(rows / 2)\n",
        "    \n",
        "    else:\n",
        "        total = gt.sum()\n",
        "        \n",
        "        if cuda:\n",
        "            i = torch.from_numpy(np.arange(0,cols)).cuda().float()\n",
        "            j = torch.from_numpy(np.arange(0,rows)).cuda().float()\n",
        "        else:\n",
        "            i = torch.from_numpy(np.arange(0,cols)).float()\n",
        "            j = torch.from_numpy(np.arange(0,rows)).float()\n",
        "            \n",
        "        X = torch.round((gt.sum(dim=0)*i).sum() / total)\n",
        "        Y = torch.round((gt.sum(dim=1)*j).sum() / total)\n",
        "        \n",
        "    return X.long(), Y.long()\n",
        "  \n",
        "    \n",
        "def fun_divideGT(gt, X, Y):\n",
        "    \n",
        "    h, w = gt.size()[-2:]\n",
        "    area = h*w\n",
        "    gt   = gt.view(h, w)\n",
        "    LT   = gt[:Y, :X]\n",
        "    RT   = gt[:Y, X:w]\n",
        "    LB   = gt[Y:h, :X]\n",
        "    RB   = gt[Y:h, X:w]\n",
        "    X    = X.float()\n",
        "    Y    = Y.float()\n",
        "    w1   = X * Y / area\n",
        "    w2   = (w - X) * Y / area\n",
        "    w3   = X * (h - Y) / area\n",
        "    w4   = 1 - w1 - w2 - w3\n",
        "    \n",
        "    return LT, RT, LB, RB, w1, w2, w3, w4\n",
        "\n",
        "def fun_dividePrediction(pred, X, Y):\n",
        "    \n",
        "    h, w = pred.size()[-2:]\n",
        "    pred = pred.view(h, w)\n",
        "    LT = pred[:Y, :X]\n",
        "    RT = pred[:Y, X:w]\n",
        "    LB = pred[Y:h, :X]\n",
        "    RB = pred[Y:h, X:w]\n",
        "        \n",
        "    return LT, RT, LB, RB\n",
        "\n",
        "\n",
        "def fun_ssim(pred, gt):\n",
        "    \n",
        "    gt       = gt.float()\n",
        "    h, w     = pred.size()[-2:]\n",
        "    N        = h*w\n",
        "    x        = pred.mean()\n",
        "    y        = gt.mean()\n",
        "    sigma_x2 = ((pred - x)*(pred - x)).sum() / (N - 1 + 1e-20)\n",
        "    sigma_y2 = ((gt - y)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "    sigma_xy = ((pred - x)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "        \n",
        "    aplha = 4 * x * y *sigma_xy\n",
        "    beta = (x*x + y*y) * (sigma_x2 + sigma_y2)\n",
        "    \n",
        "    if aplha != 0:\n",
        "        Q = aplha / (beta + 1e-20)\n",
        "    elif aplha == 0 and beta == 0:\n",
        "        Q = 1.0\n",
        "    else:\n",
        "        Q = 0\n",
        "    \n",
        "    return Q\n",
        "\n",
        "###############################################################################\n",
        "## metric funcs\n",
        "###############################################################################\n",
        "def eval_mae(pred,gt,cuda=True):\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        trans = transforms.Compose([transforms.ToTensor()])\n",
        "        \n",
        "        if cuda:\n",
        "            pred = pred.cuda()\n",
        "            gt   = gt.cuda()\n",
        "#        else:\n",
        "#            pred = trans(pred)\n",
        "#            gt = trans(gt)\n",
        "                \n",
        "        mae = torch.abs(pred - gt).mean()\n",
        "        \n",
        "    return mae.cpu().detach().numpy()\n",
        "                \n",
        "\n",
        "def eval_Smeasure(pred,gt,cuda=True):\n",
        "    \n",
        "    alpha, avg_q, img_num = 0.5, 0.0, 0.0\n",
        "   \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        trans = transforms.Compose([transforms.ToTensor()])\n",
        "        \n",
        "        if cuda:\n",
        "            pred = pred.cuda()\n",
        "            gt   = gt.cuda()\n",
        "\n",
        "        \n",
        "        y = gt.mean()\n",
        "        \n",
        "        ##\n",
        "        if y == 0:\n",
        "            x = pred.mean()\n",
        "            Q = 1.0 - x\n",
        "        elif y == 1:\n",
        "            x = pred.mean()\n",
        "            Q = x\n",
        "        else:\n",
        "            Q = alpha * fun_S_object(pred, gt) + (1-alpha) * fun_S_region(pred, gt)\n",
        "            if Q.item() < 0:\n",
        "                Q = torch.FLoatTensor([0.0])\n",
        "                \n",
        "    return Q.item()\n",
        "\n",
        "                \n",
        "def eval_fmeasure(pred, gt, cuda=True):\n",
        "    print('eval[FMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "    \n",
        "    beta2 = 0.3\n",
        "    avg_p, avg_r, img_num = 0.0, 0.0, 0.0\n",
        "    \n",
        "    ##    \n",
        "    with torch.no_grad():\n",
        "        trans = transforms.Compose([transforms.ToTensor()])\n",
        "        if cuda:\n",
        "            pred = trans(pred).cuda()\n",
        "            gt = trans(gt).cuda()\n",
        "        else:\n",
        "            pred = trans(pred)\n",
        "            gt = trans(gt)\n",
        "                \n",
        "        prec, recall = fun_eval_pr(pred, gt, 255)\n",
        "\n",
        "    return prec, recall\n",
        "              \n",
        "\n",
        "class Eval_thread():\n",
        "    def __init__(self, loader, method, dataset, output_dir, cuda):\n",
        "        self.loader = loader\n",
        "        self.method = method\n",
        "        self.dataset = dataset\n",
        "        self.cuda = cuda\n",
        "        self.logfile = os.path.join(output_dir, 'result.txt')\n",
        "    def run(self):\n",
        "        start_time = time.time()\n",
        "        mae = self.Eval_mae()\n",
        "        s = self.Eval_Smeasure()\n",
        "        \n",
        "        return mae,s\n",
        "        \n",
        "        #max_f = self.Eval_fmeasure()\n",
        "        #max_e = self.Eval_Emeasure()\n",
        "        \n",
        "        #self.LOG('{} dataset with {} method get {:.4f} mae, {:.4f} max-fmeasure, {:.4f} max-Emeasure, {:.4f} S-measure..\\n'.format(self.dataset, self.method, mae, max_f, max_e, s))\n",
        "        #return '[cost:{:.4f}s]{} dataset with {} method get {:.4f} mae, {:.4f} max-fmeasure, {:.4f} max-Emeasure, {:.4f} S-measure..'.format(time.time()-start_time, self.dataset, self.method, mae, max_f, max_e, s)\n",
        "    \n",
        "    def Eval_mae(self):\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    \n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                mea = torch.abs(pred - gt).mean()\n",
        "                if mea == mea: # for Nan\n",
        "                    avg_mae += mea\n",
        "                    img_num += 1.0\n",
        "            avg_mae /= img_num\n",
        "            \n",
        "            return avg_mae.item()\n",
        "    \n",
        "    def Eval_fmeasure(self):\n",
        "        print('eval[FMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        beta2 = 0.3\n",
        "        avg_p, avg_r, img_num = 0.0, 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                prec, recall = self._eval_pr(pred, gt, 255)\n",
        "                avg_p += prec\n",
        "                avg_r += recall\n",
        "                img_num += 1.0\n",
        "            avg_p /= img_num\n",
        "            avg_r /= img_num\n",
        "            score = (1 + beta2) * avg_p * avg_r / (beta2 * avg_p + avg_r)\n",
        "            score[score != score] = 0 # for Nan\n",
        "            \n",
        "            return score.max().item()\n",
        "    def Eval_Emeasure(self):\n",
        "        print('eval[EMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        avg_e, img_num = 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                max_e = self._eval_e(pred, gt, 255)\n",
        "                if max_e == max_e:\n",
        "                    avg_e += max_e\n",
        "                    img_num += 1.0\n",
        "                \n",
        "            avg_e /= img_num\n",
        "            return avg_e\n",
        "    def Eval_Smeasure(self):\n",
        "        #print('eval[SMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        alpha, avg_q, img_num = 0.5, 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                y = gt.mean()\n",
        "                if y == 0:\n",
        "                    x = pred.mean()\n",
        "                    Q = 1.0 - x\n",
        "                elif y == 1:\n",
        "                    x = pred.mean()\n",
        "                    Q = x\n",
        "                else:\n",
        "                    Q = alpha * self._S_object(pred, gt) + (1-alpha) * self._S_region(pred, gt)\n",
        "                    if Q.item() < 0:\n",
        "                        Q = torch.FLoatTensor([0.0])\n",
        "                img_num += 1.0\n",
        "                avg_q += Q.item()\n",
        "            avg_q /= img_num\n",
        "            \n",
        "            return avg_q\n",
        "    def LOG(self, output):\n",
        "        with open(self.logfile, 'a') as f:\n",
        "            f.write(output)\n",
        "\n",
        "    def _eval_e(self, y_pred, y, num):\n",
        "        if self.cuda:\n",
        "            score = torch.zeros(num).cuda()\n",
        "        else:\n",
        "            score = torch.zeros(num)\n",
        "        for i in range(num):\n",
        "            fm = y_pred - y_pred.mean()\n",
        "            gt = y - y.mean()\n",
        "            align_matrix = 2 * gt * fm / (gt * gt + fm * fm + 1e-20)\n",
        "            enhanced = ((align_matrix + 1) * (align_matrix + 1)) / 4\n",
        "            score[i] = torch.sum(enhanced) / (y.numel() - 1 + 1e-20)\n",
        "        return score.max()\n",
        "\n",
        "    def _eval_pr(self, y_pred, y, num):\n",
        "        if self.cuda:\n",
        "            prec, recall = torch.zeros(num).cuda(), torch.zeros(num).cuda()\n",
        "            thlist = torch.linspace(0, 1 - 1e-10, num).cuda()\n",
        "        else:\n",
        "            prec, recall = torch.zeros(num), torch.zeros(num)\n",
        "            thlist = torch.linspace(0, 1 - 1e-10, num)\n",
        "        for i in range(num):\n",
        "            y_temp = (y_pred >= thlist[i]).float()\n",
        "            tp = (y_temp * y).sum()\n",
        "            prec[i], recall[i] = tp / (y_temp.sum() + 1e-20), tp / (y.sum() + 1e-20)\n",
        "        return prec, recall\n",
        "    \n",
        "    def _S_object(self, pred, gt):\n",
        "        fg = torch.where(gt==0, torch.zeros_like(pred), pred)\n",
        "        bg = torch.where(gt==1, torch.zeros_like(pred), 1-pred)\n",
        "        o_fg = self._object(fg, gt)\n",
        "        o_bg = self._object(bg, 1-gt)\n",
        "        u = gt.mean()\n",
        "        Q = u * o_fg + (1-u) * o_bg\n",
        "        return Q\n",
        "\n",
        "    def _object(self, pred, gt):\n",
        "        temp = pred[gt == 1]\n",
        "        x = temp.mean()\n",
        "        sigma_x = temp.std()\n",
        "        score = 2.0 * x / (x * x + 1.0 + sigma_x + 1e-20)\n",
        "        \n",
        "        return score\n",
        "\n",
        "    def _S_region(self, pred, gt):\n",
        "        X, Y = self._centroid(gt)\n",
        "        gt1, gt2, gt3, gt4, w1, w2, w3, w4 = self._divideGT(gt, X, Y)\n",
        "        p1, p2, p3, p4 = self._dividePrediction(pred, X, Y)\n",
        "        Q1 = self._ssim(p1, gt1)\n",
        "        Q2 = self._ssim(p2, gt2)\n",
        "        Q3 = self._ssim(p3, gt3)\n",
        "        Q4 = self._ssim(p4, gt4)\n",
        "        Q = w1*Q1 + w2*Q2 + w3*Q3 + w4*Q4\n",
        "        # print(Q)\n",
        "        return Q\n",
        "    \n",
        "    def _centroid(self, gt):\n",
        "        rows, cols = gt.size()[-2:]\n",
        "        gt = gt.view(rows, cols)\n",
        "        if gt.sum() == 0:\n",
        "            if self.cuda:\n",
        "                X = torch.eye(1).cuda() * round(cols / 2)\n",
        "                Y = torch.eye(1).cuda() * round(rows / 2)\n",
        "            else:\n",
        "                X = torch.eye(1) * round(cols / 2)\n",
        "                Y = torch.eye(1) * round(rows / 2)\n",
        "        else:\n",
        "            total = gt.sum()\n",
        "            if self.cuda:\n",
        "                i = torch.from_numpy(np.arange(0,cols)).cuda().float()\n",
        "                j = torch.from_numpy(np.arange(0,rows)).cuda().float()\n",
        "            else:\n",
        "                i = torch.from_numpy(np.arange(0,cols)).float()\n",
        "                j = torch.from_numpy(np.arange(0,rows)).float()\n",
        "            X = torch.round((gt.sum(dim=0)*i).sum() / total)\n",
        "            Y = torch.round((gt.sum(dim=1)*j).sum() / total)\n",
        "        return X.long(), Y.long()\n",
        "    \n",
        "    def _divideGT(self, gt, X, Y):\n",
        "        h, w = gt.size()[-2:]\n",
        "        area = h*w\n",
        "        gt = gt.view(h, w)\n",
        "        LT = gt[:Y, :X]\n",
        "        RT = gt[:Y, X:w]\n",
        "        LB = gt[Y:h, :X]\n",
        "        RB = gt[Y:h, X:w]\n",
        "        X = X.float()\n",
        "        Y = Y.float()\n",
        "        w1 = X * Y / area\n",
        "        w2 = (w - X) * Y / area\n",
        "        w3 = X * (h - Y) / area\n",
        "        w4 = 1 - w1 - w2 - w3\n",
        "        return LT, RT, LB, RB, w1, w2, w3, w4\n",
        "\n",
        "    def _dividePrediction(self, pred, X, Y):\n",
        "        h, w = pred.size()[-2:]\n",
        "        pred = pred.view(h, w)\n",
        "        LT = pred[:Y, :X]\n",
        "        RT = pred[:Y, X:w]\n",
        "        LB = pred[Y:h, :X]\n",
        "        RB = pred[Y:h, X:w]\n",
        "        return LT, RT, LB, RB\n",
        "\n",
        "    def _ssim(self, pred, gt):\n",
        "        gt = gt.float()\n",
        "        h, w = pred.size()[-2:]\n",
        "        N = h*w\n",
        "        x = pred.mean()\n",
        "        y = gt.mean()\n",
        "        sigma_x2 = ((pred - x)*(pred - x)).sum() / (N - 1 + 1e-20)\n",
        "        sigma_y2 = ((gt - y)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "        sigma_xy = ((pred - x)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "        \n",
        "        aplha = 4 * x * y *sigma_xy\n",
        "        beta = (x*x + y*y) * (sigma_x2 + sigma_y2)\n",
        "\n",
        "        if aplha != 0:\n",
        "            Q = aplha / (beta + 1e-20)\n",
        "        elif aplha == 0 and beta == 0:\n",
        "            Q = 1.0\n",
        "        else:\n",
        "            Q = 0\n",
        "        return Q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOyfjL14LqZN"
      },
      "source": [
        "##Training Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmU0hbGlLzt-"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "def arguments():\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument('--epoch',       type=int,   default=250,   help='epoch number')\n",
        "  parser.add_argument('--lr',          type=float, default=1e-4,  help='learning rate')\n",
        "  parser.add_argument('--batchsize',   type=int,   default=4,    help='training batch size')\n",
        "  parser.add_argument('--trainsize',   type=int,   default=352,   help='training dataset size')\n",
        "  parser.add_argument('--clip',        type=float, default=0.5,   help='gradient clipping margin')\n",
        "  parser.add_argument('--lw',          type=float, default=0.001, help='weight')\n",
        "  parser.add_argument('--decay_rate',  type=float, default=0.1,   help='decay rate of learning rate')\n",
        "  parser.add_argument('--decay_epoch', type=int,   default=60,    help='every n epochs decay learning rate')\n",
        "  parser.add_argument('--load',        type=str,   default=None,  help='train from checkpoints')\n",
        "  parser.add_argument('--gpu_id',      type=str,   default='0',   help='train use gpu')\n",
        "\n",
        "  parser.add_argument('--rgb_label_root',      type=str, default='/content/tmp/traindataset/RGB/',           help='the training rgb images root')\n",
        "  parser.add_argument('--depth_label_root',    type=str, default='/content/tmp/traindataset/depth/',         help='the training depth images root')\n",
        "  parser.add_argument('--gt_label_root',       type=str, default='/content/tmp/traindataset/GT/',            help='the training gt images root')\n",
        "\n",
        "  parser.add_argument('--val_rgb_root',        type=str, default='/content/tmp/testdataset/NJU2K/RGB/',      help='the test rgb images root')\n",
        "  parser.add_argument('--val_depth_root',      type=str, default='/content/tmp/testdataset/NJU2K/depth/',    help='the test depth images root')\n",
        "  parser.add_argument('--val_gt_root',         type=str, default='/content/tmp/testdataset/NJU2K/GT/',       help='the test gt images root')\n",
        "\n",
        "  parser.add_argument('--save_path',           type=str, default='/content/drive/MyDrive/Checkpoint/path_with_different_input/',    help='the path to save models and logs')\n",
        "  return parser.parse_args(\"\")\n",
        "\n",
        "opt = arguments()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu1gTl-yM9Kv"
      },
      "source": [
        "##Model Training With DIfferent Loss Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK3RZTqaNF6w"
      },
      "source": [
        "### Training with Perceptual Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bo9erSOBNNOo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from piq import LPIPS\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "train_accu = []\n",
        "train_losses = []\n",
        "train_accu1 = []\n",
        "train_accu2 = []\n",
        "train_accu3 = []\n",
        "train_losses1 = []\n",
        "train_losses2 = []\n",
        "train_losses3 = []\n",
        "val_accu = []\n",
        "val_losses = []\n",
        "\n",
        "print(len(train_loader))\n",
        "\n",
        "#Lpips traditional perceptual loss\n",
        "lpips = LPIPS()\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    running_loss = 0\n",
        "    running_loss1 = 0\n",
        "    running_loss2 = 0\n",
        "    running_loss3 = 0\n",
        "    total = 0\n",
        "    total1 = 0\n",
        "    total2 = 0\n",
        "    total3 = 0\n",
        "    correct = 0\n",
        "    correct1 = 0\n",
        "    correct2 = 0\n",
        "    correct3 = 0\n",
        "\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = lpips(gts, pre_res[0])\n",
        "            loss2    = lpips(gts, pre_res[1])\n",
        "            loss3    = lpips(gts, pre_res[2])\n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "\n",
        "            #loss graph\n",
        "            running_loss1 += loss1.item()\n",
        "            running_loss2 += loss2.item()\n",
        "            running_loss3 += loss3.item()\n",
        "            predicted1 = pre_res[0]\n",
        "            predicted2 = pre_res[1]\n",
        "            predicted3 = pre_res[2]\n",
        "            total1 += images.size(0)\n",
        "            total2 += gts.size(0)\n",
        "            total3 += depths.size(0)\n",
        "            correct1 += predicted1.eq(images).sum().item()\n",
        "            correct2 += predicted2.eq(gts).sum().item()\n",
        "            correct3 += predicted3.eq(depths).sum().item()\n",
        "\n",
        "            running_loss += loss_all.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = gt + loss + predicted\n",
        "            total += images.size(0)\n",
        "            correct += outputs.eq(images).sum().item()\n",
        "            \n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "\n",
        "        train_loss = running_loss/len(train_loader)\n",
        "        train_loss1=running_loss1/len(train_loader)\n",
        "        train_loss2=running_loss2/len(train_loader)\n",
        "        train_loss3=running_loss3/len(train_loader)\n",
        "        accu = 100.*correct/total\n",
        "        accu1=100.*correct1/total1\n",
        "        accu2=100.*correct2/total2\n",
        "        accu3=100.*correct3/total3        \n",
        "        train_accu1.append(accu1)\n",
        "        train_accu2.append(accu2)\n",
        "        train_accu3.append(accu3)\n",
        "        train_losses1.append(train_loss1)\n",
        "        train_losses2.append(train_loss2)\n",
        "        train_losses3.append(train_loss3)\n",
        "        train_accu.append(accu)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "           \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-8)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "            mae_sum += np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "\n",
        "            #loss graph\n",
        "            running_loss += mae_sum.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = gt + loss + predicted\n",
        "            total += test_loader.size\n",
        "            correct += outputs.eq(image).sum().item()\n",
        "\n",
        "\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "       \n",
        "        val_loss=running_loss/len(test_loader)\n",
        "        accu=100.*correct/total\n",
        "        val_accu.append(accu)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_best_epoch_perceptual_loss.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n",
        "\n",
        "plt.plot(train_losses, '-o')\n",
        "plt.plot(train_losses1,'-o')\n",
        "plt.plot(train_losses2,'-o')\n",
        "plt.plot(train_losses3,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Perceptual Loss','Loss1', 'Loss2', 'Loss3'])\n",
        "plt.title('Train Losses')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_accu, '-o')\n",
        "plt.plot(train_accu1,'-o')\n",
        "plt.plot(train_accu2,'-o')\n",
        "plt.plot(train_accu3,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Accuracy','Acc1', 'Acc2', 'Acc3'])\n",
        "plt.title('Train Accuracy')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(val_losses,'-o')\n",
        "plt.plot(val_accu,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Losses','Accuracy'])\n",
        "plt.title('Test Losses and Accuracy')\n",
        " \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjCON1l6vmfS"
      },
      "source": [
        "### Training with SSIM Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "93a3b65787b44d459b8e1335edb0de63",
            "8b1844a4952148c287c4288f72fddfb2",
            "ead21855f0544cf19fd8f5c6563f9bfc",
            "bfb44701317349bfa693af3b83d81207",
            "749fc344b5d8455198bffc92dbaf17eb",
            "0390d01cfe2149f0bdbf1a26ad40c45c",
            "b54e8dfc22b9420eb947f1411fafe9dd",
            "9b83c730a3c648f1a0eda2504f2c9850",
            "28b330d1b30443659e9d565aea0f4981",
            "457bfe5cf38f4941a75626a6f6b40d0d",
            "dc2b83eed6aa428b877444949b69e410"
          ]
        },
        "id": "8FT0VnLNvxpi",
        "outputId": "fd687085-778b-48ff-afe2-12d7e2f95d04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USE GPU 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://shanghuagao.oss-cn-beijing.aliyuncs.com/res2net/res2net50_v1b_26w_4s-3cf99910.pth\" to /root/.cache/torch/hub/checkpoints/res2net50_v1b_26w_4s-3cf99910.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93a3b65787b44d459b8e1335edb0de63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/98.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load data...\n",
            "/content/tmp/traindataset/RGB/ /content/tmp/traindataset/GT/ /content/tmp/traindataset/depth/\n",
            "/content/tmp/traindataset/RGB/ /content/tmp/traindataset/GT/ /content/tmp/traindataset/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/traindataset/RGB/RGB_00.png', '/content/tmp/traindataset/RGB/RGB_01.png', '/content/tmp/traindataset/RGB/RGB_02.png', '/content/tmp/traindataset/RGB/RGB_10.png', '/content/tmp/traindataset/RGB/RGB_100.png', '/content/tmp/traindataset/RGB/RGB_101.png', '/content/tmp/traindataset/RGB/RGB_102.png', '/content/tmp/traindataset/RGB/RGB_11.png', '/content/tmp/traindataset/RGB/RGB_110.png', '/content/tmp/traindataset/RGB/RGB_111.png', '/content/tmp/traindataset/RGB/RGB_112.png', '/content/tmp/traindataset/RGB/RGB_12.png', '/content/tmp/traindataset/RGB/RGB_120.png', '/content/tmp/traindataset/RGB/RGB_121.png', '/content/tmp/traindataset/RGB/RGB_122.png', '/content/tmp/traindataset/RGB/RGB_130.png', '/content/tmp/traindataset/RGB/RGB_131.png', '/content/tmp/traindataset/RGB/RGB_132.png', '/content/tmp/traindataset/RGB/RGB_140.png', '/content/tmp/traindataset/RGB/RGB_141.png', '/content/tmp/traindataset/RGB/RGB_142.png', '/content/tmp/traindataset/RGB/RGB_150.png', '/content/tmp/traindataset/RGB/RGB_151.png', '/content/tmp/traindataset/RGB/RGB_152.png', '/content/tmp/traindataset/RGB/RGB_160.png', '/content/tmp/traindataset/RGB/RGB_161.png', '/content/tmp/traindataset/RGB/RGB_162.png', '/content/tmp/traindataset/RGB/RGB_170.png', '/content/tmp/traindataset/RGB/RGB_171.png', '/content/tmp/traindataset/RGB/RGB_172.png', '/content/tmp/traindataset/RGB/RGB_180.png', '/content/tmp/traindataset/RGB/RGB_181.png', '/content/tmp/traindataset/RGB/RGB_182.png', '/content/tmp/traindataset/RGB/RGB_190.png', '/content/tmp/traindataset/RGB/RGB_191.png', '/content/tmp/traindataset/RGB/RGB_192.png', '/content/tmp/traindataset/RGB/RGB_20.png', '/content/tmp/traindataset/RGB/RGB_200.png', '/content/tmp/traindataset/RGB/RGB_201.png', '/content/tmp/traindataset/RGB/RGB_202.png', '/content/tmp/traindataset/RGB/RGB_21.png', '/content/tmp/traindataset/RGB/RGB_210.png', '/content/tmp/traindataset/RGB/RGB_211.png', '/content/tmp/traindataset/RGB/RGB_212.png', '/content/tmp/traindataset/RGB/RGB_22.png', '/content/tmp/traindataset/RGB/RGB_220.png', '/content/tmp/traindataset/RGB/RGB_221.png', '/content/tmp/traindataset/RGB/RGB_222.png', '/content/tmp/traindataset/RGB/RGB_230.png', '/content/tmp/traindataset/RGB/RGB_231.png', '/content/tmp/traindataset/RGB/RGB_232.png', '/content/tmp/traindataset/RGB/RGB_240.png', '/content/tmp/traindataset/RGB/RGB_241.png', '/content/tmp/traindataset/RGB/RGB_242.png', '/content/tmp/traindataset/RGB/RGB_250.png', '/content/tmp/traindataset/RGB/RGB_251.png', '/content/tmp/traindataset/RGB/RGB_252.png', '/content/tmp/traindataset/RGB/RGB_260.png', '/content/tmp/traindataset/RGB/RGB_261.png', '/content/tmp/traindataset/RGB/RGB_262.png', '/content/tmp/traindataset/RGB/RGB_270.png', '/content/tmp/traindataset/RGB/RGB_271.png', '/content/tmp/traindataset/RGB/RGB_272.png', '/content/tmp/traindataset/RGB/RGB_280.png', '/content/tmp/traindataset/RGB/RGB_281.png', '/content/tmp/traindataset/RGB/RGB_282.png', '/content/tmp/traindataset/RGB/RGB_290.png', '/content/tmp/traindataset/RGB/RGB_291.png', '/content/tmp/traindataset/RGB/RGB_292.png', '/content/tmp/traindataset/RGB/RGB_30.png', '/content/tmp/traindataset/RGB/RGB_300.png', '/content/tmp/traindataset/RGB/RGB_301.png', '/content/tmp/traindataset/RGB/RGB_302.png', '/content/tmp/traindataset/RGB/RGB_31.png', '/content/tmp/traindataset/RGB/RGB_310.png', '/content/tmp/traindataset/RGB/RGB_311.png', '/content/tmp/traindataset/RGB/RGB_312.png', '/content/tmp/traindataset/RGB/RGB_32.png', '/content/tmp/traindataset/RGB/RGB_320.png', '/content/tmp/traindataset/RGB/RGB_321.png', '/content/tmp/traindataset/RGB/RGB_322.png', '/content/tmp/traindataset/RGB/RGB_330.png', '/content/tmp/traindataset/RGB/RGB_331.png', '/content/tmp/traindataset/RGB/RGB_332.png', '/content/tmp/traindataset/RGB/RGB_340.png', '/content/tmp/traindataset/RGB/RGB_341.png', '/content/tmp/traindataset/RGB/RGB_342.png', '/content/tmp/traindataset/RGB/RGB_350.png', '/content/tmp/traindataset/RGB/RGB_351.png', '/content/tmp/traindataset/RGB/RGB_352.png', '/content/tmp/traindataset/RGB/RGB_360.png', '/content/tmp/traindataset/RGB/RGB_361.png', '/content/tmp/traindataset/RGB/RGB_362.png', '/content/tmp/traindataset/RGB/RGB_370.png', '/content/tmp/traindataset/RGB/RGB_371.png', '/content/tmp/traindataset/RGB/RGB_372.png', '/content/tmp/traindataset/RGB/RGB_380.png', '/content/tmp/traindataset/RGB/RGB_381.png', '/content/tmp/traindataset/RGB/RGB_382.png', '/content/tmp/traindataset/RGB/RGB_390.png', '/content/tmp/traindataset/RGB/RGB_391.png', '/content/tmp/traindataset/RGB/RGB_392.png', '/content/tmp/traindataset/RGB/RGB_40.png', '/content/tmp/traindataset/RGB/RGB_400.png', '/content/tmp/traindataset/RGB/RGB_401.png', '/content/tmp/traindataset/RGB/RGB_402.png', '/content/tmp/traindataset/RGB/RGB_41.png', '/content/tmp/traindataset/RGB/RGB_410.png', '/content/tmp/traindataset/RGB/RGB_411.png', '/content/tmp/traindataset/RGB/RGB_412.png', '/content/tmp/traindataset/RGB/RGB_42.png', '/content/tmp/traindataset/RGB/RGB_420.png', '/content/tmp/traindataset/RGB/RGB_421.png', '/content/tmp/traindataset/RGB/RGB_422.png', '/content/tmp/traindataset/RGB/RGB_430.png', '/content/tmp/traindataset/RGB/RGB_431.png', '/content/tmp/traindataset/RGB/RGB_432.png', '/content/tmp/traindataset/RGB/RGB_440.png', '/content/tmp/traindataset/RGB/RGB_441.png', '/content/tmp/traindataset/RGB/RGB_442.png', '/content/tmp/traindataset/RGB/RGB_450.png', '/content/tmp/traindataset/RGB/RGB_451.png', '/content/tmp/traindataset/RGB/RGB_452.png', '/content/tmp/traindataset/RGB/RGB_460.png', '/content/tmp/traindataset/RGB/RGB_461.png', '/content/tmp/traindataset/RGB/RGB_462.png', '/content/tmp/traindataset/RGB/RGB_470.png', '/content/tmp/traindataset/RGB/RGB_471.png', '/content/tmp/traindataset/RGB/RGB_472.png', '/content/tmp/traindataset/RGB/RGB_480.png', '/content/tmp/traindataset/RGB/RGB_481.png', '/content/tmp/traindataset/RGB/RGB_482.png', '/content/tmp/traindataset/RGB/RGB_490.png', '/content/tmp/traindataset/RGB/RGB_491.png', '/content/tmp/traindataset/RGB/RGB_492.png', '/content/tmp/traindataset/RGB/RGB_50.png', '/content/tmp/traindataset/RGB/RGB_500.png', '/content/tmp/traindataset/RGB/RGB_501.png', '/content/tmp/traindataset/RGB/RGB_502.png', '/content/tmp/traindataset/RGB/RGB_51.png', '/content/tmp/traindataset/RGB/RGB_510.png', '/content/tmp/traindataset/RGB/RGB_511.png', '/content/tmp/traindataset/RGB/RGB_512.png', '/content/tmp/traindataset/RGB/RGB_52.png', '/content/tmp/traindataset/RGB/RGB_520.png', '/content/tmp/traindataset/RGB/RGB_521.png', '/content/tmp/traindataset/RGB/RGB_522.png', '/content/tmp/traindataset/RGB/RGB_530.png', '/content/tmp/traindataset/RGB/RGB_531.png', '/content/tmp/traindataset/RGB/RGB_532.png', '/content/tmp/traindataset/RGB/RGB_540.png', '/content/tmp/traindataset/RGB/RGB_541.png', '/content/tmp/traindataset/RGB/RGB_542.png', '/content/tmp/traindataset/RGB/RGB_550.png', '/content/tmp/traindataset/RGB/RGB_551.png', '/content/tmp/traindataset/RGB/RGB_552.png', '/content/tmp/traindataset/RGB/RGB_560.png', '/content/tmp/traindataset/RGB/RGB_561.png', '/content/tmp/traindataset/RGB/RGB_562.png', '/content/tmp/traindataset/RGB/RGB_570.png', '/content/tmp/traindataset/RGB/RGB_571.png', '/content/tmp/traindataset/RGB/RGB_572.png', '/content/tmp/traindataset/RGB/RGB_580.png', '/content/tmp/traindataset/RGB/RGB_581.png', '/content/tmp/traindataset/RGB/RGB_582.png', '/content/tmp/traindataset/RGB/RGB_590.png', '/content/tmp/traindataset/RGB/RGB_591.png', '/content/tmp/traindataset/RGB/RGB_592.png', '/content/tmp/traindataset/RGB/RGB_60.png', '/content/tmp/traindataset/RGB/RGB_600.png', '/content/tmp/traindataset/RGB/RGB_601.png', '/content/tmp/traindataset/RGB/RGB_602.png', '/content/tmp/traindataset/RGB/RGB_61.png', '/content/tmp/traindataset/RGB/RGB_610.png', '/content/tmp/traindataset/RGB/RGB_611.png', '/content/tmp/traindataset/RGB/RGB_612.png', '/content/tmp/traindataset/RGB/RGB_62.png', '/content/tmp/traindataset/RGB/RGB_620.png', '/content/tmp/traindataset/RGB/RGB_621.png', '/content/tmp/traindataset/RGB/RGB_622.png', '/content/tmp/traindataset/RGB/RGB_630.png', '/content/tmp/traindataset/RGB/RGB_631.png', '/content/tmp/traindataset/RGB/RGB_632.png', '/content/tmp/traindataset/RGB/RGB_640.png', '/content/tmp/traindataset/RGB/RGB_641.png', '/content/tmp/traindataset/RGB/RGB_642.png', '/content/tmp/traindataset/RGB/RGB_650.png', '/content/tmp/traindataset/RGB/RGB_651.png', '/content/tmp/traindataset/RGB/RGB_652.png', '/content/tmp/traindataset/RGB/RGB_660.png', '/content/tmp/traindataset/RGB/RGB_661.png', '/content/tmp/traindataset/RGB/RGB_662.png', '/content/tmp/traindataset/RGB/RGB_670.png', '/content/tmp/traindataset/RGB/RGB_671.png', '/content/tmp/traindataset/RGB/RGB_672.png', '/content/tmp/traindataset/RGB/RGB_680.png', '/content/tmp/traindataset/RGB/RGB_681.png', '/content/tmp/traindataset/RGB/RGB_682.png', '/content/tmp/traindataset/RGB/RGB_690.png', '/content/tmp/traindataset/RGB/RGB_691.png', '/content/tmp/traindataset/RGB/RGB_692.png', '/content/tmp/traindataset/RGB/RGB_70.png', '/content/tmp/traindataset/RGB/RGB_700.png', '/content/tmp/traindataset/RGB/RGB_701.png', '/content/tmp/traindataset/RGB/RGB_702.png', '/content/tmp/traindataset/RGB/RGB_71.png', '/content/tmp/traindataset/RGB/RGB_710.png', '/content/tmp/traindataset/RGB/RGB_711.png', '/content/tmp/traindataset/RGB/RGB_712.png', '/content/tmp/traindataset/RGB/RGB_72.png', '/content/tmp/traindataset/RGB/RGB_720.png', '/content/tmp/traindataset/RGB/RGB_721.png', '/content/tmp/traindataset/RGB/RGB_722.png', '/content/tmp/traindataset/RGB/RGB_730.png', '/content/tmp/traindataset/RGB/RGB_731.png', '/content/tmp/traindataset/RGB/RGB_732.png', '/content/tmp/traindataset/RGB/RGB_740.png', '/content/tmp/traindataset/RGB/RGB_741.png', '/content/tmp/traindataset/RGB/RGB_742.png', '/content/tmp/traindataset/RGB/RGB_750.png', '/content/tmp/traindataset/RGB/RGB_751.png', '/content/tmp/traindataset/RGB/RGB_752.png', '/content/tmp/traindataset/RGB/RGB_760.png', '/content/tmp/traindataset/RGB/RGB_761.png', '/content/tmp/traindataset/RGB/RGB_762.png', '/content/tmp/traindataset/RGB/RGB_770.png', '/content/tmp/traindataset/RGB/RGB_771.png', '/content/tmp/traindataset/RGB/RGB_772.png', '/content/tmp/traindataset/RGB/RGB_780.png', '/content/tmp/traindataset/RGB/RGB_781.png', '/content/tmp/traindataset/RGB/RGB_782.png', '/content/tmp/traindataset/RGB/RGB_790.png', '/content/tmp/traindataset/RGB/RGB_791.png', '/content/tmp/traindataset/RGB/RGB_792.png', '/content/tmp/traindataset/RGB/RGB_80.png', '/content/tmp/traindataset/RGB/RGB_81.png', '/content/tmp/traindataset/RGB/RGB_82.png', '/content/tmp/traindataset/RGB/RGB_90.png', '/content/tmp/traindataset/RGB/RGB_91.png', '/content/tmp/traindataset/RGB/RGB_92.png'] ['/content/tmp/traindataset/GT/GT_00.png', '/content/tmp/traindataset/GT/GT_01.png', '/content/tmp/traindataset/GT/GT_02.png', '/content/tmp/traindataset/GT/GT_10.png', '/content/tmp/traindataset/GT/GT_100.png', '/content/tmp/traindataset/GT/GT_101.png', '/content/tmp/traindataset/GT/GT_102.png', '/content/tmp/traindataset/GT/GT_11.png', '/content/tmp/traindataset/GT/GT_110.png', '/content/tmp/traindataset/GT/GT_111.png', '/content/tmp/traindataset/GT/GT_112.png', '/content/tmp/traindataset/GT/GT_12.png', '/content/tmp/traindataset/GT/GT_120.png', '/content/tmp/traindataset/GT/GT_121.png', '/content/tmp/traindataset/GT/GT_122.png', '/content/tmp/traindataset/GT/GT_130.png', '/content/tmp/traindataset/GT/GT_131.png', '/content/tmp/traindataset/GT/GT_132.png', '/content/tmp/traindataset/GT/GT_140.png', '/content/tmp/traindataset/GT/GT_141.png', '/content/tmp/traindataset/GT/GT_142.png', '/content/tmp/traindataset/GT/GT_150.png', '/content/tmp/traindataset/GT/GT_151.png', '/content/tmp/traindataset/GT/GT_152.png', '/content/tmp/traindataset/GT/GT_160.png', '/content/tmp/traindataset/GT/GT_161.png', '/content/tmp/traindataset/GT/GT_162.png', '/content/tmp/traindataset/GT/GT_170.png', '/content/tmp/traindataset/GT/GT_171.png', '/content/tmp/traindataset/GT/GT_172.png', '/content/tmp/traindataset/GT/GT_180.png', '/content/tmp/traindataset/GT/GT_181.png', '/content/tmp/traindataset/GT/GT_182.png', '/content/tmp/traindataset/GT/GT_190.png', '/content/tmp/traindataset/GT/GT_191.png', '/content/tmp/traindataset/GT/GT_192.png', '/content/tmp/traindataset/GT/GT_20.png', '/content/tmp/traindataset/GT/GT_200.png', '/content/tmp/traindataset/GT/GT_201.png', '/content/tmp/traindataset/GT/GT_202.png', '/content/tmp/traindataset/GT/GT_21.png', '/content/tmp/traindataset/GT/GT_210.png', '/content/tmp/traindataset/GT/GT_211.png', '/content/tmp/traindataset/GT/GT_212.png', '/content/tmp/traindataset/GT/GT_22.png', '/content/tmp/traindataset/GT/GT_220.png', '/content/tmp/traindataset/GT/GT_221.png', '/content/tmp/traindataset/GT/GT_222.png', '/content/tmp/traindataset/GT/GT_230.png', '/content/tmp/traindataset/GT/GT_231.png', '/content/tmp/traindataset/GT/GT_232.png', '/content/tmp/traindataset/GT/GT_240.png', '/content/tmp/traindataset/GT/GT_241.png', '/content/tmp/traindataset/GT/GT_242.png', '/content/tmp/traindataset/GT/GT_250.png', '/content/tmp/traindataset/GT/GT_251.png', '/content/tmp/traindataset/GT/GT_252.png', '/content/tmp/traindataset/GT/GT_260.png', '/content/tmp/traindataset/GT/GT_261.png', '/content/tmp/traindataset/GT/GT_262.png', '/content/tmp/traindataset/GT/GT_270.png', '/content/tmp/traindataset/GT/GT_271.png', '/content/tmp/traindataset/GT/GT_272.png', '/content/tmp/traindataset/GT/GT_280.png', '/content/tmp/traindataset/GT/GT_281.png', '/content/tmp/traindataset/GT/GT_282.png', '/content/tmp/traindataset/GT/GT_290.png', '/content/tmp/traindataset/GT/GT_291.png', '/content/tmp/traindataset/GT/GT_292.png', '/content/tmp/traindataset/GT/GT_30.png', '/content/tmp/traindataset/GT/GT_300.png', '/content/tmp/traindataset/GT/GT_301.png', '/content/tmp/traindataset/GT/GT_302.png', '/content/tmp/traindataset/GT/GT_31.png', '/content/tmp/traindataset/GT/GT_310.png', '/content/tmp/traindataset/GT/GT_311.png', '/content/tmp/traindataset/GT/GT_312.png', '/content/tmp/traindataset/GT/GT_32.png', '/content/tmp/traindataset/GT/GT_320.png', '/content/tmp/traindataset/GT/GT_321.png', '/content/tmp/traindataset/GT/GT_322.png', '/content/tmp/traindataset/GT/GT_330.png', '/content/tmp/traindataset/GT/GT_331.png', '/content/tmp/traindataset/GT/GT_332.png', '/content/tmp/traindataset/GT/GT_340.png', '/content/tmp/traindataset/GT/GT_341.png', '/content/tmp/traindataset/GT/GT_342.png', '/content/tmp/traindataset/GT/GT_350.png', '/content/tmp/traindataset/GT/GT_351.png', '/content/tmp/traindataset/GT/GT_352.png', '/content/tmp/traindataset/GT/GT_360.png', '/content/tmp/traindataset/GT/GT_361.png', '/content/tmp/traindataset/GT/GT_362.png', '/content/tmp/traindataset/GT/GT_370.png', '/content/tmp/traindataset/GT/GT_371.png', '/content/tmp/traindataset/GT/GT_372.png', '/content/tmp/traindataset/GT/GT_380.png', '/content/tmp/traindataset/GT/GT_381.png', '/content/tmp/traindataset/GT/GT_382.png', '/content/tmp/traindataset/GT/GT_390.png', '/content/tmp/traindataset/GT/GT_391.png', '/content/tmp/traindataset/GT/GT_392.png', '/content/tmp/traindataset/GT/GT_40.png', '/content/tmp/traindataset/GT/GT_400.png', '/content/tmp/traindataset/GT/GT_401.png', '/content/tmp/traindataset/GT/GT_402.png', '/content/tmp/traindataset/GT/GT_41.png', '/content/tmp/traindataset/GT/GT_410.png', '/content/tmp/traindataset/GT/GT_411.png', '/content/tmp/traindataset/GT/GT_412.png', '/content/tmp/traindataset/GT/GT_42.png', '/content/tmp/traindataset/GT/GT_420.png', '/content/tmp/traindataset/GT/GT_421.png', '/content/tmp/traindataset/GT/GT_422.png', '/content/tmp/traindataset/GT/GT_430.png', '/content/tmp/traindataset/GT/GT_431.png', '/content/tmp/traindataset/GT/GT_432.png', '/content/tmp/traindataset/GT/GT_440.png', '/content/tmp/traindataset/GT/GT_441.png', '/content/tmp/traindataset/GT/GT_442.png', '/content/tmp/traindataset/GT/GT_450.png', '/content/tmp/traindataset/GT/GT_451.png', '/content/tmp/traindataset/GT/GT_452.png', '/content/tmp/traindataset/GT/GT_460.png', '/content/tmp/traindataset/GT/GT_461.png', '/content/tmp/traindataset/GT/GT_462.png', '/content/tmp/traindataset/GT/GT_470.png', '/content/tmp/traindataset/GT/GT_471.png', '/content/tmp/traindataset/GT/GT_472.png', '/content/tmp/traindataset/GT/GT_480.png', '/content/tmp/traindataset/GT/GT_481.png', '/content/tmp/traindataset/GT/GT_482.png', '/content/tmp/traindataset/GT/GT_490.png', '/content/tmp/traindataset/GT/GT_491.png', '/content/tmp/traindataset/GT/GT_492.png', '/content/tmp/traindataset/GT/GT_50.png', '/content/tmp/traindataset/GT/GT_500.png', '/content/tmp/traindataset/GT/GT_501.png', '/content/tmp/traindataset/GT/GT_502.png', '/content/tmp/traindataset/GT/GT_51.png', '/content/tmp/traindataset/GT/GT_510.png', '/content/tmp/traindataset/GT/GT_511.png', '/content/tmp/traindataset/GT/GT_512.png', '/content/tmp/traindataset/GT/GT_52.png', '/content/tmp/traindataset/GT/GT_520.png', '/content/tmp/traindataset/GT/GT_521.png', '/content/tmp/traindataset/GT/GT_522.png', '/content/tmp/traindataset/GT/GT_530.png', '/content/tmp/traindataset/GT/GT_531.png', '/content/tmp/traindataset/GT/GT_532.png', '/content/tmp/traindataset/GT/GT_540.png', '/content/tmp/traindataset/GT/GT_541.png', '/content/tmp/traindataset/GT/GT_542.png', '/content/tmp/traindataset/GT/GT_550.png', '/content/tmp/traindataset/GT/GT_551.png', '/content/tmp/traindataset/GT/GT_552.png', '/content/tmp/traindataset/GT/GT_560.png', '/content/tmp/traindataset/GT/GT_561.png', '/content/tmp/traindataset/GT/GT_562.png', '/content/tmp/traindataset/GT/GT_570.png', '/content/tmp/traindataset/GT/GT_571.png', '/content/tmp/traindataset/GT/GT_572.png', '/content/tmp/traindataset/GT/GT_580.png', '/content/tmp/traindataset/GT/GT_581.png', '/content/tmp/traindataset/GT/GT_582.png', '/content/tmp/traindataset/GT/GT_590.png', '/content/tmp/traindataset/GT/GT_591.png', '/content/tmp/traindataset/GT/GT_592.png', '/content/tmp/traindataset/GT/GT_60.png', '/content/tmp/traindataset/GT/GT_600.png', '/content/tmp/traindataset/GT/GT_601.png', '/content/tmp/traindataset/GT/GT_602.png', '/content/tmp/traindataset/GT/GT_61.png', '/content/tmp/traindataset/GT/GT_610.png', '/content/tmp/traindataset/GT/GT_611.png', '/content/tmp/traindataset/GT/GT_612.png', '/content/tmp/traindataset/GT/GT_62.png', '/content/tmp/traindataset/GT/GT_620.png', '/content/tmp/traindataset/GT/GT_621.png', '/content/tmp/traindataset/GT/GT_622.png', '/content/tmp/traindataset/GT/GT_630.png', '/content/tmp/traindataset/GT/GT_631.png', '/content/tmp/traindataset/GT/GT_632.png', '/content/tmp/traindataset/GT/GT_640.png', '/content/tmp/traindataset/GT/GT_641.png', '/content/tmp/traindataset/GT/GT_642.png', '/content/tmp/traindataset/GT/GT_650.png', '/content/tmp/traindataset/GT/GT_651.png', '/content/tmp/traindataset/GT/GT_652.png', '/content/tmp/traindataset/GT/GT_660.png', '/content/tmp/traindataset/GT/GT_661.png', '/content/tmp/traindataset/GT/GT_662.png', '/content/tmp/traindataset/GT/GT_670.png', '/content/tmp/traindataset/GT/GT_671.png', '/content/tmp/traindataset/GT/GT_672.png', '/content/tmp/traindataset/GT/GT_680.png', '/content/tmp/traindataset/GT/GT_681.png', '/content/tmp/traindataset/GT/GT_682.png', '/content/tmp/traindataset/GT/GT_690.png', '/content/tmp/traindataset/GT/GT_691.png', '/content/tmp/traindataset/GT/GT_692.png', '/content/tmp/traindataset/GT/GT_70.png', '/content/tmp/traindataset/GT/GT_700.png', '/content/tmp/traindataset/GT/GT_701.png', '/content/tmp/traindataset/GT/GT_702.png', '/content/tmp/traindataset/GT/GT_71.png', '/content/tmp/traindataset/GT/GT_710.png', '/content/tmp/traindataset/GT/GT_711.png', '/content/tmp/traindataset/GT/GT_712.png', '/content/tmp/traindataset/GT/GT_72.png', '/content/tmp/traindataset/GT/GT_720.png', '/content/tmp/traindataset/GT/GT_721.png', '/content/tmp/traindataset/GT/GT_722.png', '/content/tmp/traindataset/GT/GT_730.png', '/content/tmp/traindataset/GT/GT_731.png', '/content/tmp/traindataset/GT/GT_732.png', '/content/tmp/traindataset/GT/GT_740.png', '/content/tmp/traindataset/GT/GT_741.png', '/content/tmp/traindataset/GT/GT_742.png', '/content/tmp/traindataset/GT/GT_750.png', '/content/tmp/traindataset/GT/GT_751.png', '/content/tmp/traindataset/GT/GT_752.png', '/content/tmp/traindataset/GT/GT_760.png', '/content/tmp/traindataset/GT/GT_761.png', '/content/tmp/traindataset/GT/GT_762.png', '/content/tmp/traindataset/GT/GT_770.png', '/content/tmp/traindataset/GT/GT_771.png', '/content/tmp/traindataset/GT/GT_772.png', '/content/tmp/traindataset/GT/GT_780.png', '/content/tmp/traindataset/GT/GT_781.png', '/content/tmp/traindataset/GT/GT_782.png', '/content/tmp/traindataset/GT/GT_790.png', '/content/tmp/traindataset/GT/GT_791.png', '/content/tmp/traindataset/GT/GT_792.png', '/content/tmp/traindataset/GT/GT_80.png', '/content/tmp/traindataset/GT/GT_81.png', '/content/tmp/traindataset/GT/GT_82.png', '/content/tmp/traindataset/GT/GT_90.png', '/content/tmp/traindataset/GT/GT_91.png', '/content/tmp/traindataset/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7f65f10e8650>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start train...\n",
            "2022-07-30 15:25:46.220365 Epoch [001/250], Step [0001/0060], Loss1: 0.0888 Loss2: 0.0478 Loss3: -0.0302\n",
            "2022-07-30 15:26:14.617765 Epoch [001/250], Step [0050/0060], Loss1: -0.8865 Loss2: -0.9032 Loss3: -0.9209\n",
            "2022-07-30 15:26:20.366568 Epoch [001/250], Step [0060/0060], Loss1: -0.9000 Loss2: -0.9109 Loss3: -0.9339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 MAE: 0.25626624516078406 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-07-30 15:26:31.863265 Epoch [002/250], Step [0001/0060], Loss1: -0.8683 Loss2: -0.8982 Loss3: -0.9137\n",
            "2022-07-30 15:27:00.147443 Epoch [002/250], Step [0050/0060], Loss1: -0.9120 Loss2: -0.9288 Loss3: -0.9466\n",
            "2022-07-30 15:27:05.911802 Epoch [002/250], Step [0060/0060], Loss1: -0.9200 Loss2: -0.9491 Loss3: -0.9637\n",
            "Epoch: 2 MAE: 0.18874062432183156 ####  bestMAE: 0.25626624516078406 bestEpoch: 0\n",
            "best epoch:2\n",
            "2022-07-30 15:27:16.557691 Epoch [003/250], Step [0001/0060], Loss1: -0.9309 Loss2: -0.9462 Loss3: -0.9638\n",
            "2022-07-30 15:27:46.191621 Epoch [003/250], Step [0050/0060], Loss1: -0.9096 Loss2: -0.9187 Loss3: -0.9545\n",
            "2022-07-30 15:27:51.976217 Epoch [003/250], Step [0060/0060], Loss1: -0.9383 Loss2: -0.9363 Loss3: -0.9628\n",
            "Epoch: 3 MAE: 0.15725523025270494 ####  bestMAE: 0.18874062432183156 bestEpoch: 2\n",
            "best epoch:3\n",
            "2022-07-30 15:28:02.885562 Epoch [004/250], Step [0001/0060], Loss1: -0.9266 Loss2: -0.9444 Loss3: -0.9600\n",
            "2022-07-30 15:28:31.398231 Epoch [004/250], Step [0050/0060], Loss1: -0.9506 Loss2: -0.9389 Loss3: -0.9700\n",
            "2022-07-30 15:28:37.148259 Epoch [004/250], Step [0060/0060], Loss1: -0.9334 Loss2: -0.9375 Loss3: -0.9663\n",
            "Epoch: 4 MAE: 0.16308596898639013 ####  bestMAE: 0.15725523025270494 bestEpoch: 3\n",
            "2022-07-30 15:28:45.150164 Epoch [005/250], Step [0001/0060], Loss1: -0.8898 Loss2: -0.9180 Loss3: -0.9361\n",
            "2022-07-30 15:29:13.465399 Epoch [005/250], Step [0050/0060], Loss1: -0.9493 Loss2: -0.9680 Loss3: -0.9802\n",
            "2022-07-30 15:29:19.250018 Epoch [005/250], Step [0060/0060], Loss1: -0.9435 Loss2: -0.9593 Loss3: -0.9743\n",
            "Epoch: 5 MAE: 0.14612984389855116 ####  bestMAE: 0.15725523025270494 bestEpoch: 3\n",
            "best epoch:5\n",
            "2022-07-30 15:29:32.924449 Epoch [006/250], Step [0001/0060], Loss1: -0.9446 Loss2: -0.9594 Loss3: -0.9749\n",
            "2022-07-30 15:30:04.467081 Epoch [006/250], Step [0050/0060], Loss1: -0.9480 Loss2: -0.9619 Loss3: -0.9743\n",
            "2022-07-30 15:30:10.231216 Epoch [006/250], Step [0060/0060], Loss1: -0.8822 Loss2: -0.8561 Loss3: -0.9371\n",
            "Epoch: 6 MAE: 0.13359463686665532 ####  bestMAE: 0.14612984389855116 bestEpoch: 5\n",
            "best epoch:6\n",
            "2022-07-30 15:30:21.165778 Epoch [007/250], Step [0001/0060], Loss1: -0.9557 Loss2: -0.9617 Loss3: -0.9714\n",
            "2022-07-30 15:30:49.621414 Epoch [007/250], Step [0050/0060], Loss1: -0.9580 Loss2: -0.9614 Loss3: -0.9772\n",
            "2022-07-30 15:30:55.348314 Epoch [007/250], Step [0060/0060], Loss1: -0.9613 Loss2: -0.9705 Loss3: -0.9803\n",
            "Epoch: 7 MAE: 0.14337318844265406 ####  bestMAE: 0.13359463686665532 bestEpoch: 6\n",
            "2022-07-30 15:31:03.562720 Epoch [008/250], Step [0001/0060], Loss1: -0.9517 Loss2: -0.9593 Loss3: -0.9683\n",
            "2022-07-30 15:31:32.009288 Epoch [008/250], Step [0050/0060], Loss1: -0.9611 Loss2: -0.9678 Loss3: -0.9803\n",
            "2022-07-30 15:31:37.789330 Epoch [008/250], Step [0060/0060], Loss1: -0.9506 Loss2: -0.9594 Loss3: -0.9750\n",
            "Epoch: 8 MAE: 0.12633204596383232 ####  bestMAE: 0.13359463686665532 bestEpoch: 6\n",
            "best epoch:8\n",
            "2022-07-30 15:31:48.825493 Epoch [009/250], Step [0001/0060], Loss1: -0.9501 Loss2: -0.9571 Loss3: -0.9717\n",
            "2022-07-30 15:32:18.383514 Epoch [009/250], Step [0050/0060], Loss1: -0.9578 Loss2: -0.9674 Loss3: -0.9786\n",
            "2022-07-30 15:32:24.182174 Epoch [009/250], Step [0060/0060], Loss1: -0.9608 Loss2: -0.9649 Loss3: -0.9820\n",
            "Epoch: 9 MAE: 0.13783928815649935 ####  bestMAE: 0.12633204596383232 bestEpoch: 8\n",
            "2022-07-30 15:32:32.380908 Epoch [010/250], Step [0001/0060], Loss1: -0.9614 Loss2: -0.9664 Loss3: -0.9738\n",
            "2022-07-30 15:33:00.929927 Epoch [010/250], Step [0050/0060], Loss1: -0.9569 Loss2: -0.9656 Loss3: -0.9794\n",
            "2022-07-30 15:33:06.722438 Epoch [010/250], Step [0060/0060], Loss1: -0.9712 Loss2: -0.9734 Loss3: -0.9844\n",
            "Epoch: 10 MAE: 0.1157725373525468 ####  bestMAE: 0.12633204596383232 bestEpoch: 8\n",
            "best epoch:10\n",
            "2022-07-30 15:33:20.392054 Epoch [011/250], Step [0001/0060], Loss1: -0.9395 Loss2: -0.9515 Loss3: -0.9674\n",
            "2022-07-30 15:33:48.711309 Epoch [011/250], Step [0050/0060], Loss1: -0.9689 Loss2: -0.9733 Loss3: -0.9845\n",
            "2022-07-30 15:33:54.456517 Epoch [011/250], Step [0060/0060], Loss1: -0.9725 Loss2: -0.9745 Loss3: -0.9850\n",
            "Epoch: 11 MAE: 0.12306735780504019 ####  bestMAE: 0.1157725373525468 bestEpoch: 10\n",
            "2022-07-30 15:34:02.616118 Epoch [012/250], Step [0001/0060], Loss1: -0.9627 Loss2: -0.9643 Loss3: -0.9741\n",
            "2022-07-30 15:34:34.163343 Epoch [012/250], Step [0050/0060], Loss1: -0.9655 Loss2: -0.9745 Loss3: -0.9848\n",
            "2022-07-30 15:34:39.921003 Epoch [012/250], Step [0060/0060], Loss1: -0.9491 Loss2: -0.9631 Loss3: -0.9739\n",
            "Epoch: 12 MAE: 0.11174029193857994 ####  bestMAE: 0.1157725373525468 bestEpoch: 10\n",
            "best epoch:12\n",
            "2022-07-30 15:34:50.772014 Epoch [013/250], Step [0001/0060], Loss1: -0.9650 Loss2: -0.9719 Loss3: -0.9801\n",
            "2022-07-30 15:35:19.172382 Epoch [013/250], Step [0050/0060], Loss1: -0.9536 Loss2: -0.9731 Loss3: -0.9799\n",
            "2022-07-30 15:35:24.933523 Epoch [013/250], Step [0060/0060], Loss1: -0.9579 Loss2: -0.9726 Loss3: -0.9788\n",
            "Epoch: 13 MAE: 0.10607929461847537 ####  bestMAE: 0.11174029193857994 bestEpoch: 12\n",
            "best epoch:13\n",
            "2022-07-30 15:35:35.880306 Epoch [014/250], Step [0001/0060], Loss1: -0.9733 Loss2: -0.9748 Loss3: -0.9858\n",
            "2022-07-30 15:36:04.331672 Epoch [014/250], Step [0050/0060], Loss1: -0.9694 Loss2: -0.9744 Loss3: -0.9843\n",
            "2022-07-30 15:36:10.029999 Epoch [014/250], Step [0060/0060], Loss1: -0.9547 Loss2: -0.9703 Loss3: -0.9796\n",
            "Epoch: 14 MAE: 0.10712890978212708 ####  bestMAE: 0.10607929461847537 bestEpoch: 13\n",
            "2022-07-30 15:36:18.083946 Epoch [015/250], Step [0001/0060], Loss1: -0.9751 Loss2: -0.9755 Loss3: -0.9870\n",
            "2022-07-30 15:36:48.083617 Epoch [015/250], Step [0050/0060], Loss1: -0.9584 Loss2: -0.9666 Loss3: -0.9790\n",
            "2022-07-30 15:36:53.882776 Epoch [015/250], Step [0060/0060], Loss1: -0.9652 Loss2: -0.9710 Loss3: -0.9829\n",
            "Epoch: 15 MAE: 0.10578255920813828 ####  bestMAE: 0.10607929461847537 bestEpoch: 13\n",
            "best epoch:15\n",
            "2022-07-30 15:37:07.805323 Epoch [016/250], Step [0001/0060], Loss1: -0.9717 Loss2: -0.9743 Loss3: -0.9847\n",
            "2022-07-30 15:37:36.196850 Epoch [016/250], Step [0050/0060], Loss1: -0.9718 Loss2: -0.9739 Loss3: -0.9865\n",
            "2022-07-30 15:37:41.984547 Epoch [016/250], Step [0060/0060], Loss1: -0.9616 Loss2: -0.9712 Loss3: -0.9825\n",
            "Epoch: 16 MAE: 0.10630685150307956 ####  bestMAE: 0.10578255920813828 bestEpoch: 15\n",
            "2022-07-30 15:37:50.265806 Epoch [017/250], Step [0001/0060], Loss1: -0.9622 Loss2: -0.9717 Loss3: -0.9817\n",
            "2022-07-30 15:38:18.733058 Epoch [017/250], Step [0050/0060], Loss1: -0.9731 Loss2: -0.9771 Loss3: -0.9856\n",
            "2022-07-30 15:38:24.482552 Epoch [017/250], Step [0060/0060], Loss1: -0.9702 Loss2: -0.9701 Loss3: -0.9841\n",
            "Epoch: 17 MAE: 0.09674576663466358 ####  bestMAE: 0.10578255920813828 bestEpoch: 15\n",
            "best epoch:17\n",
            "2022-07-30 15:38:36.990624 Epoch [018/250], Step [0001/0060], Loss1: -0.9723 Loss2: -0.9774 Loss3: -0.9857\n",
            "2022-07-30 15:39:05.456271 Epoch [018/250], Step [0050/0060], Loss1: -0.9702 Loss2: -0.9752 Loss3: -0.9856\n",
            "2022-07-30 15:39:11.195439 Epoch [018/250], Step [0060/0060], Loss1: -0.9750 Loss2: -0.9768 Loss3: -0.9850\n",
            "Epoch: 18 MAE: 0.10114434509681014 ####  bestMAE: 0.09674576663466358 bestEpoch: 17\n",
            "2022-07-30 15:39:19.450601 Epoch [019/250], Step [0001/0060], Loss1: -0.9637 Loss2: -0.9746 Loss3: -0.9836\n",
            "2022-07-30 15:39:47.841300 Epoch [019/250], Step [0050/0060], Loss1: -0.9684 Loss2: -0.9785 Loss3: -0.9858\n",
            "2022-07-30 15:39:53.587423 Epoch [019/250], Step [0060/0060], Loss1: -0.9725 Loss2: -0.9793 Loss3: -0.9857\n",
            "Epoch: 19 MAE: 0.09651736345240677 ####  bestMAE: 0.09674576663466358 bestEpoch: 17\n",
            "best epoch:19\n",
            "2022-07-30 15:40:04.538315 Epoch [020/250], Step [0001/0060], Loss1: -0.9761 Loss2: -0.9787 Loss3: -0.9866\n",
            "2022-07-30 15:40:32.882907 Epoch [020/250], Step [0050/0060], Loss1: -0.9784 Loss2: -0.9790 Loss3: -0.9879\n",
            "2022-07-30 15:40:38.589610 Epoch [020/250], Step [0060/0060], Loss1: -0.9769 Loss2: -0.9767 Loss3: -0.9870\n",
            "Epoch: 20 MAE: 0.09992554558648005 ####  bestMAE: 0.09651736345240677 bestEpoch: 19\n",
            "2022-07-30 15:40:51.772631 Epoch [021/250], Step [0001/0060], Loss1: -0.9661 Loss2: -0.9778 Loss3: -0.9850\n",
            "2022-07-30 15:41:20.272454 Epoch [021/250], Step [0050/0060], Loss1: -0.9789 Loss2: -0.9765 Loss3: -0.9875\n",
            "2022-07-30 15:41:26.015989 Epoch [021/250], Step [0060/0060], Loss1: -0.9725 Loss2: -0.9772 Loss3: -0.9860\n",
            "Epoch: 21 MAE: 0.09522828541104755 ####  bestMAE: 0.09651736345240677 bestEpoch: 19\n",
            "best epoch:21\n",
            "2022-07-30 15:41:36.876238 Epoch [022/250], Step [0001/0060], Loss1: -0.9724 Loss2: -0.9779 Loss3: -0.9863\n",
            "2022-07-30 15:42:05.102251 Epoch [022/250], Step [0050/0060], Loss1: -0.9787 Loss2: -0.9781 Loss3: -0.9887\n",
            "2022-07-30 15:42:10.838025 Epoch [022/250], Step [0060/0060], Loss1: -0.9738 Loss2: -0.9768 Loss3: -0.9864\n",
            "Epoch: 22 MAE: 0.09108032761427458 ####  bestMAE: 0.09522828541104755 bestEpoch: 21\n",
            "best epoch:22\n",
            "2022-07-30 15:42:21.897036 Epoch [023/250], Step [0001/0060], Loss1: -0.9748 Loss2: -0.9772 Loss3: -0.9867\n",
            "2022-07-30 15:42:50.344180 Epoch [023/250], Step [0050/0060], Loss1: -0.9779 Loss2: -0.9793 Loss3: -0.9879\n",
            "2022-07-30 15:42:58.057630 Epoch [023/250], Step [0060/0060], Loss1: -0.9685 Loss2: -0.9766 Loss3: -0.9840\n",
            "Epoch: 23 MAE: 0.09226510285069704 ####  bestMAE: 0.09108032761427458 bestEpoch: 22\n",
            "2022-07-30 15:43:07.530192 Epoch [024/250], Step [0001/0060], Loss1: -0.9731 Loss2: -0.9733 Loss3: -0.9857\n",
            "2022-07-30 15:43:35.945425 Epoch [024/250], Step [0050/0060], Loss1: -0.9767 Loss2: -0.9796 Loss3: -0.9876\n",
            "2022-07-30 15:43:41.669857 Epoch [024/250], Step [0060/0060], Loss1: -0.9757 Loss2: -0.9791 Loss3: -0.9866\n",
            "Epoch: 24 MAE: 0.09068310086689298 ####  bestMAE: 0.09108032761427458 bestEpoch: 22\n",
            "best epoch:24\n",
            "2022-07-30 15:43:52.633059 Epoch [025/250], Step [0001/0060], Loss1: -0.9799 Loss2: -0.9826 Loss3: -0.9894\n",
            "2022-07-30 15:44:20.959116 Epoch [025/250], Step [0050/0060], Loss1: -0.9739 Loss2: -0.9785 Loss3: -0.9862\n",
            "2022-07-30 15:44:26.743019 Epoch [025/250], Step [0060/0060], Loss1: -0.9785 Loss2: -0.9801 Loss3: -0.9878\n",
            "Epoch: 25 MAE: 0.09017219926945115 ####  bestMAE: 0.09068310086689298 bestEpoch: 24\n",
            "best epoch:25\n",
            "2022-07-30 15:44:40.452428 Epoch [026/250], Step [0001/0060], Loss1: -0.9815 Loss2: -0.9822 Loss3: -0.9889\n",
            "2022-07-30 15:45:10.306435 Epoch [026/250], Step [0050/0060], Loss1: -0.9762 Loss2: -0.9791 Loss3: -0.9870\n",
            "2022-07-30 15:45:18.008340 Epoch [026/250], Step [0060/0060], Loss1: -0.9817 Loss2: -0.9836 Loss3: -0.9893\n",
            "Epoch: 26 MAE: 0.08969520508296908 ####  bestMAE: 0.09017219926945115 bestEpoch: 25\n",
            "best epoch:26\n",
            "2022-07-30 15:45:28.964184 Epoch [027/250], Step [0001/0060], Loss1: -0.9667 Loss2: -0.9721 Loss3: -0.9812\n",
            "2022-07-30 15:45:57.283792 Epoch [027/250], Step [0050/0060], Loss1: -0.9743 Loss2: -0.9769 Loss3: -0.9863\n",
            "2022-07-30 15:46:03.018421 Epoch [027/250], Step [0060/0060], Loss1: -0.9717 Loss2: -0.9738 Loss3: -0.9849\n",
            "Epoch: 27 MAE: 0.08780744027839134 ####  bestMAE: 0.08969520508296908 bestEpoch: 26\n",
            "best epoch:27\n",
            "2022-07-30 15:46:14.024321 Epoch [028/250], Step [0001/0060], Loss1: -0.9734 Loss2: -0.9742 Loss3: -0.9854\n",
            "2022-07-30 15:46:42.380584 Epoch [028/250], Step [0050/0060], Loss1: -0.9821 Loss2: -0.9818 Loss3: -0.9899\n",
            "2022-07-30 15:46:48.106802 Epoch [028/250], Step [0060/0060], Loss1: -0.9821 Loss2: -0.9822 Loss3: -0.9898\n",
            "Epoch: 28 MAE: 0.08815469994116079 ####  bestMAE: 0.08780744027839134 bestEpoch: 27\n",
            "2022-07-30 15:46:56.159069 Epoch [029/250], Step [0001/0060], Loss1: -0.9795 Loss2: -0.9833 Loss3: -0.9892\n",
            "2022-07-30 15:47:25.380753 Epoch [029/250], Step [0050/0060], Loss1: -0.9725 Loss2: -0.9769 Loss3: -0.9854\n",
            "2022-07-30 15:47:31.555462 Epoch [029/250], Step [0060/0060], Loss1: -0.9804 Loss2: -0.9800 Loss3: -0.9883\n",
            "Epoch: 29 MAE: 0.08328793106886444 ####  bestMAE: 0.08780744027839134 bestEpoch: 27\n",
            "best epoch:29\n",
            "2022-07-30 15:47:42.461614 Epoch [030/250], Step [0001/0060], Loss1: -0.9723 Loss2: -0.9772 Loss3: -0.9849\n",
            "2022-07-30 15:48:10.785447 Epoch [030/250], Step [0050/0060], Loss1: -0.9817 Loss2: -0.9803 Loss3: -0.9893\n",
            "2022-07-30 15:48:16.490165 Epoch [030/250], Step [0060/0060], Loss1: -0.9731 Loss2: -0.9780 Loss3: -0.9863\n",
            "Epoch: 30 MAE: 0.08636273621251343 ####  bestMAE: 0.08328793106886444 bestEpoch: 29\n",
            "2022-07-30 15:48:27.133015 Epoch [031/250], Step [0001/0060], Loss1: -0.9780 Loss2: -0.9786 Loss3: -0.9868\n",
            "2022-07-30 15:48:55.494103 Epoch [031/250], Step [0050/0060], Loss1: -0.9757 Loss2: -0.9773 Loss3: -0.9867\n",
            "2022-07-30 15:49:01.218254 Epoch [031/250], Step [0060/0060], Loss1: -0.9827 Loss2: -0.9836 Loss3: -0.9901\n",
            "Epoch: 31 MAE: 0.0915893572852725 ####  bestMAE: 0.08328793106886444 bestEpoch: 29\n",
            "2022-07-30 15:49:09.296516 Epoch [032/250], Step [0001/0060], Loss1: -0.9810 Loss2: -0.9809 Loss3: -0.9890\n",
            "2022-07-30 15:49:40.064576 Epoch [032/250], Step [0050/0060], Loss1: -0.9741 Loss2: -0.9749 Loss3: -0.9863\n",
            "2022-07-30 15:49:46.453409 Epoch [032/250], Step [0060/0060], Loss1: -0.9724 Loss2: -0.9769 Loss3: -0.9859\n",
            "Epoch: 32 MAE: 0.0880034634423634 ####  bestMAE: 0.08328793106886444 bestEpoch: 29\n",
            "2022-07-30 15:49:54.528239 Epoch [033/250], Step [0001/0060], Loss1: -0.9807 Loss2: -0.9824 Loss3: -0.9901\n",
            "2022-07-30 15:50:22.741486 Epoch [033/250], Step [0050/0060], Loss1: -0.9804 Loss2: -0.9821 Loss3: -0.9890\n",
            "2022-07-30 15:50:28.453016 Epoch [033/250], Step [0060/0060], Loss1: -0.9807 Loss2: -0.9810 Loss3: -0.9889\n",
            "Epoch: 33 MAE: 0.08417177381969633 ####  bestMAE: 0.08328793106886444 bestEpoch: 29\n",
            "2022-07-30 15:50:36.492621 Epoch [034/250], Step [0001/0060], Loss1: -0.9786 Loss2: -0.9826 Loss3: -0.9892\n",
            "2022-07-30 15:51:04.732267 Epoch [034/250], Step [0050/0060], Loss1: -0.9783 Loss2: -0.9795 Loss3: -0.9869\n",
            "2022-07-30 15:51:10.477638 Epoch [034/250], Step [0060/0060], Loss1: -0.9764 Loss2: -0.9807 Loss3: -0.9881\n",
            "Epoch: 34 MAE: 0.07951838347016192 ####  bestMAE: 0.08328793106886444 bestEpoch: 29\n",
            "best epoch:34\n",
            "2022-07-30 15:51:21.447432 Epoch [035/250], Step [0001/0060], Loss1: -0.9757 Loss2: -0.9826 Loss3: -0.9884\n",
            "2022-07-30 15:51:50.788228 Epoch [035/250], Step [0050/0060], Loss1: -0.9809 Loss2: -0.9802 Loss3: -0.9874\n",
            "2022-07-30 15:51:56.871440 Epoch [035/250], Step [0060/0060], Loss1: -0.9835 Loss2: -0.9825 Loss3: -0.9899\n",
            "Epoch: 35 MAE: 0.08782937256747453 ####  bestMAE: 0.07951838347016192 bestEpoch: 34\n",
            "2022-07-30 15:52:07.696018 Epoch [036/250], Step [0001/0060], Loss1: -0.9822 Loss2: -0.9832 Loss3: -0.9896\n",
            "2022-07-30 15:52:35.957694 Epoch [036/250], Step [0050/0060], Loss1: -0.9805 Loss2: -0.9813 Loss3: -0.9879\n",
            "2022-07-30 15:52:41.727405 Epoch [036/250], Step [0060/0060], Loss1: -0.9746 Loss2: -0.9798 Loss3: -0.9854\n",
            "Epoch: 36 MAE: 0.0917148083479947 ####  bestMAE: 0.07951838347016192 bestEpoch: 34\n",
            "2022-07-30 15:52:49.781657 Epoch [037/250], Step [0001/0060], Loss1: -0.9798 Loss2: -0.9778 Loss3: -0.9877\n",
            "2022-07-30 15:53:18.082179 Epoch [037/250], Step [0050/0060], Loss1: -0.9621 Loss2: -0.9648 Loss3: -0.9791\n",
            "2022-07-30 15:53:23.845089 Epoch [037/250], Step [0060/0060], Loss1: -0.9754 Loss2: -0.9806 Loss3: -0.9869\n",
            "Epoch: 37 MAE: 0.07837509902066021 ####  bestMAE: 0.07951838347016192 bestEpoch: 34\n",
            "best epoch:37\n",
            "2022-07-30 15:53:34.805750 Epoch [038/250], Step [0001/0060], Loss1: -0.9796 Loss2: -0.9819 Loss3: -0.9894\n",
            "2022-07-30 15:54:05.858921 Epoch [038/250], Step [0050/0060], Loss1: -0.9792 Loss2: -0.9822 Loss3: -0.9879\n",
            "2022-07-30 15:54:12.149484 Epoch [038/250], Step [0060/0060], Loss1: -0.9795 Loss2: -0.9799 Loss3: -0.9886\n",
            "Epoch: 38 MAE: 0.08359448135214509 ####  bestMAE: 0.07837509902066021 bestEpoch: 37\n",
            "2022-07-30 15:54:20.247004 Epoch [039/250], Step [0001/0060], Loss1: -0.9837 Loss2: -0.9844 Loss3: -0.9907\n",
            "2022-07-30 15:54:48.597716 Epoch [039/250], Step [0050/0060], Loss1: -0.9838 Loss2: -0.9836 Loss3: -0.9900\n",
            "2022-07-30 15:54:54.316169 Epoch [039/250], Step [0060/0060], Loss1: -0.9756 Loss2: -0.9761 Loss3: -0.9853\n",
            "Epoch: 39 MAE: 0.08759459278570916 ####  bestMAE: 0.07837509902066021 bestEpoch: 37\n",
            "2022-07-30 15:55:02.487730 Epoch [040/250], Step [0001/0060], Loss1: -0.9780 Loss2: -0.9779 Loss3: -0.9879\n",
            "2022-07-30 15:55:30.854322 Epoch [040/250], Step [0050/0060], Loss1: -0.9785 Loss2: -0.9862 Loss3: -0.9904\n",
            "2022-07-30 15:55:36.592867 Epoch [040/250], Step [0060/0060], Loss1: -0.9812 Loss2: -0.9820 Loss3: -0.9885\n",
            "Epoch: 40 MAE: 0.08740743435249126 ####  bestMAE: 0.07837509902066021 bestEpoch: 37\n",
            "2022-07-30 15:55:47.282040 Epoch [041/250], Step [0001/0060], Loss1: -0.9821 Loss2: -0.9803 Loss3: -0.9883\n",
            "2022-07-30 15:56:17.118072 Epoch [041/250], Step [0050/0060], Loss1: -0.9818 Loss2: -0.9825 Loss3: -0.9893\n",
            "2022-07-30 15:56:24.504641 Epoch [041/250], Step [0060/0060], Loss1: -0.9851 Loss2: -0.9834 Loss3: -0.9907\n",
            "Epoch: 41 MAE: 0.0836318683119678 ####  bestMAE: 0.07837509902066021 bestEpoch: 37\n",
            "2022-07-30 15:56:32.541308 Epoch [042/250], Step [0001/0060], Loss1: -0.9797 Loss2: -0.9756 Loss3: -0.9868\n",
            "2022-07-30 15:57:00.761127 Epoch [042/250], Step [0050/0060], Loss1: -0.9788 Loss2: -0.9805 Loss3: -0.9874\n",
            "2022-07-30 15:57:06.490685 Epoch [042/250], Step [0060/0060], Loss1: -0.9774 Loss2: -0.9825 Loss3: -0.9883\n",
            "Epoch: 42 MAE: 0.07992550421013403 ####  bestMAE: 0.07837509902066021 bestEpoch: 37\n",
            "2022-07-30 15:57:14.278134 Epoch [043/250], Step [0001/0060], Loss1: -0.9751 Loss2: -0.9786 Loss3: -0.9870\n",
            "2022-07-30 15:57:42.402583 Epoch [043/250], Step [0050/0060], Loss1: -0.9824 Loss2: -0.9841 Loss3: -0.9897\n",
            "2022-07-30 15:57:48.107573 Epoch [043/250], Step [0060/0060], Loss1: -0.9663 Loss2: -0.9795 Loss3: -0.9860\n",
            "Epoch: 43 MAE: 0.08066081556693587 ####  bestMAE: 0.07837509902066021 bestEpoch: 37\n",
            "2022-07-30 15:57:55.943887 Epoch [044/250], Step [0001/0060], Loss1: -0.9833 Loss2: -0.9841 Loss3: -0.9905\n",
            "2022-07-30 15:58:24.158295 Epoch [044/250], Step [0050/0060], Loss1: -0.9799 Loss2: -0.9838 Loss3: -0.9897\n",
            "2022-07-30 15:58:30.642277 Epoch [044/250], Step [0060/0060], Loss1: -0.9772 Loss2: -0.9794 Loss3: -0.9869\n",
            "Epoch: 44 MAE: 0.08769191550199318 ####  bestMAE: 0.07837509902066021 bestEpoch: 37\n",
            "2022-07-30 15:58:38.942091 Epoch [045/250], Step [0001/0060], Loss1: -0.9861 Loss2: -0.9858 Loss3: -0.9912\n",
            "2022-07-30 15:59:07.166012 Epoch [045/250], Step [0050/0060], Loss1: -0.9811 Loss2: -0.9817 Loss3: -0.9882\n",
            "2022-07-30 15:59:12.855165 Epoch [045/250], Step [0060/0060], Loss1: -0.9852 Loss2: -0.9847 Loss3: -0.9913\n",
            "Epoch: 45 MAE: 0.07933187948963628 ####  bestMAE: 0.07837509902066021 bestEpoch: 37\n",
            "2022-07-30 15:59:23.863287 Epoch [046/250], Step [0001/0060], Loss1: -0.9837 Loss2: -0.9836 Loss3: -0.9902\n",
            "2022-07-30 15:59:52.094625 Epoch [046/250], Step [0050/0060], Loss1: -0.9843 Loss2: -0.9839 Loss3: -0.9903\n",
            "2022-07-30 15:59:57.855750 Epoch [046/250], Step [0060/0060], Loss1: -0.9789 Loss2: -0.9799 Loss3: -0.9881\n",
            "Epoch: 46 MAE: 0.07905690258772914 ####  bestMAE: 0.07837509902066021 bestEpoch: 37\n",
            "2022-07-30 16:00:06.043015 Epoch [047/250], Step [0001/0060], Loss1: -0.9762 Loss2: -0.9809 Loss3: -0.9874\n",
            "2022-07-30 16:00:34.212971 Epoch [047/250], Step [0050/0060], Loss1: -0.9858 Loss2: -0.9843 Loss3: -0.9906\n",
            "2022-07-30 16:00:41.431143 Epoch [047/250], Step [0060/0060], Loss1: -0.9829 Loss2: -0.9842 Loss3: -0.9890\n",
            "Epoch: 47 MAE: 0.08071214322690612 ####  bestMAE: 0.07837509902066021 bestEpoch: 37\n",
            "2022-07-30 16:00:51.453390 Epoch [048/250], Step [0001/0060], Loss1: -0.9840 Loss2: -0.9835 Loss3: -0.9890\n",
            "2022-07-30 16:01:19.622650 Epoch [048/250], Step [0050/0060], Loss1: -0.9811 Loss2: -0.9823 Loss3: -0.9887\n",
            "2022-07-30 16:01:25.361861 Epoch [048/250], Step [0060/0060], Loss1: -0.9837 Loss2: -0.9865 Loss3: -0.9906\n",
            "Epoch: 48 MAE: 0.07767167934034239 ####  bestMAE: 0.07837509902066021 bestEpoch: 37\n",
            "best epoch:48\n",
            "2022-07-30 16:01:37.180265 Epoch [049/250], Step [0001/0060], Loss1: -0.9788 Loss2: -0.9817 Loss3: -0.9879\n",
            "2022-07-30 16:02:05.275791 Epoch [049/250], Step [0050/0060], Loss1: -0.9807 Loss2: -0.9813 Loss3: -0.9892\n",
            "2022-07-30 16:02:11.031297 Epoch [049/250], Step [0060/0060], Loss1: -0.9848 Loss2: -0.9858 Loss3: -0.9911\n",
            "Epoch: 49 MAE: 0.0730406488186468 ####  bestMAE: 0.07767167934034239 bestEpoch: 48\n",
            "best epoch:49\n",
            "2022-07-30 16:02:22.156136 Epoch [050/250], Step [0001/0060], Loss1: -0.9844 Loss2: -0.9860 Loss3: -0.9910\n",
            "2022-07-30 16:02:50.507360 Epoch [050/250], Step [0050/0060], Loss1: -0.9736 Loss2: -0.9765 Loss3: -0.9845\n",
            "2022-07-30 16:02:56.928338 Epoch [050/250], Step [0060/0060], Loss1: -0.9768 Loss2: -0.9815 Loss3: -0.9874\n",
            "Epoch: 50 MAE: 0.07519718281175723 ####  bestMAE: 0.0730406488186468 bestEpoch: 49\n",
            "2022-07-30 16:03:08.457698 Epoch [051/250], Step [0001/0060], Loss1: -0.9782 Loss2: -0.9814 Loss3: -0.9867\n",
            "2022-07-30 16:03:36.862414 Epoch [051/250], Step [0050/0060], Loss1: -0.9717 Loss2: -0.9782 Loss3: -0.9843\n",
            "2022-07-30 16:03:42.623409 Epoch [051/250], Step [0060/0060], Loss1: -0.9811 Loss2: -0.9852 Loss3: -0.9906\n",
            "Epoch: 51 MAE: 0.07907416313413589 ####  bestMAE: 0.0730406488186468 bestEpoch: 49\n",
            "2022-07-30 16:03:50.693997 Epoch [052/250], Step [0001/0060], Loss1: -0.9854 Loss2: -0.9873 Loss3: -0.9918\n",
            "2022-07-30 16:04:19.143968 Epoch [052/250], Step [0050/0060], Loss1: -0.9773 Loss2: -0.9812 Loss3: -0.9877\n",
            "2022-07-30 16:04:24.868130 Epoch [052/250], Step [0060/0060], Loss1: -0.9812 Loss2: -0.9835 Loss3: -0.9876\n",
            "Epoch: 52 MAE: 0.07708171773839881 ####  bestMAE: 0.0730406488186468 bestEpoch: 49\n",
            "2022-07-30 16:04:33.060579 Epoch [053/250], Step [0001/0060], Loss1: -0.9752 Loss2: -0.9761 Loss3: -0.9847\n",
            "2022-07-30 16:05:01.434890 Epoch [053/250], Step [0050/0060], Loss1: -0.9797 Loss2: -0.9807 Loss3: -0.9877\n",
            "2022-07-30 16:05:07.502760 Epoch [053/250], Step [0060/0060], Loss1: -0.9805 Loss2: -0.9825 Loss3: -0.9896\n",
            "Epoch: 53 MAE: 0.0776306754823715 ####  bestMAE: 0.0730406488186468 bestEpoch: 49\n",
            "2022-07-30 16:05:18.926339 Epoch [054/250], Step [0001/0060], Loss1: -0.9852 Loss2: -0.9853 Loss3: -0.9907\n",
            "2022-07-30 16:05:47.275394 Epoch [054/250], Step [0050/0060], Loss1: -0.9859 Loss2: -0.9840 Loss3: -0.9907\n",
            "2022-07-30 16:05:53.058858 Epoch [054/250], Step [0060/0060], Loss1: -0.9833 Loss2: -0.9840 Loss3: -0.9904\n",
            "Epoch: 54 MAE: 0.08154933667056775 ####  bestMAE: 0.0730406488186468 bestEpoch: 49\n",
            "2022-07-30 16:06:01.283594 Epoch [055/250], Step [0001/0060], Loss1: -0.9836 Loss2: -0.9836 Loss3: -0.9899\n",
            "2022-07-30 16:06:29.671563 Epoch [055/250], Step [0050/0060], Loss1: -0.9854 Loss2: -0.9855 Loss3: -0.9908\n",
            "2022-07-30 16:06:35.459276 Epoch [055/250], Step [0060/0060], Loss1: -0.9835 Loss2: -0.9864 Loss3: -0.9904\n",
            "Epoch: 55 MAE: 0.08099942696788325 ####  bestMAE: 0.0730406488186468 bestEpoch: 49\n",
            "2022-07-30 16:06:46.414602 Epoch [056/250], Step [0001/0060], Loss1: -0.9860 Loss2: -0.9849 Loss3: -0.9908\n",
            "2022-07-30 16:07:14.990470 Epoch [056/250], Step [0050/0060], Loss1: -0.9764 Loss2: -0.9815 Loss3: -0.9879\n",
            "2022-07-30 16:07:20.765626 Epoch [056/250], Step [0060/0060], Loss1: -0.9806 Loss2: -0.9827 Loss3: -0.9890\n",
            "Epoch: 56 MAE: 0.07915076977361447 ####  bestMAE: 0.0730406488186468 bestEpoch: 49\n",
            "2022-07-30 16:07:32.003253 Epoch [057/250], Step [0001/0060], Loss1: -0.9794 Loss2: -0.9792 Loss3: -0.9872\n",
            "2022-07-30 16:08:01.097277 Epoch [057/250], Step [0050/0060], Loss1: -0.9857 Loss2: -0.9828 Loss3: -0.9897\n",
            "2022-07-30 16:08:06.853330 Epoch [057/250], Step [0060/0060], Loss1: -0.9861 Loss2: -0.9872 Loss3: -0.9918\n",
            "Epoch: 57 MAE: 0.07830416987181969 ####  bestMAE: 0.0730406488186468 bestEpoch: 49\n",
            "2022-07-30 16:08:15.086238 Epoch [058/250], Step [0001/0060], Loss1: -0.9798 Loss2: -0.9773 Loss3: -0.9861\n",
            "2022-07-30 16:08:43.439072 Epoch [058/250], Step [0050/0060], Loss1: -0.9783 Loss2: -0.9785 Loss3: -0.9872\n",
            "2022-07-30 16:08:49.184646 Epoch [058/250], Step [0060/0060], Loss1: -0.9821 Loss2: -0.9819 Loss3: -0.9901\n",
            "Epoch: 58 MAE: 0.07415035611107237 ####  bestMAE: 0.0730406488186468 bestEpoch: 49\n",
            "2022-07-30 16:08:57.359823 Epoch [059/250], Step [0001/0060], Loss1: -0.9826 Loss2: -0.9821 Loss3: -0.9884\n",
            "2022-07-30 16:09:25.763907 Epoch [059/250], Step [0050/0060], Loss1: -0.9852 Loss2: -0.9863 Loss3: -0.9910\n",
            "2022-07-30 16:09:31.539278 Epoch [059/250], Step [0060/0060], Loss1: -0.9857 Loss2: -0.9864 Loss3: -0.9908\n",
            "Epoch: 59 MAE: 0.07785478238706235 ####  bestMAE: 0.0730406488186468 bestEpoch: 49\n",
            "2022-07-30 16:09:40.756399 Epoch [060/250], Step [0001/0060], Loss1: -0.9832 Loss2: -0.9859 Loss3: -0.9910\n",
            "2022-07-30 16:10:09.604678 Epoch [060/250], Step [0050/0060], Loss1: -0.9811 Loss2: -0.9822 Loss3: -0.9891\n",
            "2022-07-30 16:10:15.361975 Epoch [060/250], Step [0060/0060], Loss1: -0.9714 Loss2: -0.9715 Loss3: -0.9836\n",
            "Epoch: 60 MAE: 0.07657156989687962 ####  bestMAE: 0.0730406488186468 bestEpoch: 49\n",
            "2022-07-30 16:10:26.047065 Epoch [061/250], Step [0001/0060], Loss1: -0.9864 Loss2: -0.9857 Loss3: -0.9919\n",
            "2022-07-30 16:10:54.498658 Epoch [061/250], Step [0050/0060], Loss1: -0.9789 Loss2: -0.9831 Loss3: -0.9893\n",
            "2022-07-30 16:11:00.242514 Epoch [061/250], Step [0060/0060], Loss1: -0.9832 Loss2: -0.9841 Loss3: -0.9907\n",
            "Epoch: 61 MAE: 0.07513481140136719 ####  bestMAE: 0.0730406488186468 bestEpoch: 49\n",
            "2022-07-30 16:11:08.454529 Epoch [062/250], Step [0001/0060], Loss1: -0.9859 Loss2: -0.9862 Loss3: -0.9916\n",
            "2022-07-30 16:11:36.886092 Epoch [062/250], Step [0050/0060], Loss1: -0.9864 Loss2: -0.9845 Loss3: -0.9918\n",
            "2022-07-30 16:11:42.642409 Epoch [062/250], Step [0060/0060], Loss1: -0.9778 Loss2: -0.9768 Loss3: -0.9862\n",
            "Epoch: 62 MAE: 0.07625892649251947 ####  bestMAE: 0.0730406488186468 bestEpoch: 49\n",
            "2022-07-30 16:11:52.236426 Epoch [063/250], Step [0001/0060], Loss1: -0.9799 Loss2: -0.9780 Loss3: -0.9875\n",
            "2022-07-30 16:12:22.845345 Epoch [063/250], Step [0050/0060], Loss1: -0.9803 Loss2: -0.9817 Loss3: -0.9895\n",
            "2022-07-30 16:12:28.615027 Epoch [063/250], Step [0060/0060], Loss1: -0.9842 Loss2: -0.9842 Loss3: -0.9903\n",
            "Epoch: 63 MAE: 0.07718629826944343 ####  bestMAE: 0.0730406488186468 bestEpoch: 49\n",
            "2022-07-30 16:12:36.894597 Epoch [064/250], Step [0001/0060], Loss1: -0.9868 Loss2: -0.9878 Loss3: -0.9926\n",
            "2022-07-30 16:13:05.215351 Epoch [064/250], Step [0050/0060], Loss1: -0.9829 Loss2: -0.9844 Loss3: -0.9903\n",
            "2022-07-30 16:13:10.981544 Epoch [064/250], Step [0060/0060], Loss1: -0.9837 Loss2: -0.9858 Loss3: -0.9907\n",
            "Epoch: 64 MAE: 0.07642969545233187 ####  bestMAE: 0.0730406488186468 bestEpoch: 49\n",
            "2022-07-30 16:13:19.162364 Epoch [065/250], Step [0001/0060], Loss1: -0.9860 Loss2: -0.9852 Loss3: -0.9917\n",
            "2022-07-30 16:13:47.595054 Epoch [065/250], Step [0050/0060], Loss1: -0.9833 Loss2: -0.9841 Loss3: -0.9899\n",
            "2022-07-30 16:13:53.402893 Epoch [065/250], Step [0060/0060], Loss1: -0.9874 Loss2: -0.9861 Loss3: -0.9922\n",
            "Epoch: 65 MAE: 0.0724555755292297 ####  bestMAE: 0.0730406488186468 bestEpoch: 49\n",
            "best epoch:65\n",
            "2022-07-30 16:14:08.440775 Epoch [066/250], Step [0001/0060], Loss1: -0.9818 Loss2: -0.9822 Loss3: -0.9897\n",
            "2022-07-30 16:14:38.521922 Epoch [066/250], Step [0050/0060], Loss1: -0.9863 Loss2: -0.9872 Loss3: -0.9920\n",
            "2022-07-30 16:14:44.276801 Epoch [066/250], Step [0060/0060], Loss1: -0.9847 Loss2: -0.9836 Loss3: -0.9906\n",
            "Epoch: 66 MAE: 0.07520307873922684 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:14:52.432181 Epoch [067/250], Step [0001/0060], Loss1: -0.9827 Loss2: -0.9834 Loss3: -0.9895\n",
            "2022-07-30 16:15:21.023597 Epoch [067/250], Step [0050/0060], Loss1: -0.9818 Loss2: -0.9819 Loss3: -0.9894\n",
            "2022-07-30 16:15:26.806950 Epoch [067/250], Step [0060/0060], Loss1: -0.9869 Loss2: -0.9871 Loss3: -0.9923\n",
            "Epoch: 67 MAE: 0.0747815246682949 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:15:35.057376 Epoch [068/250], Step [0001/0060], Loss1: -0.9861 Loss2: -0.9872 Loss3: -0.9918\n",
            "2022-07-30 16:16:03.412311 Epoch [068/250], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9872 Loss3: -0.9917\n",
            "2022-07-30 16:16:09.208925 Epoch [068/250], Step [0060/0060], Loss1: -0.9873 Loss2: -0.9870 Loss3: -0.9918\n",
            "Epoch: 68 MAE: 0.07372045839905109 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:16:17.436616 Epoch [069/250], Step [0001/0060], Loss1: -0.9869 Loss2: -0.9853 Loss3: -0.9920\n",
            "2022-07-30 16:16:47.153332 Epoch [069/250], Step [0050/0060], Loss1: -0.9732 Loss2: -0.9785 Loss3: -0.9854\n",
            "2022-07-30 16:16:52.895026 Epoch [069/250], Step [0060/0060], Loss1: -0.9862 Loss2: -0.9841 Loss3: -0.9909\n",
            "Epoch: 69 MAE: 0.07616743087768553 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:17:01.124633 Epoch [070/250], Step [0001/0060], Loss1: -0.9824 Loss2: -0.9848 Loss3: -0.9903\n",
            "2022-07-30 16:17:29.608180 Epoch [070/250], Step [0050/0060], Loss1: -0.9778 Loss2: -0.9813 Loss3: -0.9876\n",
            "2022-07-30 16:17:35.416518 Epoch [070/250], Step [0060/0060], Loss1: -0.9815 Loss2: -0.9850 Loss3: -0.9903\n",
            "Epoch: 70 MAE: 0.07448128558971266 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:17:46.254628 Epoch [071/250], Step [0001/0060], Loss1: -0.9853 Loss2: -0.9852 Loss3: -0.9912\n",
            "2022-07-30 16:18:14.741871 Epoch [071/250], Step [0050/0060], Loss1: -0.9847 Loss2: -0.9873 Loss3: -0.9917\n",
            "2022-07-30 16:18:20.534652 Epoch [071/250], Step [0060/0060], Loss1: -0.9839 Loss2: -0.9843 Loss3: -0.9896\n",
            "Epoch: 71 MAE: 0.07267031775580512 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:18:28.948783 Epoch [072/250], Step [0001/0060], Loss1: -0.9867 Loss2: -0.9866 Loss3: -0.9920\n",
            "2022-07-30 16:19:00.119575 Epoch [072/250], Step [0050/0060], Loss1: -0.9856 Loss2: -0.9856 Loss3: -0.9917\n",
            "2022-07-30 16:19:05.902060 Epoch [072/250], Step [0060/0060], Loss1: -0.9850 Loss2: -0.9871 Loss3: -0.9914\n",
            "Epoch: 72 MAE: 0.07436268624805267 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:19:14.136331 Epoch [073/250], Step [0001/0060], Loss1: -0.9748 Loss2: -0.9782 Loss3: -0.9865\n",
            "2022-07-30 16:19:42.419368 Epoch [073/250], Step [0050/0060], Loss1: -0.9845 Loss2: -0.9851 Loss3: -0.9913\n",
            "2022-07-30 16:19:48.183016 Epoch [073/250], Step [0060/0060], Loss1: -0.9762 Loss2: -0.9800 Loss3: -0.9867\n",
            "Epoch: 73 MAE: 0.07554939991582639 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:19:56.360941 Epoch [074/250], Step [0001/0060], Loss1: -0.9834 Loss2: -0.9835 Loss3: -0.9900\n",
            "2022-07-30 16:20:24.857945 Epoch [074/250], Step [0050/0060], Loss1: -0.9850 Loss2: -0.9866 Loss3: -0.9914\n",
            "2022-07-30 16:20:30.609888 Epoch [074/250], Step [0060/0060], Loss1: -0.9769 Loss2: -0.9865 Loss3: -0.9898\n",
            "Epoch: 74 MAE: 0.07390552046437743 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:20:38.783265 Epoch [075/250], Step [0001/0060], Loss1: -0.9875 Loss2: -0.9878 Loss3: -0.9922\n",
            "2022-07-30 16:21:08.593810 Epoch [075/250], Step [0050/0060], Loss1: -0.9860 Loss2: -0.9833 Loss3: -0.9905\n",
            "2022-07-30 16:21:14.363953 Epoch [075/250], Step [0060/0060], Loss1: -0.9770 Loss2: -0.9806 Loss3: -0.9884\n",
            "Epoch: 75 MAE: 0.0747637341009877 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:21:25.305149 Epoch [076/250], Step [0001/0060], Loss1: -0.9845 Loss2: -0.9861 Loss3: -0.9913\n",
            "2022-07-30 16:21:53.838390 Epoch [076/250], Step [0050/0060], Loss1: -0.9821 Loss2: -0.9818 Loss3: -0.9895\n",
            "2022-07-30 16:21:59.677133 Epoch [076/250], Step [0060/0060], Loss1: -0.9848 Loss2: -0.9842 Loss3: -0.9906\n",
            "Epoch: 76 MAE: 0.07327359613287387 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:22:07.911055 Epoch [077/250], Step [0001/0060], Loss1: -0.9778 Loss2: -0.9831 Loss3: -0.9887\n",
            "2022-07-30 16:22:36.513246 Epoch [077/250], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9859 Loss3: -0.9919\n",
            "2022-07-30 16:22:42.264627 Epoch [077/250], Step [0060/0060], Loss1: -0.9850 Loss2: -0.9830 Loss3: -0.9909\n",
            "Epoch: 77 MAE: 0.07325037315409022 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:22:50.539088 Epoch [078/250], Step [0001/0060], Loss1: -0.9857 Loss2: -0.9860 Loss3: -0.9914\n",
            "2022-07-30 16:23:22.508868 Epoch [078/250], Step [0050/0060], Loss1: -0.9828 Loss2: -0.9840 Loss3: -0.9905\n",
            "2022-07-30 16:23:28.292607 Epoch [078/250], Step [0060/0060], Loss1: -0.9755 Loss2: -0.9772 Loss3: -0.9863\n",
            "Epoch: 78 MAE: 0.07630381024073042 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:23:36.572240 Epoch [079/250], Step [0001/0060], Loss1: -0.9849 Loss2: -0.9873 Loss3: -0.9919\n",
            "2022-07-30 16:24:04.959334 Epoch [079/250], Step [0050/0060], Loss1: -0.9798 Loss2: -0.9838 Loss3: -0.9891\n",
            "2022-07-30 16:24:10.755693 Epoch [079/250], Step [0060/0060], Loss1: -0.9768 Loss2: -0.9793 Loss3: -0.9868\n",
            "Epoch: 79 MAE: 0.0782939555657604 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:24:18.943058 Epoch [080/250], Step [0001/0060], Loss1: -0.9842 Loss2: -0.9841 Loss3: -0.9903\n",
            "2022-07-30 16:24:47.418998 Epoch [080/250], Step [0050/0060], Loss1: -0.9834 Loss2: -0.9831 Loss3: -0.9898\n",
            "2022-07-30 16:24:53.217311 Epoch [080/250], Step [0060/0060], Loss1: -0.9795 Loss2: -0.9826 Loss3: -0.9888\n",
            "Epoch: 80 MAE: 0.07353558822914406 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:25:04.357348 Epoch [081/250], Step [0001/0060], Loss1: -0.9849 Loss2: -0.9856 Loss3: -0.9911\n",
            "2022-07-30 16:25:36.114113 Epoch [081/250], Step [0050/0060], Loss1: -0.9834 Loss2: -0.9850 Loss3: -0.9902\n",
            "2022-07-30 16:25:41.859376 Epoch [081/250], Step [0060/0060], Loss1: -0.9828 Loss2: -0.9840 Loss3: -0.9900\n",
            "Epoch: 81 MAE: 0.0760831394901982 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:25:50.011172 Epoch [082/250], Step [0001/0060], Loss1: -0.9778 Loss2: -0.9835 Loss3: -0.9888\n",
            "2022-07-30 16:26:18.414319 Epoch [082/250], Step [0050/0060], Loss1: -0.9831 Loss2: -0.9854 Loss3: -0.9903\n",
            "2022-07-30 16:26:24.182205 Epoch [082/250], Step [0060/0060], Loss1: -0.9842 Loss2: -0.9860 Loss3: -0.9916\n",
            "Epoch: 82 MAE: 0.07497684781513515 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:26:32.297411 Epoch [083/250], Step [0001/0060], Loss1: -0.9865 Loss2: -0.9889 Loss3: -0.9927\n",
            "2022-07-30 16:27:00.732445 Epoch [083/250], Step [0050/0060], Loss1: -0.9860 Loss2: -0.9866 Loss3: -0.9918\n",
            "2022-07-30 16:27:06.502794 Epoch [083/250], Step [0060/0060], Loss1: -0.9835 Loss2: -0.9812 Loss3: -0.9895\n",
            "Epoch: 83 MAE: 0.07664615298074388 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:27:14.607823 Epoch [084/250], Step [0001/0060], Loss1: -0.9872 Loss2: -0.9863 Loss3: -0.9919\n",
            "2022-07-30 16:27:44.330873 Epoch [084/250], Step [0050/0060], Loss1: -0.9878 Loss2: -0.9875 Loss3: -0.9925\n",
            "2022-07-30 16:27:50.074014 Epoch [084/250], Step [0060/0060], Loss1: -0.9842 Loss2: -0.9857 Loss3: -0.9909\n",
            "Epoch: 84 MAE: 0.07317128302559021 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:27:58.270412 Epoch [085/250], Step [0001/0060], Loss1: -0.9861 Loss2: -0.9877 Loss3: -0.9923\n",
            "2022-07-30 16:28:26.684153 Epoch [085/250], Step [0050/0060], Loss1: -0.9854 Loss2: -0.9856 Loss3: -0.9916\n",
            "2022-07-30 16:28:32.458290 Epoch [085/250], Step [0060/0060], Loss1: -0.9829 Loss2: -0.9841 Loss3: -0.9898\n",
            "Epoch: 85 MAE: 0.07590088036955979 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "2022-07-30 16:28:44.676481 Epoch [086/250], Step [0001/0060], Loss1: -0.9780 Loss2: -0.9782 Loss3: -0.9862\n",
            "2022-07-30 16:29:13.015814 Epoch [086/250], Step [0050/0060], Loss1: -0.9822 Loss2: -0.9831 Loss3: -0.9892\n",
            "2022-07-30 16:29:18.742134 Epoch [086/250], Step [0060/0060], Loss1: -0.9868 Loss2: -0.9872 Loss3: -0.9924\n",
            "Epoch: 86 MAE: 0.06967533828089477 ####  bestMAE: 0.0724555755292297 bestEpoch: 65\n",
            "best epoch:86\n",
            "2022-07-30 16:29:29.834126 Epoch [087/250], Step [0001/0060], Loss1: -0.9855 Loss2: -0.9839 Loss3: -0.9909\n",
            "2022-07-30 16:30:01.716102 Epoch [087/250], Step [0050/0060], Loss1: -0.9855 Loss2: -0.9858 Loss3: -0.9913\n",
            "2022-07-30 16:30:07.487522 Epoch [087/250], Step [0060/0060], Loss1: -0.9754 Loss2: -0.9805 Loss3: -0.9873\n",
            "Epoch: 87 MAE: 0.07471810366110826 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:30:15.697825 Epoch [088/250], Step [0001/0060], Loss1: -0.9820 Loss2: -0.9830 Loss3: -0.9898\n",
            "2022-07-30 16:30:44.100481 Epoch [088/250], Step [0050/0060], Loss1: -0.9872 Loss2: -0.9845 Loss3: -0.9914\n",
            "2022-07-30 16:30:49.862938 Epoch [088/250], Step [0060/0060], Loss1: -0.9875 Loss2: -0.9869 Loss3: -0.9922\n",
            "Epoch: 88 MAE: 0.07199821648774325 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:30:58.101811 Epoch [089/250], Step [0001/0060], Loss1: -0.9827 Loss2: -0.9842 Loss3: -0.9903\n",
            "2022-07-30 16:31:26.432399 Epoch [089/250], Step [0050/0060], Loss1: -0.9831 Loss2: -0.9856 Loss3: -0.9905\n",
            "2022-07-30 16:31:32.157480 Epoch [089/250], Step [0060/0060], Loss1: -0.9825 Loss2: -0.9857 Loss3: -0.9908\n",
            "Epoch: 89 MAE: 0.07773929091357679 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:31:40.217087 Epoch [090/250], Step [0001/0060], Loss1: -0.9829 Loss2: -0.9815 Loss3: -0.9888\n",
            "2022-07-30 16:32:09.947049 Epoch [090/250], Step [0050/0060], Loss1: -0.9883 Loss2: -0.9877 Loss3: -0.9927\n",
            "2022-07-30 16:32:15.700990 Epoch [090/250], Step [0060/0060], Loss1: -0.9807 Loss2: -0.9824 Loss3: -0.9884\n",
            "Epoch: 90 MAE: 0.07663732977771255 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:32:26.874179 Epoch [091/250], Step [0001/0060], Loss1: -0.9847 Loss2: -0.9846 Loss3: -0.9905\n",
            "2022-07-30 16:32:55.310127 Epoch [091/250], Step [0050/0060], Loss1: -0.9814 Loss2: -0.9854 Loss3: -0.9904\n",
            "2022-07-30 16:33:01.054128 Epoch [091/250], Step [0060/0060], Loss1: -0.9890 Loss2: -0.9869 Loss3: -0.9927\n",
            "Epoch: 91 MAE: 0.07340788856385247 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:33:09.221048 Epoch [092/250], Step [0001/0060], Loss1: -0.9866 Loss2: -0.9841 Loss3: -0.9905\n",
            "2022-07-30 16:33:37.666658 Epoch [092/250], Step [0050/0060], Loss1: -0.9798 Loss2: -0.9843 Loss3: -0.9894\n",
            "2022-07-30 16:33:43.418698 Epoch [092/250], Step [0060/0060], Loss1: -0.9831 Loss2: -0.9824 Loss3: -0.9893\n",
            "Epoch: 92 MAE: 0.07716078662367727 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:33:51.584579 Epoch [093/250], Step [0001/0060], Loss1: -0.9814 Loss2: -0.9824 Loss3: -0.9892\n",
            "2022-07-30 16:34:23.285772 Epoch [093/250], Step [0050/0060], Loss1: -0.9789 Loss2: -0.9815 Loss3: -0.9888\n",
            "2022-07-30 16:34:29.027417 Epoch [093/250], Step [0060/0060], Loss1: -0.9730 Loss2: -0.9752 Loss3: -0.9854\n",
            "Epoch: 93 MAE: 0.07648165566580634 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:34:37.309495 Epoch [094/250], Step [0001/0060], Loss1: -0.9847 Loss2: -0.9850 Loss3: -0.9914\n",
            "2022-07-30 16:35:05.611579 Epoch [094/250], Step [0050/0060], Loss1: -0.9829 Loss2: -0.9828 Loss3: -0.9895\n",
            "2022-07-30 16:35:11.367415 Epoch [094/250], Step [0060/0060], Loss1: -0.9835 Loss2: -0.9833 Loss3: -0.9895\n",
            "Epoch: 94 MAE: 0.07652836713841354 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:35:19.546490 Epoch [095/250], Step [0001/0060], Loss1: -0.9844 Loss2: -0.9833 Loss3: -0.9910\n",
            "2022-07-30 16:35:47.919046 Epoch [095/250], Step [0050/0060], Loss1: -0.9880 Loss2: -0.9882 Loss3: -0.9926\n",
            "2022-07-30 16:35:53.655075 Epoch [095/250], Step [0060/0060], Loss1: -0.9844 Loss2: -0.9874 Loss3: -0.9917\n",
            "Epoch: 95 MAE: 0.07518079449890781 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:36:05.357648 Epoch [096/250], Step [0001/0060], Loss1: -0.9834 Loss2: -0.9851 Loss3: -0.9908\n",
            "2022-07-30 16:36:37.035013 Epoch [096/250], Step [0050/0060], Loss1: -0.9862 Loss2: -0.9852 Loss3: -0.9914\n",
            "2022-07-30 16:36:42.772095 Epoch [096/250], Step [0060/0060], Loss1: -0.9865 Loss2: -0.9855 Loss3: -0.9911\n",
            "Epoch: 96 MAE: 0.07324911369848504 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:36:50.976013 Epoch [097/250], Step [0001/0060], Loss1: -0.9789 Loss2: -0.9819 Loss3: -0.9884\n",
            "2022-07-30 16:37:19.226020 Epoch [097/250], Step [0050/0060], Loss1: -0.9873 Loss2: -0.9860 Loss3: -0.9921\n",
            "2022-07-30 16:37:24.994288 Epoch [097/250], Step [0060/0060], Loss1: -0.9887 Loss2: -0.9862 Loss3: -0.9928\n",
            "Epoch: 97 MAE: 0.07417800645979625 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:37:33.113262 Epoch [098/250], Step [0001/0060], Loss1: -0.9839 Loss2: -0.9864 Loss3: -0.9915\n",
            "2022-07-30 16:38:01.420343 Epoch [098/250], Step [0050/0060], Loss1: -0.9760 Loss2: -0.9771 Loss3: -0.9858\n",
            "2022-07-30 16:38:07.183845 Epoch [098/250], Step [0060/0060], Loss1: -0.9853 Loss2: -0.9855 Loss3: -0.9916\n",
            "Epoch: 98 MAE: 0.07129876505130181 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:38:15.381911 Epoch [099/250], Step [0001/0060], Loss1: -0.9809 Loss2: -0.9854 Loss3: -0.9903\n",
            "2022-07-30 16:38:45.136317 Epoch [099/250], Step [0050/0060], Loss1: -0.9865 Loss2: -0.9849 Loss3: -0.9912\n",
            "2022-07-30 16:38:50.883172 Epoch [099/250], Step [0060/0060], Loss1: -0.9860 Loss2: -0.9863 Loss3: -0.9919\n",
            "Epoch: 99 MAE: 0.07467539106096538 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:38:59.080524 Epoch [100/250], Step [0001/0060], Loss1: -0.9812 Loss2: -0.9827 Loss3: -0.9899\n",
            "2022-07-30 16:39:27.292142 Epoch [100/250], Step [0050/0060], Loss1: -0.9863 Loss2: -0.9856 Loss3: -0.9916\n",
            "2022-07-30 16:39:33.014492 Epoch [100/250], Step [0060/0060], Loss1: -0.9866 Loss2: -0.9839 Loss3: -0.9910\n",
            "Epoch: 100 MAE: 0.06971713525277598 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:39:44.773248 Epoch [101/250], Step [0001/0060], Loss1: -0.9861 Loss2: -0.9878 Loss3: -0.9919\n",
            "2022-07-30 16:40:13.000775 Epoch [101/250], Step [0050/0060], Loss1: -0.9824 Loss2: -0.9853 Loss3: -0.9906\n",
            "2022-07-30 16:40:18.740192 Epoch [101/250], Step [0060/0060], Loss1: -0.9854 Loss2: -0.9846 Loss3: -0.9908\n",
            "Epoch: 101 MAE: 0.07718998550737975 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:40:26.965775 Epoch [102/250], Step [0001/0060], Loss1: -0.9853 Loss2: -0.9860 Loss3: -0.9912\n",
            "2022-07-30 16:40:57.871995 Epoch [102/250], Step [0050/0060], Loss1: -0.9884 Loss2: -0.9869 Loss3: -0.9926\n",
            "2022-07-30 16:41:03.580078 Epoch [102/250], Step [0060/0060], Loss1: -0.9842 Loss2: -0.9843 Loss3: -0.9903\n",
            "Epoch: 102 MAE: 0.07524983900564688 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:41:11.722141 Epoch [103/250], Step [0001/0060], Loss1: -0.9855 Loss2: -0.9821 Loss3: -0.9902\n",
            "2022-07-30 16:41:39.951204 Epoch [103/250], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9883 Loss3: -0.9930\n",
            "2022-07-30 16:41:45.662861 Epoch [103/250], Step [0060/0060], Loss1: -0.9864 Loss2: -0.9871 Loss3: -0.9921\n",
            "Epoch: 103 MAE: 0.07587865622586044 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:41:53.937864 Epoch [104/250], Step [0001/0060], Loss1: -0.9843 Loss2: -0.9834 Loss3: -0.9895\n",
            "2022-07-30 16:42:22.190984 Epoch [104/250], Step [0050/0060], Loss1: -0.9860 Loss2: -0.9849 Loss3: -0.9913\n",
            "2022-07-30 16:42:27.922657 Epoch [104/250], Step [0060/0060], Loss1: -0.9814 Loss2: -0.9804 Loss3: -0.9878\n",
            "Epoch: 104 MAE: 0.0735590450852005 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:42:36.127291 Epoch [105/250], Step [0001/0060], Loss1: -0.9883 Loss2: -0.9887 Loss3: -0.9927\n",
            "2022-07-30 16:43:05.686190 Epoch [105/250], Step [0050/0060], Loss1: -0.9836 Loss2: -0.9843 Loss3: -0.9910\n",
            "2022-07-30 16:43:11.405548 Epoch [105/250], Step [0060/0060], Loss1: -0.9814 Loss2: -0.9853 Loss3: -0.9904\n",
            "Epoch: 105 MAE: 0.07803059310509416 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:43:22.443048 Epoch [106/250], Step [0001/0060], Loss1: -0.9865 Loss2: -0.9858 Loss3: -0.9912\n",
            "2022-07-30 16:43:50.687965 Epoch [106/250], Step [0050/0060], Loss1: -0.9800 Loss2: -0.9828 Loss3: -0.9896\n",
            "2022-07-30 16:43:56.399888 Epoch [106/250], Step [0060/0060], Loss1: -0.9814 Loss2: -0.9832 Loss3: -0.9893\n",
            "Epoch: 106 MAE: 0.07485945328202828 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:44:04.538047 Epoch [107/250], Step [0001/0060], Loss1: -0.9879 Loss2: -0.9891 Loss3: -0.9932\n",
            "2022-07-30 16:44:32.808413 Epoch [107/250], Step [0050/0060], Loss1: -0.9831 Loss2: -0.9862 Loss3: -0.9910\n",
            "2022-07-30 16:44:38.518209 Epoch [107/250], Step [0060/0060], Loss1: -0.9853 Loss2: -0.9855 Loss3: -0.9913\n",
            "Epoch: 107 MAE: 0.07345750051831441 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:44:46.706047 Epoch [108/250], Step [0001/0060], Loss1: -0.9796 Loss2: -0.9819 Loss3: -0.9890\n",
            "2022-07-30 16:45:17.940360 Epoch [108/250], Step [0050/0060], Loss1: -0.9850 Loss2: -0.9867 Loss3: -0.9913\n",
            "2022-07-30 16:45:23.675575 Epoch [108/250], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9874 Loss3: -0.9923\n",
            "Epoch: 108 MAE: 0.07567381979927186 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:45:31.851977 Epoch [109/250], Step [0001/0060], Loss1: -0.9885 Loss2: -0.9857 Loss3: -0.9922\n",
            "2022-07-30 16:45:59.967518 Epoch [109/250], Step [0050/0060], Loss1: -0.9780 Loss2: -0.9845 Loss3: -0.9892\n",
            "2022-07-30 16:46:05.668137 Epoch [109/250], Step [0060/0060], Loss1: -0.9862 Loss2: -0.9853 Loss3: -0.9918\n",
            "Epoch: 109 MAE: 0.07627927719600618 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:46:13.905200 Epoch [110/250], Step [0001/0060], Loss1: -0.9864 Loss2: -0.9853 Loss3: -0.9915\n",
            "2022-07-30 16:46:42.177267 Epoch [110/250], Step [0050/0060], Loss1: -0.9810 Loss2: -0.9847 Loss3: -0.9896\n",
            "2022-07-30 16:46:47.908843 Epoch [110/250], Step [0060/0060], Loss1: -0.9857 Loss2: -0.9852 Loss3: -0.9917\n",
            "Epoch: 110 MAE: 0.07093040607593677 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:46:58.877382 Epoch [111/250], Step [0001/0060], Loss1: -0.9864 Loss2: -0.9841 Loss3: -0.9908\n",
            "2022-07-30 16:47:29.623689 Epoch [111/250], Step [0050/0060], Loss1: -0.9838 Loss2: -0.9833 Loss3: -0.9900\n",
            "2022-07-30 16:47:36.370357 Epoch [111/250], Step [0060/0060], Loss1: -0.9884 Loss2: -0.9883 Loss3: -0.9927\n",
            "Epoch: 111 MAE: 0.07414903681114236 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:47:44.609018 Epoch [112/250], Step [0001/0060], Loss1: -0.9857 Loss2: -0.9867 Loss3: -0.9913\n",
            "2022-07-30 16:48:13.105061 Epoch [112/250], Step [0050/0060], Loss1: -0.9863 Loss2: -0.9839 Loss3: -0.9908\n",
            "2022-07-30 16:48:18.849806 Epoch [112/250], Step [0060/0060], Loss1: -0.9874 Loss2: -0.9857 Loss3: -0.9922\n",
            "Epoch: 112 MAE: 0.07480024403365201 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:48:27.127273 Epoch [113/250], Step [0001/0060], Loss1: -0.9851 Loss2: -0.9845 Loss3: -0.9906\n",
            "2022-07-30 16:48:55.504744 Epoch [113/250], Step [0050/0060], Loss1: -0.9828 Loss2: -0.9840 Loss3: -0.9893\n",
            "2022-07-30 16:49:01.263222 Epoch [113/250], Step [0060/0060], Loss1: -0.9860 Loss2: -0.9871 Loss3: -0.9920\n",
            "Epoch: 113 MAE: 0.07447528758376994 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:49:09.577747 Epoch [114/250], Step [0001/0060], Loss1: -0.9737 Loss2: -0.9820 Loss3: -0.9872\n",
            "2022-07-30 16:49:38.704550 Epoch [114/250], Step [0050/0060], Loss1: -0.9883 Loss2: -0.9871 Loss3: -0.9925\n",
            "2022-07-30 16:49:45.248538 Epoch [114/250], Step [0060/0060], Loss1: -0.9852 Loss2: -0.9860 Loss3: -0.9915\n",
            "Epoch: 114 MAE: 0.0742033936233117 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:49:53.443467 Epoch [115/250], Step [0001/0060], Loss1: -0.9849 Loss2: -0.9847 Loss3: -0.9905\n",
            "2022-07-30 16:50:21.748755 Epoch [115/250], Step [0050/0060], Loss1: -0.9872 Loss2: -0.9884 Loss3: -0.9925\n",
            "2022-07-30 16:50:27.527789 Epoch [115/250], Step [0060/0060], Loss1: -0.9811 Loss2: -0.9829 Loss3: -0.9890\n",
            "Epoch: 115 MAE: 0.07347616725497771 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:50:38.785260 Epoch [116/250], Step [0001/0060], Loss1: -0.9825 Loss2: -0.9842 Loss3: -0.9902\n",
            "2022-07-30 16:51:07.257804 Epoch [116/250], Step [0050/0060], Loss1: -0.9813 Loss2: -0.9798 Loss3: -0.9877\n",
            "2022-07-30 16:51:13.041780 Epoch [116/250], Step [0060/0060], Loss1: -0.9873 Loss2: -0.9861 Loss3: -0.9923\n",
            "Epoch: 116 MAE: 0.07428141982467086 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:51:21.415149 Epoch [117/250], Step [0001/0060], Loss1: -0.9846 Loss2: -0.9871 Loss3: -0.9918\n",
            "2022-07-30 16:51:51.160607 Epoch [117/250], Step [0050/0060], Loss1: -0.9865 Loss2: -0.9871 Loss3: -0.9918\n",
            "2022-07-30 16:51:59.120776 Epoch [117/250], Step [0060/0060], Loss1: -0.9868 Loss2: -0.9849 Loss3: -0.9906\n",
            "Epoch: 117 MAE: 0.07647267871432833 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:52:07.496777 Epoch [118/250], Step [0001/0060], Loss1: -0.9854 Loss2: -0.9866 Loss3: -0.9919\n",
            "2022-07-30 16:52:36.087262 Epoch [118/250], Step [0050/0060], Loss1: -0.9880 Loss2: -0.9883 Loss3: -0.9927\n",
            "2022-07-30 16:52:41.971333 Epoch [118/250], Step [0060/0060], Loss1: -0.9876 Loss2: -0.9867 Loss3: -0.9922\n",
            "Epoch: 118 MAE: 0.07458206625842545 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:52:50.641971 Epoch [119/250], Step [0001/0060], Loss1: -0.9832 Loss2: -0.9846 Loss3: -0.9904\n",
            "2022-07-30 16:53:19.433147 Epoch [119/250], Step [0050/0060], Loss1: -0.9730 Loss2: -0.9767 Loss3: -0.9858\n",
            "2022-07-30 16:53:25.282435 Epoch [119/250], Step [0060/0060], Loss1: -0.9855 Loss2: -0.9827 Loss3: -0.9898\n",
            "Epoch: 119 MAE: 0.07655304933981923 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:53:34.016231 Epoch [120/250], Step [0001/0060], Loss1: -0.9851 Loss2: -0.9874 Loss3: -0.9917\n",
            "2022-07-30 16:54:02.865432 Epoch [120/250], Step [0050/0060], Loss1: -0.9846 Loss2: -0.9836 Loss3: -0.9905\n",
            "2022-07-30 16:54:09.512367 Epoch [120/250], Step [0060/0060], Loss1: -0.9845 Loss2: -0.9840 Loss3: -0.9900\n",
            "Epoch: 120 MAE: 0.07392848973551756 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:54:20.823365 Epoch [121/250], Step [0001/0060], Loss1: -0.9823 Loss2: -0.9867 Loss3: -0.9915\n",
            "2022-07-30 16:54:49.405234 Epoch [121/250], Step [0050/0060], Loss1: -0.9873 Loss2: -0.9870 Loss3: -0.9922\n",
            "2022-07-30 16:54:55.235915 Epoch [121/250], Step [0060/0060], Loss1: -0.9884 Loss2: -0.9875 Loss3: -0.9922\n",
            "Epoch: 121 MAE: 0.07409733535120729 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:55:03.676868 Epoch [122/250], Step [0001/0060], Loss1: -0.9831 Loss2: -0.9860 Loss3: -0.9908\n",
            "2022-07-30 16:55:32.149359 Epoch [122/250], Step [0050/0060], Loss1: -0.9871 Loss2: -0.9865 Loss3: -0.9916\n",
            "2022-07-30 16:55:37.920469 Epoch [122/250], Step [0060/0060], Loss1: -0.9874 Loss2: -0.9879 Loss3: -0.9922\n",
            "Epoch: 122 MAE: 0.07407346745647453 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:55:46.254762 Epoch [123/250], Step [0001/0060], Loss1: -0.9852 Loss2: -0.9857 Loss3: -0.9913\n",
            "2022-07-30 16:56:14.691088 Epoch [123/250], Step [0050/0060], Loss1: -0.9789 Loss2: -0.9837 Loss3: -0.9889\n",
            "2022-07-30 16:56:22.022276 Epoch [123/250], Step [0060/0060], Loss1: -0.9857 Loss2: -0.9869 Loss3: -0.9913\n",
            "Epoch: 123 MAE: 0.07477215827457488 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:56:32.346342 Epoch [124/250], Step [0001/0060], Loss1: -0.9822 Loss2: -0.9844 Loss3: -0.9896\n",
            "2022-07-30 16:57:00.768652 Epoch [124/250], Step [0050/0060], Loss1: -0.9803 Loss2: -0.9838 Loss3: -0.9890\n",
            "2022-07-30 16:57:06.565118 Epoch [124/250], Step [0060/0060], Loss1: -0.9876 Loss2: -0.9871 Loss3: -0.9925\n",
            "Epoch: 124 MAE: 0.07116804107787117 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:57:14.817763 Epoch [125/250], Step [0001/0060], Loss1: -0.9842 Loss2: -0.9852 Loss3: -0.9911\n",
            "2022-07-30 16:57:43.290563 Epoch [125/250], Step [0050/0060], Loss1: -0.9792 Loss2: -0.9780 Loss3: -0.9866\n",
            "2022-07-30 16:57:49.026501 Epoch [125/250], Step [0060/0060], Loss1: -0.9871 Loss2: -0.9872 Loss3: -0.9924\n",
            "Epoch: 125 MAE: 0.07351526759919665 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:58:00.261319 Epoch [126/250], Step [0001/0060], Loss1: -0.9814 Loss2: -0.9797 Loss3: -0.9882\n",
            "2022-07-30 16:58:28.682139 Epoch [126/250], Step [0050/0060], Loss1: -0.9873 Loss2: -0.9855 Loss3: -0.9913\n",
            "2022-07-30 16:58:35.246736 Epoch [126/250], Step [0060/0060], Loss1: -0.9839 Loss2: -0.9853 Loss3: -0.9910\n",
            "Epoch: 126 MAE: 0.073030306094538 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:58:46.623924 Epoch [127/250], Step [0001/0060], Loss1: -0.9876 Loss2: -0.9875 Loss3: -0.9918\n",
            "2022-07-30 16:59:15.076291 Epoch [127/250], Step [0050/0060], Loss1: -0.9857 Loss2: -0.9867 Loss3: -0.9918\n",
            "2022-07-30 16:59:20.845860 Epoch [127/250], Step [0060/0060], Loss1: -0.9824 Loss2: -0.9849 Loss3: -0.9901\n",
            "Epoch: 127 MAE: 0.07446809632437568 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 16:59:29.180824 Epoch [128/250], Step [0001/0060], Loss1: -0.9863 Loss2: -0.9860 Loss3: -0.9910\n",
            "2022-07-30 16:59:57.683583 Epoch [128/250], Step [0050/0060], Loss1: -0.9876 Loss2: -0.9857 Loss3: -0.9921\n",
            "2022-07-30 17:00:03.453536 Epoch [128/250], Step [0060/0060], Loss1: -0.9885 Loss2: -0.9879 Loss3: -0.9928\n",
            "Epoch: 128 MAE: 0.07425839530097116 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:00:11.716489 Epoch [129/250], Step [0001/0060], Loss1: -0.9825 Loss2: -0.9858 Loss3: -0.9904\n",
            "2022-07-30 17:00:40.163483 Epoch [129/250], Step [0050/0060], Loss1: -0.9857 Loss2: -0.9840 Loss3: -0.9899\n",
            "2022-07-30 17:00:45.964808 Epoch [129/250], Step [0060/0060], Loss1: -0.9866 Loss2: -0.9875 Loss3: -0.9924\n",
            "Epoch: 129 MAE: 0.07187957814130834 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:00:56.194433 Epoch [130/250], Step [0001/0060], Loss1: -0.9884 Loss2: -0.9877 Loss3: -0.9929\n",
            "2022-07-30 17:01:24.668398 Epoch [130/250], Step [0050/0060], Loss1: -0.9877 Loss2: -0.9866 Loss3: -0.9923\n",
            "2022-07-30 17:01:30.432207 Epoch [130/250], Step [0060/0060], Loss1: -0.9849 Loss2: -0.9859 Loss3: -0.9913\n",
            "Epoch: 130 MAE: 0.07495570117203647 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:01:41.644715 Epoch [131/250], Step [0001/0060], Loss1: -0.9810 Loss2: -0.9809 Loss3: -0.9886\n",
            "2022-07-30 17:02:10.148062 Epoch [131/250], Step [0050/0060], Loss1: -0.9833 Loss2: -0.9843 Loss3: -0.9900\n",
            "2022-07-30 17:02:15.941589 Epoch [131/250], Step [0060/0060], Loss1: -0.9792 Loss2: -0.9841 Loss3: -0.9894\n",
            "Epoch: 131 MAE: 0.07723089440159063 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:02:24.172842 Epoch [132/250], Step [0001/0060], Loss1: -0.9816 Loss2: -0.9852 Loss3: -0.9899\n",
            "2022-07-30 17:02:52.593206 Epoch [132/250], Step [0050/0060], Loss1: -0.9886 Loss2: -0.9878 Loss3: -0.9926\n",
            "2022-07-30 17:02:58.462562 Epoch [132/250], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9865 Loss3: -0.9915\n",
            "Epoch: 132 MAE: 0.07367919109485768 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:03:08.839045 Epoch [133/250], Step [0001/0060], Loss1: -0.9890 Loss2: -0.9892 Loss3: -0.9931\n",
            "2022-07-30 17:03:38.720197 Epoch [133/250], Step [0050/0060], Loss1: -0.9823 Loss2: -0.9842 Loss3: -0.9896\n",
            "2022-07-30 17:03:44.543257 Epoch [133/250], Step [0060/0060], Loss1: -0.9803 Loss2: -0.9829 Loss3: -0.9883\n",
            "Epoch: 133 MAE: 0.07464904739743188 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:03:52.825595 Epoch [134/250], Step [0001/0060], Loss1: -0.9845 Loss2: -0.9858 Loss3: -0.9909\n",
            "2022-07-30 17:04:21.407657 Epoch [134/250], Step [0050/0060], Loss1: -0.9873 Loss2: -0.9865 Loss3: -0.9920\n",
            "2022-07-30 17:04:27.206856 Epoch [134/250], Step [0060/0060], Loss1: -0.9806 Loss2: -0.9815 Loss3: -0.9885\n",
            "Epoch: 134 MAE: 0.07362294232403792 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:04:35.468764 Epoch [135/250], Step [0001/0060], Loss1: -0.9874 Loss2: -0.9863 Loss3: -0.9921\n",
            "2022-07-30 17:05:03.972709 Epoch [135/250], Step [0050/0060], Loss1: -0.9849 Loss2: -0.9862 Loss3: -0.9911\n",
            "2022-07-30 17:05:09.743812 Epoch [135/250], Step [0060/0060], Loss1: -0.9871 Loss2: -0.9854 Loss3: -0.9916\n",
            "Epoch: 135 MAE: 0.07152674367188147 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:05:22.709610 Epoch [136/250], Step [0001/0060], Loss1: -0.9890 Loss2: -0.9881 Loss3: -0.9931\n",
            "2022-07-30 17:05:53.276102 Epoch [136/250], Step [0050/0060], Loss1: -0.9847 Loss2: -0.9826 Loss3: -0.9897\n",
            "2022-07-30 17:05:59.068605 Epoch [136/250], Step [0060/0060], Loss1: -0.9843 Loss2: -0.9848 Loss3: -0.9907\n",
            "Epoch: 136 MAE: 0.07433276443885117 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:06:07.350549 Epoch [137/250], Step [0001/0060], Loss1: -0.9856 Loss2: -0.9867 Loss3: -0.9917\n",
            "2022-07-30 17:06:35.681954 Epoch [137/250], Step [0050/0060], Loss1: -0.9875 Loss2: -0.9884 Loss3: -0.9928\n",
            "2022-07-30 17:06:41.467037 Epoch [137/250], Step [0060/0060], Loss1: -0.9876 Loss2: -0.9873 Loss3: -0.9923\n",
            "Epoch: 137 MAE: 0.07337234825053543 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:06:49.821867 Epoch [138/250], Step [0001/0060], Loss1: -0.9846 Loss2: -0.9816 Loss3: -0.9890\n",
            "2022-07-30 17:07:18.250636 Epoch [138/250], Step [0050/0060], Loss1: -0.9873 Loss2: -0.9873 Loss3: -0.9924\n",
            "2022-07-30 17:07:24.000144 Epoch [138/250], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9877 Loss3: -0.9921\n",
            "Epoch: 138 MAE: 0.07295693826423118 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:07:33.696813 Epoch [139/250], Step [0001/0060], Loss1: -0.9856 Loss2: -0.9832 Loss3: -0.9902\n",
            "2022-07-30 17:08:02.556617 Epoch [139/250], Step [0050/0060], Loss1: -0.9883 Loss2: -0.9870 Loss3: -0.9926\n",
            "2022-07-30 17:08:08.347712 Epoch [139/250], Step [0060/0060], Loss1: -0.9849 Loss2: -0.9850 Loss3: -0.9910\n",
            "Epoch: 139 MAE: 0.07396893243941051 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:08:16.576153 Epoch [140/250], Step [0001/0060], Loss1: -0.9845 Loss2: -0.9849 Loss3: -0.9909\n",
            "2022-07-30 17:08:45.126512 Epoch [140/250], Step [0050/0060], Loss1: -0.9832 Loss2: -0.9820 Loss3: -0.9894\n",
            "2022-07-30 17:08:50.902765 Epoch [140/250], Step [0060/0060], Loss1: -0.9857 Loss2: -0.9849 Loss3: -0.9908\n",
            "Epoch: 140 MAE: 0.07502342859903975 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:09:02.183463 Epoch [141/250], Step [0001/0060], Loss1: -0.9858 Loss2: -0.9851 Loss3: -0.9914\n",
            "2022-07-30 17:09:30.753853 Epoch [141/250], Step [0050/0060], Loss1: -0.9864 Loss2: -0.9860 Loss3: -0.9915\n",
            "2022-07-30 17:09:36.507007 Epoch [141/250], Step [0060/0060], Loss1: -0.9869 Loss2: -0.9865 Loss3: -0.9916\n",
            "Epoch: 141 MAE: 0.07313762155159442 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:09:47.385343 Epoch [142/250], Step [0001/0060], Loss1: -0.9839 Loss2: -0.9813 Loss3: -0.9891\n",
            "2022-07-30 17:10:16.907813 Epoch [142/250], Step [0050/0060], Loss1: -0.9868 Loss2: -0.9869 Loss3: -0.9916\n",
            "2022-07-30 17:10:22.662033 Epoch [142/250], Step [0060/0060], Loss1: -0.9826 Loss2: -0.9838 Loss3: -0.9905\n",
            "Epoch: 142 MAE: 0.07350971842569015 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:10:30.853040 Epoch [143/250], Step [0001/0060], Loss1: -0.9820 Loss2: -0.9832 Loss3: -0.9895\n",
            "2022-07-30 17:10:59.320695 Epoch [143/250], Step [0050/0060], Loss1: -0.9871 Loss2: -0.9844 Loss3: -0.9918\n",
            "2022-07-30 17:11:05.079692 Epoch [143/250], Step [0060/0060], Loss1: -0.9800 Loss2: -0.9823 Loss3: -0.9884\n",
            "Epoch: 143 MAE: 0.07552704679902898 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:11:13.309881 Epoch [144/250], Step [0001/0060], Loss1: -0.9858 Loss2: -0.9848 Loss3: -0.9909\n",
            "2022-07-30 17:11:41.807196 Epoch [144/250], Step [0050/0060], Loss1: -0.9840 Loss2: -0.9838 Loss3: -0.9896\n",
            "2022-07-30 17:11:47.612562 Epoch [144/250], Step [0060/0060], Loss1: -0.9812 Loss2: -0.9804 Loss3: -0.9887\n",
            "Epoch: 144 MAE: 0.07720938374756509 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:11:56.273821 Epoch [145/250], Step [0001/0060], Loss1: -0.9830 Loss2: -0.9827 Loss3: -0.9895\n",
            "2022-07-30 17:12:25.758310 Epoch [145/250], Step [0050/0060], Loss1: -0.9881 Loss2: -0.9884 Loss3: -0.9924\n",
            "2022-07-30 17:12:31.574567 Epoch [145/250], Step [0060/0060], Loss1: -0.9824 Loss2: -0.9830 Loss3: -0.9898\n",
            "Epoch: 145 MAE: 0.07357844039876624 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:12:43.445732 Epoch [146/250], Step [0001/0060], Loss1: -0.9871 Loss2: -0.9865 Loss3: -0.9919\n",
            "2022-07-30 17:13:12.102755 Epoch [146/250], Step [0050/0060], Loss1: -0.9862 Loss2: -0.9866 Loss3: -0.9918\n",
            "2022-07-30 17:13:17.880957 Epoch [146/250], Step [0060/0060], Loss1: -0.9866 Loss2: -0.9871 Loss3: -0.9917\n",
            "Epoch: 146 MAE: 0.07277225332916096 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:13:26.271350 Epoch [147/250], Step [0001/0060], Loss1: -0.9779 Loss2: -0.9833 Loss3: -0.9890\n",
            "2022-07-30 17:13:54.662344 Epoch [147/250], Step [0050/0060], Loss1: -0.9866 Loss2: -0.9819 Loss3: -0.9903\n",
            "2022-07-30 17:14:00.413521 Epoch [147/250], Step [0060/0060], Loss1: -0.9866 Loss2: -0.9853 Loss3: -0.9913\n",
            "Epoch: 147 MAE: 0.07291093725376029 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:14:10.588716 Epoch [148/250], Step [0001/0060], Loss1: -0.9869 Loss2: -0.9872 Loss3: -0.9916\n",
            "2022-07-30 17:14:40.777558 Epoch [148/250], Step [0050/0060], Loss1: -0.9868 Loss2: -0.9861 Loss3: -0.9919\n",
            "2022-07-30 17:14:46.541020 Epoch [148/250], Step [0060/0060], Loss1: -0.9804 Loss2: -0.9832 Loss3: -0.9886\n",
            "Epoch: 148 MAE: 0.07439815117568564 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:14:54.855741 Epoch [149/250], Step [0001/0060], Loss1: -0.9851 Loss2: -0.9833 Loss3: -0.9899\n",
            "2022-07-30 17:15:23.270017 Epoch [149/250], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9868 Loss3: -0.9917\n",
            "2022-07-30 17:15:29.049298 Epoch [149/250], Step [0060/0060], Loss1: -0.9825 Loss2: -0.9854 Loss3: -0.9900\n",
            "Epoch: 149 MAE: 0.07381085945815638 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:15:37.361530 Epoch [150/250], Step [0001/0060], Loss1: -0.9884 Loss2: -0.9889 Loss3: -0.9928\n",
            "2022-07-30 17:16:05.848334 Epoch [150/250], Step [0050/0060], Loss1: -0.9848 Loss2: -0.9865 Loss3: -0.9913\n",
            "2022-07-30 17:16:11.634964 Epoch [150/250], Step [0060/0060], Loss1: -0.9835 Loss2: -0.9859 Loss3: -0.9908\n",
            "Epoch: 150 MAE: 0.07518318882694955 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:16:24.913974 Epoch [151/250], Step [0001/0060], Loss1: -0.9765 Loss2: -0.9815 Loss3: -0.9874\n",
            "2022-07-30 17:16:55.392341 Epoch [151/250], Step [0050/0060], Loss1: -0.9865 Loss2: -0.9855 Loss3: -0.9913\n",
            "2022-07-30 17:17:01.155853 Epoch [151/250], Step [0060/0060], Loss1: -0.9862 Loss2: -0.9866 Loss3: -0.9922\n",
            "Epoch: 151 MAE: 0.0717105834698551 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:17:09.424940 Epoch [152/250], Step [0001/0060], Loss1: -0.9859 Loss2: -0.9853 Loss3: -0.9912\n",
            "2022-07-30 17:17:37.890263 Epoch [152/250], Step [0050/0060], Loss1: -0.9865 Loss2: -0.9868 Loss3: -0.9920\n",
            "2022-07-30 17:17:43.654056 Epoch [152/250], Step [0060/0060], Loss1: -0.9833 Loss2: -0.9826 Loss3: -0.9905\n",
            "Epoch: 152 MAE: 0.07301550083059483 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:17:51.954528 Epoch [153/250], Step [0001/0060], Loss1: -0.9883 Loss2: -0.9886 Loss3: -0.9925\n",
            "2022-07-30 17:18:20.332505 Epoch [153/250], Step [0050/0060], Loss1: -0.9826 Loss2: -0.9837 Loss3: -0.9901\n",
            "2022-07-30 17:18:26.144779 Epoch [153/250], Step [0060/0060], Loss1: -0.9886 Loss2: -0.9874 Loss3: -0.9924\n",
            "Epoch: 153 MAE: 0.07201658491104371 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:18:34.458635 Epoch [154/250], Step [0001/0060], Loss1: -0.9872 Loss2: -0.9854 Loss3: -0.9915\n",
            "2022-07-30 17:19:04.311384 Epoch [154/250], Step [0050/0060], Loss1: -0.9852 Loss2: -0.9824 Loss3: -0.9903\n",
            "2022-07-30 17:19:10.088308 Epoch [154/250], Step [0060/0060], Loss1: -0.9870 Loss2: -0.9856 Loss3: -0.9915\n",
            "Epoch: 154 MAE: 0.07524745234736693 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:19:18.409386 Epoch [155/250], Step [0001/0060], Loss1: -0.9868 Loss2: -0.9877 Loss3: -0.9922\n",
            "2022-07-30 17:19:46.890916 Epoch [155/250], Step [0050/0060], Loss1: -0.9851 Loss2: -0.9853 Loss3: -0.9907\n",
            "2022-07-30 17:19:52.652353 Epoch [155/250], Step [0060/0060], Loss1: -0.9788 Loss2: -0.9809 Loss3: -0.9874\n",
            "Epoch: 155 MAE: 0.07560708469814723 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:20:03.970934 Epoch [156/250], Step [0001/0060], Loss1: -0.9879 Loss2: -0.9857 Loss3: -0.9917\n",
            "2022-07-30 17:20:32.556878 Epoch [156/250], Step [0050/0060], Loss1: -0.9831 Loss2: -0.9863 Loss3: -0.9912\n",
            "2022-07-30 17:20:38.331895 Epoch [156/250], Step [0060/0060], Loss1: -0.9800 Loss2: -0.9793 Loss3: -0.9876\n",
            "Epoch: 156 MAE: 0.0745914493036018 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:20:47.013154 Epoch [157/250], Step [0001/0060], Loss1: -0.9848 Loss2: -0.9856 Loss3: -0.9909\n",
            "2022-07-30 17:21:18.176328 Epoch [157/250], Step [0050/0060], Loss1: -0.9885 Loss2: -0.9882 Loss3: -0.9927\n",
            "2022-07-30 17:21:23.962553 Epoch [157/250], Step [0060/0060], Loss1: -0.9819 Loss2: -0.9815 Loss3: -0.9881\n",
            "Epoch: 157 MAE: 0.07488177329774885 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:21:32.314147 Epoch [158/250], Step [0001/0060], Loss1: -0.9824 Loss2: -0.9834 Loss3: -0.9899\n",
            "2022-07-30 17:22:00.746702 Epoch [158/250], Step [0050/0060], Loss1: -0.9861 Loss2: -0.9849 Loss3: -0.9909\n",
            "2022-07-30 17:22:06.545418 Epoch [158/250], Step [0060/0060], Loss1: -0.9871 Loss2: -0.9875 Loss3: -0.9917\n",
            "Epoch: 158 MAE: 0.07592002575990385 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:22:14.794166 Epoch [159/250], Step [0001/0060], Loss1: -0.9880 Loss2: -0.9870 Loss3: -0.9920\n",
            "2022-07-30 17:22:43.291164 Epoch [159/250], Step [0050/0060], Loss1: -0.9875 Loss2: -0.9855 Loss3: -0.9915\n",
            "2022-07-30 17:22:49.055522 Epoch [159/250], Step [0060/0060], Loss1: -0.9857 Loss2: -0.9875 Loss3: -0.9920\n",
            "Epoch: 159 MAE: 0.07149622488274146 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:22:57.350764 Epoch [160/250], Step [0001/0060], Loss1: -0.9870 Loss2: -0.9867 Loss3: -0.9919\n",
            "2022-07-30 17:23:27.333697 Epoch [160/250], Step [0050/0060], Loss1: -0.9836 Loss2: -0.9794 Loss3: -0.9880\n",
            "2022-07-30 17:23:33.117155 Epoch [160/250], Step [0060/0060], Loss1: -0.9890 Loss2: -0.9884 Loss3: -0.9931\n",
            "Epoch: 160 MAE: 0.07110509615095836 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:23:44.225402 Epoch [161/250], Step [0001/0060], Loss1: -0.9887 Loss2: -0.9869 Loss3: -0.9926\n",
            "2022-07-30 17:24:12.617669 Epoch [161/250], Step [0050/0060], Loss1: -0.9805 Loss2: -0.9835 Loss3: -0.9886\n",
            "2022-07-30 17:24:18.431802 Epoch [161/250], Step [0060/0060], Loss1: -0.9867 Loss2: -0.9869 Loss3: -0.9915\n",
            "Epoch: 161 MAE: 0.07184233398033833 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:24:26.848979 Epoch [162/250], Step [0001/0060], Loss1: -0.9826 Loss2: -0.9842 Loss3: -0.9898\n",
            "2022-07-30 17:24:55.256879 Epoch [162/250], Step [0050/0060], Loss1: -0.9866 Loss2: -0.9829 Loss3: -0.9909\n",
            "2022-07-30 17:25:01.048243 Epoch [162/250], Step [0060/0060], Loss1: -0.9811 Loss2: -0.9837 Loss3: -0.9893\n",
            "Epoch: 162 MAE: 0.07522249781896195 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:25:09.344838 Epoch [163/250], Step [0001/0060], Loss1: -0.9866 Loss2: -0.9865 Loss3: -0.9920\n",
            "2022-07-30 17:25:40.624322 Epoch [163/250], Step [0050/0060], Loss1: -0.9883 Loss2: -0.9880 Loss3: -0.9924\n",
            "2022-07-30 17:25:46.393445 Epoch [163/250], Step [0060/0060], Loss1: -0.9886 Loss2: -0.9888 Loss3: -0.9933\n",
            "Epoch: 163 MAE: 0.07474222748367874 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:25:54.736536 Epoch [164/250], Step [0001/0060], Loss1: -0.9834 Loss2: -0.9818 Loss3: -0.9891\n",
            "2022-07-30 17:26:23.200746 Epoch [164/250], Step [0050/0060], Loss1: -0.9848 Loss2: -0.9868 Loss3: -0.9917\n",
            "2022-07-30 17:26:29.002376 Epoch [164/250], Step [0060/0060], Loss1: -0.9826 Loss2: -0.9819 Loss3: -0.9895\n",
            "Epoch: 164 MAE: 0.07382272886851476 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:26:37.306388 Epoch [165/250], Step [0001/0060], Loss1: -0.9883 Loss2: -0.9869 Loss3: -0.9923\n",
            "2022-07-30 17:27:05.809081 Epoch [165/250], Step [0050/0060], Loss1: -0.9859 Loss2: -0.9859 Loss3: -0.9917\n",
            "2022-07-30 17:27:11.598370 Epoch [165/250], Step [0060/0060], Loss1: -0.9861 Loss2: -0.9868 Loss3: -0.9918\n",
            "Epoch: 165 MAE: 0.0737839690213481 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:27:22.745371 Epoch [166/250], Step [0001/0060], Loss1: -0.9873 Loss2: -0.9891 Loss3: -0.9927\n",
            "2022-07-30 17:27:54.672154 Epoch [166/250], Step [0050/0060], Loss1: -0.9866 Loss2: -0.9864 Loss3: -0.9922\n",
            "2022-07-30 17:28:00.401697 Epoch [166/250], Step [0060/0060], Loss1: -0.9814 Loss2: -0.9814 Loss3: -0.9892\n",
            "Epoch: 166 MAE: 0.07312326910634519 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:28:08.801828 Epoch [167/250], Step [0001/0060], Loss1: -0.9872 Loss2: -0.9886 Loss3: -0.9925\n",
            "2022-07-30 17:28:37.282385 Epoch [167/250], Step [0050/0060], Loss1: -0.9858 Loss2: -0.9856 Loss3: -0.9915\n",
            "2022-07-30 17:28:43.068827 Epoch [167/250], Step [0060/0060], Loss1: -0.9830 Loss2: -0.9841 Loss3: -0.9903\n",
            "Epoch: 167 MAE: 0.07285664038683372 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:28:51.465315 Epoch [168/250], Step [0001/0060], Loss1: -0.9830 Loss2: -0.9823 Loss3: -0.9892\n",
            "2022-07-30 17:29:19.897942 Epoch [168/250], Step [0050/0060], Loss1: -0.9827 Loss2: -0.9852 Loss3: -0.9906\n",
            "2022-07-30 17:29:25.660386 Epoch [168/250], Step [0060/0060], Loss1: -0.9878 Loss2: -0.9878 Loss3: -0.9924\n",
            "Epoch: 168 MAE: 0.07254681133088611 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:29:33.950630 Epoch [169/250], Step [0001/0060], Loss1: -0.9832 Loss2: -0.9861 Loss3: -0.9914\n",
            "2022-07-30 17:30:04.004925 Epoch [169/250], Step [0050/0060], Loss1: -0.9870 Loss2: -0.9865 Loss3: -0.9913\n",
            "2022-07-30 17:30:09.811852 Epoch [169/250], Step [0060/0060], Loss1: -0.9724 Loss2: -0.9779 Loss3: -0.9852\n",
            "Epoch: 169 MAE: 0.07361643205874813 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:30:18.196598 Epoch [170/250], Step [0001/0060], Loss1: -0.9880 Loss2: -0.9870 Loss3: -0.9919\n",
            "2022-07-30 17:30:46.705806 Epoch [170/250], Step [0050/0060], Loss1: -0.9889 Loss2: -0.9877 Loss3: -0.9928\n",
            "2022-07-30 17:30:52.483278 Epoch [170/250], Step [0060/0060], Loss1: -0.9842 Loss2: -0.9854 Loss3: -0.9899\n",
            "Epoch: 170 MAE: 0.07422848413860988 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:31:03.575940 Epoch [171/250], Step [0001/0060], Loss1: -0.9850 Loss2: -0.9843 Loss3: -0.9902\n",
            "2022-07-30 17:31:32.048398 Epoch [171/250], Step [0050/0060], Loss1: -0.9883 Loss2: -0.9867 Loss3: -0.9926\n",
            "2022-07-30 17:31:37.807351 Epoch [171/250], Step [0060/0060], Loss1: -0.9868 Loss2: -0.9878 Loss3: -0.9923\n",
            "Epoch: 171 MAE: 0.07311510686521176 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:31:46.120867 Epoch [172/250], Step [0001/0060], Loss1: -0.9857 Loss2: -0.9826 Loss3: -0.9907\n",
            "2022-07-30 17:32:17.909608 Epoch [172/250], Step [0050/0060], Loss1: -0.9866 Loss2: -0.9886 Loss3: -0.9928\n",
            "2022-07-30 17:32:23.678801 Epoch [172/250], Step [0060/0060], Loss1: -0.9884 Loss2: -0.9872 Loss3: -0.9926\n",
            "Epoch: 172 MAE: 0.07489695826535503 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:32:31.995945 Epoch [173/250], Step [0001/0060], Loss1: -0.9838 Loss2: -0.9827 Loss3: -0.9895\n",
            "2022-07-30 17:33:00.329228 Epoch [173/250], Step [0050/0060], Loss1: -0.9861 Loss2: -0.9867 Loss3: -0.9913\n",
            "2022-07-30 17:33:06.111643 Epoch [173/250], Step [0060/0060], Loss1: -0.9889 Loss2: -0.9877 Loss3: -0.9925\n",
            "Epoch: 173 MAE: 0.07274866386696145 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:33:14.431300 Epoch [174/250], Step [0001/0060], Loss1: -0.9834 Loss2: -0.9825 Loss3: -0.9892\n",
            "2022-07-30 17:33:42.877880 Epoch [174/250], Step [0050/0060], Loss1: -0.9862 Loss2: -0.9868 Loss3: -0.9915\n",
            "2022-07-30 17:33:48.645700 Epoch [174/250], Step [0060/0060], Loss1: -0.9859 Loss2: -0.9863 Loss3: -0.9917\n",
            "Epoch: 174 MAE: 0.07386379357998964 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:33:57.015903 Epoch [175/250], Step [0001/0060], Loss1: -0.9837 Loss2: -0.9847 Loss3: -0.9907\n",
            "2022-07-30 17:34:27.135349 Epoch [175/250], Step [0050/0060], Loss1: -0.9835 Loss2: -0.9854 Loss3: -0.9904\n",
            "2022-07-30 17:34:32.906102 Epoch [175/250], Step [0060/0060], Loss1: -0.9886 Loss2: -0.9875 Loss3: -0.9924\n",
            "Epoch: 175 MAE: 0.07322633137778632 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:34:44.681683 Epoch [176/250], Step [0001/0060], Loss1: -0.9817 Loss2: -0.9833 Loss3: -0.9886\n",
            "2022-07-30 17:35:13.115901 Epoch [176/250], Step [0050/0060], Loss1: -0.9882 Loss2: -0.9869 Loss3: -0.9924\n",
            "2022-07-30 17:35:18.914252 Epoch [176/250], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9896 Loss3: -0.9936\n",
            "Epoch: 176 MAE: 0.07547841531259043 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:35:27.300916 Epoch [177/250], Step [0001/0060], Loss1: -0.9873 Loss2: -0.9857 Loss3: -0.9914\n",
            "2022-07-30 17:35:55.781988 Epoch [177/250], Step [0050/0060], Loss1: -0.9857 Loss2: -0.9843 Loss3: -0.9908\n",
            "2022-07-30 17:36:01.568829 Epoch [177/250], Step [0060/0060], Loss1: -0.9855 Loss2: -0.9847 Loss3: -0.9897\n",
            "Epoch: 177 MAE: 0.07423651140202922 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:36:09.947249 Epoch [178/250], Step [0001/0060], Loss1: -0.9851 Loss2: -0.9843 Loss3: -0.9907\n",
            "2022-07-30 17:36:41.806672 Epoch [178/250], Step [0050/0060], Loss1: -0.9875 Loss2: -0.9876 Loss3: -0.9925\n",
            "2022-07-30 17:36:47.575213 Epoch [178/250], Step [0060/0060], Loss1: -0.9802 Loss2: -0.9852 Loss3: -0.9897\n",
            "Epoch: 178 MAE: 0.07565302737806212 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:36:55.902227 Epoch [179/250], Step [0001/0060], Loss1: -0.9862 Loss2: -0.9876 Loss3: -0.9920\n",
            "2022-07-30 17:37:24.363284 Epoch [179/250], Step [0050/0060], Loss1: -0.9885 Loss2: -0.9875 Loss3: -0.9925\n",
            "2022-07-30 17:37:30.139234 Epoch [179/250], Step [0060/0060], Loss1: -0.9876 Loss2: -0.9864 Loss3: -0.9919\n",
            "Epoch: 179 MAE: 0.07227594335243184 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:37:38.439378 Epoch [180/250], Step [0001/0060], Loss1: -0.9863 Loss2: -0.9864 Loss3: -0.9912\n",
            "2022-07-30 17:38:06.766578 Epoch [180/250], Step [0050/0060], Loss1: -0.9882 Loss2: -0.9856 Loss3: -0.9918\n",
            "2022-07-30 17:38:12.514803 Epoch [180/250], Step [0060/0060], Loss1: -0.9713 Loss2: -0.9790 Loss3: -0.9859\n",
            "Epoch: 180 MAE: 0.07401179545770877 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:38:23.730299 Epoch [181/250], Step [0001/0060], Loss1: -0.9841 Loss2: -0.9863 Loss3: -0.9914\n",
            "2022-07-30 17:38:55.493095 Epoch [181/250], Step [0050/0060], Loss1: -0.9837 Loss2: -0.9863 Loss3: -0.9907\n",
            "2022-07-30 17:39:01.234075 Epoch [181/250], Step [0060/0060], Loss1: -0.9884 Loss2: -0.9876 Loss3: -0.9925\n",
            "Epoch: 181 MAE: 0.07296967990814694 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:39:09.498879 Epoch [182/250], Step [0001/0060], Loss1: -0.9868 Loss2: -0.9868 Loss3: -0.9912\n",
            "2022-07-30 17:39:37.968095 Epoch [182/250], Step [0050/0060], Loss1: -0.9873 Loss2: -0.9861 Loss3: -0.9921\n",
            "2022-07-30 17:39:43.796113 Epoch [182/250], Step [0060/0060], Loss1: -0.9865 Loss2: -0.9874 Loss3: -0.9920\n",
            "Epoch: 182 MAE: 0.07191880044483004 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:39:52.062350 Epoch [183/250], Step [0001/0060], Loss1: -0.9860 Loss2: -0.9849 Loss3: -0.9918\n",
            "2022-07-30 17:40:20.482465 Epoch [183/250], Step [0050/0060], Loss1: -0.9865 Loss2: -0.9869 Loss3: -0.9920\n",
            "2022-07-30 17:40:26.223407 Epoch [183/250], Step [0060/0060], Loss1: -0.9853 Loss2: -0.9870 Loss3: -0.9913\n",
            "Epoch: 183 MAE: 0.07481133849532517 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:40:34.506091 Epoch [184/250], Step [0001/0060], Loss1: -0.9875 Loss2: -0.9869 Loss3: -0.9921\n",
            "2022-07-30 17:41:04.528281 Epoch [184/250], Step [0050/0060], Loss1: -0.9886 Loss2: -0.9872 Loss3: -0.9922\n",
            "2022-07-30 17:41:10.286449 Epoch [184/250], Step [0060/0060], Loss1: -0.9880 Loss2: -0.9882 Loss3: -0.9926\n",
            "Epoch: 184 MAE: 0.07263408484282316 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:41:18.568043 Epoch [185/250], Step [0001/0060], Loss1: -0.9858 Loss2: -0.9854 Loss3: -0.9909\n",
            "2022-07-30 17:41:47.063459 Epoch [185/250], Step [0050/0060], Loss1: -0.9826 Loss2: -0.9838 Loss3: -0.9906\n",
            "2022-07-30 17:41:52.842422 Epoch [185/250], Step [0060/0060], Loss1: -0.9824 Loss2: -0.9845 Loss3: -0.9904\n",
            "Epoch: 185 MAE: 0.07341345933379316 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:42:03.986171 Epoch [186/250], Step [0001/0060], Loss1: -0.9860 Loss2: -0.9859 Loss3: -0.9916\n",
            "2022-07-30 17:42:32.427377 Epoch [186/250], Step [0050/0060], Loss1: -0.9834 Loss2: -0.9840 Loss3: -0.9890\n",
            "2022-07-30 17:42:38.181911 Epoch [186/250], Step [0060/0060], Loss1: -0.9812 Loss2: -0.9829 Loss3: -0.9893\n",
            "Epoch: 186 MAE: 0.07526107439919123 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:42:46.456363 Epoch [187/250], Step [0001/0060], Loss1: -0.9883 Loss2: -0.9880 Loss3: -0.9927\n",
            "2022-07-30 17:43:17.740344 Epoch [187/250], Step [0050/0060], Loss1: -0.9860 Loss2: -0.9856 Loss3: -0.9908\n",
            "2022-07-30 17:43:23.671508 Epoch [187/250], Step [0060/0060], Loss1: -0.9890 Loss2: -0.9881 Loss3: -0.9926\n",
            "Epoch: 187 MAE: 0.07486018337269941 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:43:32.002827 Epoch [188/250], Step [0001/0060], Loss1: -0.9872 Loss2: -0.9887 Loss3: -0.9929\n",
            "2022-07-30 17:44:00.436727 Epoch [188/250], Step [0050/0060], Loss1: -0.9857 Loss2: -0.9853 Loss3: -0.9914\n",
            "2022-07-30 17:44:06.209766 Epoch [188/250], Step [0060/0060], Loss1: -0.9861 Loss2: -0.9884 Loss3: -0.9919\n",
            "Epoch: 188 MAE: 0.07269247302302607 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:44:14.564137 Epoch [189/250], Step [0001/0060], Loss1: -0.9846 Loss2: -0.9876 Loss3: -0.9918\n",
            "2022-07-30 17:44:43.066138 Epoch [189/250], Step [0050/0060], Loss1: -0.9846 Loss2: -0.9848 Loss3: -0.9911\n",
            "2022-07-30 17:44:48.821517 Epoch [189/250], Step [0060/0060], Loss1: -0.9885 Loss2: -0.9880 Loss3: -0.9927\n",
            "Epoch: 189 MAE: 0.07465955148929011 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:44:57.148380 Epoch [190/250], Step [0001/0060], Loss1: -0.9773 Loss2: -0.9807 Loss3: -0.9873\n",
            "2022-07-30 17:45:26.992964 Epoch [190/250], Step [0050/0060], Loss1: -0.9826 Loss2: -0.9855 Loss3: -0.9899\n",
            "2022-07-30 17:45:32.745499 Epoch [190/250], Step [0060/0060], Loss1: -0.9857 Loss2: -0.9848 Loss3: -0.9908\n",
            "Epoch: 190 MAE: 0.07316624959309896 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:45:44.896918 Epoch [191/250], Step [0001/0060], Loss1: -0.9806 Loss2: -0.9806 Loss3: -0.9879\n",
            "2022-07-30 17:46:13.246988 Epoch [191/250], Step [0050/0060], Loss1: -0.9887 Loss2: -0.9881 Loss3: -0.9925\n",
            "2022-07-30 17:46:19.007518 Epoch [191/250], Step [0060/0060], Loss1: -0.9767 Loss2: -0.9815 Loss3: -0.9874\n",
            "Epoch: 191 MAE: 0.07449086355784583 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:46:27.297419 Epoch [192/250], Step [0001/0060], Loss1: -0.9884 Loss2: -0.9878 Loss3: -0.9926\n",
            "2022-07-30 17:46:55.867564 Epoch [192/250], Step [0050/0060], Loss1: -0.9811 Loss2: -0.9791 Loss3: -0.9880\n",
            "2022-07-30 17:47:01.660523 Epoch [192/250], Step [0060/0060], Loss1: -0.9874 Loss2: -0.9875 Loss3: -0.9927\n",
            "Epoch: 192 MAE: 0.07480858434445012 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:47:09.936913 Epoch [193/250], Step [0001/0060], Loss1: -0.9883 Loss2: -0.9870 Loss3: -0.9920\n",
            "2022-07-30 17:47:41.727705 Epoch [193/250], Step [0050/0060], Loss1: -0.9811 Loss2: -0.9848 Loss3: -0.9903\n",
            "2022-07-30 17:47:47.522642 Epoch [193/250], Step [0060/0060], Loss1: -0.9882 Loss2: -0.9883 Loss3: -0.9921\n",
            "Epoch: 193 MAE: 0.0748424600671839 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:47:55.962329 Epoch [194/250], Step [0001/0060], Loss1: -0.9857 Loss2: -0.9857 Loss3: -0.9915\n",
            "2022-07-30 17:48:24.374655 Epoch [194/250], Step [0050/0060], Loss1: -0.9860 Loss2: -0.9861 Loss3: -0.9908\n",
            "2022-07-30 17:48:30.145153 Epoch [194/250], Step [0060/0060], Loss1: -0.9871 Loss2: -0.9866 Loss3: -0.9920\n",
            "Epoch: 194 MAE: 0.07478583689089173 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:48:38.379977 Epoch [195/250], Step [0001/0060], Loss1: -0.9869 Loss2: -0.9873 Loss3: -0.9923\n",
            "2022-07-30 17:49:06.799659 Epoch [195/250], Step [0050/0060], Loss1: -0.9866 Loss2: -0.9850 Loss3: -0.9903\n",
            "2022-07-30 17:49:12.531247 Epoch [195/250], Step [0060/0060], Loss1: -0.9861 Loss2: -0.9865 Loss3: -0.9913\n",
            "Epoch: 195 MAE: 0.07354231577070933 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:49:23.794289 Epoch [196/250], Step [0001/0060], Loss1: -0.9855 Loss2: -0.9877 Loss3: -0.9917\n",
            "2022-07-30 17:49:55.577327 Epoch [196/250], Step [0050/0060], Loss1: -0.9828 Loss2: -0.9850 Loss3: -0.9902\n",
            "2022-07-30 17:50:01.379750 Epoch [196/250], Step [0060/0060], Loss1: -0.9822 Loss2: -0.9845 Loss3: -0.9905\n",
            "Epoch: 196 MAE: 0.07401041969420417 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:50:09.781457 Epoch [197/250], Step [0001/0060], Loss1: -0.9884 Loss2: -0.9877 Loss3: -0.9925\n",
            "2022-07-30 17:50:38.343579 Epoch [197/250], Step [0050/0060], Loss1: -0.9887 Loss2: -0.9882 Loss3: -0.9930\n",
            "2022-07-30 17:50:44.102696 Epoch [197/250], Step [0060/0060], Loss1: -0.9831 Loss2: -0.9845 Loss3: -0.9903\n",
            "Epoch: 197 MAE: 0.07319994437000744 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:50:52.302070 Epoch [198/250], Step [0001/0060], Loss1: -0.9855 Loss2: -0.9836 Loss3: -0.9901\n",
            "2022-07-30 17:51:20.681481 Epoch [198/250], Step [0050/0060], Loss1: -0.9799 Loss2: -0.9798 Loss3: -0.9882\n",
            "2022-07-30 17:51:26.446807 Epoch [198/250], Step [0060/0060], Loss1: -0.9836 Loss2: -0.9848 Loss3: -0.9908\n",
            "Epoch: 198 MAE: 0.07344877111848702 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:51:34.695804 Epoch [199/250], Step [0001/0060], Loss1: -0.9859 Loss2: -0.9877 Loss3: -0.9920\n",
            "2022-07-30 17:52:04.332979 Epoch [199/250], Step [0050/0060], Loss1: -0.9846 Loss2: -0.9843 Loss3: -0.9894\n",
            "2022-07-30 17:52:10.085583 Epoch [199/250], Step [0060/0060], Loss1: -0.9797 Loss2: -0.9818 Loss3: -0.9888\n",
            "Epoch: 199 MAE: 0.07251611876109287 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:52:18.266814 Epoch [200/250], Step [0001/0060], Loss1: -0.9854 Loss2: -0.9839 Loss3: -0.9906\n",
            "2022-07-30 17:52:46.710662 Epoch [200/250], Step [0050/0060], Loss1: -0.9872 Loss2: -0.9878 Loss3: -0.9924\n",
            "2022-07-30 17:52:52.473150 Epoch [200/250], Step [0060/0060], Loss1: -0.9846 Loss2: -0.9858 Loss3: -0.9908\n",
            "Epoch: 200 MAE: 0.07556377764101378 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:53:03.679067 Epoch [201/250], Step [0001/0060], Loss1: -0.9848 Loss2: -0.9838 Loss3: -0.9902\n",
            "2022-07-30 17:53:32.043830 Epoch [201/250], Step [0050/0060], Loss1: -0.9861 Loss2: -0.9850 Loss3: -0.9906\n",
            "2022-07-30 17:53:37.808990 Epoch [201/250], Step [0060/0060], Loss1: -0.9803 Loss2: -0.9846 Loss3: -0.9893\n",
            "Epoch: 201 MAE: 0.07374789066415613 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:53:46.077337 Epoch [202/250], Step [0001/0060], Loss1: -0.9886 Loss2: -0.9892 Loss3: -0.9928\n",
            "2022-07-30 17:54:17.745952 Epoch [202/250], Step [0050/0060], Loss1: -0.9860 Loss2: -0.9852 Loss3: -0.9901\n",
            "2022-07-30 17:54:23.513093 Epoch [202/250], Step [0060/0060], Loss1: -0.9754 Loss2: -0.9801 Loss3: -0.9867\n",
            "Epoch: 202 MAE: 0.07171706083590391 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:54:31.814964 Epoch [203/250], Step [0001/0060], Loss1: -0.9867 Loss2: -0.9869 Loss3: -0.9918\n",
            "2022-07-30 17:55:00.197369 Epoch [203/250], Step [0050/0060], Loss1: -0.9846 Loss2: -0.9846 Loss3: -0.9911\n",
            "2022-07-30 17:55:05.969596 Epoch [203/250], Step [0060/0060], Loss1: -0.9850 Loss2: -0.9850 Loss3: -0.9910\n",
            "Epoch: 203 MAE: 0.07121789442799079 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:55:14.224993 Epoch [204/250], Step [0001/0060], Loss1: -0.9888 Loss2: -0.9886 Loss3: -0.9933\n",
            "2022-07-30 17:55:42.627038 Epoch [204/250], Step [0050/0060], Loss1: -0.9852 Loss2: -0.9850 Loss3: -0.9905\n",
            "2022-07-30 17:55:48.362583 Epoch [204/250], Step [0060/0060], Loss1: -0.9816 Loss2: -0.9820 Loss3: -0.9887\n",
            "Epoch: 204 MAE: 0.07549139416407026 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:55:56.667258 Epoch [205/250], Step [0001/0060], Loss1: -0.9846 Loss2: -0.9880 Loss3: -0.9915\n",
            "2022-07-30 17:56:26.413838 Epoch [205/250], Step [0050/0060], Loss1: -0.9837 Loss2: -0.9851 Loss3: -0.9903\n",
            "2022-07-30 17:56:32.166314 Epoch [205/250], Step [0060/0060], Loss1: -0.9857 Loss2: -0.9874 Loss3: -0.9918\n",
            "Epoch: 205 MAE: 0.07324874756828187 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:56:44.576569 Epoch [206/250], Step [0001/0060], Loss1: -0.9883 Loss2: -0.9889 Loss3: -0.9930\n",
            "2022-07-30 17:57:12.941163 Epoch [206/250], Step [0050/0060], Loss1: -0.9854 Loss2: -0.9841 Loss3: -0.9902\n",
            "2022-07-30 17:57:18.700690 Epoch [206/250], Step [0060/0060], Loss1: -0.9864 Loss2: -0.9834 Loss3: -0.9901\n",
            "Epoch: 206 MAE: 0.07447953905378067 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:57:27.002859 Epoch [207/250], Step [0001/0060], Loss1: -0.9850 Loss2: -0.9852 Loss3: -0.9909\n",
            "2022-07-30 17:57:55.323757 Epoch [207/250], Step [0050/0060], Loss1: -0.9842 Loss2: -0.9823 Loss3: -0.9896\n",
            "2022-07-30 17:58:01.116411 Epoch [207/250], Step [0060/0060], Loss1: -0.9847 Loss2: -0.9848 Loss3: -0.9902\n",
            "Epoch: 207 MAE: 0.0740304429695089 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:58:09.362018 Epoch [208/250], Step [0001/0060], Loss1: -0.9873 Loss2: -0.9873 Loss3: -0.9924\n",
            "2022-07-30 17:58:41.015679 Epoch [208/250], Step [0050/0060], Loss1: -0.9853 Loss2: -0.9861 Loss3: -0.9911\n",
            "2022-07-30 17:58:46.777460 Epoch [208/250], Step [0060/0060], Loss1: -0.9890 Loss2: -0.9866 Loss3: -0.9925\n",
            "Epoch: 208 MAE: 0.07236609670850964 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:58:55.012529 Epoch [209/250], Step [0001/0060], Loss1: -0.9847 Loss2: -0.9841 Loss3: -0.9902\n",
            "2022-07-30 17:59:23.372402 Epoch [209/250], Step [0050/0060], Loss1: -0.9868 Loss2: -0.9855 Loss3: -0.9914\n",
            "2022-07-30 17:59:29.114344 Epoch [209/250], Step [0060/0060], Loss1: -0.9881 Loss2: -0.9868 Loss3: -0.9923\n",
            "Epoch: 209 MAE: 0.072930214493363 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 17:59:37.417074 Epoch [210/250], Step [0001/0060], Loss1: -0.9846 Loss2: -0.9862 Loss3: -0.9912\n",
            "2022-07-30 18:00:05.778211 Epoch [210/250], Step [0050/0060], Loss1: -0.9821 Loss2: -0.9840 Loss3: -0.9901\n",
            "2022-07-30 18:00:11.527613 Epoch [210/250], Step [0060/0060], Loss1: -0.9860 Loss2: -0.9855 Loss3: -0.9905\n",
            "Epoch: 210 MAE: 0.07486115354709523 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 18:00:22.441823 Epoch [211/250], Step [0001/0060], Loss1: -0.9842 Loss2: -0.9838 Loss3: -0.9906\n",
            "2022-07-30 18:00:53.768085 Epoch [211/250], Step [0050/0060], Loss1: -0.9855 Loss2: -0.9856 Loss3: -0.9918\n",
            "2022-07-30 18:00:59.959290 Epoch [211/250], Step [0060/0060], Loss1: -0.9869 Loss2: -0.9864 Loss3: -0.9912\n",
            "Epoch: 211 MAE: 0.07334106394853541 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 18:01:08.253906 Epoch [212/250], Step [0001/0060], Loss1: -0.9887 Loss2: -0.9879 Loss3: -0.9926\n",
            "2022-07-30 18:01:36.744234 Epoch [212/250], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9886 Loss3: -0.9928\n",
            "2022-07-30 18:01:42.532211 Epoch [212/250], Step [0060/0060], Loss1: -0.9833 Loss2: -0.9815 Loss3: -0.9883\n",
            "Epoch: 212 MAE: 0.07419429864832962 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 18:01:50.770058 Epoch [213/250], Step [0001/0060], Loss1: -0.9886 Loss2: -0.9891 Loss3: -0.9931\n",
            "2022-07-30 18:02:19.129283 Epoch [213/250], Step [0050/0060], Loss1: -0.9850 Loss2: -0.9857 Loss3: -0.9909\n",
            "2022-07-30 18:02:24.930473 Epoch [213/250], Step [0060/0060], Loss1: -0.9875 Loss2: -0.9863 Loss3: -0.9914\n",
            "Epoch: 213 MAE: 0.07576886020640215 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 18:02:33.343649 Epoch [214/250], Step [0001/0060], Loss1: -0.9826 Loss2: -0.9823 Loss3: -0.9894\n",
            "2022-07-30 18:03:02.881112 Epoch [214/250], Step [0050/0060], Loss1: -0.9834 Loss2: -0.9835 Loss3: -0.9898\n",
            "2022-07-30 18:03:09.185908 Epoch [214/250], Step [0060/0060], Loss1: -0.9886 Loss2: -0.9893 Loss3: -0.9930\n",
            "Epoch: 214 MAE: 0.07527537633502292 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 18:03:17.554437 Epoch [215/250], Step [0001/0060], Loss1: -0.9841 Loss2: -0.9839 Loss3: -0.9913\n",
            "2022-07-30 18:03:46.292206 Epoch [215/250], Step [0050/0060], Loss1: -0.9854 Loss2: -0.9865 Loss3: -0.9915\n",
            "2022-07-30 18:03:52.027988 Epoch [215/250], Step [0060/0060], Loss1: -0.9853 Loss2: -0.9855 Loss3: -0.9906\n",
            "Epoch: 215 MAE: 0.07323428789774576 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 18:04:03.158793 Epoch [216/250], Step [0001/0060], Loss1: -0.9849 Loss2: -0.9867 Loss3: -0.9919\n",
            "2022-07-30 18:04:31.672592 Epoch [216/250], Step [0050/0060], Loss1: -0.9838 Loss2: -0.9850 Loss3: -0.9904\n",
            "2022-07-30 18:04:37.471942 Epoch [216/250], Step [0060/0060], Loss1: -0.9858 Loss2: -0.9858 Loss3: -0.9908\n",
            "Epoch: 216 MAE: 0.07446134607627909 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 18:04:45.871850 Epoch [217/250], Step [0001/0060], Loss1: -0.9883 Loss2: -0.9875 Loss3: -0.9918\n",
            "2022-07-30 18:05:16.439955 Epoch [217/250], Step [0050/0060], Loss1: -0.9882 Loss2: -0.9874 Loss3: -0.9923\n",
            "2022-07-30 18:05:23.394576 Epoch [217/250], Step [0060/0060], Loss1: -0.9860 Loss2: -0.9842 Loss3: -0.9899\n",
            "Epoch: 217 MAE: 0.07452095889540575 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 18:05:31.719791 Epoch [218/250], Step [0001/0060], Loss1: -0.9859 Loss2: -0.9860 Loss3: -0.9911\n",
            "2022-07-30 18:06:00.106193 Epoch [218/250], Step [0050/0060], Loss1: -0.9821 Loss2: -0.9812 Loss3: -0.9881\n",
            "2022-07-30 18:06:05.879705 Epoch [218/250], Step [0060/0060], Loss1: -0.9864 Loss2: -0.9854 Loss3: -0.9911\n",
            "Epoch: 218 MAE: 0.07309812878805493 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 18:06:14.210149 Epoch [219/250], Step [0001/0060], Loss1: -0.9885 Loss2: -0.9888 Loss3: -0.9929\n",
            "2022-07-30 18:06:42.579373 Epoch [219/250], Step [0050/0060], Loss1: -0.9856 Loss2: -0.9866 Loss3: -0.9910\n",
            "2022-07-30 18:06:48.330160 Epoch [219/250], Step [0060/0060], Loss1: -0.9859 Loss2: -0.9836 Loss3: -0.9906\n",
            "Epoch: 219 MAE: 0.07468305330427867 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 18:06:56.654763 Epoch [220/250], Step [0001/0060], Loss1: -0.9872 Loss2: -0.9872 Loss3: -0.9922\n",
            "2022-07-30 18:07:25.372232 Epoch [220/250], Step [0050/0060], Loss1: -0.9878 Loss2: -0.9875 Loss3: -0.9922\n",
            "2022-07-30 18:07:32.136785 Epoch [220/250], Step [0060/0060], Loss1: -0.9865 Loss2: -0.9879 Loss3: -0.9921\n",
            "Epoch: 220 MAE: 0.07409672515102168 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 18:07:43.495371 Epoch [221/250], Step [0001/0060], Loss1: -0.9861 Loss2: -0.9850 Loss3: -0.9913\n",
            "2022-07-30 18:08:11.837517 Epoch [221/250], Step [0050/0060], Loss1: -0.9845 Loss2: -0.9851 Loss3: -0.9908\n",
            "2022-07-30 18:08:17.589568 Epoch [221/250], Step [0060/0060], Loss1: -0.9843 Loss2: -0.9848 Loss3: -0.9907\n",
            "Epoch: 221 MAE: 0.07374231944008475 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "2022-07-30 18:08:25.923795 Epoch [222/250], Step [0001/0060], Loss1: -0.9839 Loss2: -0.9846 Loss3: -0.9907\n",
            "2022-07-30 18:08:54.344295 Epoch [222/250], Step [0050/0060], Loss1: -0.9887 Loss2: -0.9881 Loss3: -0.9930\n",
            "2022-07-30 18:09:00.161810 Epoch [222/250], Step [0060/0060], Loss1: -0.9878 Loss2: -0.9888 Loss3: -0.9928\n",
            "Epoch: 222 MAE: 0.06965464874550147 ####  bestMAE: 0.06967533828089477 bestEpoch: 86\n",
            "best epoch:222\n",
            "2022-07-30 18:09:11.948526 Epoch [223/250], Step [0001/0060], Loss1: -0.9827 Loss2: -0.9830 Loss3: -0.9896\n",
            "2022-07-30 18:09:42.590363 Epoch [223/250], Step [0050/0060], Loss1: -0.9808 Loss2: -0.9838 Loss3: -0.9886\n",
            "2022-07-30 18:09:49.445934 Epoch [223/250], Step [0060/0060], Loss1: -0.9804 Loss2: -0.9836 Loss3: -0.9886\n",
            "Epoch: 223 MAE: 0.07290192260944024 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:09:57.841173 Epoch [224/250], Step [0001/0060], Loss1: -0.9856 Loss2: -0.9870 Loss3: -0.9917\n",
            "2022-07-30 18:10:26.437273 Epoch [224/250], Step [0050/0060], Loss1: -0.9855 Loss2: -0.9873 Loss3: -0.9917\n",
            "2022-07-30 18:10:32.225873 Epoch [224/250], Step [0060/0060], Loss1: -0.9869 Loss2: -0.9875 Loss3: -0.9923\n",
            "Epoch: 224 MAE: 0.07250501773975514 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:10:40.478114 Epoch [225/250], Step [0001/0060], Loss1: -0.9885 Loss2: -0.9878 Loss3: -0.9925\n",
            "2022-07-30 18:11:08.942354 Epoch [225/250], Step [0050/0060], Loss1: -0.9856 Loss2: -0.9856 Loss3: -0.9912\n",
            "2022-07-30 18:11:14.773026 Epoch [225/250], Step [0060/0060], Loss1: -0.9841 Loss2: -0.9823 Loss3: -0.9900\n",
            "Epoch: 225 MAE: 0.07496596437282665 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:11:25.946836 Epoch [226/250], Step [0001/0060], Loss1: -0.9850 Loss2: -0.9829 Loss3: -0.9898\n",
            "2022-07-30 18:11:56.136644 Epoch [226/250], Step [0050/0060], Loss1: -0.9843 Loss2: -0.9846 Loss3: -0.9898\n",
            "2022-07-30 18:12:03.175568 Epoch [226/250], Step [0060/0060], Loss1: -0.9878 Loss2: -0.9847 Loss3: -0.9917\n",
            "Epoch: 226 MAE: 0.07480544897614332 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:12:11.343851 Epoch [227/250], Step [0001/0060], Loss1: -0.9862 Loss2: -0.9850 Loss3: -0.9912\n",
            "2022-07-30 18:12:39.852362 Epoch [227/250], Step [0050/0060], Loss1: -0.9849 Loss2: -0.9852 Loss3: -0.9911\n",
            "2022-07-30 18:12:45.603804 Epoch [227/250], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9856 Loss3: -0.9920\n",
            "Epoch: 227 MAE: 0.07409286796731292 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:12:53.828222 Epoch [228/250], Step [0001/0060], Loss1: -0.9837 Loss2: -0.9821 Loss3: -0.9897\n",
            "2022-07-30 18:13:22.148424 Epoch [228/250], Step [0050/0060], Loss1: -0.9874 Loss2: -0.9884 Loss3: -0.9929\n",
            "2022-07-30 18:13:27.931331 Epoch [228/250], Step [0060/0060], Loss1: -0.9834 Loss2: -0.9830 Loss3: -0.9899\n",
            "Epoch: 228 MAE: 0.07427947342080417 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:13:36.105280 Epoch [229/250], Step [0001/0060], Loss1: -0.9890 Loss2: -0.9870 Loss3: -0.9926\n",
            "2022-07-30 18:14:04.481527 Epoch [229/250], Step [0050/0060], Loss1: -0.9831 Loss2: -0.9809 Loss3: -0.9886\n",
            "2022-07-30 18:14:11.463304 Epoch [229/250], Step [0060/0060], Loss1: -0.9886 Loss2: -0.9873 Loss3: -0.9924\n",
            "Epoch: 229 MAE: 0.0749464733386166 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:14:19.769288 Epoch [230/250], Step [0001/0060], Loss1: -0.9869 Loss2: -0.9850 Loss3: -0.9917\n",
            "2022-07-30 18:14:48.165464 Epoch [230/250], Step [0050/0060], Loss1: -0.9783 Loss2: -0.9816 Loss3: -0.9878\n",
            "2022-07-30 18:14:53.917329 Epoch [230/250], Step [0060/0060], Loss1: -0.9860 Loss2: -0.9871 Loss3: -0.9918\n",
            "Epoch: 230 MAE: 0.07554074514479864 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:15:05.100665 Epoch [231/250], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9894 Loss3: -0.9934\n",
            "2022-07-30 18:15:33.455048 Epoch [231/250], Step [0050/0060], Loss1: -0.9830 Loss2: -0.9834 Loss3: -0.9901\n",
            "2022-07-30 18:15:39.201975 Epoch [231/250], Step [0060/0060], Loss1: -0.9880 Loss2: -0.9870 Loss3: -0.9922\n",
            "Epoch: 231 MAE: 0.07318183177362673 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:15:47.583669 Epoch [232/250], Step [0001/0060], Loss1: -0.9841 Loss2: -0.9841 Loss3: -0.9894\n",
            "2022-07-30 18:16:16.453571 Epoch [232/250], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9857 Loss3: -0.9915\n",
            "2022-07-30 18:16:24.390326 Epoch [232/250], Step [0060/0060], Loss1: -0.9887 Loss2: -0.9889 Loss3: -0.9931\n",
            "Epoch: 232 MAE: 0.07304498919734245 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:16:33.473842 Epoch [233/250], Step [0001/0060], Loss1: -0.9866 Loss2: -0.9866 Loss3: -0.9914\n",
            "2022-07-30 18:17:01.857772 Epoch [233/250], Step [0050/0060], Loss1: -0.9870 Loss2: -0.9874 Loss3: -0.9916\n",
            "2022-07-30 18:17:07.621013 Epoch [233/250], Step [0060/0060], Loss1: -0.9853 Loss2: -0.9816 Loss3: -0.9899\n",
            "Epoch: 233 MAE: 0.07494107776217988 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:17:15.859308 Epoch [234/250], Step [0001/0060], Loss1: -0.9853 Loss2: -0.9855 Loss3: -0.9906\n",
            "2022-07-30 18:17:44.219569 Epoch [234/250], Step [0050/0060], Loss1: -0.9862 Loss2: -0.9851 Loss3: -0.9920\n",
            "2022-07-30 18:17:49.948520 Epoch [234/250], Step [0060/0060], Loss1: -0.9864 Loss2: -0.9848 Loss3: -0.9912\n",
            "Epoch: 234 MAE: 0.07497780734269077 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:17:58.167950 Epoch [235/250], Step [0001/0060], Loss1: -0.9854 Loss2: -0.9873 Loss3: -0.9919\n",
            "2022-07-30 18:18:27.767590 Epoch [235/250], Step [0050/0060], Loss1: -0.9782 Loss2: -0.9781 Loss3: -0.9870\n",
            "2022-07-30 18:18:34.394984 Epoch [235/250], Step [0060/0060], Loss1: -0.9829 Loss2: -0.9840 Loss3: -0.9902\n",
            "Epoch: 235 MAE: 0.07673412716577925 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:18:46.962574 Epoch [236/250], Step [0001/0060], Loss1: -0.9810 Loss2: -0.9847 Loss3: -0.9903\n",
            "2022-07-30 18:19:15.615775 Epoch [236/250], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9874 Loss3: -0.9927\n",
            "2022-07-30 18:19:21.369415 Epoch [236/250], Step [0060/0060], Loss1: -0.9886 Loss2: -0.9885 Loss3: -0.9925\n",
            "Epoch: 236 MAE: 0.07195812129469772 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:19:29.670236 Epoch [237/250], Step [0001/0060], Loss1: -0.9860 Loss2: -0.9870 Loss3: -0.9919\n",
            "2022-07-30 18:19:58.073563 Epoch [237/250], Step [0050/0060], Loss1: -0.9886 Loss2: -0.9865 Loss3: -0.9920\n",
            "2022-07-30 18:20:03.809378 Epoch [237/250], Step [0060/0060], Loss1: -0.9844 Loss2: -0.9846 Loss3: -0.9915\n",
            "Epoch: 237 MAE: 0.07446159271966843 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:20:12.030813 Epoch [238/250], Step [0001/0060], Loss1: -0.9858 Loss2: -0.9848 Loss3: -0.9911\n",
            "2022-07-30 18:20:40.632929 Epoch [238/250], Step [0050/0060], Loss1: -0.9818 Loss2: -0.9848 Loss3: -0.9894\n",
            "2022-07-30 18:20:48.356583 Epoch [238/250], Step [0060/0060], Loss1: -0.9839 Loss2: -0.9834 Loss3: -0.9901\n",
            "Epoch: 238 MAE: 0.07493408006335062 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:20:57.881587 Epoch [239/250], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9887 Loss3: -0.9933\n",
            "2022-07-30 18:21:26.282654 Epoch [239/250], Step [0050/0060], Loss1: -0.9843 Loss2: -0.9858 Loss3: -0.9908\n",
            "2022-07-30 18:21:32.058926 Epoch [239/250], Step [0060/0060], Loss1: -0.9821 Loss2: -0.9843 Loss3: -0.9896\n",
            "Epoch: 239 MAE: 0.07266364354935903 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:21:40.328726 Epoch [240/250], Step [0001/0060], Loss1: -0.9840 Loss2: -0.9822 Loss3: -0.9894\n",
            "2022-07-30 18:22:08.547404 Epoch [240/250], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9876 Loss3: -0.9922\n",
            "2022-07-30 18:22:14.271380 Epoch [240/250], Step [0060/0060], Loss1: -0.9871 Loss2: -0.9870 Loss3: -0.9918\n",
            "Epoch: 240 MAE: 0.07305450903675542 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:22:25.625839 Epoch [241/250], Step [0001/0060], Loss1: -0.9849 Loss2: -0.9858 Loss3: -0.9906\n",
            "2022-07-30 18:22:54.076792 Epoch [241/250], Step [0050/0060], Loss1: -0.9846 Loss2: -0.9864 Loss3: -0.9913\n",
            "2022-07-30 18:23:01.367540 Epoch [241/250], Step [0060/0060], Loss1: -0.9835 Loss2: -0.9862 Loss3: -0.9908\n",
            "Epoch: 241 MAE: 0.07442872385499338 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:23:10.915900 Epoch [242/250], Step [0001/0060], Loss1: -0.9865 Loss2: -0.9843 Loss3: -0.9909\n",
            "2022-07-30 18:23:39.559622 Epoch [242/250], Step [0050/0060], Loss1: -0.9823 Loss2: -0.9805 Loss3: -0.9882\n",
            "2022-07-30 18:23:45.292798 Epoch [242/250], Step [0060/0060], Loss1: -0.9885 Loss2: -0.9878 Loss3: -0.9925\n",
            "Epoch: 242 MAE: 0.07194970489179017 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:23:53.585496 Epoch [243/250], Step [0001/0060], Loss1: -0.9864 Loss2: -0.9855 Loss3: -0.9915\n",
            "2022-07-30 18:24:21.958761 Epoch [243/250], Step [0050/0060], Loss1: -0.9811 Loss2: -0.9842 Loss3: -0.9893\n",
            "2022-07-30 18:24:27.735111 Epoch [243/250], Step [0060/0060], Loss1: -0.9882 Loss2: -0.9869 Loss3: -0.9914\n",
            "Epoch: 243 MAE: 0.07328867180637581 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:24:36.018570 Epoch [244/250], Step [0001/0060], Loss1: -0.9844 Loss2: -0.9817 Loss3: -0.9898\n",
            "2022-07-30 18:25:04.428208 Epoch [244/250], Step [0050/0060], Loss1: -0.9849 Loss2: -0.9838 Loss3: -0.9899\n",
            "2022-07-30 18:25:10.972903 Epoch [244/250], Step [0060/0060], Loss1: -0.9884 Loss2: -0.9855 Loss3: -0.9917\n",
            "Epoch: 244 MAE: 0.07600538137728573 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:25:20.020418 Epoch [245/250], Step [0001/0060], Loss1: -0.9871 Loss2: -0.9878 Loss3: -0.9918\n",
            "2022-07-30 18:25:48.333856 Epoch [245/250], Step [0050/0060], Loss1: -0.9830 Loss2: -0.9817 Loss3: -0.9888\n",
            "2022-07-30 18:25:54.087755 Epoch [245/250], Step [0060/0060], Loss1: -0.9826 Loss2: -0.9823 Loss3: -0.9885\n",
            "Epoch: 245 MAE: 0.07234555547199556 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:26:05.892978 Epoch [246/250], Step [0001/0060], Loss1: -0.9871 Loss2: -0.9874 Loss3: -0.9918\n",
            "2022-07-30 18:26:34.362984 Epoch [246/250], Step [0050/0060], Loss1: -0.9873 Loss2: -0.9872 Loss3: -0.9924\n",
            "2022-07-30 18:26:40.126674 Epoch [246/250], Step [0060/0060], Loss1: -0.9863 Loss2: -0.9856 Loss3: -0.9905\n",
            "Epoch: 246 MAE: 0.07344443003336588 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:26:48.335646 Epoch [247/250], Step [0001/0060], Loss1: -0.9801 Loss2: -0.9796 Loss3: -0.9880\n",
            "2022-07-30 18:27:16.603844 Epoch [247/250], Step [0050/0060], Loss1: -0.9818 Loss2: -0.9834 Loss3: -0.9899\n",
            "2022-07-30 18:27:22.985997 Epoch [247/250], Step [0060/0060], Loss1: -0.9863 Loss2: -0.9862 Loss3: -0.9916\n",
            "Epoch: 247 MAE: 0.07519048564648502 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:27:34.401862 Epoch [248/250], Step [0001/0060], Loss1: -0.9835 Loss2: -0.9831 Loss3: -0.9887\n",
            "2022-07-30 18:28:02.769241 Epoch [248/250], Step [0050/0060], Loss1: -0.9877 Loss2: -0.9860 Loss3: -0.9919\n",
            "2022-07-30 18:28:08.549729 Epoch [248/250], Step [0060/0060], Loss1: -0.9835 Loss2: -0.9854 Loss3: -0.9903\n",
            "Epoch: 248 MAE: 0.07534453457625456 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n",
            "2022-07-30 18:28:16.794201 Epoch [249/250], Step [0001/0060], Loss1: -0.9814 Loss2: -0.9838 Loss3: -0.9890\n",
            "2022-07-30 18:28:45.166190 Epoch [249/250], Step [0050/0060], Loss1: -0.9889 Loss2: -0.9881 Loss3: -0.9925\n",
            "2022-07-30 18:28:51.052588 Epoch [249/250], Step [0060/0060], Loss1: -0.9852 Loss2: -0.9853 Loss3: -0.9901\n",
            "Epoch: 249 MAE: 0.07536795590920423 ####  bestMAE: 0.06965464874550147 bestEpoch: 222\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "train_accu = []\n",
        "train_losses = []\n",
        "train_accu1 = []\n",
        "train_accu2 = []\n",
        "train_accu3 = []\n",
        "train_losses1 = []\n",
        "train_losses2 = []\n",
        "train_losses3 = []\n",
        "val_accu = []\n",
        "val_losses = []\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    running_loss = 0\n",
        "    running_loss1 = 0\n",
        "    running_loss2 = 0\n",
        "    running_loss3 = 0\n",
        "    total = 0\n",
        "    total1 = 0\n",
        "    total2 = 0\n",
        "    total3 = 0\n",
        "    correct = 0\n",
        "    correct1 = 0\n",
        "    correct2 = 0\n",
        "    correct3 = 0\n",
        "\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = fun_ssim(gts, pre_res[0])\n",
        "            loss2    = fun_ssim(gts, pre_res[1])\n",
        "            loss3    = fun_ssim(gts, pre_res[2])\n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "\n",
        "            #loss graph\n",
        "            running_loss1 += loss1.item()\n",
        "            running_loss2 += loss2.item()\n",
        "            running_loss3 += loss3.item()\n",
        "            predicted1 = pre_res[0]\n",
        "            predicted2 = pre_res[1]\n",
        "            predicted3 = pre_res[2]\n",
        "            total1 += images.size(0)\n",
        "            total2 += gts.size(0)\n",
        "            total3 += depths.size(0)\n",
        "            correct1 += predicted1.eq(images).sum().item()\n",
        "            correct2 += predicted2.eq(gts).sum().item()\n",
        "            correct3 += predicted3.eq(depths).sum().item()\n",
        "\n",
        "            running_loss += loss_all.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = gt + loss + predicted\n",
        "            total += images.size(0)\n",
        "            correct += outputs.eq(images).sum().item()\n",
        "            \n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "\n",
        "        train_loss = running_loss/len(train_loader)\n",
        "        train_loss1=running_loss1/len(train_loader)\n",
        "        train_loss2=running_loss2/len(train_loader)\n",
        "        train_loss3=running_loss3/len(train_loader)\n",
        "        accu = 100.*correct/total\n",
        "        accu1=100.*correct1/total1\n",
        "        accu2=100.*correct2/total2\n",
        "        accu3=100.*correct3/total3        \n",
        "        train_accu1.append(accu1)\n",
        "        train_accu2.append(accu2)\n",
        "        train_accu3.append(accu3)\n",
        "        train_losses1.append(train_loss1)\n",
        "        train_losses2.append(train_loss2)\n",
        "        train_losses3.append(train_loss3)\n",
        "        train_accu.append(accu)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "           \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-8)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "            mae_sum += np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "\n",
        "            #loss graph\n",
        "            running_loss += mae_sum.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = gt + loss + predicted\n",
        "            total += test_loader.size\n",
        "            correct += outputs.eq(image).sum().item()\n",
        "\n",
        "\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "       \n",
        "        val_loss=running_loss/len(test_loader)\n",
        "        accu=100.*correct/total\n",
        "        val_accu.append(accu)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_best_epoch_ssim_loss.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n",
        "\n",
        "plt.plot(train_losses, '-')\n",
        "plt.plot(train_losses1,'-')\n",
        "plt.plot(train_losses2,'-')\n",
        "plt.plot(train_losses3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['SSIM Loss','Loss1', 'Loss2', 'Loss3'])\n",
        "plt.title('Train Losses')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_accu, '-')\n",
        "plt.plot(train_accu1,'-')\n",
        "plt.plot(train_accu2,'-')\n",
        "plt.plot(train_accu3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Accuracy','Acc1', 'Acc2', 'Acc3'])\n",
        "plt.title('Train Accuracy')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(val_losses,'-o')\n",
        "plt.plot(val_accu,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Losses','Accuracy'])\n",
        "plt.title('Test Losses and Accuracy')\n",
        " \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqwDqeD0Ke-G"
      },
      "source": [
        "### Training with structure loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a23243cf8fc441389fd50a34828f9fe2",
            "c74748b9f48a407e9794456f46a0eace",
            "d7d51bc216514adc9f29a056ff6ae6d2",
            "d0977e3fa9634ff2aa66ca36eef0d991",
            "c83165c488014758beea79ce6b512d2e",
            "ab803beac7464f99a0b5bfb6ed7a1a82",
            "35cd0d7de3e340728900e43624a8286f",
            "a80a0775846d49f8ad894df38234318d",
            "0ed9816fb8804fe583cbfc794d11a84e",
            "4e4737a2b68049c9aaa7594eda512bfe",
            "48cb2939a71e47bbbca478f30376bbcf"
          ]
        },
        "id": "nu8W0ZsJKl_U",
        "outputId": "477a37aa-4350-461c-b12d-faef0c3697d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USE GPU 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://shanghuagao.oss-cn-beijing.aliyuncs.com/res2net/res2net50_v1b_26w_4s-3cf99910.pth\" to /root/.cache/torch/hub/checkpoints/res2net50_v1b_26w_4s-3cf99910.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a23243cf8fc441389fd50a34828f9fe2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/98.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load data...\n",
            "/content/tmp/traindataset/RGB/ /content/tmp/traindataset/GT/ /content/tmp/traindataset/depth/\n",
            "/content/tmp/traindataset/RGB/ /content/tmp/traindataset/GT/ /content/tmp/traindataset/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/traindataset/RGB/RGB_00.png', '/content/tmp/traindataset/RGB/RGB_01.png', '/content/tmp/traindataset/RGB/RGB_02.png', '/content/tmp/traindataset/RGB/RGB_10.png', '/content/tmp/traindataset/RGB/RGB_100.png', '/content/tmp/traindataset/RGB/RGB_101.png', '/content/tmp/traindataset/RGB/RGB_102.png', '/content/tmp/traindataset/RGB/RGB_11.png', '/content/tmp/traindataset/RGB/RGB_110.png', '/content/tmp/traindataset/RGB/RGB_111.png', '/content/tmp/traindataset/RGB/RGB_112.png', '/content/tmp/traindataset/RGB/RGB_12.png', '/content/tmp/traindataset/RGB/RGB_120.png', '/content/tmp/traindataset/RGB/RGB_121.png', '/content/tmp/traindataset/RGB/RGB_122.png', '/content/tmp/traindataset/RGB/RGB_130.png', '/content/tmp/traindataset/RGB/RGB_131.png', '/content/tmp/traindataset/RGB/RGB_132.png', '/content/tmp/traindataset/RGB/RGB_140.png', '/content/tmp/traindataset/RGB/RGB_141.png', '/content/tmp/traindataset/RGB/RGB_142.png', '/content/tmp/traindataset/RGB/RGB_150.png', '/content/tmp/traindataset/RGB/RGB_151.png', '/content/tmp/traindataset/RGB/RGB_152.png', '/content/tmp/traindataset/RGB/RGB_160.png', '/content/tmp/traindataset/RGB/RGB_161.png', '/content/tmp/traindataset/RGB/RGB_162.png', '/content/tmp/traindataset/RGB/RGB_170.png', '/content/tmp/traindataset/RGB/RGB_171.png', '/content/tmp/traindataset/RGB/RGB_172.png', '/content/tmp/traindataset/RGB/RGB_180.png', '/content/tmp/traindataset/RGB/RGB_181.png', '/content/tmp/traindataset/RGB/RGB_182.png', '/content/tmp/traindataset/RGB/RGB_190.png', '/content/tmp/traindataset/RGB/RGB_191.png', '/content/tmp/traindataset/RGB/RGB_192.png', '/content/tmp/traindataset/RGB/RGB_20.png', '/content/tmp/traindataset/RGB/RGB_200.png', '/content/tmp/traindataset/RGB/RGB_201.png', '/content/tmp/traindataset/RGB/RGB_202.png', '/content/tmp/traindataset/RGB/RGB_21.png', '/content/tmp/traindataset/RGB/RGB_210.png', '/content/tmp/traindataset/RGB/RGB_211.png', '/content/tmp/traindataset/RGB/RGB_212.png', '/content/tmp/traindataset/RGB/RGB_22.png', '/content/tmp/traindataset/RGB/RGB_220.png', '/content/tmp/traindataset/RGB/RGB_221.png', '/content/tmp/traindataset/RGB/RGB_222.png', '/content/tmp/traindataset/RGB/RGB_230.png', '/content/tmp/traindataset/RGB/RGB_231.png', '/content/tmp/traindataset/RGB/RGB_232.png', '/content/tmp/traindataset/RGB/RGB_240.png', '/content/tmp/traindataset/RGB/RGB_241.png', '/content/tmp/traindataset/RGB/RGB_242.png', '/content/tmp/traindataset/RGB/RGB_250.png', '/content/tmp/traindataset/RGB/RGB_251.png', '/content/tmp/traindataset/RGB/RGB_252.png', '/content/tmp/traindataset/RGB/RGB_260.png', '/content/tmp/traindataset/RGB/RGB_261.png', '/content/tmp/traindataset/RGB/RGB_262.png', '/content/tmp/traindataset/RGB/RGB_270.png', '/content/tmp/traindataset/RGB/RGB_271.png', '/content/tmp/traindataset/RGB/RGB_272.png', '/content/tmp/traindataset/RGB/RGB_280.png', '/content/tmp/traindataset/RGB/RGB_281.png', '/content/tmp/traindataset/RGB/RGB_282.png', '/content/tmp/traindataset/RGB/RGB_290.png', '/content/tmp/traindataset/RGB/RGB_291.png', '/content/tmp/traindataset/RGB/RGB_292.png', '/content/tmp/traindataset/RGB/RGB_30.png', '/content/tmp/traindataset/RGB/RGB_300.png', '/content/tmp/traindataset/RGB/RGB_301.png', '/content/tmp/traindataset/RGB/RGB_302.png', '/content/tmp/traindataset/RGB/RGB_31.png', '/content/tmp/traindataset/RGB/RGB_310.png', '/content/tmp/traindataset/RGB/RGB_311.png', '/content/tmp/traindataset/RGB/RGB_312.png', '/content/tmp/traindataset/RGB/RGB_32.png', '/content/tmp/traindataset/RGB/RGB_320.png', '/content/tmp/traindataset/RGB/RGB_321.png', '/content/tmp/traindataset/RGB/RGB_322.png', '/content/tmp/traindataset/RGB/RGB_330.png', '/content/tmp/traindataset/RGB/RGB_331.png', '/content/tmp/traindataset/RGB/RGB_332.png', '/content/tmp/traindataset/RGB/RGB_340.png', '/content/tmp/traindataset/RGB/RGB_341.png', '/content/tmp/traindataset/RGB/RGB_342.png', '/content/tmp/traindataset/RGB/RGB_350.png', '/content/tmp/traindataset/RGB/RGB_351.png', '/content/tmp/traindataset/RGB/RGB_352.png', '/content/tmp/traindataset/RGB/RGB_360.png', '/content/tmp/traindataset/RGB/RGB_361.png', '/content/tmp/traindataset/RGB/RGB_362.png', '/content/tmp/traindataset/RGB/RGB_370.png', '/content/tmp/traindataset/RGB/RGB_371.png', '/content/tmp/traindataset/RGB/RGB_372.png', '/content/tmp/traindataset/RGB/RGB_380.png', '/content/tmp/traindataset/RGB/RGB_381.png', '/content/tmp/traindataset/RGB/RGB_382.png', '/content/tmp/traindataset/RGB/RGB_390.png', '/content/tmp/traindataset/RGB/RGB_391.png', '/content/tmp/traindataset/RGB/RGB_392.png', '/content/tmp/traindataset/RGB/RGB_40.png', '/content/tmp/traindataset/RGB/RGB_400.png', '/content/tmp/traindataset/RGB/RGB_401.png', '/content/tmp/traindataset/RGB/RGB_402.png', '/content/tmp/traindataset/RGB/RGB_41.png', '/content/tmp/traindataset/RGB/RGB_410.png', '/content/tmp/traindataset/RGB/RGB_411.png', '/content/tmp/traindataset/RGB/RGB_412.png', '/content/tmp/traindataset/RGB/RGB_42.png', '/content/tmp/traindataset/RGB/RGB_420.png', '/content/tmp/traindataset/RGB/RGB_421.png', '/content/tmp/traindataset/RGB/RGB_422.png', '/content/tmp/traindataset/RGB/RGB_430.png', '/content/tmp/traindataset/RGB/RGB_431.png', '/content/tmp/traindataset/RGB/RGB_432.png', '/content/tmp/traindataset/RGB/RGB_440.png', '/content/tmp/traindataset/RGB/RGB_441.png', '/content/tmp/traindataset/RGB/RGB_442.png', '/content/tmp/traindataset/RGB/RGB_450.png', '/content/tmp/traindataset/RGB/RGB_451.png', '/content/tmp/traindataset/RGB/RGB_452.png', '/content/tmp/traindataset/RGB/RGB_460.png', '/content/tmp/traindataset/RGB/RGB_461.png', '/content/tmp/traindataset/RGB/RGB_462.png', '/content/tmp/traindataset/RGB/RGB_470.png', '/content/tmp/traindataset/RGB/RGB_471.png', '/content/tmp/traindataset/RGB/RGB_472.png', '/content/tmp/traindataset/RGB/RGB_480.png', '/content/tmp/traindataset/RGB/RGB_481.png', '/content/tmp/traindataset/RGB/RGB_482.png', '/content/tmp/traindataset/RGB/RGB_490.png', '/content/tmp/traindataset/RGB/RGB_491.png', '/content/tmp/traindataset/RGB/RGB_492.png', '/content/tmp/traindataset/RGB/RGB_50.png', '/content/tmp/traindataset/RGB/RGB_500.png', '/content/tmp/traindataset/RGB/RGB_501.png', '/content/tmp/traindataset/RGB/RGB_502.png', '/content/tmp/traindataset/RGB/RGB_51.png', '/content/tmp/traindataset/RGB/RGB_510.png', '/content/tmp/traindataset/RGB/RGB_511.png', '/content/tmp/traindataset/RGB/RGB_512.png', '/content/tmp/traindataset/RGB/RGB_52.png', '/content/tmp/traindataset/RGB/RGB_520.png', '/content/tmp/traindataset/RGB/RGB_521.png', '/content/tmp/traindataset/RGB/RGB_522.png', '/content/tmp/traindataset/RGB/RGB_530.png', '/content/tmp/traindataset/RGB/RGB_531.png', '/content/tmp/traindataset/RGB/RGB_532.png', '/content/tmp/traindataset/RGB/RGB_540.png', '/content/tmp/traindataset/RGB/RGB_541.png', '/content/tmp/traindataset/RGB/RGB_542.png', '/content/tmp/traindataset/RGB/RGB_550.png', '/content/tmp/traindataset/RGB/RGB_551.png', '/content/tmp/traindataset/RGB/RGB_552.png', '/content/tmp/traindataset/RGB/RGB_560.png', '/content/tmp/traindataset/RGB/RGB_561.png', '/content/tmp/traindataset/RGB/RGB_562.png', '/content/tmp/traindataset/RGB/RGB_570.png', '/content/tmp/traindataset/RGB/RGB_571.png', '/content/tmp/traindataset/RGB/RGB_572.png', '/content/tmp/traindataset/RGB/RGB_580.png', '/content/tmp/traindataset/RGB/RGB_581.png', '/content/tmp/traindataset/RGB/RGB_582.png', '/content/tmp/traindataset/RGB/RGB_590.png', '/content/tmp/traindataset/RGB/RGB_591.png', '/content/tmp/traindataset/RGB/RGB_592.png', '/content/tmp/traindataset/RGB/RGB_60.png', '/content/tmp/traindataset/RGB/RGB_600.png', '/content/tmp/traindataset/RGB/RGB_601.png', '/content/tmp/traindataset/RGB/RGB_602.png', '/content/tmp/traindataset/RGB/RGB_61.png', '/content/tmp/traindataset/RGB/RGB_610.png', '/content/tmp/traindataset/RGB/RGB_611.png', '/content/tmp/traindataset/RGB/RGB_612.png', '/content/tmp/traindataset/RGB/RGB_62.png', '/content/tmp/traindataset/RGB/RGB_620.png', '/content/tmp/traindataset/RGB/RGB_621.png', '/content/tmp/traindataset/RGB/RGB_622.png', '/content/tmp/traindataset/RGB/RGB_630.png', '/content/tmp/traindataset/RGB/RGB_631.png', '/content/tmp/traindataset/RGB/RGB_632.png', '/content/tmp/traindataset/RGB/RGB_640.png', '/content/tmp/traindataset/RGB/RGB_641.png', '/content/tmp/traindataset/RGB/RGB_642.png', '/content/tmp/traindataset/RGB/RGB_650.png', '/content/tmp/traindataset/RGB/RGB_651.png', '/content/tmp/traindataset/RGB/RGB_652.png', '/content/tmp/traindataset/RGB/RGB_660.png', '/content/tmp/traindataset/RGB/RGB_661.png', '/content/tmp/traindataset/RGB/RGB_662.png', '/content/tmp/traindataset/RGB/RGB_670.png', '/content/tmp/traindataset/RGB/RGB_671.png', '/content/tmp/traindataset/RGB/RGB_672.png', '/content/tmp/traindataset/RGB/RGB_680.png', '/content/tmp/traindataset/RGB/RGB_681.png', '/content/tmp/traindataset/RGB/RGB_682.png', '/content/tmp/traindataset/RGB/RGB_690.png', '/content/tmp/traindataset/RGB/RGB_691.png', '/content/tmp/traindataset/RGB/RGB_692.png', '/content/tmp/traindataset/RGB/RGB_70.png', '/content/tmp/traindataset/RGB/RGB_700.png', '/content/tmp/traindataset/RGB/RGB_701.png', '/content/tmp/traindataset/RGB/RGB_702.png', '/content/tmp/traindataset/RGB/RGB_71.png', '/content/tmp/traindataset/RGB/RGB_710.png', '/content/tmp/traindataset/RGB/RGB_711.png', '/content/tmp/traindataset/RGB/RGB_712.png', '/content/tmp/traindataset/RGB/RGB_72.png', '/content/tmp/traindataset/RGB/RGB_720.png', '/content/tmp/traindataset/RGB/RGB_721.png', '/content/tmp/traindataset/RGB/RGB_722.png', '/content/tmp/traindataset/RGB/RGB_730.png', '/content/tmp/traindataset/RGB/RGB_731.png', '/content/tmp/traindataset/RGB/RGB_732.png', '/content/tmp/traindataset/RGB/RGB_740.png', '/content/tmp/traindataset/RGB/RGB_741.png', '/content/tmp/traindataset/RGB/RGB_742.png', '/content/tmp/traindataset/RGB/RGB_750.png', '/content/tmp/traindataset/RGB/RGB_751.png', '/content/tmp/traindataset/RGB/RGB_752.png', '/content/tmp/traindataset/RGB/RGB_760.png', '/content/tmp/traindataset/RGB/RGB_761.png', '/content/tmp/traindataset/RGB/RGB_762.png', '/content/tmp/traindataset/RGB/RGB_770.png', '/content/tmp/traindataset/RGB/RGB_771.png', '/content/tmp/traindataset/RGB/RGB_772.png', '/content/tmp/traindataset/RGB/RGB_780.png', '/content/tmp/traindataset/RGB/RGB_781.png', '/content/tmp/traindataset/RGB/RGB_782.png', '/content/tmp/traindataset/RGB/RGB_790.png', '/content/tmp/traindataset/RGB/RGB_791.png', '/content/tmp/traindataset/RGB/RGB_792.png', '/content/tmp/traindataset/RGB/RGB_80.png', '/content/tmp/traindataset/RGB/RGB_81.png', '/content/tmp/traindataset/RGB/RGB_82.png', '/content/tmp/traindataset/RGB/RGB_90.png', '/content/tmp/traindataset/RGB/RGB_91.png', '/content/tmp/traindataset/RGB/RGB_92.png'] ['/content/tmp/traindataset/GT/GT_00.png', '/content/tmp/traindataset/GT/GT_01.png', '/content/tmp/traindataset/GT/GT_02.png', '/content/tmp/traindataset/GT/GT_10.png', '/content/tmp/traindataset/GT/GT_100.png', '/content/tmp/traindataset/GT/GT_101.png', '/content/tmp/traindataset/GT/GT_102.png', '/content/tmp/traindataset/GT/GT_11.png', '/content/tmp/traindataset/GT/GT_110.png', '/content/tmp/traindataset/GT/GT_111.png', '/content/tmp/traindataset/GT/GT_112.png', '/content/tmp/traindataset/GT/GT_12.png', '/content/tmp/traindataset/GT/GT_120.png', '/content/tmp/traindataset/GT/GT_121.png', '/content/tmp/traindataset/GT/GT_122.png', '/content/tmp/traindataset/GT/GT_130.png', '/content/tmp/traindataset/GT/GT_131.png', '/content/tmp/traindataset/GT/GT_132.png', '/content/tmp/traindataset/GT/GT_140.png', '/content/tmp/traindataset/GT/GT_141.png', '/content/tmp/traindataset/GT/GT_142.png', '/content/tmp/traindataset/GT/GT_150.png', '/content/tmp/traindataset/GT/GT_151.png', '/content/tmp/traindataset/GT/GT_152.png', '/content/tmp/traindataset/GT/GT_160.png', '/content/tmp/traindataset/GT/GT_161.png', '/content/tmp/traindataset/GT/GT_162.png', '/content/tmp/traindataset/GT/GT_170.png', '/content/tmp/traindataset/GT/GT_171.png', '/content/tmp/traindataset/GT/GT_172.png', '/content/tmp/traindataset/GT/GT_180.png', '/content/tmp/traindataset/GT/GT_181.png', '/content/tmp/traindataset/GT/GT_182.png', '/content/tmp/traindataset/GT/GT_190.png', '/content/tmp/traindataset/GT/GT_191.png', '/content/tmp/traindataset/GT/GT_192.png', '/content/tmp/traindataset/GT/GT_20.png', '/content/tmp/traindataset/GT/GT_200.png', '/content/tmp/traindataset/GT/GT_201.png', '/content/tmp/traindataset/GT/GT_202.png', '/content/tmp/traindataset/GT/GT_21.png', '/content/tmp/traindataset/GT/GT_210.png', '/content/tmp/traindataset/GT/GT_211.png', '/content/tmp/traindataset/GT/GT_212.png', '/content/tmp/traindataset/GT/GT_22.png', '/content/tmp/traindataset/GT/GT_220.png', '/content/tmp/traindataset/GT/GT_221.png', '/content/tmp/traindataset/GT/GT_222.png', '/content/tmp/traindataset/GT/GT_230.png', '/content/tmp/traindataset/GT/GT_231.png', '/content/tmp/traindataset/GT/GT_232.png', '/content/tmp/traindataset/GT/GT_240.png', '/content/tmp/traindataset/GT/GT_241.png', '/content/tmp/traindataset/GT/GT_242.png', '/content/tmp/traindataset/GT/GT_250.png', '/content/tmp/traindataset/GT/GT_251.png', '/content/tmp/traindataset/GT/GT_252.png', '/content/tmp/traindataset/GT/GT_260.png', '/content/tmp/traindataset/GT/GT_261.png', '/content/tmp/traindataset/GT/GT_262.png', '/content/tmp/traindataset/GT/GT_270.png', '/content/tmp/traindataset/GT/GT_271.png', '/content/tmp/traindataset/GT/GT_272.png', '/content/tmp/traindataset/GT/GT_280.png', '/content/tmp/traindataset/GT/GT_281.png', '/content/tmp/traindataset/GT/GT_282.png', '/content/tmp/traindataset/GT/GT_290.png', '/content/tmp/traindataset/GT/GT_291.png', '/content/tmp/traindataset/GT/GT_292.png', '/content/tmp/traindataset/GT/GT_30.png', '/content/tmp/traindataset/GT/GT_300.png', '/content/tmp/traindataset/GT/GT_301.png', '/content/tmp/traindataset/GT/GT_302.png', '/content/tmp/traindataset/GT/GT_31.png', '/content/tmp/traindataset/GT/GT_310.png', '/content/tmp/traindataset/GT/GT_311.png', '/content/tmp/traindataset/GT/GT_312.png', '/content/tmp/traindataset/GT/GT_32.png', '/content/tmp/traindataset/GT/GT_320.png', '/content/tmp/traindataset/GT/GT_321.png', '/content/tmp/traindataset/GT/GT_322.png', '/content/tmp/traindataset/GT/GT_330.png', '/content/tmp/traindataset/GT/GT_331.png', '/content/tmp/traindataset/GT/GT_332.png', '/content/tmp/traindataset/GT/GT_340.png', '/content/tmp/traindataset/GT/GT_341.png', '/content/tmp/traindataset/GT/GT_342.png', '/content/tmp/traindataset/GT/GT_350.png', '/content/tmp/traindataset/GT/GT_351.png', '/content/tmp/traindataset/GT/GT_352.png', '/content/tmp/traindataset/GT/GT_360.png', '/content/tmp/traindataset/GT/GT_361.png', '/content/tmp/traindataset/GT/GT_362.png', '/content/tmp/traindataset/GT/GT_370.png', '/content/tmp/traindataset/GT/GT_371.png', '/content/tmp/traindataset/GT/GT_372.png', '/content/tmp/traindataset/GT/GT_380.png', '/content/tmp/traindataset/GT/GT_381.png', '/content/tmp/traindataset/GT/GT_382.png', '/content/tmp/traindataset/GT/GT_390.png', '/content/tmp/traindataset/GT/GT_391.png', '/content/tmp/traindataset/GT/GT_392.png', '/content/tmp/traindataset/GT/GT_40.png', '/content/tmp/traindataset/GT/GT_400.png', '/content/tmp/traindataset/GT/GT_401.png', '/content/tmp/traindataset/GT/GT_402.png', '/content/tmp/traindataset/GT/GT_41.png', '/content/tmp/traindataset/GT/GT_410.png', '/content/tmp/traindataset/GT/GT_411.png', '/content/tmp/traindataset/GT/GT_412.png', '/content/tmp/traindataset/GT/GT_42.png', '/content/tmp/traindataset/GT/GT_420.png', '/content/tmp/traindataset/GT/GT_421.png', '/content/tmp/traindataset/GT/GT_422.png', '/content/tmp/traindataset/GT/GT_430.png', '/content/tmp/traindataset/GT/GT_431.png', '/content/tmp/traindataset/GT/GT_432.png', '/content/tmp/traindataset/GT/GT_440.png', '/content/tmp/traindataset/GT/GT_441.png', '/content/tmp/traindataset/GT/GT_442.png', '/content/tmp/traindataset/GT/GT_450.png', '/content/tmp/traindataset/GT/GT_451.png', '/content/tmp/traindataset/GT/GT_452.png', '/content/tmp/traindataset/GT/GT_460.png', '/content/tmp/traindataset/GT/GT_461.png', '/content/tmp/traindataset/GT/GT_462.png', '/content/tmp/traindataset/GT/GT_470.png', '/content/tmp/traindataset/GT/GT_471.png', '/content/tmp/traindataset/GT/GT_472.png', '/content/tmp/traindataset/GT/GT_480.png', '/content/tmp/traindataset/GT/GT_481.png', '/content/tmp/traindataset/GT/GT_482.png', '/content/tmp/traindataset/GT/GT_490.png', '/content/tmp/traindataset/GT/GT_491.png', '/content/tmp/traindataset/GT/GT_492.png', '/content/tmp/traindataset/GT/GT_50.png', '/content/tmp/traindataset/GT/GT_500.png', '/content/tmp/traindataset/GT/GT_501.png', '/content/tmp/traindataset/GT/GT_502.png', '/content/tmp/traindataset/GT/GT_51.png', '/content/tmp/traindataset/GT/GT_510.png', '/content/tmp/traindataset/GT/GT_511.png', '/content/tmp/traindataset/GT/GT_512.png', '/content/tmp/traindataset/GT/GT_52.png', '/content/tmp/traindataset/GT/GT_520.png', '/content/tmp/traindataset/GT/GT_521.png', '/content/tmp/traindataset/GT/GT_522.png', '/content/tmp/traindataset/GT/GT_530.png', '/content/tmp/traindataset/GT/GT_531.png', '/content/tmp/traindataset/GT/GT_532.png', '/content/tmp/traindataset/GT/GT_540.png', '/content/tmp/traindataset/GT/GT_541.png', '/content/tmp/traindataset/GT/GT_542.png', '/content/tmp/traindataset/GT/GT_550.png', '/content/tmp/traindataset/GT/GT_551.png', '/content/tmp/traindataset/GT/GT_552.png', '/content/tmp/traindataset/GT/GT_560.png', '/content/tmp/traindataset/GT/GT_561.png', '/content/tmp/traindataset/GT/GT_562.png', '/content/tmp/traindataset/GT/GT_570.png', '/content/tmp/traindataset/GT/GT_571.png', '/content/tmp/traindataset/GT/GT_572.png', '/content/tmp/traindataset/GT/GT_580.png', '/content/tmp/traindataset/GT/GT_581.png', '/content/tmp/traindataset/GT/GT_582.png', '/content/tmp/traindataset/GT/GT_590.png', '/content/tmp/traindataset/GT/GT_591.png', '/content/tmp/traindataset/GT/GT_592.png', '/content/tmp/traindataset/GT/GT_60.png', '/content/tmp/traindataset/GT/GT_600.png', '/content/tmp/traindataset/GT/GT_601.png', '/content/tmp/traindataset/GT/GT_602.png', '/content/tmp/traindataset/GT/GT_61.png', '/content/tmp/traindataset/GT/GT_610.png', '/content/tmp/traindataset/GT/GT_611.png', '/content/tmp/traindataset/GT/GT_612.png', '/content/tmp/traindataset/GT/GT_62.png', '/content/tmp/traindataset/GT/GT_620.png', '/content/tmp/traindataset/GT/GT_621.png', '/content/tmp/traindataset/GT/GT_622.png', '/content/tmp/traindataset/GT/GT_630.png', '/content/tmp/traindataset/GT/GT_631.png', '/content/tmp/traindataset/GT/GT_632.png', '/content/tmp/traindataset/GT/GT_640.png', '/content/tmp/traindataset/GT/GT_641.png', '/content/tmp/traindataset/GT/GT_642.png', '/content/tmp/traindataset/GT/GT_650.png', '/content/tmp/traindataset/GT/GT_651.png', '/content/tmp/traindataset/GT/GT_652.png', '/content/tmp/traindataset/GT/GT_660.png', '/content/tmp/traindataset/GT/GT_661.png', '/content/tmp/traindataset/GT/GT_662.png', '/content/tmp/traindataset/GT/GT_670.png', '/content/tmp/traindataset/GT/GT_671.png', '/content/tmp/traindataset/GT/GT_672.png', '/content/tmp/traindataset/GT/GT_680.png', '/content/tmp/traindataset/GT/GT_681.png', '/content/tmp/traindataset/GT/GT_682.png', '/content/tmp/traindataset/GT/GT_690.png', '/content/tmp/traindataset/GT/GT_691.png', '/content/tmp/traindataset/GT/GT_692.png', '/content/tmp/traindataset/GT/GT_70.png', '/content/tmp/traindataset/GT/GT_700.png', '/content/tmp/traindataset/GT/GT_701.png', '/content/tmp/traindataset/GT/GT_702.png', '/content/tmp/traindataset/GT/GT_71.png', '/content/tmp/traindataset/GT/GT_710.png', '/content/tmp/traindataset/GT/GT_711.png', '/content/tmp/traindataset/GT/GT_712.png', '/content/tmp/traindataset/GT/GT_72.png', '/content/tmp/traindataset/GT/GT_720.png', '/content/tmp/traindataset/GT/GT_721.png', '/content/tmp/traindataset/GT/GT_722.png', '/content/tmp/traindataset/GT/GT_730.png', '/content/tmp/traindataset/GT/GT_731.png', '/content/tmp/traindataset/GT/GT_732.png', '/content/tmp/traindataset/GT/GT_740.png', '/content/tmp/traindataset/GT/GT_741.png', '/content/tmp/traindataset/GT/GT_742.png', '/content/tmp/traindataset/GT/GT_750.png', '/content/tmp/traindataset/GT/GT_751.png', '/content/tmp/traindataset/GT/GT_752.png', '/content/tmp/traindataset/GT/GT_760.png', '/content/tmp/traindataset/GT/GT_761.png', '/content/tmp/traindataset/GT/GT_762.png', '/content/tmp/traindataset/GT/GT_770.png', '/content/tmp/traindataset/GT/GT_771.png', '/content/tmp/traindataset/GT/GT_772.png', '/content/tmp/traindataset/GT/GT_780.png', '/content/tmp/traindataset/GT/GT_781.png', '/content/tmp/traindataset/GT/GT_782.png', '/content/tmp/traindataset/GT/GT_790.png', '/content/tmp/traindataset/GT/GT_791.png', '/content/tmp/traindataset/GT/GT_792.png', '/content/tmp/traindataset/GT/GT_80.png', '/content/tmp/traindataset/GT/GT_81.png', '/content/tmp/traindataset/GT/GT_82.png', '/content/tmp/traindataset/GT/GT_90.png', '/content/tmp/traindataset/GT/GT_91.png', '/content/tmp/traindataset/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7f9737fc9ed0>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start train...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-02 10:31:55.243932 Epoch [001/250], Step [0001/0060], Loss1: 5.3920 Loss2: 2.2832 Loss3: 1.5002\n",
            "2022-08-02 10:32:20.373705 Epoch [001/250], Step [0050/0060], Loss1: 1.4177 Loss2: 0.6010 Loss3: -0.0688\n",
            "2022-08-02 10:32:25.548090 Epoch [001/250], Step [0060/0060], Loss1: 1.3712 Loss2: 0.5511 Loss3: -0.0547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 MAE: 0.18369101731234752 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-08-02 10:32:34.175307 Epoch [002/250], Step [0001/0060], Loss1: 1.3635 Loss2: 0.4540 Loss3: -0.2539\n",
            "2022-08-02 10:32:59.327656 Epoch [002/250], Step [0050/0060], Loss1: 1.1513 Loss2: 0.2352 Loss3: -0.3590\n",
            "2022-08-02 10:33:04.444657 Epoch [002/250], Step [0060/0060], Loss1: 1.1052 Loss2: 0.0884 Loss3: -0.6304\n",
            "Epoch: 2 MAE: 0.32698941387196695 ####  bestMAE: 0.18369101731234752 bestEpoch: 0\n",
            "2022-08-02 10:33:09.452566 Epoch [003/250], Step [0001/0060], Loss1: 1.1222 Loss2: 0.1984 Loss3: -0.4147\n",
            "2022-08-02 10:33:34.580621 Epoch [003/250], Step [0050/0060], Loss1: 0.9592 Loss2: 0.0347 Loss3: -0.3067\n",
            "2022-08-02 10:33:39.730632 Epoch [003/250], Step [0060/0060], Loss1: 0.8650 Loss2: -0.0555 Loss3: -0.4718\n",
            "Epoch: 3 MAE: 0.2410830581503571 ####  bestMAE: 0.18369101731234752 bestEpoch: 0\n",
            "2022-08-02 10:33:44.820725 Epoch [004/250], Step [0001/0060], Loss1: 0.8866 Loss2: -0.0150 Loss3: -0.4062\n",
            "2022-08-02 10:34:10.029975 Epoch [004/250], Step [0050/0060], Loss1: 0.6171 Loss2: -0.3355 Loss3: -0.8401\n",
            "2022-08-02 10:34:15.182081 Epoch [004/250], Step [0060/0060], Loss1: 0.6618 Loss2: -0.1543 Loss3: -0.5706\n",
            "Epoch: 4 MAE: 0.2869258137859364 ####  bestMAE: 0.18369101731234752 bestEpoch: 0\n",
            "2022-08-02 10:34:20.237213 Epoch [005/250], Step [0001/0060], Loss1: 0.6880 Loss2: -0.2272 Loss3: -0.6554\n",
            "2022-08-02 10:34:45.282050 Epoch [005/250], Step [0050/0060], Loss1: 0.5215 Loss2: -0.2338 Loss3: -0.6470\n",
            "2022-08-02 10:34:50.394794 Epoch [005/250], Step [0060/0060], Loss1: 0.4126 Loss2: -0.0499 Loss3: -0.4187\n",
            "Epoch: 5 MAE: 0.14971622103736518 ####  bestMAE: 0.18369101731234752 bestEpoch: 0\n",
            "best epoch:5\n",
            "2022-08-02 10:34:59.883039 Epoch [006/250], Step [0001/0060], Loss1: 0.4763 Loss2: -0.0293 Loss3: -0.0909\n",
            "2022-08-02 10:35:25.267342 Epoch [006/250], Step [0050/0060], Loss1: 0.3059 Loss2: -0.3556 Loss3: -0.7378\n",
            "2022-08-02 10:35:30.400010 Epoch [006/250], Step [0060/0060], Loss1: 0.3235 Loss2: -0.3541 Loss3: -0.7136\n",
            "Epoch: 6 MAE: 0.2628672532177478 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:35:35.531432 Epoch [007/250], Step [0001/0060], Loss1: 0.2290 Loss2: -0.3983 Loss3: -0.7298\n",
            "2022-08-02 10:36:00.677441 Epoch [007/250], Step [0050/0060], Loss1: 0.1849 Loss2: -0.5234 Loss3: -0.8175\n",
            "2022-08-02 10:36:05.777021 Epoch [007/250], Step [0060/0060], Loss1: 0.1885 Loss2: -0.6186 Loss3: -0.8302\n",
            "Epoch: 7 MAE: 0.2899831297536376 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:36:10.996497 Epoch [008/250], Step [0001/0060], Loss1: 0.0630 Loss2: -0.8535 Loss3: -1.0767\n",
            "2022-08-02 10:36:36.148010 Epoch [008/250], Step [0050/0060], Loss1: 0.0179 Loss2: 0.0602 Loss3: -1.0428\n",
            "2022-08-02 10:36:41.289634 Epoch [008/250], Step [0060/0060], Loss1: -0.0242 Loss2: -0.1880 Loss3: -1.1072\n",
            "Epoch: 8 MAE: 0.3052186992181042 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:36:46.438711 Epoch [009/250], Step [0001/0060], Loss1: 0.1468 Loss2: 0.0538 Loss3: -0.8201\n",
            "2022-08-02 10:37:11.613129 Epoch [009/250], Step [0050/0060], Loss1: -0.0068 Loss2: -0.2973 Loss3: -0.9670\n",
            "2022-08-02 10:37:16.735836 Epoch [009/250], Step [0060/0060], Loss1: -0.0313 Loss2: -0.4763 Loss3: -1.1341\n",
            "Epoch: 9 MAE: 0.351277098882766 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:37:21.916132 Epoch [010/250], Step [0001/0060], Loss1: -0.0421 Loss2: -0.4251 Loss3: -1.0571\n",
            "2022-08-02 10:37:47.101884 Epoch [010/250], Step [0050/0060], Loss1: 0.0315 Loss2: -0.1479 Loss3: -0.7128\n",
            "2022-08-02 10:37:52.220743 Epoch [010/250], Step [0060/0060], Loss1: 0.2025 Loss2: -0.0299 Loss3: -0.3473\n",
            "Epoch: 10 MAE: 0.4376380722611038 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:37:59.564045 Epoch [011/250], Step [0001/0060], Loss1: 0.1954 Loss2: -0.1378 Loss3: -0.6701\n",
            "2022-08-02 10:38:24.849080 Epoch [011/250], Step [0050/0060], Loss1: 0.1233 Loss2: -0.3975 Loss3: 0.3595\n",
            "2022-08-02 10:38:30.032905 Epoch [011/250], Step [0060/0060], Loss1: 0.0342 Loss2: -0.5088 Loss3: -4.2267\n",
            "Epoch: 11 MAE: 0.41231294864069223 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:38:35.254903 Epoch [012/250], Step [0001/0060], Loss1: 0.2964 Loss2: -0.5032 Loss3: -0.5502\n",
            "2022-08-02 10:39:00.499122 Epoch [012/250], Step [0050/0060], Loss1: -0.2303 Loss2: -0.7906 Loss3: -0.8753\n",
            "2022-08-02 10:39:05.667892 Epoch [012/250], Step [0060/0060], Loss1: -0.1596 Loss2: -0.6656 Loss3: -0.7855\n",
            "Epoch: 12 MAE: 0.37488286053692843 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:39:10.899904 Epoch [013/250], Step [0001/0060], Loss1: 0.1079 Loss2: -0.3655 Loss3: -0.4258\n",
            "2022-08-02 10:39:36.114123 Epoch [013/250], Step [0050/0060], Loss1: -0.2594 Loss2: -0.8393 Loss3: -1.0754\n",
            "2022-08-02 10:39:41.228351 Epoch [013/250], Step [0060/0060], Loss1: -0.3256 Loss2: -0.9411 Loss3: -1.2027\n",
            "Epoch: 13 MAE: 0.34870982296252384 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:39:46.505654 Epoch [014/250], Step [0001/0060], Loss1: -0.1780 Loss2: -0.7245 Loss3: -0.9505\n",
            "2022-08-02 10:40:11.679086 Epoch [014/250], Step [0050/0060], Loss1: -0.2885 Loss2: -0.8321 Loss3: -1.1169\n",
            "2022-08-02 10:40:16.813685 Epoch [014/250], Step [0060/0060], Loss1: -0.2605 Loss2: -0.8092 Loss3: -1.0670\n",
            "Epoch: 14 MAE: 0.3562985193161738 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:40:22.119994 Epoch [015/250], Step [0001/0060], Loss1: -0.3272 Loss2: -0.9041 Loss3: -1.1964\n",
            "2022-08-02 10:40:47.249957 Epoch [015/250], Step [0050/0060], Loss1: -0.3075 Loss2: -0.8891 Loss3: -1.1891\n",
            "2022-08-02 10:40:52.349371 Epoch [015/250], Step [0060/0060], Loss1: -0.5070 Loss2: -1.1645 Loss3: -1.4832\n",
            "Epoch: 15 MAE: 0.33850615122961614 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:40:59.452050 Epoch [016/250], Step [0001/0060], Loss1: -0.5104 Loss2: -1.1413 Loss3: -1.4921\n",
            "2022-08-02 10:41:24.534336 Epoch [016/250], Step [0050/0060], Loss1: -0.4963 Loss2: -1.1226 Loss3: -1.4534\n",
            "2022-08-02 10:41:29.676895 Epoch [016/250], Step [0060/0060], Loss1: -0.3464 Loss2: -0.9110 Loss3: -1.1879\n",
            "Epoch: 16 MAE: 0.301043130380136 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:41:34.853332 Epoch [017/250], Step [0001/0060], Loss1: -0.5905 Loss2: -1.2868 Loss3: -1.6170\n",
            "2022-08-02 10:42:00.028557 Epoch [017/250], Step [0050/0060], Loss1: -0.7834 Loss2: -0.8816 Loss3: -1.9059\n",
            "2022-08-02 10:42:05.169061 Epoch [017/250], Step [0060/0060], Loss1: -0.6589 Loss2: -0.2991 Loss3: -1.7171\n",
            "Epoch: 17 MAE: 0.469965491723762 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:42:10.296694 Epoch [018/250], Step [0001/0060], Loss1: -0.6711 Loss2: -0.7979 Loss3: -1.7180\n",
            "2022-08-02 10:42:35.356525 Epoch [018/250], Step [0050/0060], Loss1: -0.8930 Loss2: -0.9038 Loss3: -2.0602\n",
            "2022-08-02 10:42:40.476599 Epoch [018/250], Step [0060/0060], Loss1: -0.5957 Loss2: -0.6537 Loss3: -1.5421\n",
            "Epoch: 18 MAE: 0.3434263417077442 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:42:45.679135 Epoch [019/250], Step [0001/0060], Loss1: -0.6529 Loss2: -0.6609 Loss3: -1.6696\n",
            "2022-08-02 10:43:10.736689 Epoch [019/250], Step [0050/0060], Loss1: -0.8694 Loss2: -1.1441 Loss3: -1.9612\n",
            "2022-08-02 10:43:15.832064 Epoch [019/250], Step [0060/0060], Loss1: -0.7947 Loss2: -0.6734 Loss3: -1.8726\n",
            "Epoch: 19 MAE: 0.3507392681464947 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:43:20.934203 Epoch [020/250], Step [0001/0060], Loss1: -0.5324 Loss2: -0.5876 Loss3: -1.4567\n",
            "2022-08-02 10:43:46.021732 Epoch [020/250], Step [0050/0060], Loss1: -0.6184 Loss2: -0.5901 Loss3: -1.5724\n",
            "2022-08-02 10:43:51.176329 Epoch [020/250], Step [0060/0060], Loss1: -0.8026 Loss2: -0.4060 Loss3: -1.8175\n",
            "Epoch: 20 MAE: 0.3305774708904286 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:43:58.345922 Epoch [021/250], Step [0001/0060], Loss1: -0.9154 Loss2: -0.6767 Loss3: -2.0578\n",
            "2022-08-02 10:44:23.524330 Epoch [021/250], Step [0050/0060], Loss1: -0.6609 Loss2: -0.7085 Loss3: -1.6469\n",
            "2022-08-02 10:44:28.628494 Epoch [021/250], Step [0060/0060], Loss1: -0.8496 Loss2: -0.8328 Loss3: -1.9047\n",
            "Epoch: 21 MAE: 0.3307335303574011 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:44:33.752209 Epoch [022/250], Step [0001/0060], Loss1: -0.9717 Loss2: -1.0241 Loss3: -2.2041\n",
            "2022-08-02 10:44:58.839521 Epoch [022/250], Step [0050/0060], Loss1: -0.8892 Loss2: -1.0394 Loss3: -1.9431\n",
            "2022-08-02 10:45:03.959115 Epoch [022/250], Step [0060/0060], Loss1: -1.0966 Loss2: -1.3330 Loss3: -2.3180\n",
            "Epoch: 22 MAE: 0.346217631183604 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:45:09.097032 Epoch [023/250], Step [0001/0060], Loss1: -1.0134 Loss2: -1.2286 Loss3: -2.1456\n",
            "2022-08-02 10:45:34.186738 Epoch [023/250], Step [0050/0060], Loss1: -1.3858 Loss2: -1.7335 Loss3: -2.8438\n",
            "2022-08-02 10:45:39.347997 Epoch [023/250], Step [0060/0060], Loss1: -1.2231 Loss2: -1.5154 Loss3: -2.4323\n",
            "Epoch: 23 MAE: 0.3791979605054098 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:45:44.572967 Epoch [024/250], Step [0001/0060], Loss1: -1.3735 Loss2: -1.6724 Loss3: -2.6879\n",
            "2022-08-02 10:46:09.614896 Epoch [024/250], Step [0050/0060], Loss1: -1.3559 Loss2: -1.7313 Loss3: -2.6916\n",
            "2022-08-02 10:46:14.725995 Epoch [024/250], Step [0060/0060], Loss1: -1.3243 Loss2: -1.6660 Loss3: -2.6111\n",
            "Epoch: 24 MAE: 0.37504442043405367 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:46:19.925850 Epoch [025/250], Step [0001/0060], Loss1: -1.4126 Loss2: -1.7552 Loss3: -2.7110\n",
            "2022-08-02 10:46:45.210373 Epoch [025/250], Step [0050/0060], Loss1: -1.4807 Loss2: -1.8676 Loss3: -2.7961\n",
            "2022-08-02 10:46:50.306420 Epoch [025/250], Step [0060/0060], Loss1: -1.1632 Loss2: -1.4695 Loss3: -2.2777\n",
            "Epoch: 25 MAE: 0.4137740769966571 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:46:57.770027 Epoch [026/250], Step [0001/0060], Loss1: -1.3010 Loss2: -1.7214 Loss3: -2.6354\n",
            "2022-08-02 10:47:22.963369 Epoch [026/250], Step [0050/0060], Loss1: -1.2677 Loss2: -1.6788 Loss3: -2.5418\n",
            "2022-08-02 10:47:28.079363 Epoch [026/250], Step [0060/0060], Loss1: -1.2787 Loss2: -1.6320 Loss3: -2.4784\n",
            "Epoch: 26 MAE: 0.4170957224205058 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:47:33.302130 Epoch [027/250], Step [0001/0060], Loss1: -1.2921 Loss2: -1.6717 Loss3: -2.5294\n",
            "2022-08-02 10:47:58.430536 Epoch [027/250], Step [0050/0060], Loss1: -1.4669 Loss2: -1.8186 Loss3: -2.7718\n",
            "2022-08-02 10:48:03.633334 Epoch [027/250], Step [0060/0060], Loss1: -1.1065 Loss2: -1.4085 Loss3: -2.1812\n",
            "Epoch: 27 MAE: 0.4161619709156177 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:48:08.757710 Epoch [028/250], Step [0001/0060], Loss1: -1.2321 Loss2: -1.5884 Loss3: -2.4088\n",
            "2022-08-02 10:48:33.977038 Epoch [028/250], Step [0050/0060], Loss1: -1.1096 Loss2: -1.4264 Loss3: -2.1887\n",
            "2022-08-02 10:48:39.110715 Epoch [028/250], Step [0060/0060], Loss1: -1.4324 Loss2: -1.8575 Loss3: -2.7258\n",
            "Epoch: 28 MAE: 0.423589838421534 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:48:44.305954 Epoch [029/250], Step [0001/0060], Loss1: -1.4659 Loss2: -1.8405 Loss3: -2.7490\n",
            "2022-08-02 10:49:09.442321 Epoch [029/250], Step [0050/0060], Loss1: -1.3416 Loss2: -1.7474 Loss3: -2.5798\n",
            "2022-08-02 10:49:14.559282 Epoch [029/250], Step [0060/0060], Loss1: -2.1514 Loss2: -2.6643 Loss3: -3.8311\n",
            "Epoch: 29 MAE: 0.42964330118169236 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:49:19.742901 Epoch [030/250], Step [0001/0060], Loss1: -1.4936 Loss2: -1.8691 Loss3: -2.7964\n",
            "2022-08-02 10:49:44.846042 Epoch [030/250], Step [0050/0060], Loss1: -1.6419 Loss2: -2.0800 Loss3: -3.0307\n",
            "2022-08-02 10:49:50.024744 Epoch [030/250], Step [0060/0060], Loss1: -1.9791 Loss2: -2.4842 Loss3: -3.5756\n",
            "Epoch: 30 MAE: 0.4338050660632908 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:49:57.298302 Epoch [031/250], Step [0001/0060], Loss1: -1.6912 Loss2: -2.1306 Loss3: -3.1401\n",
            "2022-08-02 10:50:22.626846 Epoch [031/250], Step [0050/0060], Loss1: -2.1026 Loss2: -2.6023 Loss3: -3.7485\n",
            "2022-08-02 10:50:27.802291 Epoch [031/250], Step [0060/0060], Loss1: -1.7065 Loss2: -2.1265 Loss3: -3.1053\n",
            "Epoch: 31 MAE: 0.424407725258479 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:50:33.014337 Epoch [032/250], Step [0001/0060], Loss1: -2.2103 Loss2: -2.7037 Loss3: -3.8668\n",
            "2022-08-02 10:50:58.270030 Epoch [032/250], Step [0050/0060], Loss1: -1.0447 Loss2: -2.7468 Loss3: -2.8101\n",
            "2022-08-02 10:51:03.385372 Epoch [032/250], Step [0060/0060], Loss1: -0.6814 Loss2: -1.8118 Loss3: -2.0153\n",
            "Epoch: 32 MAE: 0.450169919937376 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:51:08.645379 Epoch [033/250], Step [0001/0060], Loss1: -1.1902 Loss2: -2.3294 Loss3: -2.8410\n",
            "2022-08-02 10:51:33.778052 Epoch [033/250], Step [0050/0060], Loss1: -1.3889 Loss2: -2.2853 Loss3: 0.0581\n",
            "2022-08-02 10:51:38.946950 Epoch [033/250], Step [0060/0060], Loss1: -1.4196 Loss2: -2.1862 Loss3: -0.3130\n",
            "Epoch: 33 MAE: 0.43436946525775577 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:51:44.198637 Epoch [034/250], Step [0001/0060], Loss1: -1.5777 Loss2: -2.5063 Loss3: -0.7373\n",
            "2022-08-02 10:52:09.335967 Epoch [034/250], Step [0050/0060], Loss1: -2.0021 Loss2: -2.7620 Loss3: -2.9678\n",
            "2022-08-02 10:52:14.485194 Epoch [034/250], Step [0060/0060], Loss1: -1.5912 Loss2: -2.1916 Loss3: -2.6025\n",
            "Epoch: 34 MAE: 0.35555285216639276 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:52:19.701846 Epoch [035/250], Step [0001/0060], Loss1: -1.9463 Loss2: -2.7245 Loss3: -3.1300\n",
            "2022-08-02 10:52:44.887311 Epoch [035/250], Step [0050/0060], Loss1: -1.8313 Loss2: -2.7221 Loss3: -2.8744\n",
            "2022-08-02 10:52:50.070881 Epoch [035/250], Step [0060/0060], Loss1: -1.6113 Loss2: -2.2172 Loss3: -2.4950\n",
            "Epoch: 35 MAE: 0.4699112568204364 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:52:57.267180 Epoch [036/250], Step [0001/0060], Loss1: -1.7136 Loss2: -2.3241 Loss3: -2.2046\n",
            "2022-08-02 10:53:22.501247 Epoch [036/250], Step [0050/0060], Loss1: -1.5868 Loss2: -2.2678 Loss3: -2.0241\n",
            "2022-08-02 10:53:27.619044 Epoch [036/250], Step [0060/0060], Loss1: -2.0274 Loss2: -2.9029 Loss3: -2.3848\n",
            "Epoch: 36 MAE: 0.5453715603944487 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:53:32.773392 Epoch [037/250], Step [0001/0060], Loss1: -2.2320 Loss2: -3.0505 Loss3: -2.3742\n",
            "2022-08-02 10:53:58.013274 Epoch [037/250], Step [0050/0060], Loss1: -2.2148 Loss2: -2.9491 Loss3: -2.4210\n",
            "2022-08-02 10:54:03.132111 Epoch [037/250], Step [0060/0060], Loss1: -2.2501 Loss2: -3.0304 Loss3: -2.4983\n",
            "Epoch: 37 MAE: 0.5185324419617022 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:54:08.315186 Epoch [038/250], Step [0001/0060], Loss1: -1.7715 Loss2: -2.5234 Loss3: -2.1337\n",
            "2022-08-02 10:54:33.536006 Epoch [038/250], Step [0050/0060], Loss1: -2.0840 Loss2: -2.8054 Loss3: -2.3996\n",
            "2022-08-02 10:54:38.652854 Epoch [038/250], Step [0060/0060], Loss1: -2.5244 Loss2: -3.1962 Loss3: -2.7539\n",
            "Epoch: 38 MAE: 0.5211619091538526 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:54:43.903531 Epoch [039/250], Step [0001/0060], Loss1: -2.5006 Loss2: -3.2267 Loss3: -2.8061\n",
            "2022-08-02 10:55:09.079520 Epoch [039/250], Step [0050/0060], Loss1: -2.4035 Loss2: -3.0944 Loss3: -2.7890\n",
            "2022-08-02 10:55:14.205803 Epoch [039/250], Step [0060/0060], Loss1: -1.9215 Loss2: -2.6172 Loss3: -2.3726\n",
            "Epoch: 39 MAE: 0.5279124927016162 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:55:19.362386 Epoch [040/250], Step [0001/0060], Loss1: -2.4200 Loss2: -3.0826 Loss3: -2.7425\n",
            "2022-08-02 10:55:44.602534 Epoch [040/250], Step [0050/0060], Loss1: -3.3091 Loss2: -4.0103 Loss3: -3.5443\n",
            "2022-08-02 10:55:49.732600 Epoch [040/250], Step [0060/0060], Loss1: -2.6972 Loss2: -3.3343 Loss3: -2.9865\n",
            "Epoch: 40 MAE: 0.5327406012318122 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:55:56.933941 Epoch [041/250], Step [0001/0060], Loss1: -2.7120 Loss2: -3.3596 Loss3: -2.9191\n",
            "2022-08-02 10:56:22.176880 Epoch [041/250], Step [0050/0060], Loss1: 0.9711 Loss2: -3.7089 Loss3: -3.2657\n",
            "2022-08-02 10:56:27.298783 Epoch [041/250], Step [0060/0060], Loss1: 0.6115 Loss2: -2.4170 Loss3: -2.2136\n",
            "Epoch: 41 MAE: 0.5695775890854929 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:56:32.538365 Epoch [042/250], Step [0001/0060], Loss1: 0.7555 Loss2: -3.3532 Loss3: -3.0658\n",
            "2022-08-02 10:56:57.746402 Epoch [042/250], Step [0050/0060], Loss1: -1.1077 Loss2: -3.4063 Loss3: -3.1574\n",
            "2022-08-02 10:57:02.902541 Epoch [042/250], Step [0060/0060], Loss1: -1.6661 Loss2: -3.9040 Loss3: -3.6246\n",
            "Epoch: 42 MAE: 0.5594683062841022 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:57:08.156965 Epoch [043/250], Step [0001/0060], Loss1: -1.0940 Loss2: -3.0768 Loss3: -2.8607\n",
            "2022-08-02 10:57:33.278208 Epoch [043/250], Step [0050/0060], Loss1: -2.3545 Loss2: -1.8177 Loss3: -3.2556\n",
            "2022-08-02 10:57:38.421720 Epoch [043/250], Step [0060/0060], Loss1: -2.1592 Loss2: -1.7664 Loss3: -3.0574\n",
            "Epoch: 43 MAE: 0.5708927021329366 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:57:43.706077 Epoch [044/250], Step [0001/0060], Loss1: -2.1177 Loss2: -1.7615 Loss3: -2.9782\n",
            "2022-08-02 10:58:08.836413 Epoch [044/250], Step [0050/0060], Loss1: -2.3376 Loss2: -1.7772 Loss3: -3.1675\n",
            "2022-08-02 10:58:13.947646 Epoch [044/250], Step [0060/0060], Loss1: -2.7021 Loss2: -2.0465 Loss3: -3.5821\n",
            "Epoch: 44 MAE: 0.5701884218246216 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:58:19.099489 Epoch [045/250], Step [0001/0060], Loss1: -2.9496 Loss2: -2.1647 Loss3: -3.8320\n",
            "2022-08-02 10:58:44.293028 Epoch [045/250], Step [0050/0060], Loss1: -2.5747 Loss2: -2.2992 Loss3: -3.4255\n",
            "2022-08-02 10:58:49.456710 Epoch [045/250], Step [0060/0060], Loss1: -2.6876 Loss2: -2.4187 Loss3: -3.5396\n",
            "Epoch: 45 MAE: 0.5687726072281126 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:58:56.852895 Epoch [046/250], Step [0001/0060], Loss1: -2.7174 Loss2: -2.4629 Loss3: -3.5320\n",
            "2022-08-02 10:59:22.136894 Epoch [046/250], Step [0050/0060], Loss1: -1.9249 Loss2: -1.8893 Loss3: -2.7344\n",
            "2022-08-02 10:59:27.220861 Epoch [046/250], Step [0060/0060], Loss1: -2.8536 Loss2: -2.6515 Loss3: -3.7392\n",
            "Epoch: 46 MAE: 0.565636791249432 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 10:59:32.403298 Epoch [047/250], Step [0001/0060], Loss1: -2.0029 Loss2: -1.9443 Loss3: -2.7726\n",
            "2022-08-02 10:59:57.564398 Epoch [047/250], Step [0050/0060], Loss1: -3.4739 Loss2: -3.1777 Loss3: -4.4078\n",
            "2022-08-02 11:00:02.684493 Epoch [047/250], Step [0060/0060], Loss1: -2.5065 Loss2: -2.4019 Loss3: -3.3251\n",
            "Epoch: 47 MAE: 0.5620564786719265 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:00:07.878316 Epoch [048/250], Step [0001/0060], Loss1: -3.3588 Loss2: -3.0969 Loss3: -4.2362\n",
            "2022-08-02 11:00:33.071634 Epoch [048/250], Step [0050/0060], Loss1: -3.4004 Loss2: -3.1442 Loss3: -4.3160\n",
            "2022-08-02 11:00:38.189670 Epoch [048/250], Step [0060/0060], Loss1: -3.6069 Loss2: -3.3301 Loss3: -4.5395\n",
            "Epoch: 48 MAE: 0.5532451569087925 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:00:43.372567 Epoch [049/250], Step [0001/0060], Loss1: -3.4593 Loss2: -3.2371 Loss3: -4.4092\n",
            "2022-08-02 11:01:08.551522 Epoch [049/250], Step [0050/0060], Loss1: -3.3287 Loss2: -3.1499 Loss3: -4.3082\n",
            "2022-08-02 11:01:13.660040 Epoch [049/250], Step [0060/0060], Loss1: -3.2909 Loss2: -3.1038 Loss3: -4.2510\n",
            "Epoch: 49 MAE: 0.5516135676954158 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:01:18.756477 Epoch [050/250], Step [0001/0060], Loss1: -2.5437 Loss2: -2.4338 Loss3: -3.3830\n",
            "2022-08-02 11:01:43.889364 Epoch [050/250], Step [0050/0060], Loss1: -3.3212 Loss2: -3.1013 Loss3: -4.2576\n",
            "2022-08-02 11:01:49.016779 Epoch [050/250], Step [0060/0060], Loss1: -2.9273 Loss2: -2.7704 Loss3: -3.8147\n",
            "Epoch: 50 MAE: 0.5413026444369522 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:01:56.919447 Epoch [051/250], Step [0001/0060], Loss1: -3.1268 Loss2: -2.9345 Loss3: -4.0502\n",
            "2022-08-02 11:02:22.357063 Epoch [051/250], Step [0050/0060], Loss1: -2.9746 Loss2: -2.7838 Loss3: -3.8622\n",
            "2022-08-02 11:02:27.527780 Epoch [051/250], Step [0060/0060], Loss1: -3.4182 Loss2: -3.1916 Loss3: -4.3898\n",
            "Epoch: 51 MAE: 0.5514817414460359 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:02:32.709437 Epoch [052/250], Step [0001/0060], Loss1: -3.8392 Loss2: -3.5796 Loss3: -4.8805\n",
            "2022-08-02 11:02:57.863811 Epoch [052/250], Step [0050/0060], Loss1: -3.3963 Loss2: -3.1552 Loss3: -4.3255\n",
            "2022-08-02 11:03:02.992183 Epoch [052/250], Step [0060/0060], Loss1: -3.9805 Loss2: -3.6992 Loss3: -5.0640\n",
            "Epoch: 52 MAE: 0.543573213607546 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:03:08.187781 Epoch [053/250], Step [0001/0060], Loss1: -4.0061 Loss2: -3.8012 Loss3: -5.1595\n",
            "2022-08-02 11:03:33.360342 Epoch [053/250], Step [0050/0060], Loss1: -3.2472 Loss2: -3.0564 Loss3: -4.2431\n",
            "2022-08-02 11:03:38.552712 Epoch [053/250], Step [0060/0060], Loss1: -3.8939 Loss2: -3.6510 Loss3: -5.0220\n",
            "Epoch: 53 MAE: 0.5338605834315063 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:03:43.675737 Epoch [054/250], Step [0001/0060], Loss1: -4.2932 Loss2: -4.0324 Loss3: -5.4819\n",
            "2022-08-02 11:04:08.869216 Epoch [054/250], Step [0050/0060], Loss1: -3.4057 Loss2: -3.2448 Loss3: -4.4853\n",
            "2022-08-02 11:04:13.995402 Epoch [054/250], Step [0060/0060], Loss1: -3.4581 Loss2: -3.2360 Loss3: -4.4748\n",
            "Epoch: 54 MAE: 0.54474126180013 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:04:19.195688 Epoch [055/250], Step [0001/0060], Loss1: -3.9915 Loss2: -3.7808 Loss3: -5.1903\n",
            "2022-08-02 11:04:44.521859 Epoch [055/250], Step [0050/0060], Loss1: -3.8002 Loss2: -3.6243 Loss3: -4.9957\n",
            "2022-08-02 11:04:49.648342 Epoch [055/250], Step [0060/0060], Loss1: -3.3528 Loss2: -3.1954 Loss3: -4.4002\n",
            "Epoch: 55 MAE: 0.5421306929008042 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:04:56.820651 Epoch [056/250], Step [0001/0060], Loss1: -4.6070 Loss2: -4.2858 Loss3: -5.8726\n",
            "2022-08-02 11:05:22.062963 Epoch [056/250], Step [0050/0060], Loss1: -4.1729 Loss2: -3.9003 Loss3: -5.3581\n",
            "2022-08-02 11:05:27.183023 Epoch [056/250], Step [0060/0060], Loss1: -3.6050 Loss2: -3.4890 Loss3: -4.7733\n",
            "Epoch: 56 MAE: 0.5450171043759299 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:05:32.301588 Epoch [057/250], Step [0001/0060], Loss1: -3.6745 Loss2: -3.4574 Loss3: -4.7820\n",
            "2022-08-02 11:05:57.545715 Epoch [057/250], Step [0050/0060], Loss1: -3.1391 Loss2: -3.0333 Loss3: -4.2083\n",
            "2022-08-02 11:06:02.676146 Epoch [057/250], Step [0060/0060], Loss1: -3.2287 Loss2: -3.0368 Loss3: -4.2211\n",
            "Epoch: 57 MAE: 0.5502612425789001 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:06:07.867230 Epoch [058/250], Step [0001/0060], Loss1: -3.3440 Loss2: -3.1733 Loss3: -4.4012\n",
            "2022-08-02 11:06:33.022178 Epoch [058/250], Step [0050/0060], Loss1: -3.9437 Loss2: -3.6896 Loss3: -5.1087\n",
            "2022-08-02 11:06:38.112870 Epoch [058/250], Step [0060/0060], Loss1: -3.5132 Loss2: -3.2742 Loss3: -4.5740\n",
            "Epoch: 58 MAE: 0.5456297431421028 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:06:43.254730 Epoch [059/250], Step [0001/0060], Loss1: -4.2589 Loss2: -3.9774 Loss3: -5.4817\n",
            "2022-08-02 11:07:08.374583 Epoch [059/250], Step [0050/0060], Loss1: -4.5551 Loss2: -4.2959 Loss3: -5.8984\n",
            "2022-08-02 11:07:13.554768 Epoch [059/250], Step [0060/0060], Loss1: -3.7970 Loss2: -3.6549 Loss3: -5.0562\n",
            "Epoch: 59 MAE: 0.5438673739963108 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:07:18.764180 Epoch [060/250], Step [0001/0060], Loss1: -4.2354 Loss2: -3.9799 Loss3: -5.4914\n",
            "2022-08-02 11:07:44.109830 Epoch [060/250], Step [0050/0060], Loss1: -5.1284 Loss2: -4.7548 Loss3: -6.5304\n",
            "2022-08-02 11:07:49.248684 Epoch [060/250], Step [0060/0060], Loss1: -4.5946 Loss2: -4.3602 Loss3: -5.9656\n",
            "Epoch: 60 MAE: 0.5500528793738633 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:07:56.495012 Epoch [061/250], Step [0001/0060], Loss1: -4.5441 Loss2: -4.3110 Loss3: -5.9181\n",
            "2022-08-02 11:08:21.616976 Epoch [061/250], Step [0050/0060], Loss1: -4.0526 Loss2: -3.7984 Loss3: -5.2474\n",
            "2022-08-02 11:08:26.765004 Epoch [061/250], Step [0060/0060], Loss1: -4.1359 Loss2: -3.8684 Loss3: -5.3389\n",
            "Epoch: 61 MAE: 0.5419525534009176 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:08:31.957922 Epoch [062/250], Step [0001/0060], Loss1: -3.2295 Loss2: -3.1177 Loss3: -4.3358\n",
            "2022-08-02 11:08:57.156082 Epoch [062/250], Step [0050/0060], Loss1: -3.7755 Loss2: -3.5639 Loss3: -4.9271\n",
            "2022-08-02 11:09:02.296159 Epoch [062/250], Step [0060/0060], Loss1: -3.9203 Loss2: -3.7134 Loss3: -5.1362\n",
            "Epoch: 62 MAE: 0.5452880310381532 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:09:07.395927 Epoch [063/250], Step [0001/0060], Loss1: -4.6449 Loss2: -4.3498 Loss3: -5.9714\n",
            "2022-08-02 11:09:32.587190 Epoch [063/250], Step [0050/0060], Loss1: -5.1992 Loss2: -4.8526 Loss3: -6.6446\n",
            "2022-08-02 11:09:37.693692 Epoch [063/250], Step [0060/0060], Loss1: -4.1694 Loss2: -3.9711 Loss3: -5.4567\n",
            "Epoch: 63 MAE: 0.5441426264041316 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:09:42.912057 Epoch [064/250], Step [0001/0060], Loss1: -4.8007 Loss2: -4.4784 Loss3: -6.1692\n",
            "2022-08-02 11:10:08.103027 Epoch [064/250], Step [0050/0060], Loss1: -3.8285 Loss2: -3.6904 Loss3: -5.0941\n",
            "2022-08-02 11:10:13.201129 Epoch [064/250], Step [0060/0060], Loss1: -4.6386 Loss2: -4.3277 Loss3: -5.9370\n",
            "Epoch: 64 MAE: 0.5469967352650154 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:10:18.366971 Epoch [065/250], Step [0001/0060], Loss1: -4.9349 Loss2: -4.6641 Loss3: -6.3738\n",
            "2022-08-02 11:10:43.422927 Epoch [065/250], Step [0050/0060], Loss1: -5.2460 Loss2: -4.9195 Loss3: -6.7285\n",
            "2022-08-02 11:10:48.548837 Epoch [065/250], Step [0060/0060], Loss1: -4.7684 Loss2: -4.4650 Loss3: -6.1656\n",
            "Epoch: 65 MAE: 0.5401930737369274 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:10:55.832307 Epoch [066/250], Step [0001/0060], Loss1: -4.7049 Loss2: -4.4325 Loss3: -6.0957\n",
            "2022-08-02 11:11:21.205751 Epoch [066/250], Step [0050/0060], Loss1: -4.3047 Loss2: -4.1498 Loss3: -5.6754\n",
            "2022-08-02 11:11:26.308264 Epoch [066/250], Step [0060/0060], Loss1: -4.6864 Loss2: -4.4156 Loss3: -6.0519\n",
            "Epoch: 66 MAE: 0.5455132741776726 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:11:31.442998 Epoch [067/250], Step [0001/0060], Loss1: -4.0179 Loss2: -3.7637 Loss3: -5.2115\n",
            "2022-08-02 11:11:56.726215 Epoch [067/250], Step [0050/0060], Loss1: -4.2174 Loss2: -4.0159 Loss3: -5.5377\n",
            "2022-08-02 11:12:01.896474 Epoch [067/250], Step [0060/0060], Loss1: -3.6009 Loss2: -3.4464 Loss3: -4.8079\n",
            "Epoch: 67 MAE: 0.543028768710989 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:12:07.035857 Epoch [068/250], Step [0001/0060], Loss1: -5.0080 Loss2: -4.6826 Loss3: -6.4225\n",
            "2022-08-02 11:12:32.177275 Epoch [068/250], Step [0050/0060], Loss1: -4.2722 Loss2: -4.2106 Loss3: -5.7328\n",
            "2022-08-02 11:12:37.282903 Epoch [068/250], Step [0060/0060], Loss1: -3.9637 Loss2: -3.6849 Loss3: -5.1362\n",
            "Epoch: 68 MAE: 0.5465977962433346 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:12:42.505343 Epoch [069/250], Step [0001/0060], Loss1: -4.7226 Loss2: -4.5064 Loss3: -6.1504\n",
            "2022-08-02 11:13:07.707982 Epoch [069/250], Step [0050/0060], Loss1: -2.9292 Loss2: -2.7952 Loss3: -3.9521\n",
            "2022-08-02 11:13:12.855360 Epoch [069/250], Step [0060/0060], Loss1: -4.3986 Loss2: -4.1511 Loss3: -5.7047\n",
            "Epoch: 69 MAE: 0.548626792948082 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:13:18.114670 Epoch [070/250], Step [0001/0060], Loss1: -4.2161 Loss2: -4.0388 Loss3: -5.5528\n",
            "2022-08-02 11:13:43.304054 Epoch [070/250], Step [0050/0060], Loss1: -3.9682 Loss2: -3.7618 Loss3: -5.2077\n",
            "2022-08-02 11:13:48.412201 Epoch [070/250], Step [0060/0060], Loss1: -5.4497 Loss2: -5.1064 Loss3: -6.9724\n",
            "Epoch: 70 MAE: 0.5429359153464989 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:13:55.707233 Epoch [071/250], Step [0001/0060], Loss1: -3.5832 Loss2: -3.4274 Loss3: -4.7504\n",
            "2022-08-02 11:14:20.967512 Epoch [071/250], Step [0050/0060], Loss1: -4.4335 Loss2: -4.2173 Loss3: -5.8226\n",
            "2022-08-02 11:14:26.080029 Epoch [071/250], Step [0060/0060], Loss1: -4.8816 Loss2: -4.6280 Loss3: -6.3411\n",
            "Epoch: 71 MAE: 0.541794172014509 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:14:31.230146 Epoch [072/250], Step [0001/0060], Loss1: -5.4597 Loss2: -5.0850 Loss3: -6.9534\n",
            "2022-08-02 11:14:56.421059 Epoch [072/250], Step [0050/0060], Loss1: -4.2461 Loss2: -3.9922 Loss3: -5.5298\n",
            "2022-08-02 11:15:01.611896 Epoch [072/250], Step [0060/0060], Loss1: -4.2580 Loss2: -4.0041 Loss3: -5.5253\n",
            "Epoch: 72 MAE: 0.5461512215427622 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:15:06.761104 Epoch [073/250], Step [0001/0060], Loss1: -4.1688 Loss2: -3.9490 Loss3: -5.4407\n",
            "2022-08-02 11:15:32.116066 Epoch [073/250], Step [0050/0060], Loss1: -4.9112 Loss2: -4.6594 Loss3: -6.3530\n",
            "2022-08-02 11:15:37.232358 Epoch [073/250], Step [0060/0060], Loss1: -4.6211 Loss2: -4.3902 Loss3: -6.0297\n",
            "Epoch: 73 MAE: 0.5437485855344744 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:15:42.456778 Epoch [074/250], Step [0001/0060], Loss1: -4.0073 Loss2: -3.8746 Loss3: -5.3572\n",
            "2022-08-02 11:16:07.711883 Epoch [074/250], Step [0050/0060], Loss1: -4.8573 Loss2: -4.6089 Loss3: -6.3110\n",
            "2022-08-02 11:16:12.830835 Epoch [074/250], Step [0060/0060], Loss1: -4.4605 Loss2: -4.2358 Loss3: -5.8355\n",
            "Epoch: 74 MAE: 0.5436206337257666 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:16:17.980096 Epoch [075/250], Step [0001/0060], Loss1: -4.3883 Loss2: -4.1413 Loss3: -5.6990\n",
            "2022-08-02 11:16:43.340283 Epoch [075/250], Step [0050/0060], Loss1: -4.1009 Loss2: -3.8458 Loss3: -5.2843\n",
            "2022-08-02 11:16:48.485673 Epoch [075/250], Step [0060/0060], Loss1: -4.4694 Loss2: -4.2654 Loss3: -5.8560\n",
            "Epoch: 75 MAE: 0.5471506948319691 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:16:55.907800 Epoch [076/250], Step [0001/0060], Loss1: -4.4785 Loss2: -4.1970 Loss3: -5.7808\n",
            "2022-08-02 11:17:21.126093 Epoch [076/250], Step [0050/0060], Loss1: -3.8342 Loss2: -3.6903 Loss3: -5.1063\n",
            "2022-08-02 11:17:26.272267 Epoch [076/250], Step [0060/0060], Loss1: -4.7137 Loss2: -4.4179 Loss3: -6.0621\n",
            "Epoch: 76 MAE: 0.553029022216797 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:17:31.564049 Epoch [077/250], Step [0001/0060], Loss1: -4.6918 Loss2: -4.5092 Loss3: -6.1545\n",
            "2022-08-02 11:17:56.835167 Epoch [077/250], Step [0050/0060], Loss1: -5.3264 Loss2: -4.9763 Loss3: -6.8044\n",
            "2022-08-02 11:18:02.034695 Epoch [077/250], Step [0060/0060], Loss1: -5.6466 Loss2: -5.2703 Loss3: -7.1980\n",
            "Epoch: 77 MAE: 0.5465562915297413 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:18:07.304652 Epoch [078/250], Step [0001/0060], Loss1: -4.1793 Loss2: -3.9361 Loss3: -5.4499\n",
            "2022-08-02 11:18:32.568327 Epoch [078/250], Step [0050/0060], Loss1: -4.3188 Loss2: -4.1561 Loss3: -5.7121\n",
            "2022-08-02 11:18:37.674909 Epoch [078/250], Step [0060/0060], Loss1: -4.3689 Loss2: -4.1652 Loss3: -5.7280\n",
            "Epoch: 78 MAE: 0.5461493517355943 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:18:42.867660 Epoch [079/250], Step [0001/0060], Loss1: -5.2436 Loss2: -4.9454 Loss3: -6.7703\n",
            "2022-08-02 11:19:07.994578 Epoch [079/250], Step [0050/0060], Loss1: -4.7944 Loss2: -4.5829 Loss3: -6.2724\n",
            "2022-08-02 11:19:13.131399 Epoch [079/250], Step [0060/0060], Loss1: -4.0143 Loss2: -3.7837 Loss3: -5.2337\n",
            "Epoch: 79 MAE: 0.5484791710263206 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:19:18.443390 Epoch [080/250], Step [0001/0060], Loss1: -5.2277 Loss2: -4.9299 Loss3: -6.7519\n",
            "2022-08-02 11:19:43.659616 Epoch [080/250], Step [0050/0060], Loss1: -4.3614 Loss2: -4.1067 Loss3: -5.6577\n",
            "2022-08-02 11:19:48.810913 Epoch [080/250], Step [0060/0060], Loss1: -5.9912 Loss2: -5.5390 Loss3: -7.5805\n",
            "Epoch: 80 MAE: 0.5461328738580935 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:19:56.121775 Epoch [081/250], Step [0001/0060], Loss1: -4.4390 Loss2: -4.2676 Loss3: -5.8252\n",
            "2022-08-02 11:20:21.516522 Epoch [081/250], Step [0050/0060], Loss1: -3.7973 Loss2: -3.6215 Loss3: -5.0088\n",
            "2022-08-02 11:20:26.628398 Epoch [081/250], Step [0060/0060], Loss1: -4.4229 Loss2: -4.1729 Loss3: -5.7291\n",
            "Epoch: 81 MAE: 0.544454465189939 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:20:31.842620 Epoch [082/250], Step [0001/0060], Loss1: -4.8805 Loss2: -4.6651 Loss3: -6.3550\n",
            "2022-08-02 11:20:57.074775 Epoch [082/250], Step [0050/0060], Loss1: -5.7378 Loss2: -5.3418 Loss3: -7.3114\n",
            "2022-08-02 11:21:02.226677 Epoch [082/250], Step [0060/0060], Loss1: -3.5171 Loss2: -3.3504 Loss3: -4.6492\n",
            "Epoch: 82 MAE: 0.5510165962340341 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:21:07.412001 Epoch [083/250], Step [0001/0060], Loss1: -4.8997 Loss2: -4.5798 Loss3: -6.2939\n",
            "2022-08-02 11:21:32.686677 Epoch [083/250], Step [0050/0060], Loss1: -5.7088 Loss2: -5.3189 Loss3: -7.2763\n",
            "2022-08-02 11:21:37.802512 Epoch [083/250], Step [0060/0060], Loss1: -4.1735 Loss2: -4.0037 Loss3: -5.5170\n",
            "Epoch: 83 MAE: 0.5567189235788176 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:21:43.014019 Epoch [084/250], Step [0001/0060], Loss1: -4.6182 Loss2: -4.3431 Loss3: -5.9617\n",
            "2022-08-02 11:22:08.207320 Epoch [084/250], Step [0050/0060], Loss1: -4.0063 Loss2: -3.8974 Loss3: -5.3727\n",
            "2022-08-02 11:22:13.299806 Epoch [084/250], Step [0060/0060], Loss1: -3.9880 Loss2: -3.7766 Loss3: -5.2214\n",
            "Epoch: 84 MAE: 0.5499462511173633 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:22:18.553406 Epoch [085/250], Step [0001/0060], Loss1: -5.9274 Loss2: -5.5402 Loss3: -7.6132\n",
            "2022-08-02 11:22:43.625367 Epoch [085/250], Step [0050/0060], Loss1: -5.1354 Loss2: -4.9181 Loss3: -6.6918\n",
            "2022-08-02 11:22:48.729941 Epoch [085/250], Step [0060/0060], Loss1: -4.0262 Loss2: -3.8923 Loss3: -5.3513\n",
            "Epoch: 85 MAE: 0.5491706073094929 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:22:56.050157 Epoch [086/250], Step [0001/0060], Loss1: -3.9352 Loss2: -3.7411 Loss3: -5.1744\n",
            "2022-08-02 11:23:21.332618 Epoch [086/250], Step [0050/0060], Loss1: -3.7327 Loss2: -3.6219 Loss3: -5.0092\n",
            "2022-08-02 11:23:26.500228 Epoch [086/250], Step [0060/0060], Loss1: -4.7355 Loss2: -4.4630 Loss3: -6.1395\n",
            "Epoch: 86 MAE: 0.5461461861423715 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:23:31.635413 Epoch [087/250], Step [0001/0060], Loss1: -4.1380 Loss2: -3.9091 Loss3: -5.4027\n",
            "2022-08-02 11:23:56.855527 Epoch [087/250], Step [0050/0060], Loss1: -5.0033 Loss2: -4.7773 Loss3: -6.5210\n",
            "2022-08-02 11:24:01.991613 Epoch [087/250], Step [0060/0060], Loss1: -4.3082 Loss2: -4.1220 Loss3: -5.6739\n",
            "Epoch: 87 MAE: 0.5406254093230715 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:24:07.238144 Epoch [088/250], Step [0001/0060], Loss1: -4.1304 Loss2: -3.9905 Loss3: -5.4933\n",
            "2022-08-02 11:24:32.492398 Epoch [088/250], Step [0050/0060], Loss1: -5.6571 Loss2: -5.3135 Loss3: -7.2536\n",
            "2022-08-02 11:24:37.641652 Epoch [088/250], Step [0060/0060], Loss1: -4.9511 Loss2: -4.8002 Loss3: -6.5758\n",
            "Epoch: 88 MAE: 0.5526577363190829 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:24:42.948169 Epoch [089/250], Step [0001/0060], Loss1: -4.5857 Loss2: -4.4047 Loss3: -6.0441\n",
            "2022-08-02 11:25:08.174629 Epoch [089/250], Step [0050/0060], Loss1: -4.9137 Loss2: -4.7010 Loss3: -6.4388\n",
            "2022-08-02 11:25:13.359482 Epoch [089/250], Step [0060/0060], Loss1: -5.0669 Loss2: -4.8211 Loss3: -6.5930\n",
            "Epoch: 89 MAE: 0.5576643646078765 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:25:18.547069 Epoch [090/250], Step [0001/0060], Loss1: -4.5199 Loss2: -4.3436 Loss3: -5.9384\n",
            "2022-08-02 11:25:43.672601 Epoch [090/250], Step [0050/0060], Loss1: -5.3676 Loss2: -5.0571 Loss3: -6.9144\n",
            "2022-08-02 11:25:48.789582 Epoch [090/250], Step [0060/0060], Loss1: -4.4472 Loss2: -4.2922 Loss3: -5.8983\n",
            "Epoch: 90 MAE: 0.5504114076321722 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:25:56.017390 Epoch [091/250], Step [0001/0060], Loss1: -5.0754 Loss2: -4.8549 Loss3: -6.6246\n",
            "2022-08-02 11:26:21.380231 Epoch [091/250], Step [0050/0060], Loss1: -5.4221 Loss2: -5.1096 Loss3: -6.9718\n",
            "2022-08-02 11:26:26.520644 Epoch [091/250], Step [0060/0060], Loss1: -6.2069 Loss2: -5.7597 Loss3: -7.8673\n",
            "Epoch: 91 MAE: 0.5428145054408485 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:26:31.737375 Epoch [092/250], Step [0001/0060], Loss1: -3.6138 Loss2: -3.4808 Loss3: -4.8135\n",
            "2022-08-02 11:26:56.954888 Epoch [092/250], Step [0050/0060], Loss1: -4.4758 Loss2: -4.3412 Loss3: -5.9250\n",
            "2022-08-02 11:27:02.048264 Epoch [092/250], Step [0060/0060], Loss1: -4.5769 Loss2: -4.3353 Loss3: -5.9649\n",
            "Epoch: 92 MAE: 0.5484841757476645 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:27:07.185731 Epoch [093/250], Step [0001/0060], Loss1: -5.8340 Loss2: -5.4876 Loss3: -7.5129\n",
            "2022-08-02 11:27:32.364859 Epoch [093/250], Step [0050/0060], Loss1: -4.4379 Loss2: -4.2038 Loss3: -5.7839\n",
            "2022-08-02 11:27:37.510952 Epoch [093/250], Step [0060/0060], Loss1: -3.3539 Loss2: -3.2083 Loss3: -4.4805\n",
            "Epoch: 93 MAE: 0.5498746050476395 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:27:42.748338 Epoch [094/250], Step [0001/0060], Loss1: -5.3697 Loss2: -5.0624 Loss3: -6.9283\n",
            "2022-08-02 11:28:08.005961 Epoch [094/250], Step [0050/0060], Loss1: -5.1620 Loss2: -4.8984 Loss3: -6.6884\n",
            "2022-08-02 11:28:13.137086 Epoch [094/250], Step [0060/0060], Loss1: -5.2530 Loss2: -4.9514 Loss3: -6.7800\n",
            "Epoch: 94 MAE: 0.5534923509062911 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:28:18.339717 Epoch [095/250], Step [0001/0060], Loss1: -4.7352 Loss2: -4.5455 Loss3: -6.2322\n",
            "2022-08-02 11:28:43.565122 Epoch [095/250], Step [0050/0060], Loss1: -4.8279 Loss2: -4.6584 Loss3: -6.3587\n",
            "2022-08-02 11:28:48.704438 Epoch [095/250], Step [0060/0060], Loss1: -5.1421 Loss2: -4.8207 Loss3: -6.5952\n",
            "Epoch: 95 MAE: 0.5515542739787428 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:28:55.912812 Epoch [096/250], Step [0001/0060], Loss1: -4.1690 Loss2: -3.9755 Loss3: -5.4743\n",
            "2022-08-02 11:29:21.244400 Epoch [096/250], Step [0050/0060], Loss1: -5.2801 Loss2: -4.9823 Loss3: -6.8130\n",
            "2022-08-02 11:29:26.373425 Epoch [096/250], Step [0060/0060], Loss1: -5.6677 Loss2: -5.3531 Loss3: -7.2986\n",
            "Epoch: 96 MAE: 0.5503644000663959 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:29:31.784537 Epoch [097/250], Step [0001/0060], Loss1: -5.1698 Loss2: -4.9484 Loss3: -6.7464\n",
            "2022-08-02 11:29:57.339671 Epoch [097/250], Step [0050/0060], Loss1: -4.8119 Loss2: -4.5539 Loss3: -6.2460\n",
            "2022-08-02 11:30:02.682362 Epoch [097/250], Step [0060/0060], Loss1: -3.1771 Loss2: -3.1383 Loss3: -4.3500\n",
            "Epoch: 97 MAE: 0.5611089789173592 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:30:07.998291 Epoch [098/250], Step [0001/0060], Loss1: -4.6978 Loss2: -4.3865 Loss3: -6.0263\n",
            "2022-08-02 11:30:33.087649 Epoch [098/250], Step [0050/0060], Loss1: -4.5616 Loss2: -4.3784 Loss3: -5.9986\n",
            "2022-08-02 11:30:38.197615 Epoch [098/250], Step [0060/0060], Loss1: -4.7621 Loss2: -4.5580 Loss3: -6.2487\n",
            "Epoch: 98 MAE: 0.5519454245592551 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:30:43.344695 Epoch [099/250], Step [0001/0060], Loss1: -5.0540 Loss2: -4.8136 Loss3: -6.5930\n",
            "2022-08-02 11:31:08.655964 Epoch [099/250], Step [0050/0060], Loss1: -5.7300 Loss2: -5.3667 Loss3: -7.3416\n",
            "2022-08-02 11:31:13.801782 Epoch [099/250], Step [0060/0060], Loss1: -5.2309 Loss2: -4.9665 Loss3: -6.7907\n",
            "Epoch: 99 MAE: 0.5463741435701885 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:31:19.045290 Epoch [100/250], Step [0001/0060], Loss1: -3.8205 Loss2: -3.6368 Loss3: -5.0480\n",
            "2022-08-02 11:31:44.089809 Epoch [100/250], Step [0050/0060], Loss1: -4.8861 Loss2: -4.6519 Loss3: -6.3701\n",
            "2022-08-02 11:31:49.182607 Epoch [100/250], Step [0060/0060], Loss1: -4.1167 Loss2: -3.9026 Loss3: -5.3896\n",
            "Epoch: 100 MAE: 0.560767083546472 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:31:56.415204 Epoch [101/250], Step [0001/0060], Loss1: -3.8954 Loss2: -3.8546 Loss3: -5.3012\n",
            "2022-08-02 11:32:21.766947 Epoch [101/250], Step [0050/0060], Loss1: -5.2265 Loss2: -5.0367 Loss3: -6.8656\n",
            "2022-08-02 11:32:26.886209 Epoch [101/250], Step [0060/0060], Loss1: -4.0577 Loss2: -3.8611 Loss3: -5.3247\n",
            "Epoch: 101 MAE: 0.5553529575892858 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:32:32.060176 Epoch [102/250], Step [0001/0060], Loss1: -5.4141 Loss2: -5.1635 Loss3: -7.0438\n",
            "2022-08-02 11:32:57.329577 Epoch [102/250], Step [0050/0060], Loss1: -4.6528 Loss2: -4.4847 Loss3: -6.1528\n",
            "2022-08-02 11:33:02.493706 Epoch [102/250], Step [0060/0060], Loss1: -3.9819 Loss2: -3.7930 Loss3: -5.2555\n",
            "Epoch: 102 MAE: 0.5513647969563803 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:33:07.664581 Epoch [103/250], Step [0001/0060], Loss1: -5.2052 Loss2: -4.9648 Loss3: -6.7739\n",
            "2022-08-02 11:33:32.836919 Epoch [103/250], Step [0050/0060], Loss1: -4.6492 Loss2: -4.4852 Loss3: -6.1536\n",
            "2022-08-02 11:33:37.975635 Epoch [103/250], Step [0060/0060], Loss1: -5.4844 Loss2: -5.1734 Loss3: -7.0562\n",
            "Epoch: 103 MAE: 0.5552076422474371 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:33:43.233794 Epoch [104/250], Step [0001/0060], Loss1: -4.9482 Loss2: -4.7402 Loss3: -6.4867\n",
            "2022-08-02 11:34:08.328302 Epoch [104/250], Step [0050/0060], Loss1: -5.4671 Loss2: -5.1655 Loss3: -7.0504\n",
            "2022-08-02 11:34:13.477666 Epoch [104/250], Step [0060/0060], Loss1: -5.0898 Loss2: -4.9380 Loss3: -6.7568\n",
            "Epoch: 104 MAE: 0.5522985355437748 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:34:18.796488 Epoch [105/250], Step [0001/0060], Loss1: -4.9905 Loss2: -4.7918 Loss3: -6.5568\n",
            "2022-08-02 11:34:43.835367 Epoch [105/250], Step [0050/0060], Loss1: -5.3094 Loss2: -5.0542 Loss3: -6.9074\n",
            "2022-08-02 11:34:48.981765 Epoch [105/250], Step [0060/0060], Loss1: -6.5632 Loss2: -6.1104 Loss3: -8.3615\n",
            "Epoch: 105 MAE: 0.5487205634546028 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:34:56.280315 Epoch [106/250], Step [0001/0060], Loss1: -4.2401 Loss2: -4.1478 Loss3: -5.6913\n",
            "2022-08-02 11:35:21.680589 Epoch [106/250], Step [0050/0060], Loss1: -4.0125 Loss2: -3.8669 Loss3: -5.3334\n",
            "2022-08-02 11:35:26.825561 Epoch [106/250], Step [0060/0060], Loss1: -5.5533 Loss2: -5.2685 Loss3: -7.1874\n",
            "Epoch: 106 MAE: 0.553178406569062 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:35:32.073054 Epoch [107/250], Step [0001/0060], Loss1: -5.3018 Loss2: -5.0402 Loss3: -6.8759\n",
            "2022-08-02 11:35:57.094333 Epoch [107/250], Step [0050/0060], Loss1: -4.4193 Loss2: -4.2523 Loss3: -5.8257\n",
            "2022-08-02 11:36:02.198134 Epoch [107/250], Step [0060/0060], Loss1: -5.9308 Loss2: -5.6399 Loss3: -7.6806\n",
            "Epoch: 107 MAE: 0.5541384815034412 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:36:07.445719 Epoch [108/250], Step [0001/0060], Loss1: -5.6991 Loss2: -5.3760 Loss3: -7.3376\n",
            "2022-08-02 11:36:32.619725 Epoch [108/250], Step [0050/0060], Loss1: -5.2246 Loss2: -5.0194 Loss3: -6.8539\n",
            "2022-08-02 11:36:37.725788 Epoch [108/250], Step [0060/0060], Loss1: -4.5651 Loss2: -4.3401 Loss3: -5.9619\n",
            "Epoch: 108 MAE: 0.5555862951530981 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:36:42.978015 Epoch [109/250], Step [0001/0060], Loss1: -5.7545 Loss2: -5.4487 Loss3: -7.4259\n",
            "2022-08-02 11:37:08.087667 Epoch [109/250], Step [0050/0060], Loss1: -5.9986 Loss2: -5.6647 Loss3: -7.7244\n",
            "2022-08-02 11:37:13.225021 Epoch [109/250], Step [0060/0060], Loss1: -5.1683 Loss2: -4.9486 Loss3: -6.7555\n",
            "Epoch: 109 MAE: 0.5559695523378081 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:37:18.443036 Epoch [110/250], Step [0001/0060], Loss1: -4.5362 Loss2: -4.2955 Loss3: -5.9132\n",
            "2022-08-02 11:37:43.519894 Epoch [110/250], Step [0050/0060], Loss1: -5.6940 Loss2: -5.4275 Loss3: -7.3813\n",
            "2022-08-02 11:37:48.620492 Epoch [110/250], Step [0060/0060], Loss1: -6.1466 Loss2: -5.7986 Loss3: -7.9043\n",
            "Epoch: 110 MAE: 0.5563785508574633 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:37:55.925215 Epoch [111/250], Step [0001/0060], Loss1: -5.3467 Loss2: -5.1289 Loss3: -6.9821\n",
            "2022-08-02 11:38:21.113662 Epoch [111/250], Step [0050/0060], Loss1: -4.7114 Loss2: -4.6214 Loss3: -6.3102\n",
            "2022-08-02 11:38:26.250071 Epoch [111/250], Step [0060/0060], Loss1: -3.9279 Loss2: -3.8269 Loss3: -5.2813\n",
            "Epoch: 111 MAE: 0.5560582123610076 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:38:31.460993 Epoch [112/250], Step [0001/0060], Loss1: -4.4013 Loss2: -4.3225 Loss3: -5.9193\n",
            "2022-08-02 11:38:56.617905 Epoch [112/250], Step [0050/0060], Loss1: -5.1935 Loss2: -4.9080 Loss3: -6.7009\n",
            "2022-08-02 11:39:01.714583 Epoch [112/250], Step [0060/0060], Loss1: -4.8956 Loss2: -4.6529 Loss3: -6.3683\n",
            "Epoch: 112 MAE: 0.5582908622297661 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:39:06.909277 Epoch [113/250], Step [0001/0060], Loss1: -4.7385 Loss2: -4.5357 Loss3: -6.2170\n",
            "2022-08-02 11:39:32.083411 Epoch [113/250], Step [0050/0060], Loss1: -6.1950 Loss2: -5.8141 Loss3: -7.9358\n",
            "2022-08-02 11:39:37.183058 Epoch [113/250], Step [0060/0060], Loss1: -5.2479 Loss2: -5.0556 Loss3: -6.8747\n",
            "Epoch: 113 MAE: 0.5558195560192934 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:39:42.443763 Epoch [114/250], Step [0001/0060], Loss1: -5.2851 Loss2: -5.0947 Loss3: -6.9383\n",
            "2022-08-02 11:40:07.554253 Epoch [114/250], Step [0050/0060], Loss1: -4.7977 Loss2: -4.6686 Loss3: -6.3729\n",
            "2022-08-02 11:40:12.694501 Epoch [114/250], Step [0060/0060], Loss1: -5.4194 Loss2: -5.1542 Loss3: -7.0306\n",
            "Epoch: 114 MAE: 0.5581149897499688 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:40:17.921839 Epoch [115/250], Step [0001/0060], Loss1: -5.4250 Loss2: -5.2274 Loss3: -7.1245\n",
            "2022-08-02 11:40:42.982974 Epoch [115/250], Step [0050/0060], Loss1: -5.2689 Loss2: -5.1171 Loss3: -6.9753\n",
            "2022-08-02 11:40:48.091464 Epoch [115/250], Step [0060/0060], Loss1: -5.2551 Loss2: -5.0092 Loss3: -6.8393\n",
            "Epoch: 115 MAE: 0.5597367842739851 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:40:55.445583 Epoch [116/250], Step [0001/0060], Loss1: -5.3704 Loss2: -5.1063 Loss3: -6.9504\n",
            "2022-08-02 11:41:20.728971 Epoch [116/250], Step [0050/0060], Loss1: -6.4436 Loss2: -6.0713 Loss3: -8.2612\n",
            "2022-08-02 11:41:25.882297 Epoch [116/250], Step [0060/0060], Loss1: -4.4348 Loss2: -4.2976 Loss3: -5.8995\n",
            "Epoch: 116 MAE: 0.5632863370703641 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:41:31.025596 Epoch [117/250], Step [0001/0060], Loss1: -5.0429 Loss2: -4.8171 Loss3: -6.5885\n",
            "2022-08-02 11:41:56.146938 Epoch [117/250], Step [0050/0060], Loss1: -5.6897 Loss2: -5.4541 Loss3: -7.4215\n",
            "2022-08-02 11:42:01.291081 Epoch [117/250], Step [0060/0060], Loss1: -4.4961 Loss2: -4.3701 Loss3: -5.9979\n",
            "Epoch: 117 MAE: 0.5616974902279164 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:42:06.428505 Epoch [118/250], Step [0001/0060], Loss1: -4.5801 Loss2: -4.4382 Loss3: -6.0694\n",
            "2022-08-02 11:42:31.572687 Epoch [118/250], Step [0050/0060], Loss1: -5.5286 Loss2: -5.3018 Loss3: -7.2004\n",
            "2022-08-02 11:42:36.706331 Epoch [118/250], Step [0060/0060], Loss1: -5.2681 Loss2: -5.0653 Loss3: -6.9061\n",
            "Epoch: 118 MAE: 0.5563594232791313 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:42:41.875515 Epoch [119/250], Step [0001/0060], Loss1: -3.8176 Loss2: -3.7438 Loss3: -5.1444\n",
            "2022-08-02 11:43:06.931085 Epoch [119/250], Step [0050/0060], Loss1: -5.1681 Loss2: -4.9675 Loss3: -6.7714\n",
            "2022-08-02 11:43:12.056556 Epoch [119/250], Step [0060/0060], Loss1: -4.4797 Loss2: -4.2841 Loss3: -5.8675\n",
            "Epoch: 119 MAE: 0.5589541553315661 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:43:17.211053 Epoch [120/250], Step [0001/0060], Loss1: -5.5646 Loss2: -5.2903 Loss3: -7.2086\n",
            "2022-08-02 11:43:42.363334 Epoch [120/250], Step [0050/0060], Loss1: -5.1102 Loss2: -4.9160 Loss3: -6.6956\n",
            "2022-08-02 11:43:47.547579 Epoch [120/250], Step [0060/0060], Loss1: -6.0053 Loss2: -5.7511 Loss3: -7.8127\n",
            "Epoch: 120 MAE: 0.5598336033089453 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:43:54.724885 Epoch [121/250], Step [0001/0060], Loss1: -5.4641 Loss2: -5.2226 Loss3: -7.1176\n",
            "2022-08-02 11:44:19.997355 Epoch [121/250], Step [0050/0060], Loss1: -5.5148 Loss2: -5.2928 Loss3: -7.2094\n",
            "2022-08-02 11:44:25.125514 Epoch [121/250], Step [0060/0060], Loss1: -5.6348 Loss2: -5.3878 Loss3: -7.3320\n",
            "Epoch: 121 MAE: 0.5593774228373531 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:44:30.308488 Epoch [122/250], Step [0001/0060], Loss1: -5.7416 Loss2: -5.5423 Loss3: -7.5330\n",
            "2022-08-02 11:44:55.341235 Epoch [122/250], Step [0050/0060], Loss1: -4.7083 Loss2: -4.6151 Loss3: -6.3069\n",
            "2022-08-02 11:45:00.577187 Epoch [122/250], Step [0060/0060], Loss1: -5.1935 Loss2: -4.9794 Loss3: -6.8025\n",
            "Epoch: 122 MAE: 0.5588241512560969 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:45:05.747464 Epoch [123/250], Step [0001/0060], Loss1: -4.2963 Loss2: -4.1302 Loss3: -5.6825\n",
            "2022-08-02 11:45:30.799416 Epoch [123/250], Step [0050/0060], Loss1: -4.0586 Loss2: -3.9103 Loss3: -5.3843\n",
            "2022-08-02 11:45:35.898757 Epoch [123/250], Step [0060/0060], Loss1: -5.4824 Loss2: -5.2290 Loss3: -7.1118\n",
            "Epoch: 123 MAE: 0.5629933336046007 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:45:41.080389 Epoch [124/250], Step [0001/0060], Loss1: -5.2564 Loss2: -5.0756 Loss3: -6.9163\n",
            "2022-08-02 11:46:06.172700 Epoch [124/250], Step [0050/0060], Loss1: -4.5316 Loss2: -4.4658 Loss3: -6.0832\n",
            "2022-08-02 11:46:11.270395 Epoch [124/250], Step [0060/0060], Loss1: -4.0804 Loss2: -3.9300 Loss3: -5.4051\n",
            "Epoch: 124 MAE: 0.5614480841096746 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:46:16.493001 Epoch [125/250], Step [0001/0060], Loss1: -5.5512 Loss2: -5.3172 Loss3: -7.2287\n",
            "2022-08-02 11:46:41.570028 Epoch [125/250], Step [0050/0060], Loss1: -5.3281 Loss2: -5.1658 Loss3: -7.0238\n",
            "2022-08-02 11:46:46.670441 Epoch [125/250], Step [0060/0060], Loss1: -5.1520 Loss2: -4.9614 Loss3: -6.7703\n",
            "Epoch: 125 MAE: 0.560005750706587 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:46:53.998610 Epoch [126/250], Step [0001/0060], Loss1: -5.6067 Loss2: -5.4254 Loss3: -7.3723\n",
            "2022-08-02 11:47:19.232717 Epoch [126/250], Step [0050/0060], Loss1: -5.4351 Loss2: -5.2580 Loss3: -7.1569\n",
            "2022-08-02 11:47:24.366931 Epoch [126/250], Step [0060/0060], Loss1: -5.3911 Loss2: -5.1545 Loss3: -7.0267\n",
            "Epoch: 126 MAE: 0.5526720335622314 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:47:29.560848 Epoch [127/250], Step [0001/0060], Loss1: -4.5784 Loss2: -4.4219 Loss3: -6.0555\n",
            "2022-08-02 11:47:54.691280 Epoch [127/250], Step [0050/0060], Loss1: -5.4932 Loss2: -5.2553 Loss3: -7.1632\n",
            "2022-08-02 11:47:59.808759 Epoch [127/250], Step [0060/0060], Loss1: -5.8719 Loss2: -5.6085 Loss3: -7.6289\n",
            "Epoch: 127 MAE: 0.5566393421314381 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:48:05.002060 Epoch [128/250], Step [0001/0060], Loss1: -4.3100 Loss2: -4.1341 Loss3: -5.6823\n",
            "2022-08-02 11:48:30.065034 Epoch [128/250], Step [0050/0060], Loss1: -5.7916 Loss2: -5.4739 Loss3: -7.4549\n",
            "2022-08-02 11:48:35.184445 Epoch [128/250], Step [0060/0060], Loss1: -4.7336 Loss2: -4.5719 Loss3: -6.2447\n",
            "Epoch: 128 MAE: 0.5572585244153544 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:48:40.494530 Epoch [129/250], Step [0001/0060], Loss1: -4.1031 Loss2: -4.0001 Loss3: -5.4870\n",
            "2022-08-02 11:49:05.699427 Epoch [129/250], Step [0050/0060], Loss1: -5.8751 Loss2: -5.5921 Loss3: -7.6126\n",
            "2022-08-02 11:49:10.809859 Epoch [129/250], Step [0060/0060], Loss1: -5.3294 Loss2: -5.1317 Loss3: -6.9965\n",
            "Epoch: 129 MAE: 0.5580257524762835 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:49:16.110095 Epoch [130/250], Step [0001/0060], Loss1: -4.8518 Loss2: -4.6713 Loss3: -6.3847\n",
            "2022-08-02 11:49:41.383770 Epoch [130/250], Step [0050/0060], Loss1: -5.5170 Loss2: -5.2941 Loss3: -7.2143\n",
            "2022-08-02 11:49:46.533093 Epoch [130/250], Step [0060/0060], Loss1: -5.2765 Loss2: -5.0664 Loss3: -6.8917\n",
            "Epoch: 130 MAE: 0.5606463889470175 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:49:53.876638 Epoch [131/250], Step [0001/0060], Loss1: -5.2666 Loss2: -5.0346 Loss3: -6.8708\n",
            "2022-08-02 11:50:19.352730 Epoch [131/250], Step [0050/0060], Loss1: -5.7241 Loss2: -5.4781 Loss3: -7.4547\n",
            "2022-08-02 11:50:24.510380 Epoch [131/250], Step [0060/0060], Loss1: -4.8309 Loss2: -4.6057 Loss3: -6.3091\n",
            "Epoch: 131 MAE: 0.5618362935384117 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:50:29.706960 Epoch [132/250], Step [0001/0060], Loss1: -4.4421 Loss2: -4.2179 Loss3: -5.7950\n",
            "2022-08-02 11:50:54.877364 Epoch [132/250], Step [0050/0060], Loss1: -5.3113 Loss2: -5.1013 Loss3: -6.9553\n",
            "2022-08-02 11:51:00.042900 Epoch [132/250], Step [0060/0060], Loss1: -5.9479 Loss2: -5.6608 Loss3: -7.6993\n",
            "Epoch: 132 MAE: 0.554637911357577 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:51:05.259988 Epoch [133/250], Step [0001/0060], Loss1: -4.7953 Loss2: -4.6365 Loss3: -6.3348\n",
            "2022-08-02 11:51:30.485599 Epoch [133/250], Step [0050/0060], Loss1: -5.5840 Loss2: -5.3439 Loss3: -7.2745\n",
            "2022-08-02 11:51:35.678805 Epoch [133/250], Step [0060/0060], Loss1: -5.3881 Loss2: -5.1318 Loss3: -6.9921\n",
            "Epoch: 133 MAE: 0.5614948704633765 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:51:40.901961 Epoch [134/250], Step [0001/0060], Loss1: -4.9476 Loss2: -4.7435 Loss3: -6.4799\n",
            "2022-08-02 11:52:06.107885 Epoch [134/250], Step [0050/0060], Loss1: -6.0374 Loss2: -5.7916 Loss3: -7.8579\n",
            "2022-08-02 11:52:11.216763 Epoch [134/250], Step [0060/0060], Loss1: -4.3971 Loss2: -4.2209 Loss3: -5.7916\n",
            "Epoch: 134 MAE: 0.5622355393505599 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:52:16.358294 Epoch [135/250], Step [0001/0060], Loss1: -5.1437 Loss2: -4.9079 Loss3: -6.6994\n",
            "2022-08-02 11:52:41.472914 Epoch [135/250], Step [0050/0060], Loss1: -3.9449 Loss2: -3.8326 Loss3: -5.2465\n",
            "2022-08-02 11:52:46.631923 Epoch [135/250], Step [0060/0060], Loss1: -5.2057 Loss2: -4.9804 Loss3: -6.7981\n",
            "Epoch: 135 MAE: 0.5612335374620226 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:52:53.966200 Epoch [136/250], Step [0001/0060], Loss1: -5.6420 Loss2: -5.3714 Loss3: -7.3249\n",
            "2022-08-02 11:53:19.300094 Epoch [136/250], Step [0050/0060], Loss1: -5.1629 Loss2: -4.9440 Loss3: -6.7460\n",
            "2022-08-02 11:53:24.401950 Epoch [136/250], Step [0060/0060], Loss1: -5.8907 Loss2: -5.6476 Loss3: -7.6721\n",
            "Epoch: 136 MAE: 0.557914950254733 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:53:29.703435 Epoch [137/250], Step [0001/0060], Loss1: -4.9427 Loss2: -4.7483 Loss3: -6.4754\n",
            "2022-08-02 11:53:54.966301 Epoch [137/250], Step [0050/0060], Loss1: -4.9196 Loss2: -4.7416 Loss3: -6.4776\n",
            "2022-08-02 11:54:00.126053 Epoch [137/250], Step [0060/0060], Loss1: -5.7843 Loss2: -5.5393 Loss3: -7.5390\n",
            "Epoch: 137 MAE: 0.5665507022918218 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:54:05.414494 Epoch [138/250], Step [0001/0060], Loss1: -5.2860 Loss2: -5.1658 Loss3: -7.0240\n",
            "2022-08-02 11:54:30.606290 Epoch [138/250], Step [0050/0060], Loss1: -4.7141 Loss2: -4.5223 Loss3: -6.1921\n",
            "2022-08-02 11:54:35.706316 Epoch [138/250], Step [0060/0060], Loss1: -5.4955 Loss2: -5.2244 Loss3: -7.1324\n",
            "Epoch: 138 MAE: 0.5594622294108074 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:54:40.920301 Epoch [139/250], Step [0001/0060], Loss1: -5.1817 Loss2: -4.9608 Loss3: -6.7610\n",
            "2022-08-02 11:55:06.025184 Epoch [139/250], Step [0050/0060], Loss1: -4.4771 Loss2: -4.3430 Loss3: -5.9528\n",
            "2022-08-02 11:55:11.127623 Epoch [139/250], Step [0060/0060], Loss1: -4.7241 Loss2: -4.5979 Loss3: -6.2786\n",
            "Epoch: 139 MAE: 0.5565374699345341 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:55:16.362715 Epoch [140/250], Step [0001/0060], Loss1: -5.2678 Loss2: -5.1262 Loss3: -6.9749\n",
            "2022-08-02 11:55:41.474560 Epoch [140/250], Step [0050/0060], Loss1: -5.4222 Loss2: -5.1454 Loss3: -7.0202\n",
            "2022-08-02 11:55:46.583112 Epoch [140/250], Step [0060/0060], Loss1: -5.7452 Loss2: -5.5187 Loss3: -7.5051\n",
            "Epoch: 140 MAE: 0.5580372215957239 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:55:53.894218 Epoch [141/250], Step [0001/0060], Loss1: -5.4641 Loss2: -5.2530 Loss3: -7.1493\n",
            "2022-08-02 11:56:19.255513 Epoch [141/250], Step [0050/0060], Loss1: -4.8691 Loss2: -4.7133 Loss3: -6.4363\n",
            "2022-08-02 11:56:24.378940 Epoch [141/250], Step [0060/0060], Loss1: -4.8874 Loss2: -4.7729 Loss3: -6.5133\n",
            "Epoch: 141 MAE: 0.5569972543867807 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:56:29.537277 Epoch [142/250], Step [0001/0060], Loss1: -4.8040 Loss2: -4.6617 Loss3: -6.3581\n",
            "2022-08-02 11:56:54.649130 Epoch [142/250], Step [0050/0060], Loss1: -5.2864 Loss2: -5.1245 Loss3: -6.9823\n",
            "2022-08-02 11:56:59.843545 Epoch [142/250], Step [0060/0060], Loss1: -6.0020 Loss2: -5.7471 Loss3: -7.7956\n",
            "Epoch: 142 MAE: 0.5599209110320559 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:57:05.145325 Epoch [143/250], Step [0001/0060], Loss1: -5.2113 Loss2: -4.9642 Loss3: -6.7795\n",
            "2022-08-02 11:57:30.294555 Epoch [143/250], Step [0050/0060], Loss1: -5.0875 Loss2: -4.9091 Loss3: -6.6955\n",
            "2022-08-02 11:57:35.421700 Epoch [143/250], Step [0060/0060], Loss1: -5.0525 Loss2: -4.8897 Loss3: -6.6706\n",
            "Epoch: 143 MAE: 0.5619093306607039 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:57:40.647623 Epoch [144/250], Step [0001/0060], Loss1: -3.5962 Loss2: -3.5131 Loss3: -4.8417\n",
            "2022-08-02 11:58:05.873866 Epoch [144/250], Step [0050/0060], Loss1: -4.6624 Loss2: -4.5660 Loss3: -6.2343\n",
            "2022-08-02 11:58:11.008935 Epoch [144/250], Step [0060/0060], Loss1: -5.2450 Loss2: -5.0697 Loss3: -6.9066\n",
            "Epoch: 144 MAE: 0.5594664671559813 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:58:16.218494 Epoch [145/250], Step [0001/0060], Loss1: -5.0796 Loss2: -4.8967 Loss3: -6.6873\n",
            "2022-08-02 11:58:41.482734 Epoch [145/250], Step [0050/0060], Loss1: -4.2431 Loss2: -4.0826 Loss3: -5.5935\n",
            "2022-08-02 11:58:46.642837 Epoch [145/250], Step [0060/0060], Loss1: -5.0477 Loss2: -4.8495 Loss3: -6.6098\n",
            "Epoch: 145 MAE: 0.5614676597635582 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:58:54.021621 Epoch [146/250], Step [0001/0060], Loss1: -5.4858 Loss2: -5.2747 Loss3: -7.1847\n",
            "2022-08-02 11:59:19.516334 Epoch [146/250], Step [0050/0060], Loss1: -5.4889 Loss2: -5.3086 Loss3: -7.2132\n",
            "2022-08-02 11:59:24.696116 Epoch [146/250], Step [0060/0060], Loss1: -5.5474 Loss2: -5.3332 Loss3: -7.2618\n",
            "Epoch: 146 MAE: 0.5583090581338872 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 11:59:29.932310 Epoch [147/250], Step [0001/0060], Loss1: -5.2193 Loss2: -5.0037 Loss3: -6.8247\n",
            "2022-08-02 11:59:55.136367 Epoch [147/250], Step [0050/0060], Loss1: -5.4096 Loss2: -5.1921 Loss3: -7.0726\n",
            "2022-08-02 12:00:00.258459 Epoch [147/250], Step [0060/0060], Loss1: -5.8767 Loss2: -5.6410 Loss3: -7.6619\n",
            "Epoch: 147 MAE: 0.5598398400362207 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:00:05.490874 Epoch [148/250], Step [0001/0060], Loss1: -5.0087 Loss2: -4.7929 Loss3: -6.5512\n",
            "2022-08-02 12:00:30.713702 Epoch [148/250], Step [0050/0060], Loss1: -5.2880 Loss2: -5.1686 Loss3: -7.0170\n",
            "2022-08-02 12:00:35.863760 Epoch [148/250], Step [0060/0060], Loss1: -5.7073 Loss2: -5.4241 Loss3: -7.3899\n",
            "Epoch: 148 MAE: 0.5579759555392795 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:00:41.088000 Epoch [149/250], Step [0001/0060], Loss1: -4.6110 Loss2: -4.4953 Loss3: -6.1456\n",
            "2022-08-02 12:01:06.267438 Epoch [149/250], Step [0050/0060], Loss1: -4.6692 Loss2: -4.4851 Loss3: -6.1625\n",
            "2022-08-02 12:01:11.494358 Epoch [149/250], Step [0060/0060], Loss1: -5.6956 Loss2: -5.4362 Loss3: -7.3942\n",
            "Epoch: 149 MAE: 0.5572413304243137 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:01:16.747142 Epoch [150/250], Step [0001/0060], Loss1: -5.2229 Loss2: -5.0561 Loss3: -6.8974\n",
            "2022-08-02 12:01:41.931352 Epoch [150/250], Step [0050/0060], Loss1: -4.9220 Loss2: -4.7038 Loss3: -6.4159\n",
            "2022-08-02 12:01:47.077693 Epoch [150/250], Step [0060/0060], Loss1: -5.0574 Loss2: -4.8717 Loss3: -6.6450\n",
            "Epoch: 150 MAE: 0.5636714027041478 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:01:54.307949 Epoch [151/250], Step [0001/0060], Loss1: -5.3573 Loss2: -5.1469 Loss3: -7.0159\n",
            "2022-08-02 12:02:19.839375 Epoch [151/250], Step [0050/0060], Loss1: -5.4254 Loss2: -5.1450 Loss3: -7.0115\n",
            "2022-08-02 12:02:25.028687 Epoch [151/250], Step [0060/0060], Loss1: -5.2775 Loss2: -5.0289 Loss3: -6.8631\n",
            "Epoch: 151 MAE: 0.5591080341641866 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:02:30.303976 Epoch [152/250], Step [0001/0060], Loss1: -4.5171 Loss2: -4.4463 Loss3: -6.0770\n",
            "2022-08-02 12:02:55.487171 Epoch [152/250], Step [0050/0060], Loss1: -5.2529 Loss2: -5.0773 Loss3: -6.8985\n",
            "2022-08-02 12:03:00.599282 Epoch [152/250], Step [0060/0060], Loss1: -5.3366 Loss2: -5.1571 Loss3: -7.0238\n",
            "Epoch: 152 MAE: 0.5557526030363862 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:03:05.891307 Epoch [153/250], Step [0001/0060], Loss1: -5.3649 Loss2: -5.1918 Loss3: -7.0662\n",
            "2022-08-02 12:03:31.105686 Epoch [153/250], Step [0050/0060], Loss1: -4.3520 Loss2: -4.2153 Loss3: -5.7816\n",
            "2022-08-02 12:03:36.236674 Epoch [153/250], Step [0060/0060], Loss1: -5.7305 Loss2: -5.4547 Loss3: -7.4339\n",
            "Epoch: 153 MAE: 0.5562098403204054 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:03:41.517345 Epoch [154/250], Step [0001/0060], Loss1: -4.7485 Loss2: -4.6297 Loss3: -6.3183\n",
            "2022-08-02 12:04:06.728292 Epoch [154/250], Step [0050/0060], Loss1: -5.2572 Loss2: -5.0925 Loss3: -6.9328\n",
            "2022-08-02 12:04:11.857283 Epoch [154/250], Step [0060/0060], Loss1: -5.5656 Loss2: -5.3740 Loss3: -7.2879\n",
            "Epoch: 154 MAE: 0.5525442997362247 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:04:17.246498 Epoch [155/250], Step [0001/0060], Loss1: -4.7093 Loss2: -4.4963 Loss3: -6.1636\n",
            "2022-08-02 12:04:42.311282 Epoch [155/250], Step [0050/0060], Loss1: -6.0621 Loss2: -5.7829 Loss3: -7.8556\n",
            "2022-08-02 12:04:47.411006 Epoch [155/250], Step [0060/0060], Loss1: -3.6235 Loss2: -3.5881 Loss3: -4.9246\n",
            "Epoch: 155 MAE: 0.5593368312290735 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:04:54.685822 Epoch [156/250], Step [0001/0060], Loss1: -4.7872 Loss2: -4.7024 Loss3: -6.4233\n",
            "2022-08-02 12:05:19.985128 Epoch [156/250], Step [0050/0060], Loss1: -4.3706 Loss2: -4.2517 Loss3: -5.8248\n",
            "2022-08-02 12:05:25.105304 Epoch [156/250], Step [0060/0060], Loss1: -5.3872 Loss2: -5.1942 Loss3: -7.0769\n",
            "Epoch: 156 MAE: 0.5554634271853813 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:05:30.393582 Epoch [157/250], Step [0001/0060], Loss1: -4.1591 Loss2: -4.1020 Loss3: -5.6105\n",
            "2022-08-02 12:05:55.444741 Epoch [157/250], Step [0050/0060], Loss1: -5.8733 Loss2: -5.5832 Loss3: -7.5905\n",
            "2022-08-02 12:06:00.547976 Epoch [157/250], Step [0060/0060], Loss1: -4.2329 Loss2: -4.1554 Loss3: -5.6764\n",
            "Epoch: 157 MAE: 0.5614723956395709 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:06:05.765198 Epoch [158/250], Step [0001/0060], Loss1: -5.2038 Loss2: -4.9854 Loss3: -6.7949\n",
            "2022-08-02 12:06:30.941114 Epoch [158/250], Step [0050/0060], Loss1: -4.8581 Loss2: -4.6918 Loss3: -6.4066\n",
            "2022-08-02 12:06:36.096772 Epoch [158/250], Step [0060/0060], Loss1: -4.6914 Loss2: -4.5656 Loss3: -6.2358\n",
            "Epoch: 158 MAE: 0.5636138165186322 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:06:41.399090 Epoch [159/250], Step [0001/0060], Loss1: -5.6022 Loss2: -5.3859 Loss3: -7.3239\n",
            "2022-08-02 12:07:06.563166 Epoch [159/250], Step [0050/0060], Loss1: -4.1830 Loss2: -4.0732 Loss3: -5.5796\n",
            "2022-08-02 12:07:11.668276 Epoch [159/250], Step [0060/0060], Loss1: -4.9496 Loss2: -4.7404 Loss3: -6.4711\n",
            "Epoch: 159 MAE: 0.5588530678723854 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:07:16.937027 Epoch [160/250], Step [0001/0060], Loss1: -5.7433 Loss2: -5.5117 Loss3: -7.4923\n",
            "2022-08-02 12:07:42.185950 Epoch [160/250], Step [0050/0060], Loss1: -4.6369 Loss2: -4.5146 Loss3: -6.1693\n",
            "2022-08-02 12:07:47.335775 Epoch [160/250], Step [0060/0060], Loss1: -5.2969 Loss2: -5.1100 Loss3: -6.9528\n",
            "Epoch: 160 MAE: 0.5572257955238302 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:07:54.753312 Epoch [161/250], Step [0001/0060], Loss1: -4.5004 Loss2: -4.4158 Loss3: -6.0341\n",
            "2022-08-02 12:08:20.213528 Epoch [161/250], Step [0050/0060], Loss1: -5.9432 Loss2: -5.6730 Loss3: -7.7102\n",
            "2022-08-02 12:08:25.359484 Epoch [161/250], Step [0060/0060], Loss1: -5.1230 Loss2: -4.9048 Loss3: -6.6924\n",
            "Epoch: 161 MAE: 0.5589082126516515 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:08:30.521740 Epoch [162/250], Step [0001/0060], Loss1: -5.2209 Loss2: -5.0033 Loss3: -6.8243\n",
            "2022-08-02 12:08:55.761848 Epoch [162/250], Step [0050/0060], Loss1: -4.0273 Loss2: -3.9312 Loss3: -5.3866\n",
            "2022-08-02 12:09:00.879399 Epoch [162/250], Step [0060/0060], Loss1: -4.7343 Loss2: -4.5338 Loss3: -6.2007\n",
            "Epoch: 162 MAE: 0.5618125342313576 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:09:06.051872 Epoch [163/250], Step [0001/0060], Loss1: -3.8951 Loss2: -3.7759 Loss3: -5.1955\n",
            "2022-08-02 12:09:31.421130 Epoch [163/250], Step [0050/0060], Loss1: -4.8097 Loss2: -4.6192 Loss3: -6.3161\n",
            "2022-08-02 12:09:36.589601 Epoch [163/250], Step [0060/0060], Loss1: -4.7471 Loss2: -4.6408 Loss3: -6.3336\n",
            "Epoch: 163 MAE: 0.5591432948844143 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:09:41.770328 Epoch [164/250], Step [0001/0060], Loss1: -4.8685 Loss2: -4.5957 Loss3: -6.2835\n",
            "2022-08-02 12:10:06.884330 Epoch [164/250], Step [0050/0060], Loss1: -4.4119 Loss2: -4.3148 Loss3: -5.9112\n",
            "2022-08-02 12:10:12.019280 Epoch [164/250], Step [0060/0060], Loss1: -5.2291 Loss2: -5.0286 Loss3: -6.8681\n",
            "Epoch: 164 MAE: 0.5623933717434999 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:10:17.155312 Epoch [165/250], Step [0001/0060], Loss1: -4.8140 Loss2: -4.6632 Loss3: -6.3688\n",
            "2022-08-02 12:10:42.397760 Epoch [165/250], Step [0050/0060], Loss1: -5.3544 Loss2: -5.1599 Loss3: -7.0372\n",
            "2022-08-02 12:10:47.535925 Epoch [165/250], Step [0060/0060], Loss1: -5.5870 Loss2: -5.3271 Loss3: -7.2471\n",
            "Epoch: 165 MAE: 0.5622180870096519 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:10:55.928303 Epoch [166/250], Step [0001/0060], Loss1: -4.0046 Loss2: -3.9057 Loss3: -5.3564\n",
            "2022-08-02 12:11:21.380678 Epoch [166/250], Step [0050/0060], Loss1: -5.0052 Loss2: -4.8474 Loss3: -6.6077\n",
            "2022-08-02 12:11:26.501885 Epoch [166/250], Step [0060/0060], Loss1: -6.0602 Loss2: -5.8129 Loss3: -7.8920\n",
            "Epoch: 166 MAE: 0.5599093256551754 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:11:31.817716 Epoch [167/250], Step [0001/0060], Loss1: -5.7282 Loss2: -5.4937 Loss3: -7.4709\n",
            "2022-08-02 12:11:56.957309 Epoch [167/250], Step [0050/0060], Loss1: -5.7415 Loss2: -5.4694 Loss3: -7.4385\n",
            "2022-08-02 12:12:02.084872 Epoch [167/250], Step [0060/0060], Loss1: -5.1391 Loss2: -4.9479 Loss3: -6.7408\n",
            "Epoch: 167 MAE: 0.5585449638568535 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:12:07.360657 Epoch [168/250], Step [0001/0060], Loss1: -4.7442 Loss2: -4.5416 Loss3: -6.2143\n",
            "2022-08-02 12:12:32.551877 Epoch [168/250], Step [0050/0060], Loss1: -4.7318 Loss2: -4.5858 Loss3: -6.2676\n",
            "2022-08-02 12:12:37.667366 Epoch [168/250], Step [0060/0060], Loss1: -5.2091 Loss2: -5.0345 Loss3: -6.8468\n",
            "Epoch: 168 MAE: 0.5613662719726562 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:12:42.946521 Epoch [169/250], Step [0001/0060], Loss1: -5.4242 Loss2: -5.1984 Loss3: -7.0797\n",
            "2022-08-02 12:13:08.229636 Epoch [169/250], Step [0050/0060], Loss1: -4.8882 Loss2: -4.7073 Loss3: -6.4324\n",
            "2022-08-02 12:13:13.404187 Epoch [169/250], Step [0060/0060], Loss1: -4.7717 Loss2: -4.6674 Loss3: -6.3614\n",
            "Epoch: 169 MAE: 0.5588634454636349 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:13:18.788889 Epoch [170/250], Step [0001/0060], Loss1: -5.7040 Loss2: -5.4505 Loss3: -7.4243\n",
            "2022-08-02 12:13:43.933154 Epoch [170/250], Step [0050/0060], Loss1: -5.3416 Loss2: -5.1741 Loss3: -7.0493\n",
            "2022-08-02 12:13:49.055419 Epoch [170/250], Step [0060/0060], Loss1: -4.3841 Loss2: -4.2701 Loss3: -5.8188\n",
            "Epoch: 170 MAE: 0.5605562757058118 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:13:56.634905 Epoch [171/250], Step [0001/0060], Loss1: -4.4222 Loss2: -4.2675 Loss3: -5.8484\n",
            "2022-08-02 12:14:21.883906 Epoch [171/250], Step [0050/0060], Loss1: -4.6657 Loss2: -4.5359 Loss3: -6.1936\n",
            "2022-08-02 12:14:27.034209 Epoch [171/250], Step [0060/0060], Loss1: -5.0411 Loss2: -4.8065 Loss3: -6.5606\n",
            "Epoch: 171 MAE: 0.5550469841528191 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:14:32.411914 Epoch [172/250], Step [0001/0060], Loss1: -4.7826 Loss2: -4.5723 Loss3: -6.2532\n",
            "2022-08-02 12:14:57.667386 Epoch [172/250], Step [0050/0060], Loss1: -5.7317 Loss2: -5.5045 Loss3: -7.4833\n",
            "2022-08-02 12:15:02.772895 Epoch [172/250], Step [0060/0060], Loss1: -5.2364 Loss2: -4.9847 Loss3: -6.7892\n",
            "Epoch: 172 MAE: 0.5590779533588067 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:15:08.047872 Epoch [173/250], Step [0001/0060], Loss1: -5.2990 Loss2: -5.0726 Loss3: -6.9142\n",
            "2022-08-02 12:15:33.259488 Epoch [173/250], Step [0050/0060], Loss1: -5.4150 Loss2: -5.2433 Loss3: -7.1248\n",
            "2022-08-02 12:15:38.362963 Epoch [173/250], Step [0060/0060], Loss1: -5.0210 Loss2: -4.8336 Loss3: -6.6076\n",
            "Epoch: 173 MAE: 0.5625895198438535 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:15:43.657861 Epoch [174/250], Step [0001/0060], Loss1: -5.8699 Loss2: -5.6019 Loss3: -7.6180\n",
            "2022-08-02 12:16:08.805695 Epoch [174/250], Step [0050/0060], Loss1: -5.8250 Loss2: -5.5321 Loss3: -7.5241\n",
            "2022-08-02 12:16:13.963887 Epoch [174/250], Step [0060/0060], Loss1: -4.0603 Loss2: -3.9095 Loss3: -5.3490\n",
            "Epoch: 174 MAE: 0.5632114906916542 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:16:19.297472 Epoch [175/250], Step [0001/0060], Loss1: -5.1835 Loss2: -4.9799 Loss3: -6.7898\n",
            "2022-08-02 12:16:44.478514 Epoch [175/250], Step [0050/0060], Loss1: -4.7981 Loss2: -4.5638 Loss3: -6.2392\n",
            "2022-08-02 12:16:49.601469 Epoch [175/250], Step [0060/0060], Loss1: -4.7122 Loss2: -4.5653 Loss3: -6.2371\n",
            "Epoch: 175 MAE: 0.5577846208198991 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:16:57.173480 Epoch [176/250], Step [0001/0060], Loss1: -5.1382 Loss2: -4.9393 Loss3: -6.7335\n",
            "2022-08-02 12:17:22.539511 Epoch [176/250], Step [0050/0060], Loss1: -5.7999 Loss2: -5.5576 Loss3: -7.5390\n",
            "2022-08-02 12:17:27.638193 Epoch [176/250], Step [0060/0060], Loss1: -5.2099 Loss2: -5.0362 Loss3: -6.8601\n",
            "Epoch: 176 MAE: 0.559449319183511 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:17:32.868570 Epoch [177/250], Step [0001/0060], Loss1: -4.0483 Loss2: -4.0178 Loss3: -5.4849\n",
            "2022-08-02 12:17:58.071536 Epoch [177/250], Step [0050/0060], Loss1: -5.1426 Loss2: -4.9369 Loss3: -6.7409\n",
            "2022-08-02 12:18:03.223375 Epoch [177/250], Step [0060/0060], Loss1: -4.5317 Loss2: -4.4462 Loss3: -6.0765\n",
            "Epoch: 177 MAE: 0.5601967770208125 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:18:08.435882 Epoch [178/250], Step [0001/0060], Loss1: -4.5549 Loss2: -4.3559 Loss3: -5.9710\n",
            "2022-08-02 12:18:33.649883 Epoch [178/250], Step [0050/0060], Loss1: -5.3501 Loss2: -5.2108 Loss3: -7.0911\n",
            "2022-08-02 12:18:38.901631 Epoch [178/250], Step [0060/0060], Loss1: -5.3214 Loss2: -5.1007 Loss3: -6.9504\n",
            "Epoch: 178 MAE: 0.5555824417033521 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:18:44.220907 Epoch [179/250], Step [0001/0060], Loss1: -5.3001 Loss2: -5.0601 Loss3: -6.9013\n",
            "2022-08-02 12:19:09.359818 Epoch [179/250], Step [0050/0060], Loss1: -5.4977 Loss2: -5.2397 Loss3: -7.1188\n",
            "2022-08-02 12:19:14.476079 Epoch [179/250], Step [0060/0060], Loss1: -5.2479 Loss2: -5.0248 Loss3: -6.8519\n",
            "Epoch: 179 MAE: 0.5657337321932352 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:19:19.862206 Epoch [180/250], Step [0001/0060], Loss1: -4.8635 Loss2: -4.7527 Loss3: -6.4825\n",
            "2022-08-02 12:19:45.049491 Epoch [180/250], Step [0050/0060], Loss1: -5.0069 Loss2: -4.8223 Loss3: -6.5830\n",
            "2022-08-02 12:19:50.224809 Epoch [180/250], Step [0060/0060], Loss1: -5.0667 Loss2: -4.9106 Loss3: -6.6831\n",
            "Epoch: 180 MAE: 0.5603980751643105 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:19:57.949594 Epoch [181/250], Step [0001/0060], Loss1: -5.7355 Loss2: -5.4939 Loss3: -7.4738\n",
            "2022-08-02 12:20:23.339623 Epoch [181/250], Step [0050/0060], Loss1: -5.3732 Loss2: -5.1985 Loss3: -7.0690\n",
            "2022-08-02 12:20:28.582352 Epoch [181/250], Step [0060/0060], Loss1: -5.9012 Loss2: -5.5845 Loss3: -7.5964\n",
            "Epoch: 181 MAE: 0.5606700215011675 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:20:33.890118 Epoch [182/250], Step [0001/0060], Loss1: -4.8535 Loss2: -4.7222 Loss3: -6.4443\n",
            "2022-08-02 12:20:59.016762 Epoch [182/250], Step [0050/0060], Loss1: -5.8620 Loss2: -5.5825 Loss3: -7.5910\n",
            "2022-08-02 12:21:04.163847 Epoch [182/250], Step [0060/0060], Loss1: -4.9918 Loss2: -4.8120 Loss3: -6.5635\n",
            "Epoch: 182 MAE: 0.5601385530340608 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:21:09.490396 Epoch [183/250], Step [0001/0060], Loss1: -5.1040 Loss2: -4.8852 Loss3: -6.6582\n",
            "2022-08-02 12:21:34.674460 Epoch [183/250], Step [0050/0060], Loss1: -4.6943 Loss2: -4.5848 Loss3: -6.2427\n",
            "2022-08-02 12:21:39.776135 Epoch [183/250], Step [0060/0060], Loss1: -5.2185 Loss2: -5.0404 Loss3: -6.8754\n",
            "Epoch: 183 MAE: 0.5618429831852987 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:21:45.135109 Epoch [184/250], Step [0001/0060], Loss1: -5.0622 Loss2: -4.8726 Loss3: -6.6504\n",
            "2022-08-02 12:22:10.282677 Epoch [184/250], Step [0050/0060], Loss1: -4.4808 Loss2: -4.3766 Loss3: -5.9873\n",
            "2022-08-02 12:22:15.406301 Epoch [184/250], Step [0060/0060], Loss1: -5.0949 Loss2: -4.8453 Loss3: -6.6049\n",
            "Epoch: 184 MAE: 0.5644591211389611 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:22:20.691399 Epoch [185/250], Step [0001/0060], Loss1: -5.1907 Loss2: -5.0488 Loss3: -6.8634\n",
            "2022-08-02 12:22:45.914555 Epoch [185/250], Step [0050/0060], Loss1: -5.1514 Loss2: -5.0064 Loss3: -6.8232\n",
            "2022-08-02 12:22:51.032443 Epoch [185/250], Step [0060/0060], Loss1: -4.4374 Loss2: -4.2705 Loss3: -5.8438\n",
            "Epoch: 185 MAE: 0.5628277410275091 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:22:58.606055 Epoch [186/250], Step [0001/0060], Loss1: -5.4883 Loss2: -5.2348 Loss3: -7.1320\n",
            "2022-08-02 12:23:23.803062 Epoch [186/250], Step [0050/0060], Loss1: -5.1383 Loss2: -4.9234 Loss3: -6.7100\n",
            "2022-08-02 12:23:28.906081 Epoch [186/250], Step [0060/0060], Loss1: -3.7892 Loss2: -3.7846 Loss3: -5.1900\n",
            "Epoch: 186 MAE: 0.5618726546676072 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:23:34.193255 Epoch [187/250], Step [0001/0060], Loss1: -4.9720 Loss2: -4.8539 Loss3: -6.6077\n",
            "2022-08-02 12:23:59.396688 Epoch [187/250], Step [0050/0060], Loss1: -4.8218 Loss2: -4.6085 Loss3: -6.2952\n",
            "2022-08-02 12:24:04.550981 Epoch [187/250], Step [0060/0060], Loss1: -5.5016 Loss2: -5.2721 Loss3: -7.1708\n",
            "Epoch: 187 MAE: 0.5567170812213232 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:24:09.780285 Epoch [188/250], Step [0001/0060], Loss1: -5.6938 Loss2: -5.4094 Loss3: -7.3773\n",
            "2022-08-02 12:24:35.001574 Epoch [188/250], Step [0050/0060], Loss1: -4.7227 Loss2: -4.5894 Loss3: -6.2634\n",
            "2022-08-02 12:24:40.207528 Epoch [188/250], Step [0060/0060], Loss1: -5.6632 Loss2: -5.4743 Loss3: -7.4354\n",
            "Epoch: 188 MAE: 0.5573778150447461 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:24:45.416912 Epoch [189/250], Step [0001/0060], Loss1: -5.6138 Loss2: -5.3438 Loss3: -7.2712\n",
            "2022-08-02 12:25:10.667173 Epoch [189/250], Step [0050/0060], Loss1: -5.1119 Loss2: -4.8788 Loss3: -6.6485\n",
            "2022-08-02 12:25:15.879723 Epoch [189/250], Step [0060/0060], Loss1: -5.0898 Loss2: -4.9690 Loss3: -6.7588\n",
            "Epoch: 189 MAE: 0.5605250856106875 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:25:21.169669 Epoch [190/250], Step [0001/0060], Loss1: -4.7082 Loss2: -4.5095 Loss3: -6.1539\n",
            "2022-08-02 12:25:46.264519 Epoch [190/250], Step [0050/0060], Loss1: -4.2554 Loss2: -4.1298 Loss3: -5.6648\n",
            "2022-08-02 12:25:51.375812 Epoch [190/250], Step [0060/0060], Loss1: -4.7242 Loss2: -4.6919 Loss3: -6.3774\n",
            "Epoch: 190 MAE: 0.5638571344607722 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:25:58.710902 Epoch [191/250], Step [0001/0060], Loss1: -5.0503 Loss2: -4.8661 Loss3: -6.6278\n",
            "2022-08-02 12:26:24.038350 Epoch [191/250], Step [0050/0060], Loss1: -5.7864 Loss2: -5.4891 Loss3: -7.4630\n",
            "2022-08-02 12:26:29.136573 Epoch [191/250], Step [0060/0060], Loss1: -4.5537 Loss2: -4.3466 Loss3: -5.9450\n",
            "Epoch: 191 MAE: 0.5626628960503472 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:26:34.341321 Epoch [192/250], Step [0001/0060], Loss1: -3.9549 Loss2: -3.8705 Loss3: -5.2983\n",
            "2022-08-02 12:26:59.596291 Epoch [192/250], Step [0050/0060], Loss1: -4.4526 Loss2: -4.4005 Loss3: -6.0083\n",
            "2022-08-02 12:27:04.760775 Epoch [192/250], Step [0060/0060], Loss1: -5.0153 Loss2: -4.8850 Loss3: -6.6594\n",
            "Epoch: 192 MAE: 0.560758939066892 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:27:09.957486 Epoch [193/250], Step [0001/0060], Loss1: -4.8461 Loss2: -4.6713 Loss3: -6.3764\n",
            "2022-08-02 12:27:35.103699 Epoch [193/250], Step [0050/0060], Loss1: -5.8309 Loss2: -5.5240 Loss3: -7.5207\n",
            "2022-08-02 12:27:40.220678 Epoch [193/250], Step [0060/0060], Loss1: -5.7235 Loss2: -5.4694 Loss3: -7.4467\n",
            "Epoch: 193 MAE: 0.5648713078574528 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:27:45.426194 Epoch [194/250], Step [0001/0060], Loss1: -5.9592 Loss2: -5.6877 Loss3: -7.7256\n",
            "2022-08-02 12:28:10.699133 Epoch [194/250], Step [0050/0060], Loss1: -5.4955 Loss2: -5.3147 Loss3: -7.2271\n",
            "2022-08-02 12:28:15.864725 Epoch [194/250], Step [0060/0060], Loss1: -4.5149 Loss2: -4.3457 Loss3: -5.9464\n",
            "Epoch: 194 MAE: 0.5581520920203479 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:28:21.057154 Epoch [195/250], Step [0001/0060], Loss1: -5.7675 Loss2: -5.4982 Loss3: -7.4827\n",
            "2022-08-02 12:28:46.114606 Epoch [195/250], Step [0050/0060], Loss1: -5.8742 Loss2: -5.6273 Loss3: -7.6417\n",
            "2022-08-02 12:28:51.237486 Epoch [195/250], Step [0060/0060], Loss1: -5.6888 Loss2: -5.4675 Loss3: -7.4305\n",
            "Epoch: 195 MAE: 0.5578208229024573 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:28:58.734782 Epoch [196/250], Step [0001/0060], Loss1: -4.6043 Loss2: -4.4870 Loss3: -6.1213\n",
            "2022-08-02 12:29:23.894384 Epoch [196/250], Step [0050/0060], Loss1: -4.5773 Loss2: -4.3806 Loss3: -5.9968\n",
            "2022-08-02 12:29:29.041151 Epoch [196/250], Step [0060/0060], Loss1: -5.7091 Loss2: -5.4695 Loss3: -7.4350\n",
            "Epoch: 196 MAE: 0.5651135754459119 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:29:34.328731 Epoch [197/250], Step [0001/0060], Loss1: -4.5792 Loss2: -4.3869 Loss3: -5.9953\n",
            "2022-08-02 12:29:59.484714 Epoch [197/250], Step [0050/0060], Loss1: -5.0503 Loss2: -4.9035 Loss3: -6.6758\n",
            "2022-08-02 12:30:04.588675 Epoch [197/250], Step [0060/0060], Loss1: -5.9614 Loss2: -5.6655 Loss3: -7.7102\n",
            "Epoch: 197 MAE: 0.5597984951766081 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:30:09.934857 Epoch [198/250], Step [0001/0060], Loss1: -6.0676 Loss2: -5.7487 Loss3: -7.8281\n",
            "2022-08-02 12:30:35.171450 Epoch [198/250], Step [0050/0060], Loss1: -6.3356 Loss2: -6.0177 Loss3: -8.1731\n",
            "2022-08-02 12:30:40.279389 Epoch [198/250], Step [0060/0060], Loss1: -5.4249 Loss2: -5.3112 Loss3: -7.2171\n",
            "Epoch: 198 MAE: 0.5597448528632915 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:30:45.651987 Epoch [199/250], Step [0001/0060], Loss1: -4.6323 Loss2: -4.4370 Loss3: -6.0670\n",
            "2022-08-02 12:31:10.807922 Epoch [199/250], Step [0050/0060], Loss1: -4.5804 Loss2: -4.3870 Loss3: -6.0086\n",
            "2022-08-02 12:31:15.926760 Epoch [199/250], Step [0060/0060], Loss1: -3.6287 Loss2: -3.5989 Loss3: -4.9379\n",
            "Epoch: 199 MAE: 0.5629339163643975 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:31:21.210538 Epoch [200/250], Step [0001/0060], Loss1: -5.1584 Loss2: -5.0244 Loss3: -6.8417\n",
            "2022-08-02 12:31:46.339158 Epoch [200/250], Step [0050/0060], Loss1: -4.4511 Loss2: -4.2725 Loss3: -5.8437\n",
            "2022-08-02 12:31:51.442270 Epoch [200/250], Step [0060/0060], Loss1: -4.7772 Loss2: -4.6522 Loss3: -6.3554\n",
            "Epoch: 200 MAE: 0.5592089851823432 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:31:58.848670 Epoch [201/250], Step [0001/0060], Loss1: -4.6512 Loss2: -4.4676 Loss3: -6.1125\n",
            "2022-08-02 12:32:24.113364 Epoch [201/250], Step [0050/0060], Loss1: -5.7699 Loss2: -5.4996 Loss3: -7.4847\n",
            "2022-08-02 12:32:29.210183 Epoch [201/250], Step [0060/0060], Loss1: -5.9539 Loss2: -5.7099 Loss3: -7.7683\n",
            "Epoch: 201 MAE: 0.5579106253164787 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:32:34.504197 Epoch [202/250], Step [0001/0060], Loss1: -4.7429 Loss2: -4.5497 Loss3: -6.2084\n",
            "2022-08-02 12:32:59.607719 Epoch [202/250], Step [0050/0060], Loss1: -5.5904 Loss2: -5.3647 Loss3: -7.2991\n",
            "2022-08-02 12:33:04.754259 Epoch [202/250], Step [0060/0060], Loss1: -4.3039 Loss2: -4.1858 Loss3: -5.7402\n",
            "Epoch: 202 MAE: 0.5674838369864004 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:33:10.021663 Epoch [203/250], Step [0001/0060], Loss1: -5.4496 Loss2: -5.2344 Loss3: -7.1162\n",
            "2022-08-02 12:33:35.258792 Epoch [203/250], Step [0050/0060], Loss1: -5.1867 Loss2: -4.9820 Loss3: -6.7836\n",
            "2022-08-02 12:33:40.385244 Epoch [203/250], Step [0060/0060], Loss1: -5.5223 Loss2: -5.2950 Loss3: -7.2154\n",
            "Epoch: 203 MAE: 0.5643292091006327 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:33:45.689132 Epoch [204/250], Step [0001/0060], Loss1: -5.6471 Loss2: -5.4365 Loss3: -7.3817\n",
            "2022-08-02 12:34:10.807144 Epoch [204/250], Step [0050/0060], Loss1: -4.4505 Loss2: -4.3729 Loss3: -5.9647\n",
            "2022-08-02 12:34:15.911507 Epoch [204/250], Step [0060/0060], Loss1: -3.4350 Loss2: -3.3918 Loss3: -4.6683\n",
            "Epoch: 204 MAE: 0.5628096258577218 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:34:21.223854 Epoch [205/250], Step [0001/0060], Loss1: -5.4341 Loss2: -5.2302 Loss3: -7.1219\n",
            "2022-08-02 12:34:46.439751 Epoch [205/250], Step [0050/0060], Loss1: -4.0727 Loss2: -3.9350 Loss3: -5.4172\n",
            "2022-08-02 12:34:51.557285 Epoch [205/250], Step [0060/0060], Loss1: -5.1266 Loss2: -5.0066 Loss3: -6.8222\n",
            "Epoch: 205 MAE: 0.5577948006120308 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:34:58.892132 Epoch [206/250], Step [0001/0060], Loss1: -4.1431 Loss2: -4.0229 Loss3: -5.5029\n",
            "2022-08-02 12:35:24.374739 Epoch [206/250], Step [0050/0060], Loss1: -4.1694 Loss2: -4.0007 Loss3: -5.4775\n",
            "2022-08-02 12:35:29.546271 Epoch [206/250], Step [0060/0060], Loss1: -5.0650 Loss2: -4.8498 Loss3: -6.6022\n",
            "Epoch: 206 MAE: 0.5621207649997934 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:35:34.751203 Epoch [207/250], Step [0001/0060], Loss1: -4.7670 Loss2: -4.6492 Loss3: -6.3563\n",
            "2022-08-02 12:35:59.910933 Epoch [207/250], Step [0050/0060], Loss1: -5.7926 Loss2: -5.5370 Loss3: -7.5357\n",
            "2022-08-02 12:36:05.076415 Epoch [207/250], Step [0060/0060], Loss1: -5.6283 Loss2: -5.4827 Loss3: -7.4166\n",
            "Epoch: 207 MAE: 0.5621532420001963 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:36:10.333645 Epoch [208/250], Step [0001/0060], Loss1: -5.5849 Loss2: -5.3516 Loss3: -7.2697\n",
            "2022-08-02 12:36:35.503021 Epoch [208/250], Step [0050/0060], Loss1: -4.6572 Loss2: -4.4722 Loss3: -6.1020\n",
            "2022-08-02 12:36:40.662605 Epoch [208/250], Step [0060/0060], Loss1: -5.8501 Loss2: -5.6250 Loss3: -7.6411\n",
            "Epoch: 208 MAE: 0.5603815318919994 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:36:45.928958 Epoch [209/250], Step [0001/0060], Loss1: -5.4506 Loss2: -5.2495 Loss3: -7.1508\n",
            "2022-08-02 12:37:10.978365 Epoch [209/250], Step [0050/0060], Loss1: -4.2187 Loss2: -4.0848 Loss3: -5.5943\n",
            "2022-08-02 12:37:16.093288 Epoch [209/250], Step [0060/0060], Loss1: -5.5318 Loss2: -5.4327 Loss3: -7.3290\n",
            "Epoch: 209 MAE: 0.5607037942876261 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:37:21.419034 Epoch [210/250], Step [0001/0060], Loss1: -3.7439 Loss2: -3.6954 Loss3: -5.0458\n",
            "2022-08-02 12:37:46.490570 Epoch [210/250], Step [0050/0060], Loss1: -5.4578 Loss2: -5.3126 Loss3: -7.2030\n",
            "2022-08-02 12:37:51.635011 Epoch [210/250], Step [0060/0060], Loss1: -5.8328 Loss2: -5.6223 Loss3: -7.6315\n",
            "Epoch: 210 MAE: 0.5628750973656066 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:37:58.999969 Epoch [211/250], Step [0001/0060], Loss1: -5.8747 Loss2: -5.6444 Loss3: -7.6636\n",
            "2022-08-02 12:38:24.122468 Epoch [211/250], Step [0050/0060], Loss1: -4.1145 Loss2: -4.1418 Loss3: -5.6382\n",
            "2022-08-02 12:38:29.237781 Epoch [211/250], Step [0060/0060], Loss1: -4.7336 Loss2: -4.6163 Loss3: -6.2955\n",
            "Epoch: 211 MAE: 0.5660545591324093 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:38:34.461399 Epoch [212/250], Step [0001/0060], Loss1: -4.7248 Loss2: -4.6022 Loss3: -6.2776\n",
            "2022-08-02 12:38:59.762710 Epoch [212/250], Step [0050/0060], Loss1: -5.3449 Loss2: -5.1215 Loss3: -6.9728\n",
            "2022-08-02 12:39:04.979569 Epoch [212/250], Step [0060/0060], Loss1: -4.9643 Loss2: -4.7818 Loss3: -6.5327\n",
            "Epoch: 212 MAE: 0.5592670783794748 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:39:10.227009 Epoch [213/250], Step [0001/0060], Loss1: -4.9292 Loss2: -4.8070 Loss3: -6.5481\n",
            "2022-08-02 12:39:35.312196 Epoch [213/250], Step [0050/0060], Loss1: -4.2627 Loss2: -4.1209 Loss3: -5.6541\n",
            "2022-08-02 12:39:40.424534 Epoch [213/250], Step [0060/0060], Loss1: -5.1068 Loss2: -4.8965 Loss3: -6.6751\n",
            "Epoch: 213 MAE: 0.5634849693661645 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:39:45.821571 Epoch [214/250], Step [0001/0060], Loss1: -4.7177 Loss2: -4.5750 Loss3: -6.2707\n",
            "2022-08-02 12:40:10.948175 Epoch [214/250], Step [0050/0060], Loss1: -5.8598 Loss2: -5.6937 Loss3: -7.7027\n",
            "2022-08-02 12:40:16.185668 Epoch [214/250], Step [0060/0060], Loss1: -5.6442 Loss2: -5.4015 Loss3: -7.3456\n",
            "Epoch: 214 MAE: 0.5575412051892156 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:40:21.602139 Epoch [215/250], Step [0001/0060], Loss1: -6.0433 Loss2: -5.7510 Loss3: -7.8032\n",
            "2022-08-02 12:40:47.043470 Epoch [215/250], Step [0050/0060], Loss1: -5.2087 Loss2: -5.0643 Loss3: -6.8642\n",
            "2022-08-02 12:40:52.167162 Epoch [215/250], Step [0060/0060], Loss1: -4.7039 Loss2: -4.5017 Loss3: -6.1536\n",
            "Epoch: 215 MAE: 0.5605995565747459 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:40:59.972579 Epoch [216/250], Step [0001/0060], Loss1: -5.5222 Loss2: -5.3394 Loss3: -7.2604\n",
            "2022-08-02 12:41:25.503342 Epoch [216/250], Step [0050/0060], Loss1: -5.5479 Loss2: -5.3524 Loss3: -7.2707\n",
            "2022-08-02 12:41:30.644765 Epoch [216/250], Step [0060/0060], Loss1: -4.8677 Loss2: -4.6852 Loss3: -6.3952\n",
            "Epoch: 216 MAE: 0.5656338258773561 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:41:35.816510 Epoch [217/250], Step [0001/0060], Loss1: -5.4268 Loss2: -5.2593 Loss3: -7.1452\n",
            "2022-08-02 12:42:01.228077 Epoch [217/250], Step [0050/0060], Loss1: -5.4227 Loss2: -5.2407 Loss3: -7.1271\n",
            "2022-08-02 12:42:06.365249 Epoch [217/250], Step [0060/0060], Loss1: -5.6985 Loss2: -5.4155 Loss3: -7.3670\n",
            "Epoch: 217 MAE: 0.5594409882076203 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:42:12.034411 Epoch [218/250], Step [0001/0060], Loss1: -5.7866 Loss2: -5.5770 Loss3: -7.5601\n",
            "2022-08-02 12:42:37.297021 Epoch [218/250], Step [0050/0060], Loss1: -5.2066 Loss2: -5.0574 Loss3: -6.8761\n",
            "2022-08-02 12:42:42.429787 Epoch [218/250], Step [0060/0060], Loss1: -6.6256 Loss2: -6.2551 Loss3: -8.5126\n",
            "Epoch: 218 MAE: 0.5610546188758163 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:42:48.126268 Epoch [219/250], Step [0001/0060], Loss1: -4.4880 Loss2: -4.3581 Loss3: -5.9596\n",
            "2022-08-02 12:43:13.383248 Epoch [219/250], Step [0050/0060], Loss1: -4.5779 Loss2: -4.4487 Loss3: -6.0610\n",
            "2022-08-02 12:43:18.490667 Epoch [219/250], Step [0060/0060], Loss1: -4.2660 Loss2: -4.1322 Loss3: -5.6547\n",
            "Epoch: 219 MAE: 0.5656874698053592 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:43:23.906954 Epoch [220/250], Step [0001/0060], Loss1: -5.4303 Loss2: -5.2437 Loss3: -7.1333\n",
            "2022-08-02 12:43:49.156450 Epoch [220/250], Step [0050/0060], Loss1: -5.4775 Loss2: -5.3312 Loss3: -7.2232\n",
            "2022-08-02 12:43:54.248449 Epoch [220/250], Step [0060/0060], Loss1: -5.8873 Loss2: -5.6940 Loss3: -7.7312\n",
            "Epoch: 220 MAE: 0.5599743482801651 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:44:01.735967 Epoch [221/250], Step [0001/0060], Loss1: -4.6175 Loss2: -4.4904 Loss3: -6.1220\n",
            "2022-08-02 12:44:27.161327 Epoch [221/250], Step [0050/0060], Loss1: -6.1409 Loss2: -5.8364 Loss3: -7.9225\n",
            "2022-08-02 12:44:32.305810 Epoch [221/250], Step [0060/0060], Loss1: -4.7064 Loss2: -4.6016 Loss3: -6.2853\n",
            "Epoch: 221 MAE: 0.5633616686624193 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:44:37.609814 Epoch [222/250], Step [0001/0060], Loss1: -6.0190 Loss2: -5.7325 Loss3: -7.7964\n",
            "2022-08-02 12:45:02.713606 Epoch [222/250], Step [0050/0060], Loss1: -5.5491 Loss2: -5.3022 Loss3: -7.2201\n",
            "2022-08-02 12:45:07.820801 Epoch [222/250], Step [0060/0060], Loss1: -5.5491 Loss2: -5.3018 Loss3: -7.2140\n",
            "Epoch: 222 MAE: 0.5578229962707197 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:45:13.158294 Epoch [223/250], Step [0001/0060], Loss1: -5.5371 Loss2: -5.2973 Loss3: -7.2215\n",
            "2022-08-02 12:45:38.433191 Epoch [223/250], Step [0050/0060], Loss1: -5.9457 Loss2: -5.6564 Loss3: -7.6817\n",
            "2022-08-02 12:45:43.659464 Epoch [223/250], Step [0060/0060], Loss1: -5.4352 Loss2: -5.2120 Loss3: -7.0812\n",
            "Epoch: 223 MAE: 0.5596852798058243 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:45:49.042787 Epoch [224/250], Step [0001/0060], Loss1: -5.2280 Loss2: -5.0783 Loss3: -6.9024\n",
            "2022-08-02 12:46:14.214778 Epoch [224/250], Step [0050/0060], Loss1: -5.7872 Loss2: -5.5097 Loss3: -7.4937\n",
            "2022-08-02 12:46:19.426861 Epoch [224/250], Step [0060/0060], Loss1: -4.9653 Loss2: -4.7690 Loss3: -6.5163\n",
            "Epoch: 224 MAE: 0.5639939404038523 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:46:24.737144 Epoch [225/250], Step [0001/0060], Loss1: -5.0464 Loss2: -4.8718 Loss3: -6.6424\n",
            "2022-08-02 12:46:49.870740 Epoch [225/250], Step [0050/0060], Loss1: -5.3499 Loss2: -5.2007 Loss3: -7.0704\n",
            "2022-08-02 12:46:55.048446 Epoch [225/250], Step [0060/0060], Loss1: -5.0683 Loss2: -4.9542 Loss3: -6.7516\n",
            "Epoch: 225 MAE: 0.5650082833426339 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:47:02.512468 Epoch [226/250], Step [0001/0060], Loss1: -5.0579 Loss2: -4.8992 Loss3: -6.6831\n",
            "2022-08-02 12:47:28.067688 Epoch [226/250], Step [0050/0060], Loss1: -5.5146 Loss2: -5.3422 Loss3: -7.2755\n",
            "2022-08-02 12:47:33.180556 Epoch [226/250], Step [0060/0060], Loss1: -5.6232 Loss2: -5.4321 Loss3: -7.3733\n",
            "Epoch: 226 MAE: 0.5576942605316324 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:47:38.468811 Epoch [227/250], Step [0001/0060], Loss1: -4.7005 Loss2: -4.5238 Loss3: -6.1832\n",
            "2022-08-02 12:48:03.773796 Epoch [227/250], Step [0050/0060], Loss1: -5.9925 Loss2: -5.7141 Loss3: -7.7695\n",
            "2022-08-02 12:48:08.902895 Epoch [227/250], Step [0060/0060], Loss1: -5.5256 Loss2: -5.3177 Loss3: -7.2307\n",
            "Epoch: 227 MAE: 0.5575681970989892 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:48:14.277414 Epoch [228/250], Step [0001/0060], Loss1: -5.9704 Loss2: -5.6822 Loss3: -7.7401\n",
            "2022-08-02 12:48:39.409129 Epoch [228/250], Step [0050/0060], Loss1: -5.5741 Loss2: -5.3528 Loss3: -7.2793\n",
            "2022-08-02 12:48:44.556186 Epoch [228/250], Step [0060/0060], Loss1: -5.1707 Loss2: -4.9942 Loss3: -6.8073\n",
            "Epoch: 228 MAE: 0.5618766978430368 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:48:49.811980 Epoch [229/250], Step [0001/0060], Loss1: -4.8112 Loss2: -4.6841 Loss3: -6.3959\n",
            "2022-08-02 12:49:15.059992 Epoch [229/250], Step [0050/0060], Loss1: -4.7903 Loss2: -4.6128 Loss3: -6.2902\n",
            "2022-08-02 12:49:20.187663 Epoch [229/250], Step [0060/0060], Loss1: -4.4274 Loss2: -4.4595 Loss3: -6.0455\n",
            "Epoch: 229 MAE: 0.5653552302607785 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:49:25.524529 Epoch [230/250], Step [0001/0060], Loss1: -4.5508 Loss2: -4.4606 Loss3: -6.0947\n",
            "2022-08-02 12:49:50.788009 Epoch [230/250], Step [0050/0060], Loss1: -5.2079 Loss2: -5.0280 Loss3: -6.8464\n",
            "2022-08-02 12:49:55.902408 Epoch [230/250], Step [0060/0060], Loss1: -5.6019 Loss2: -5.4239 Loss3: -7.3585\n",
            "Epoch: 230 MAE: 0.5574179125589039 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:50:03.372961 Epoch [231/250], Step [0001/0060], Loss1: -5.7710 Loss2: -5.5227 Loss3: -7.5198\n",
            "2022-08-02 12:50:28.674122 Epoch [231/250], Step [0050/0060], Loss1: -4.1841 Loss2: -4.0216 Loss3: -5.5292\n",
            "2022-08-02 12:50:33.796072 Epoch [231/250], Step [0060/0060], Loss1: -5.8733 Loss2: -5.6046 Loss3: -7.6220\n",
            "Epoch: 231 MAE: 0.5594704263677042 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:50:39.102000 Epoch [232/250], Step [0001/0060], Loss1: -6.0155 Loss2: -5.7363 Loss3: -7.7901\n",
            "2022-08-02 12:51:04.442970 Epoch [232/250], Step [0050/0060], Loss1: -5.1167 Loss2: -4.9094 Loss3: -6.6946\n",
            "2022-08-02 12:51:09.594065 Epoch [232/250], Step [0060/0060], Loss1: -5.3110 Loss2: -5.0574 Loss3: -6.8776\n",
            "Epoch: 232 MAE: 0.5631472415015812 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:51:14.850658 Epoch [233/250], Step [0001/0060], Loss1: -5.3771 Loss2: -5.1393 Loss3: -7.0005\n",
            "2022-08-02 12:51:39.993234 Epoch [233/250], Step [0050/0060], Loss1: -5.8726 Loss2: -5.5858 Loss3: -7.5851\n",
            "2022-08-02 12:51:45.157850 Epoch [233/250], Step [0060/0060], Loss1: -4.4899 Loss2: -4.3162 Loss3: -5.8996\n",
            "Epoch: 233 MAE: 0.5637016578956885 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:51:50.449094 Epoch [234/250], Step [0001/0060], Loss1: -4.6264 Loss2: -4.5755 Loss3: -6.2353\n",
            "2022-08-02 12:52:15.660457 Epoch [234/250], Step [0050/0060], Loss1: -5.6249 Loss2: -5.4311 Loss3: -7.3867\n",
            "2022-08-02 12:52:20.768191 Epoch [234/250], Step [0060/0060], Loss1: -5.7117 Loss2: -5.5389 Loss3: -7.5139\n",
            "Epoch: 234 MAE: 0.560568315616991 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:52:26.035857 Epoch [235/250], Step [0001/0060], Loss1: -5.4717 Loss2: -5.1893 Loss3: -7.0657\n",
            "2022-08-02 12:52:51.243627 Epoch [235/250], Step [0050/0060], Loss1: -4.5268 Loss2: -4.4642 Loss3: -6.0964\n",
            "2022-08-02 12:52:56.340462 Epoch [235/250], Step [0060/0060], Loss1: -4.2980 Loss2: -4.1589 Loss3: -5.6975\n",
            "Epoch: 235 MAE: 0.5643231742091912 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:53:03.684498 Epoch [236/250], Step [0001/0060], Loss1: -5.5049 Loss2: -5.3006 Loss3: -7.2074\n",
            "2022-08-02 12:53:28.956219 Epoch [236/250], Step [0050/0060], Loss1: -5.2104 Loss2: -5.0999 Loss3: -6.9302\n",
            "2022-08-02 12:53:34.141143 Epoch [236/250], Step [0060/0060], Loss1: -5.1347 Loss2: -5.0002 Loss3: -6.8045\n",
            "Epoch: 236 MAE: 0.5603565954783608 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:53:39.404500 Epoch [237/250], Step [0001/0060], Loss1: -4.9307 Loss2: -4.7100 Loss3: -6.4248\n",
            "2022-08-02 12:54:04.704985 Epoch [237/250], Step [0050/0060], Loss1: -5.2040 Loss2: -5.0152 Loss3: -6.8257\n",
            "2022-08-02 12:54:09.866452 Epoch [237/250], Step [0060/0060], Loss1: -5.5512 Loss2: -5.3123 Loss3: -7.2239\n",
            "Epoch: 237 MAE: 0.5607104128883 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:54:15.089230 Epoch [238/250], Step [0001/0060], Loss1: -4.4064 Loss2: -4.3427 Loss3: -5.9319\n",
            "2022-08-02 12:54:40.251358 Epoch [238/250], Step [0050/0060], Loss1: -5.4425 Loss2: -5.1689 Loss3: -7.0473\n",
            "2022-08-02 12:54:45.377696 Epoch [238/250], Step [0060/0060], Loss1: -5.8607 Loss2: -5.5987 Loss3: -7.6030\n",
            "Epoch: 238 MAE: 0.5561109359176067 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:54:50.741187 Epoch [239/250], Step [0001/0060], Loss1: -5.4989 Loss2: -5.2813 Loss3: -7.1861\n",
            "2022-08-02 12:55:15.857802 Epoch [239/250], Step [0050/0060], Loss1: -6.3896 Loss2: -6.0694 Loss3: -8.2415\n",
            "2022-08-02 12:55:20.988997 Epoch [239/250], Step [0060/0060], Loss1: -6.0877 Loss2: -5.8317 Loss3: -7.9019\n",
            "Epoch: 239 MAE: 0.5558380797048096 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:55:26.254310 Epoch [240/250], Step [0001/0060], Loss1: -4.8999 Loss2: -4.7465 Loss3: -6.4897\n",
            "2022-08-02 12:55:51.617441 Epoch [240/250], Step [0050/0060], Loss1: -5.3612 Loss2: -5.2002 Loss3: -7.0757\n",
            "2022-08-02 12:55:56.796405 Epoch [240/250], Step [0060/0060], Loss1: -5.3046 Loss2: -5.0864 Loss3: -6.9198\n",
            "Epoch: 240 MAE: 0.5616367182655941 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:56:04.487041 Epoch [241/250], Step [0001/0060], Loss1: -4.9337 Loss2: -4.7196 Loss3: -6.4532\n",
            "2022-08-02 12:56:30.023594 Epoch [241/250], Step [0050/0060], Loss1: -5.4027 Loss2: -5.1692 Loss3: -7.0377\n",
            "2022-08-02 12:56:35.184165 Epoch [241/250], Step [0060/0060], Loss1: -4.5823 Loss2: -4.4248 Loss3: -6.0422\n",
            "Epoch: 241 MAE: 0.5597560426419373 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:56:40.497421 Epoch [242/250], Step [0001/0060], Loss1: -6.0520 Loss2: -5.7626 Loss3: -7.8333\n",
            "2022-08-02 12:57:05.728139 Epoch [242/250], Step [0050/0060], Loss1: -4.6866 Loss2: -4.4741 Loss3: -6.1151\n",
            "2022-08-02 12:57:10.834375 Epoch [242/250], Step [0060/0060], Loss1: -4.8824 Loss2: -4.7108 Loss3: -6.4307\n",
            "Epoch: 242 MAE: 0.5618355136447482 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:57:16.092630 Epoch [243/250], Step [0001/0060], Loss1: -5.5009 Loss2: -5.3182 Loss3: -7.2397\n",
            "2022-08-02 12:57:41.556862 Epoch [243/250], Step [0050/0060], Loss1: -5.9290 Loss2: -5.6418 Loss3: -7.6679\n",
            "2022-08-02 12:57:46.711705 Epoch [243/250], Step [0060/0060], Loss1: -5.3246 Loss2: -5.1146 Loss3: -6.9670\n",
            "Epoch: 243 MAE: 0.5601718753229373 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:57:51.968433 Epoch [244/250], Step [0001/0060], Loss1: -5.3286 Loss2: -5.1302 Loss3: -6.9926\n",
            "2022-08-02 12:58:17.242662 Epoch [244/250], Step [0050/0060], Loss1: -5.4425 Loss2: -5.2593 Loss3: -7.1502\n",
            "2022-08-02 12:58:22.363318 Epoch [244/250], Step [0060/0060], Loss1: -5.6483 Loss2: -5.4312 Loss3: -7.3821\n",
            "Epoch: 244 MAE: 0.5632374766516307 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:58:27.800374 Epoch [245/250], Step [0001/0060], Loss1: -5.0816 Loss2: -4.9283 Loss3: -6.7117\n",
            "2022-08-02 12:58:53.486451 Epoch [245/250], Step [0050/0060], Loss1: -5.6466 Loss2: -5.4336 Loss3: -7.3947\n",
            "2022-08-02 12:58:58.688905 Epoch [245/250], Step [0060/0060], Loss1: -5.6831 Loss2: -5.4481 Loss3: -7.4005\n",
            "Epoch: 245 MAE: 0.5618652505218669 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:59:06.522176 Epoch [246/250], Step [0001/0060], Loss1: -5.5648 Loss2: -5.3515 Loss3: -7.2824\n",
            "2022-08-02 12:59:32.278932 Epoch [246/250], Step [0050/0060], Loss1: -4.7428 Loss2: -4.5394 Loss3: -6.1956\n",
            "2022-08-02 12:59:37.453286 Epoch [246/250], Step [0060/0060], Loss1: -5.7653 Loss2: -5.5462 Loss3: -7.5336\n",
            "Epoch: 246 MAE: 0.5611760295888104 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 12:59:43.088570 Epoch [247/250], Step [0001/0060], Loss1: -5.2877 Loss2: -5.1054 Loss3: -6.9422\n",
            "2022-08-02 13:00:08.455309 Epoch [247/250], Step [0050/0060], Loss1: -4.7199 Loss2: -4.5911 Loss3: -6.2753\n",
            "2022-08-02 13:00:13.619834 Epoch [247/250], Step [0060/0060], Loss1: -5.4417 Loss2: -5.2661 Loss3: -7.1659\n",
            "Epoch: 247 MAE: 0.5556043602675989 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 13:00:19.123319 Epoch [248/250], Step [0001/0060], Loss1: -4.7427 Loss2: -4.5708 Loss3: -6.2410\n",
            "2022-08-02 13:00:44.358554 Epoch [248/250], Step [0050/0060], Loss1: -5.1588 Loss2: -4.9613 Loss3: -6.7614\n",
            "2022-08-02 13:00:49.585692 Epoch [248/250], Step [0060/0060], Loss1: -6.0412 Loss2: -5.7372 Loss3: -7.7949\n",
            "Epoch: 248 MAE: 0.5622549721046731 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n",
            "2022-08-02 13:00:55.123134 Epoch [249/250], Step [0001/0060], Loss1: -5.5122 Loss2: -5.2993 Loss3: -7.2100\n",
            "2022-08-02 13:01:20.634699 Epoch [249/250], Step [0050/0060], Loss1: -4.2361 Loss2: -4.1045 Loss3: -5.6220\n",
            "2022-08-02 13:01:25.841124 Epoch [249/250], Step [0060/0060], Loss1: -5.3206 Loss2: -5.0891 Loss3: -6.9313\n",
            "Epoch: 249 MAE: 0.5612931129415198 ####  bestMAE: 0.14971622103736518 bestEpoch: 5\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "def structure_loss(pred, mask):\n",
        "    weit  = 1+5*torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15)-mask)\n",
        "    wbce  = F.binary_cross_entropy_with_logits(pred, mask, reduce='none')\n",
        "    wbce  = (weit*wbce).sum(dim=(2,3))/weit.sum(dim=(2,3))\n",
        "\n",
        "    pred  = torch.sigmoid(pred)\n",
        "    inter = ((pred*mask)*weit).sum(dim=(2,3))\n",
        "    union = ((pred+mask)*weit).sum(dim=(2,3))\n",
        "    wiou  = 1-(inter+1)/(union-inter+1)\n",
        "    return (wbce+wiou).mean()\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "train_accu = []\n",
        "train_losses = []\n",
        "train_accu1 = []\n",
        "train_accu2 = []\n",
        "train_accu3 = []\n",
        "train_losses1 = []\n",
        "train_losses2 = []\n",
        "train_losses3 = []\n",
        "val_accu = []\n",
        "val_losses = []\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    running_loss = 0\n",
        "    running_loss1 = 0\n",
        "    running_loss2 = 0\n",
        "    running_loss3 = 0\n",
        "    total = 0\n",
        "    total1 = 0\n",
        "    total2 = 0\n",
        "    total3 = 0\n",
        "    correct = 0\n",
        "    correct1 = 0\n",
        "    correct2 = 0\n",
        "    correct3 = 0\n",
        "\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = structure_loss(gts, pre_res[0])\n",
        "            loss2    = structure_loss(gts, pre_res[1])\n",
        "            loss3    = structure_loss(gts, pre_res[2])\n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "\n",
        "            #loss graph\n",
        "            running_loss1 += loss1.item()\n",
        "            running_loss2 += loss2.item()\n",
        "            running_loss3 += loss3.item()\n",
        "            predicted1 = pre_res[0]\n",
        "            predicted2 = pre_res[1]\n",
        "            predicted3 = pre_res[2]\n",
        "            total1 += images.size(0)\n",
        "            total2 += gts.size(0)\n",
        "            total3 += depths.size(0)\n",
        "            correct1 += predicted1.eq(images).sum().item()\n",
        "            correct2 += predicted2.eq(gts).sum().item()\n",
        "            correct3 += predicted3.eq(depths).sum().item()\n",
        "\n",
        "            running_loss += loss_all.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = gt + loss + predicted\n",
        "            total += images.size(0)\n",
        "            correct += outputs.eq(images).sum().item()\n",
        "            \n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "\n",
        "        train_loss = running_loss/len(train_loader)\n",
        "        train_loss1=running_loss1/len(train_loader)\n",
        "        train_loss2=running_loss2/len(train_loader)\n",
        "        train_loss3=running_loss3/len(train_loader)\n",
        "        accu = 100.*correct/total\n",
        "        accu1=100.*correct1/total1\n",
        "        accu2=100.*correct2/total2\n",
        "        accu3=100.*correct3/total3        \n",
        "        train_accu1.append(accu1)\n",
        "        train_accu2.append(accu2)\n",
        "        train_accu3.append(accu3)\n",
        "        train_losses1.append(train_loss1)\n",
        "        train_losses2.append(train_loss2)\n",
        "        train_losses3.append(train_loss3)\n",
        "        train_accu.append(accu)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "           \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-8)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "            mae_sum += np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "\n",
        "            #loss graph\n",
        "            running_loss += mae_sum.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = gt + loss + predicted\n",
        "            total += test_loader.size\n",
        "            correct += outputs.eq(image).sum().item()\n",
        "\n",
        "\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "       \n",
        "        val_loss=running_loss/len(test_loader)\n",
        "        accu=100.*correct/total\n",
        "        val_accu.append(accu)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_best_epoch_structure_loss.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n",
        "\n",
        "plt.plot(train_losses, '-')\n",
        "plt.plot(train_losses1,'-')\n",
        "plt.plot(train_losses2,'-')\n",
        "plt.plot(train_losses3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['SSIM Loss','Loss1', 'Loss2', 'Loss3'])\n",
        "plt.title('Train Losses')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_accu, '-')\n",
        "plt.plot(train_accu1,'-')\n",
        "plt.plot(train_accu2,'-')\n",
        "plt.plot(train_accu3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Accuracy','Acc1', 'Acc2', 'Acc3'])\n",
        "plt.title('Train Accuracy')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(val_losses,'-o')\n",
        "plt.plot(val_accu,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Losses','Accuracy'])\n",
        "plt.title('Test Losses and Accuracy')\n",
        " \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL3_39G6PkKb"
      },
      "source": [
        "### Training with ssim and psnr metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iWglYVOVPobs",
        "outputId": "a0cf2ea6-2be0-4684-a301-7ea4078aa872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE GPU 0\n",
            "load data...\n",
            "/content/tmp/traindataset/RGB/ /content/tmp/traindataset/GT/ /content/tmp/traindataset/depth/\n",
            "/content/tmp/traindataset/RGB/ /content/tmp/traindataset/GT/ /content/tmp/traindataset/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/traindataset/RGB/RGB_00.png', '/content/tmp/traindataset/RGB/RGB_01.png', '/content/tmp/traindataset/RGB/RGB_02.png', '/content/tmp/traindataset/RGB/RGB_10.png', '/content/tmp/traindataset/RGB/RGB_100.png', '/content/tmp/traindataset/RGB/RGB_101.png', '/content/tmp/traindataset/RGB/RGB_102.png', '/content/tmp/traindataset/RGB/RGB_11.png', '/content/tmp/traindataset/RGB/RGB_110.png', '/content/tmp/traindataset/RGB/RGB_111.png', '/content/tmp/traindataset/RGB/RGB_112.png', '/content/tmp/traindataset/RGB/RGB_12.png', '/content/tmp/traindataset/RGB/RGB_120.png', '/content/tmp/traindataset/RGB/RGB_121.png', '/content/tmp/traindataset/RGB/RGB_122.png', '/content/tmp/traindataset/RGB/RGB_130.png', '/content/tmp/traindataset/RGB/RGB_131.png', '/content/tmp/traindataset/RGB/RGB_132.png', '/content/tmp/traindataset/RGB/RGB_140.png', '/content/tmp/traindataset/RGB/RGB_141.png', '/content/tmp/traindataset/RGB/RGB_142.png', '/content/tmp/traindataset/RGB/RGB_150.png', '/content/tmp/traindataset/RGB/RGB_151.png', '/content/tmp/traindataset/RGB/RGB_152.png', '/content/tmp/traindataset/RGB/RGB_160.png', '/content/tmp/traindataset/RGB/RGB_161.png', '/content/tmp/traindataset/RGB/RGB_162.png', '/content/tmp/traindataset/RGB/RGB_170.png', '/content/tmp/traindataset/RGB/RGB_171.png', '/content/tmp/traindataset/RGB/RGB_172.png', '/content/tmp/traindataset/RGB/RGB_180.png', '/content/tmp/traindataset/RGB/RGB_181.png', '/content/tmp/traindataset/RGB/RGB_182.png', '/content/tmp/traindataset/RGB/RGB_190.png', '/content/tmp/traindataset/RGB/RGB_191.png', '/content/tmp/traindataset/RGB/RGB_192.png', '/content/tmp/traindataset/RGB/RGB_20.png', '/content/tmp/traindataset/RGB/RGB_200.png', '/content/tmp/traindataset/RGB/RGB_201.png', '/content/tmp/traindataset/RGB/RGB_202.png', '/content/tmp/traindataset/RGB/RGB_21.png', '/content/tmp/traindataset/RGB/RGB_210.png', '/content/tmp/traindataset/RGB/RGB_211.png', '/content/tmp/traindataset/RGB/RGB_212.png', '/content/tmp/traindataset/RGB/RGB_22.png', '/content/tmp/traindataset/RGB/RGB_220.png', '/content/tmp/traindataset/RGB/RGB_221.png', '/content/tmp/traindataset/RGB/RGB_222.png', '/content/tmp/traindataset/RGB/RGB_230.png', '/content/tmp/traindataset/RGB/RGB_231.png', '/content/tmp/traindataset/RGB/RGB_232.png', '/content/tmp/traindataset/RGB/RGB_240.png', '/content/tmp/traindataset/RGB/RGB_241.png', '/content/tmp/traindataset/RGB/RGB_242.png', '/content/tmp/traindataset/RGB/RGB_250.png', '/content/tmp/traindataset/RGB/RGB_251.png', '/content/tmp/traindataset/RGB/RGB_252.png', '/content/tmp/traindataset/RGB/RGB_260.png', '/content/tmp/traindataset/RGB/RGB_261.png', '/content/tmp/traindataset/RGB/RGB_262.png', '/content/tmp/traindataset/RGB/RGB_270.png', '/content/tmp/traindataset/RGB/RGB_271.png', '/content/tmp/traindataset/RGB/RGB_272.png', '/content/tmp/traindataset/RGB/RGB_280.png', '/content/tmp/traindataset/RGB/RGB_281.png', '/content/tmp/traindataset/RGB/RGB_282.png', '/content/tmp/traindataset/RGB/RGB_290.png', '/content/tmp/traindataset/RGB/RGB_291.png', '/content/tmp/traindataset/RGB/RGB_292.png', '/content/tmp/traindataset/RGB/RGB_30.png', '/content/tmp/traindataset/RGB/RGB_300.png', '/content/tmp/traindataset/RGB/RGB_301.png', '/content/tmp/traindataset/RGB/RGB_302.png', '/content/tmp/traindataset/RGB/RGB_31.png', '/content/tmp/traindataset/RGB/RGB_310.png', '/content/tmp/traindataset/RGB/RGB_311.png', '/content/tmp/traindataset/RGB/RGB_312.png', '/content/tmp/traindataset/RGB/RGB_32.png', '/content/tmp/traindataset/RGB/RGB_320.png', '/content/tmp/traindataset/RGB/RGB_321.png', '/content/tmp/traindataset/RGB/RGB_322.png', '/content/tmp/traindataset/RGB/RGB_330.png', '/content/tmp/traindataset/RGB/RGB_331.png', '/content/tmp/traindataset/RGB/RGB_332.png', '/content/tmp/traindataset/RGB/RGB_340.png', '/content/tmp/traindataset/RGB/RGB_341.png', '/content/tmp/traindataset/RGB/RGB_342.png', '/content/tmp/traindataset/RGB/RGB_350.png', '/content/tmp/traindataset/RGB/RGB_351.png', '/content/tmp/traindataset/RGB/RGB_352.png', '/content/tmp/traindataset/RGB/RGB_360.png', '/content/tmp/traindataset/RGB/RGB_361.png', '/content/tmp/traindataset/RGB/RGB_362.png', '/content/tmp/traindataset/RGB/RGB_370.png', '/content/tmp/traindataset/RGB/RGB_371.png', '/content/tmp/traindataset/RGB/RGB_372.png', '/content/tmp/traindataset/RGB/RGB_380.png', '/content/tmp/traindataset/RGB/RGB_381.png', '/content/tmp/traindataset/RGB/RGB_382.png', '/content/tmp/traindataset/RGB/RGB_390.png', '/content/tmp/traindataset/RGB/RGB_391.png', '/content/tmp/traindataset/RGB/RGB_392.png', '/content/tmp/traindataset/RGB/RGB_40.png', '/content/tmp/traindataset/RGB/RGB_400.png', '/content/tmp/traindataset/RGB/RGB_401.png', '/content/tmp/traindataset/RGB/RGB_402.png', '/content/tmp/traindataset/RGB/RGB_41.png', '/content/tmp/traindataset/RGB/RGB_410.png', '/content/tmp/traindataset/RGB/RGB_411.png', '/content/tmp/traindataset/RGB/RGB_412.png', '/content/tmp/traindataset/RGB/RGB_42.png', '/content/tmp/traindataset/RGB/RGB_420.png', '/content/tmp/traindataset/RGB/RGB_421.png', '/content/tmp/traindataset/RGB/RGB_422.png', '/content/tmp/traindataset/RGB/RGB_430.png', '/content/tmp/traindataset/RGB/RGB_431.png', '/content/tmp/traindataset/RGB/RGB_432.png', '/content/tmp/traindataset/RGB/RGB_440.png', '/content/tmp/traindataset/RGB/RGB_441.png', '/content/tmp/traindataset/RGB/RGB_442.png', '/content/tmp/traindataset/RGB/RGB_450.png', '/content/tmp/traindataset/RGB/RGB_451.png', '/content/tmp/traindataset/RGB/RGB_452.png', '/content/tmp/traindataset/RGB/RGB_460.png', '/content/tmp/traindataset/RGB/RGB_461.png', '/content/tmp/traindataset/RGB/RGB_462.png', '/content/tmp/traindataset/RGB/RGB_470.png', '/content/tmp/traindataset/RGB/RGB_471.png', '/content/tmp/traindataset/RGB/RGB_472.png', '/content/tmp/traindataset/RGB/RGB_480.png', '/content/tmp/traindataset/RGB/RGB_481.png', '/content/tmp/traindataset/RGB/RGB_482.png', '/content/tmp/traindataset/RGB/RGB_490.png', '/content/tmp/traindataset/RGB/RGB_491.png', '/content/tmp/traindataset/RGB/RGB_492.png', '/content/tmp/traindataset/RGB/RGB_50.png', '/content/tmp/traindataset/RGB/RGB_500.png', '/content/tmp/traindataset/RGB/RGB_501.png', '/content/tmp/traindataset/RGB/RGB_502.png', '/content/tmp/traindataset/RGB/RGB_51.png', '/content/tmp/traindataset/RGB/RGB_510.png', '/content/tmp/traindataset/RGB/RGB_511.png', '/content/tmp/traindataset/RGB/RGB_512.png', '/content/tmp/traindataset/RGB/RGB_52.png', '/content/tmp/traindataset/RGB/RGB_520.png', '/content/tmp/traindataset/RGB/RGB_521.png', '/content/tmp/traindataset/RGB/RGB_522.png', '/content/tmp/traindataset/RGB/RGB_530.png', '/content/tmp/traindataset/RGB/RGB_531.png', '/content/tmp/traindataset/RGB/RGB_532.png', '/content/tmp/traindataset/RGB/RGB_540.png', '/content/tmp/traindataset/RGB/RGB_541.png', '/content/tmp/traindataset/RGB/RGB_542.png', '/content/tmp/traindataset/RGB/RGB_550.png', '/content/tmp/traindataset/RGB/RGB_551.png', '/content/tmp/traindataset/RGB/RGB_552.png', '/content/tmp/traindataset/RGB/RGB_560.png', '/content/tmp/traindataset/RGB/RGB_561.png', '/content/tmp/traindataset/RGB/RGB_562.png', '/content/tmp/traindataset/RGB/RGB_570.png', '/content/tmp/traindataset/RGB/RGB_571.png', '/content/tmp/traindataset/RGB/RGB_572.png', '/content/tmp/traindataset/RGB/RGB_580.png', '/content/tmp/traindataset/RGB/RGB_581.png', '/content/tmp/traindataset/RGB/RGB_582.png', '/content/tmp/traindataset/RGB/RGB_590.png', '/content/tmp/traindataset/RGB/RGB_591.png', '/content/tmp/traindataset/RGB/RGB_592.png', '/content/tmp/traindataset/RGB/RGB_60.png', '/content/tmp/traindataset/RGB/RGB_600.png', '/content/tmp/traindataset/RGB/RGB_601.png', '/content/tmp/traindataset/RGB/RGB_602.png', '/content/tmp/traindataset/RGB/RGB_61.png', '/content/tmp/traindataset/RGB/RGB_610.png', '/content/tmp/traindataset/RGB/RGB_611.png', '/content/tmp/traindataset/RGB/RGB_612.png', '/content/tmp/traindataset/RGB/RGB_62.png', '/content/tmp/traindataset/RGB/RGB_620.png', '/content/tmp/traindataset/RGB/RGB_621.png', '/content/tmp/traindataset/RGB/RGB_622.png', '/content/tmp/traindataset/RGB/RGB_630.png', '/content/tmp/traindataset/RGB/RGB_631.png', '/content/tmp/traindataset/RGB/RGB_632.png', '/content/tmp/traindataset/RGB/RGB_640.png', '/content/tmp/traindataset/RGB/RGB_641.png', '/content/tmp/traindataset/RGB/RGB_642.png', '/content/tmp/traindataset/RGB/RGB_650.png', '/content/tmp/traindataset/RGB/RGB_651.png', '/content/tmp/traindataset/RGB/RGB_652.png', '/content/tmp/traindataset/RGB/RGB_660.png', '/content/tmp/traindataset/RGB/RGB_661.png', '/content/tmp/traindataset/RGB/RGB_662.png', '/content/tmp/traindataset/RGB/RGB_670.png', '/content/tmp/traindataset/RGB/RGB_671.png', '/content/tmp/traindataset/RGB/RGB_672.png', '/content/tmp/traindataset/RGB/RGB_680.png', '/content/tmp/traindataset/RGB/RGB_681.png', '/content/tmp/traindataset/RGB/RGB_682.png', '/content/tmp/traindataset/RGB/RGB_690.png', '/content/tmp/traindataset/RGB/RGB_691.png', '/content/tmp/traindataset/RGB/RGB_692.png', '/content/tmp/traindataset/RGB/RGB_70.png', '/content/tmp/traindataset/RGB/RGB_700.png', '/content/tmp/traindataset/RGB/RGB_701.png', '/content/tmp/traindataset/RGB/RGB_702.png', '/content/tmp/traindataset/RGB/RGB_71.png', '/content/tmp/traindataset/RGB/RGB_710.png', '/content/tmp/traindataset/RGB/RGB_711.png', '/content/tmp/traindataset/RGB/RGB_712.png', '/content/tmp/traindataset/RGB/RGB_72.png', '/content/tmp/traindataset/RGB/RGB_720.png', '/content/tmp/traindataset/RGB/RGB_721.png', '/content/tmp/traindataset/RGB/RGB_722.png', '/content/tmp/traindataset/RGB/RGB_730.png', '/content/tmp/traindataset/RGB/RGB_731.png', '/content/tmp/traindataset/RGB/RGB_732.png', '/content/tmp/traindataset/RGB/RGB_740.png', '/content/tmp/traindataset/RGB/RGB_741.png', '/content/tmp/traindataset/RGB/RGB_742.png', '/content/tmp/traindataset/RGB/RGB_750.png', '/content/tmp/traindataset/RGB/RGB_751.png', '/content/tmp/traindataset/RGB/RGB_752.png', '/content/tmp/traindataset/RGB/RGB_760.png', '/content/tmp/traindataset/RGB/RGB_761.png', '/content/tmp/traindataset/RGB/RGB_762.png', '/content/tmp/traindataset/RGB/RGB_770.png', '/content/tmp/traindataset/RGB/RGB_771.png', '/content/tmp/traindataset/RGB/RGB_772.png', '/content/tmp/traindataset/RGB/RGB_780.png', '/content/tmp/traindataset/RGB/RGB_781.png', '/content/tmp/traindataset/RGB/RGB_782.png', '/content/tmp/traindataset/RGB/RGB_790.png', '/content/tmp/traindataset/RGB/RGB_791.png', '/content/tmp/traindataset/RGB/RGB_792.png', '/content/tmp/traindataset/RGB/RGB_80.png', '/content/tmp/traindataset/RGB/RGB_81.png', '/content/tmp/traindataset/RGB/RGB_82.png', '/content/tmp/traindataset/RGB/RGB_90.png', '/content/tmp/traindataset/RGB/RGB_91.png', '/content/tmp/traindataset/RGB/RGB_92.png'] ['/content/tmp/traindataset/GT/GT_00.png', '/content/tmp/traindataset/GT/GT_01.png', '/content/tmp/traindataset/GT/GT_02.png', '/content/tmp/traindataset/GT/GT_10.png', '/content/tmp/traindataset/GT/GT_100.png', '/content/tmp/traindataset/GT/GT_101.png', '/content/tmp/traindataset/GT/GT_102.png', '/content/tmp/traindataset/GT/GT_11.png', '/content/tmp/traindataset/GT/GT_110.png', '/content/tmp/traindataset/GT/GT_111.png', '/content/tmp/traindataset/GT/GT_112.png', '/content/tmp/traindataset/GT/GT_12.png', '/content/tmp/traindataset/GT/GT_120.png', '/content/tmp/traindataset/GT/GT_121.png', '/content/tmp/traindataset/GT/GT_122.png', '/content/tmp/traindataset/GT/GT_130.png', '/content/tmp/traindataset/GT/GT_131.png', '/content/tmp/traindataset/GT/GT_132.png', '/content/tmp/traindataset/GT/GT_140.png', '/content/tmp/traindataset/GT/GT_141.png', '/content/tmp/traindataset/GT/GT_142.png', '/content/tmp/traindataset/GT/GT_150.png', '/content/tmp/traindataset/GT/GT_151.png', '/content/tmp/traindataset/GT/GT_152.png', '/content/tmp/traindataset/GT/GT_160.png', '/content/tmp/traindataset/GT/GT_161.png', '/content/tmp/traindataset/GT/GT_162.png', '/content/tmp/traindataset/GT/GT_170.png', '/content/tmp/traindataset/GT/GT_171.png', '/content/tmp/traindataset/GT/GT_172.png', '/content/tmp/traindataset/GT/GT_180.png', '/content/tmp/traindataset/GT/GT_181.png', '/content/tmp/traindataset/GT/GT_182.png', '/content/tmp/traindataset/GT/GT_190.png', '/content/tmp/traindataset/GT/GT_191.png', '/content/tmp/traindataset/GT/GT_192.png', '/content/tmp/traindataset/GT/GT_20.png', '/content/tmp/traindataset/GT/GT_200.png', '/content/tmp/traindataset/GT/GT_201.png', '/content/tmp/traindataset/GT/GT_202.png', '/content/tmp/traindataset/GT/GT_21.png', '/content/tmp/traindataset/GT/GT_210.png', '/content/tmp/traindataset/GT/GT_211.png', '/content/tmp/traindataset/GT/GT_212.png', '/content/tmp/traindataset/GT/GT_22.png', '/content/tmp/traindataset/GT/GT_220.png', '/content/tmp/traindataset/GT/GT_221.png', '/content/tmp/traindataset/GT/GT_222.png', '/content/tmp/traindataset/GT/GT_230.png', '/content/tmp/traindataset/GT/GT_231.png', '/content/tmp/traindataset/GT/GT_232.png', '/content/tmp/traindataset/GT/GT_240.png', '/content/tmp/traindataset/GT/GT_241.png', '/content/tmp/traindataset/GT/GT_242.png', '/content/tmp/traindataset/GT/GT_250.png', '/content/tmp/traindataset/GT/GT_251.png', '/content/tmp/traindataset/GT/GT_252.png', '/content/tmp/traindataset/GT/GT_260.png', '/content/tmp/traindataset/GT/GT_261.png', '/content/tmp/traindataset/GT/GT_262.png', '/content/tmp/traindataset/GT/GT_270.png', '/content/tmp/traindataset/GT/GT_271.png', '/content/tmp/traindataset/GT/GT_272.png', '/content/tmp/traindataset/GT/GT_280.png', '/content/tmp/traindataset/GT/GT_281.png', '/content/tmp/traindataset/GT/GT_282.png', '/content/tmp/traindataset/GT/GT_290.png', '/content/tmp/traindataset/GT/GT_291.png', '/content/tmp/traindataset/GT/GT_292.png', '/content/tmp/traindataset/GT/GT_30.png', '/content/tmp/traindataset/GT/GT_300.png', '/content/tmp/traindataset/GT/GT_301.png', '/content/tmp/traindataset/GT/GT_302.png', '/content/tmp/traindataset/GT/GT_31.png', '/content/tmp/traindataset/GT/GT_310.png', '/content/tmp/traindataset/GT/GT_311.png', '/content/tmp/traindataset/GT/GT_312.png', '/content/tmp/traindataset/GT/GT_32.png', '/content/tmp/traindataset/GT/GT_320.png', '/content/tmp/traindataset/GT/GT_321.png', '/content/tmp/traindataset/GT/GT_322.png', '/content/tmp/traindataset/GT/GT_330.png', '/content/tmp/traindataset/GT/GT_331.png', '/content/tmp/traindataset/GT/GT_332.png', '/content/tmp/traindataset/GT/GT_340.png', '/content/tmp/traindataset/GT/GT_341.png', '/content/tmp/traindataset/GT/GT_342.png', '/content/tmp/traindataset/GT/GT_350.png', '/content/tmp/traindataset/GT/GT_351.png', '/content/tmp/traindataset/GT/GT_352.png', '/content/tmp/traindataset/GT/GT_360.png', '/content/tmp/traindataset/GT/GT_361.png', '/content/tmp/traindataset/GT/GT_362.png', '/content/tmp/traindataset/GT/GT_370.png', '/content/tmp/traindataset/GT/GT_371.png', '/content/tmp/traindataset/GT/GT_372.png', '/content/tmp/traindataset/GT/GT_380.png', '/content/tmp/traindataset/GT/GT_381.png', '/content/tmp/traindataset/GT/GT_382.png', '/content/tmp/traindataset/GT/GT_390.png', '/content/tmp/traindataset/GT/GT_391.png', '/content/tmp/traindataset/GT/GT_392.png', '/content/tmp/traindataset/GT/GT_40.png', '/content/tmp/traindataset/GT/GT_400.png', '/content/tmp/traindataset/GT/GT_401.png', '/content/tmp/traindataset/GT/GT_402.png', '/content/tmp/traindataset/GT/GT_41.png', '/content/tmp/traindataset/GT/GT_410.png', '/content/tmp/traindataset/GT/GT_411.png', '/content/tmp/traindataset/GT/GT_412.png', '/content/tmp/traindataset/GT/GT_42.png', '/content/tmp/traindataset/GT/GT_420.png', '/content/tmp/traindataset/GT/GT_421.png', '/content/tmp/traindataset/GT/GT_422.png', '/content/tmp/traindataset/GT/GT_430.png', '/content/tmp/traindataset/GT/GT_431.png', '/content/tmp/traindataset/GT/GT_432.png', '/content/tmp/traindataset/GT/GT_440.png', '/content/tmp/traindataset/GT/GT_441.png', '/content/tmp/traindataset/GT/GT_442.png', '/content/tmp/traindataset/GT/GT_450.png', '/content/tmp/traindataset/GT/GT_451.png', '/content/tmp/traindataset/GT/GT_452.png', '/content/tmp/traindataset/GT/GT_460.png', '/content/tmp/traindataset/GT/GT_461.png', '/content/tmp/traindataset/GT/GT_462.png', '/content/tmp/traindataset/GT/GT_470.png', '/content/tmp/traindataset/GT/GT_471.png', '/content/tmp/traindataset/GT/GT_472.png', '/content/tmp/traindataset/GT/GT_480.png', '/content/tmp/traindataset/GT/GT_481.png', '/content/tmp/traindataset/GT/GT_482.png', '/content/tmp/traindataset/GT/GT_490.png', '/content/tmp/traindataset/GT/GT_491.png', '/content/tmp/traindataset/GT/GT_492.png', '/content/tmp/traindataset/GT/GT_50.png', '/content/tmp/traindataset/GT/GT_500.png', '/content/tmp/traindataset/GT/GT_501.png', '/content/tmp/traindataset/GT/GT_502.png', '/content/tmp/traindataset/GT/GT_51.png', '/content/tmp/traindataset/GT/GT_510.png', '/content/tmp/traindataset/GT/GT_511.png', '/content/tmp/traindataset/GT/GT_512.png', '/content/tmp/traindataset/GT/GT_52.png', '/content/tmp/traindataset/GT/GT_520.png', '/content/tmp/traindataset/GT/GT_521.png', '/content/tmp/traindataset/GT/GT_522.png', '/content/tmp/traindataset/GT/GT_530.png', '/content/tmp/traindataset/GT/GT_531.png', '/content/tmp/traindataset/GT/GT_532.png', '/content/tmp/traindataset/GT/GT_540.png', '/content/tmp/traindataset/GT/GT_541.png', '/content/tmp/traindataset/GT/GT_542.png', '/content/tmp/traindataset/GT/GT_550.png', '/content/tmp/traindataset/GT/GT_551.png', '/content/tmp/traindataset/GT/GT_552.png', '/content/tmp/traindataset/GT/GT_560.png', '/content/tmp/traindataset/GT/GT_561.png', '/content/tmp/traindataset/GT/GT_562.png', '/content/tmp/traindataset/GT/GT_570.png', '/content/tmp/traindataset/GT/GT_571.png', '/content/tmp/traindataset/GT/GT_572.png', '/content/tmp/traindataset/GT/GT_580.png', '/content/tmp/traindataset/GT/GT_581.png', '/content/tmp/traindataset/GT/GT_582.png', '/content/tmp/traindataset/GT/GT_590.png', '/content/tmp/traindataset/GT/GT_591.png', '/content/tmp/traindataset/GT/GT_592.png', '/content/tmp/traindataset/GT/GT_60.png', '/content/tmp/traindataset/GT/GT_600.png', '/content/tmp/traindataset/GT/GT_601.png', '/content/tmp/traindataset/GT/GT_602.png', '/content/tmp/traindataset/GT/GT_61.png', '/content/tmp/traindataset/GT/GT_610.png', '/content/tmp/traindataset/GT/GT_611.png', '/content/tmp/traindataset/GT/GT_612.png', '/content/tmp/traindataset/GT/GT_62.png', '/content/tmp/traindataset/GT/GT_620.png', '/content/tmp/traindataset/GT/GT_621.png', '/content/tmp/traindataset/GT/GT_622.png', '/content/tmp/traindataset/GT/GT_630.png', '/content/tmp/traindataset/GT/GT_631.png', '/content/tmp/traindataset/GT/GT_632.png', '/content/tmp/traindataset/GT/GT_640.png', '/content/tmp/traindataset/GT/GT_641.png', '/content/tmp/traindataset/GT/GT_642.png', '/content/tmp/traindataset/GT/GT_650.png', '/content/tmp/traindataset/GT/GT_651.png', '/content/tmp/traindataset/GT/GT_652.png', '/content/tmp/traindataset/GT/GT_660.png', '/content/tmp/traindataset/GT/GT_661.png', '/content/tmp/traindataset/GT/GT_662.png', '/content/tmp/traindataset/GT/GT_670.png', '/content/tmp/traindataset/GT/GT_671.png', '/content/tmp/traindataset/GT/GT_672.png', '/content/tmp/traindataset/GT/GT_680.png', '/content/tmp/traindataset/GT/GT_681.png', '/content/tmp/traindataset/GT/GT_682.png', '/content/tmp/traindataset/GT/GT_690.png', '/content/tmp/traindataset/GT/GT_691.png', '/content/tmp/traindataset/GT/GT_692.png', '/content/tmp/traindataset/GT/GT_70.png', '/content/tmp/traindataset/GT/GT_700.png', '/content/tmp/traindataset/GT/GT_701.png', '/content/tmp/traindataset/GT/GT_702.png', '/content/tmp/traindataset/GT/GT_71.png', '/content/tmp/traindataset/GT/GT_710.png', '/content/tmp/traindataset/GT/GT_711.png', '/content/tmp/traindataset/GT/GT_712.png', '/content/tmp/traindataset/GT/GT_72.png', '/content/tmp/traindataset/GT/GT_720.png', '/content/tmp/traindataset/GT/GT_721.png', '/content/tmp/traindataset/GT/GT_722.png', '/content/tmp/traindataset/GT/GT_730.png', '/content/tmp/traindataset/GT/GT_731.png', '/content/tmp/traindataset/GT/GT_732.png', '/content/tmp/traindataset/GT/GT_740.png', '/content/tmp/traindataset/GT/GT_741.png', '/content/tmp/traindataset/GT/GT_742.png', '/content/tmp/traindataset/GT/GT_750.png', '/content/tmp/traindataset/GT/GT_751.png', '/content/tmp/traindataset/GT/GT_752.png', '/content/tmp/traindataset/GT/GT_760.png', '/content/tmp/traindataset/GT/GT_761.png', '/content/tmp/traindataset/GT/GT_762.png', '/content/tmp/traindataset/GT/GT_770.png', '/content/tmp/traindataset/GT/GT_771.png', '/content/tmp/traindataset/GT/GT_772.png', '/content/tmp/traindataset/GT/GT_780.png', '/content/tmp/traindataset/GT/GT_781.png', '/content/tmp/traindataset/GT/GT_782.png', '/content/tmp/traindataset/GT/GT_790.png', '/content/tmp/traindataset/GT/GT_791.png', '/content/tmp/traindataset/GT/GT_792.png', '/content/tmp/traindataset/GT/GT_80.png', '/content/tmp/traindataset/GT/GT_81.png', '/content/tmp/traindataset/GT/GT_82.png', '/content/tmp/traindataset/GT/GT_90.png', '/content/tmp/traindataset/GT/GT_91.png', '/content/tmp/traindataset/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7f8d757ed050>\n",
            "Start train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-08-02 20:33:12.243481 Epoch [001/250], Step [0001/0060], Loss1: 0.1345 Loss2: 0.0407 Loss3: 0.1981\n",
            "2022-08-02 20:33:36.510610 Epoch [001/250], Step [0050/0060], Loss1: -0.8865 Loss2: -0.8831 Loss3: -0.8958\n",
            "2022-08-02 20:33:41.461313 Epoch [001/250], Step [0060/0060], Loss1: -0.9025 Loss2: -0.9089 Loss3: -0.9202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 MAE: 58.70158962813258 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-08-02 20:33:46.697670 Epoch [002/250], Step [0001/0060], Loss1: -0.8902 Loss2: -0.8926 Loss3: -0.9102\n",
            "2022-08-02 20:34:11.081185 Epoch [002/250], Step [0050/0060], Loss1: -0.9238 Loss2: -0.9378 Loss3: -0.9524\n",
            "2022-08-02 20:34:16.051623 Epoch [002/250], Step [0060/0060], Loss1: -0.9266 Loss2: -0.9446 Loss3: -0.9547\n",
            "Epoch: 2 MAE: 58.57994643024768 ####  bestMAE: 58.70158962813258 bestEpoch: 0\n",
            "best epoch:2\n",
            "2022-08-02 20:34:23.627539 Epoch [003/250], Step [0001/0060], Loss1: -0.9274 Loss2: -0.9341 Loss3: -0.9504\n",
            "2022-08-02 20:34:48.113743 Epoch [003/250], Step [0050/0060], Loss1: -0.9429 Loss2: -0.9480 Loss3: -0.9638\n",
            "2022-08-02 20:34:53.089127 Epoch [003/250], Step [0060/0060], Loss1: -0.9093 Loss2: -0.9211 Loss3: -0.9484\n",
            "Epoch: 3 MAE: 58.550647856009256 ####  bestMAE: 58.57994643024768 bestEpoch: 2\n",
            "best epoch:3\n",
            "2022-08-02 20:35:00.481213 Epoch [004/250], Step [0001/0060], Loss1: -0.9427 Loss2: -0.9418 Loss3: -0.9661\n",
            "2022-08-02 20:35:24.923486 Epoch [004/250], Step [0050/0060], Loss1: -0.9381 Loss2: -0.9389 Loss3: -0.9525\n",
            "2022-08-02 20:35:29.889985 Epoch [004/250], Step [0060/0060], Loss1: -0.9081 Loss2: -0.9223 Loss3: -0.9621\n",
            "Epoch: 4 MAE: 58.494095485913455 ####  bestMAE: 58.550647856009256 bestEpoch: 3\n",
            "best epoch:4\n",
            "2022-08-02 20:35:37.397340 Epoch [005/250], Step [0001/0060], Loss1: -0.9478 Loss2: -0.9504 Loss3: -0.9649\n",
            "2022-08-02 20:36:02.068381 Epoch [005/250], Step [0050/0060], Loss1: -0.9374 Loss2: -0.9590 Loss3: -0.9660\n",
            "2022-08-02 20:36:07.027327 Epoch [005/250], Step [0060/0060], Loss1: -0.9418 Loss2: -0.9556 Loss3: -0.9663\n",
            "Epoch: 5 MAE: 58.416069081402995 ####  bestMAE: 58.494095485913455 bestEpoch: 4\n",
            "best epoch:5\n",
            "2022-08-02 20:36:16.543609 Epoch [006/250], Step [0001/0060], Loss1: -0.9470 Loss2: -0.9593 Loss3: -0.9694\n",
            "2022-08-02 20:36:41.320255 Epoch [006/250], Step [0050/0060], Loss1: -0.9517 Loss2: -0.9341 Loss3: -0.9698\n",
            "2022-08-02 20:36:46.305180 Epoch [006/250], Step [0060/0060], Loss1: -0.9532 Loss2: -0.9668 Loss3: -0.9710\n",
            "Epoch: 6 MAE: 58.6933265838664 ####  bestMAE: 58.416069081402995 bestEpoch: 5\n",
            "2022-08-02 20:36:51.646161 Epoch [007/250], Step [0001/0060], Loss1: -0.9377 Loss2: -0.9361 Loss3: -0.9601\n",
            "2022-08-02 20:37:15.995234 Epoch [007/250], Step [0050/0060], Loss1: -0.9563 Loss2: -0.9578 Loss3: -0.9734\n",
            "2022-08-02 20:37:20.954499 Epoch [007/250], Step [0060/0060], Loss1: -0.9555 Loss2: -0.9621 Loss3: -0.9751\n",
            "Epoch: 7 MAE: 58.42758042366525 ####  bestMAE: 58.416069081402995 bestEpoch: 5\n",
            "2022-08-02 20:37:26.396087 Epoch [008/250], Step [0001/0060], Loss1: -0.9521 Loss2: -0.9649 Loss3: -0.9750\n",
            "2022-08-02 20:37:50.830401 Epoch [008/250], Step [0050/0060], Loss1: -0.9719 Loss2: -0.9706 Loss3: -0.9838\n",
            "2022-08-02 20:37:55.820331 Epoch [008/250], Step [0060/0060], Loss1: -0.9601 Loss2: -0.9666 Loss3: -0.9786\n",
            "Epoch: 8 MAE: 58.45731365856976 ####  bestMAE: 58.416069081402995 bestEpoch: 5\n",
            "2022-08-02 20:38:01.388279 Epoch [009/250], Step [0001/0060], Loss1: -0.9607 Loss2: -0.9604 Loss3: -0.9765\n",
            "2022-08-02 20:38:25.879643 Epoch [009/250], Step [0050/0060], Loss1: -0.9571 Loss2: -0.9705 Loss3: -0.9765\n",
            "2022-08-02 20:38:30.885505 Epoch [009/250], Step [0060/0060], Loss1: -0.9433 Loss2: -0.9611 Loss3: -0.9742\n",
            "Epoch: 9 MAE: 58.35630302916197 ####  bestMAE: 58.416069081402995 bestEpoch: 5\n",
            "best epoch:9\n",
            "2022-08-02 20:38:38.562211 Epoch [010/250], Step [0001/0060], Loss1: -0.9615 Loss2: -0.9703 Loss3: -0.9803\n",
            "2022-08-02 20:39:03.204147 Epoch [010/250], Step [0050/0060], Loss1: -0.9649 Loss2: -0.9731 Loss3: -0.9813\n",
            "2022-08-02 20:39:08.184539 Epoch [010/250], Step [0060/0060], Loss1: -0.9469 Loss2: -0.9572 Loss3: -0.9719\n",
            "Epoch: 10 MAE: 58.457856190775985 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:39:15.908463 Epoch [011/250], Step [0001/0060], Loss1: -0.9701 Loss2: -0.9728 Loss3: -0.9842\n",
            "2022-08-02 20:39:40.587950 Epoch [011/250], Step [0050/0060], Loss1: -0.9685 Loss2: -0.9678 Loss3: -0.9806\n",
            "2022-08-02 20:39:45.580774 Epoch [011/250], Step [0060/0060], Loss1: -0.9662 Loss2: -0.9697 Loss3: -0.9801\n",
            "Epoch: 11 MAE: 58.6812614125553 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:39:51.205011 Epoch [012/250], Step [0001/0060], Loss1: -0.9680 Loss2: -0.9698 Loss3: -0.9802\n",
            "2022-08-02 20:40:15.681762 Epoch [012/250], Step [0050/0060], Loss1: -0.9664 Loss2: -0.9733 Loss3: -0.9806\n",
            "2022-08-02 20:40:20.686352 Epoch [012/250], Step [0060/0060], Loss1: -0.9688 Loss2: -0.9740 Loss3: -0.9751\n",
            "Epoch: 12 MAE: 58.5744209015716 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:40:26.308715 Epoch [013/250], Step [0001/0060], Loss1: -0.9655 Loss2: -0.9699 Loss3: -0.9774\n",
            "2022-08-02 20:40:50.769468 Epoch [013/250], Step [0050/0060], Loss1: -0.9627 Loss2: -0.9636 Loss3: -0.9760\n",
            "2022-08-02 20:40:55.764378 Epoch [013/250], Step [0060/0060], Loss1: -0.9618 Loss2: -0.9700 Loss3: -0.9800\n",
            "Epoch: 13 MAE: 58.61708973818768 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:41:01.574898 Epoch [014/250], Step [0001/0060], Loss1: -0.9746 Loss2: -0.9727 Loss3: -0.9840\n",
            "2022-08-02 20:41:26.082916 Epoch [014/250], Step [0050/0060], Loss1: -0.9696 Loss2: -0.9732 Loss3: -0.9832\n",
            "2022-08-02 20:41:31.082619 Epoch [014/250], Step [0060/0060], Loss1: -0.9620 Loss2: -0.9714 Loss3: -0.9802\n",
            "Epoch: 14 MAE: 58.384287145220505 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:41:36.730208 Epoch [015/250], Step [0001/0060], Loss1: -0.9765 Loss2: -0.9724 Loss3: -0.9855\n",
            "2022-08-02 20:42:01.174202 Epoch [015/250], Step [0050/0060], Loss1: -0.9679 Loss2: -0.9699 Loss3: -0.9833\n",
            "2022-08-02 20:42:06.180932 Epoch [015/250], Step [0060/0060], Loss1: -0.9658 Loss2: -0.9716 Loss3: -0.9816\n",
            "Epoch: 15 MAE: 58.50400603217833 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:42:14.004188 Epoch [016/250], Step [0001/0060], Loss1: -0.9738 Loss2: -0.9762 Loss3: -0.9859\n",
            "2022-08-02 20:42:38.771764 Epoch [016/250], Step [0050/0060], Loss1: -0.9734 Loss2: -0.9778 Loss3: -0.9841\n",
            "2022-08-02 20:42:43.767492 Epoch [016/250], Step [0060/0060], Loss1: -0.9547 Loss2: -0.9676 Loss3: -0.9773\n",
            "Epoch: 16 MAE: 58.42379065595163 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:42:49.465635 Epoch [017/250], Step [0001/0060], Loss1: -0.9742 Loss2: -0.9766 Loss3: -0.9850\n",
            "2022-08-02 20:43:14.070222 Epoch [017/250], Step [0050/0060], Loss1: -0.9728 Loss2: -0.9757 Loss3: -0.9847\n",
            "2022-08-02 20:43:19.073887 Epoch [017/250], Step [0060/0060], Loss1: -0.9720 Loss2: -0.9775 Loss3: -0.9845\n",
            "Epoch: 17 MAE: 58.36435299638301 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:43:24.745387 Epoch [018/250], Step [0001/0060], Loss1: -0.9659 Loss2: -0.9755 Loss3: -0.9824\n",
            "2022-08-02 20:43:49.291859 Epoch [018/250], Step [0050/0060], Loss1: -0.9781 Loss2: -0.9774 Loss3: -0.9857\n",
            "2022-08-02 20:43:54.287373 Epoch [018/250], Step [0060/0060], Loss1: -0.9656 Loss2: -0.9689 Loss3: -0.9800\n",
            "Epoch: 18 MAE: 58.54774938451706 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:44:00.095103 Epoch [019/250], Step [0001/0060], Loss1: -0.9684 Loss2: -0.9724 Loss3: -0.9814\n",
            "2022-08-02 20:44:24.608002 Epoch [019/250], Step [0050/0060], Loss1: -0.9702 Loss2: -0.9713 Loss3: -0.9837\n",
            "2022-08-02 20:44:29.611704 Epoch [019/250], Step [0060/0060], Loss1: -0.9627 Loss2: -0.9670 Loss3: -0.9788\n",
            "Epoch: 19 MAE: 58.36368214013852 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:44:35.318589 Epoch [020/250], Step [0001/0060], Loss1: -0.9715 Loss2: -0.9772 Loss3: -0.9856\n",
            "2022-08-02 20:44:59.815854 Epoch [020/250], Step [0050/0060], Loss1: -0.9752 Loss2: -0.9776 Loss3: -0.9862\n",
            "2022-08-02 20:45:04.816920 Epoch [020/250], Step [0060/0060], Loss1: -0.9679 Loss2: -0.9720 Loss3: -0.9835\n",
            "Epoch: 20 MAE: 58.51731372574579 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:45:12.600046 Epoch [021/250], Step [0001/0060], Loss1: -0.9820 Loss2: -0.9810 Loss3: -0.9891\n",
            "2022-08-02 20:45:37.207760 Epoch [021/250], Step [0050/0060], Loss1: -0.9647 Loss2: -0.9693 Loss3: -0.9787\n",
            "2022-08-02 20:45:42.207682 Epoch [021/250], Step [0060/0060], Loss1: -0.9594 Loss2: -0.9704 Loss3: -0.9764\n",
            "Epoch: 21 MAE: 58.544532992996395 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:45:47.844550 Epoch [022/250], Step [0001/0060], Loss1: -0.9688 Loss2: -0.9713 Loss3: -0.9815\n",
            "2022-08-02 20:46:12.325634 Epoch [022/250], Step [0050/0060], Loss1: -0.9796 Loss2: -0.9775 Loss3: -0.9870\n",
            "2022-08-02 20:46:17.335165 Epoch [022/250], Step [0060/0060], Loss1: -0.9817 Loss2: -0.9814 Loss3: -0.9888\n",
            "Epoch: 22 MAE: 58.496269343314204 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:46:23.060250 Epoch [023/250], Step [0001/0060], Loss1: -0.9656 Loss2: -0.9739 Loss3: -0.9824\n",
            "2022-08-02 20:46:47.614749 Epoch [023/250], Step [0050/0060], Loss1: -0.9751 Loss2: -0.9804 Loss3: -0.9863\n",
            "2022-08-02 20:46:52.618096 Epoch [023/250], Step [0060/0060], Loss1: -0.9761 Loss2: -0.9750 Loss3: -0.9852\n",
            "Epoch: 23 MAE: 58.47087609217029 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:46:58.286681 Epoch [024/250], Step [0001/0060], Loss1: -0.9710 Loss2: -0.9780 Loss3: -0.9852\n",
            "2022-08-02 20:47:22.774134 Epoch [024/250], Step [0050/0060], Loss1: -0.9789 Loss2: -0.9782 Loss3: -0.9872\n",
            "2022-08-02 20:47:27.758374 Epoch [024/250], Step [0060/0060], Loss1: -0.9792 Loss2: -0.9803 Loss3: -0.9885\n",
            "Epoch: 24 MAE: 58.56685700528365 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:47:33.584408 Epoch [025/250], Step [0001/0060], Loss1: -0.9683 Loss2: -0.9787 Loss3: -0.9831\n",
            "2022-08-02 20:47:58.179837 Epoch [025/250], Step [0050/0060], Loss1: -0.9492 Loss2: -0.9709 Loss3: -0.9788\n",
            "2022-08-02 20:48:03.177211 Epoch [025/250], Step [0060/0060], Loss1: -0.9700 Loss2: -0.9755 Loss3: -0.9827\n",
            "Epoch: 25 MAE: 58.54820885865639 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:48:10.859748 Epoch [026/250], Step [0001/0060], Loss1: -0.9757 Loss2: -0.9786 Loss3: -0.9860\n",
            "2022-08-02 20:48:35.409977 Epoch [026/250], Step [0050/0060], Loss1: -0.9801 Loss2: -0.9796 Loss3: -0.9866\n",
            "2022-08-02 20:48:40.378889 Epoch [026/250], Step [0060/0060], Loss1: -0.9802 Loss2: -0.9837 Loss3: -0.9895\n",
            "Epoch: 26 MAE: 58.53807201351539 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:48:45.898909 Epoch [027/250], Step [0001/0060], Loss1: -0.9811 Loss2: -0.9830 Loss3: -0.9891\n",
            "2022-08-02 20:49:10.307215 Epoch [027/250], Step [0050/0060], Loss1: -0.9740 Loss2: -0.9744 Loss3: -0.9849\n",
            "2022-08-02 20:49:15.287320 Epoch [027/250], Step [0060/0060], Loss1: -0.9788 Loss2: -0.9799 Loss3: -0.9874\n",
            "Epoch: 27 MAE: 58.5718196260508 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:49:20.881770 Epoch [028/250], Step [0001/0060], Loss1: -0.9771 Loss2: -0.9813 Loss3: -0.9879\n",
            "2022-08-02 20:49:45.280015 Epoch [028/250], Step [0050/0060], Loss1: -0.9799 Loss2: -0.9774 Loss3: -0.9867\n",
            "2022-08-02 20:49:50.291504 Epoch [028/250], Step [0060/0060], Loss1: -0.9818 Loss2: -0.9817 Loss3: -0.9882\n",
            "Epoch: 28 MAE: 58.50410784962972 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:49:55.891391 Epoch [029/250], Step [0001/0060], Loss1: -0.9783 Loss2: -0.9794 Loss3: -0.9863\n",
            "2022-08-02 20:50:20.322504 Epoch [029/250], Step [0050/0060], Loss1: -0.9696 Loss2: -0.9754 Loss3: -0.9824\n",
            "2022-08-02 20:50:25.304213 Epoch [029/250], Step [0060/0060], Loss1: -0.9824 Loss2: -0.9822 Loss3: -0.9892\n",
            "Epoch: 29 MAE: 58.42630592142664 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:50:30.862271 Epoch [030/250], Step [0001/0060], Loss1: -0.9676 Loss2: -0.9706 Loss3: -0.9823\n",
            "2022-08-02 20:50:55.294041 Epoch [030/250], Step [0050/0060], Loss1: -0.9710 Loss2: -0.9741 Loss3: -0.9844\n",
            "2022-08-02 20:51:00.276272 Epoch [030/250], Step [0060/0060], Loss1: -0.9835 Loss2: -0.9836 Loss3: -0.9900\n",
            "Epoch: 30 MAE: 58.51512245223527 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:51:08.005101 Epoch [031/250], Step [0001/0060], Loss1: -0.9733 Loss2: -0.9783 Loss3: -0.9855\n",
            "2022-08-02 20:51:32.732514 Epoch [031/250], Step [0050/0060], Loss1: -0.9704 Loss2: -0.9794 Loss3: -0.9854\n",
            "2022-08-02 20:51:37.711176 Epoch [031/250], Step [0060/0060], Loss1: -0.9821 Loss2: -0.9811 Loss3: -0.9896\n",
            "Epoch: 31 MAE: 58.51952529792136 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:51:43.292385 Epoch [032/250], Step [0001/0060], Loss1: -0.9770 Loss2: -0.9835 Loss3: -0.9884\n",
            "2022-08-02 20:52:07.709145 Epoch [032/250], Step [0050/0060], Loss1: -0.9721 Loss2: -0.9755 Loss3: -0.9835\n",
            "2022-08-02 20:52:12.697757 Epoch [032/250], Step [0060/0060], Loss1: -0.9837 Loss2: -0.9821 Loss3: -0.9895\n",
            "Epoch: 32 MAE: 58.46450985762357 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:52:18.298585 Epoch [033/250], Step [0001/0060], Loss1: -0.9714 Loss2: -0.9746 Loss3: -0.9842\n",
            "2022-08-02 20:52:42.765704 Epoch [033/250], Step [0050/0060], Loss1: -0.9818 Loss2: -0.9816 Loss3: -0.9886\n",
            "2022-08-02 20:52:47.746177 Epoch [033/250], Step [0060/0060], Loss1: -0.9837 Loss2: -0.9818 Loss3: -0.9905\n",
            "Epoch: 33 MAE: 58.45424463632329 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:52:53.349229 Epoch [034/250], Step [0001/0060], Loss1: -0.9736 Loss2: -0.9776 Loss3: -0.9833\n",
            "2022-08-02 20:53:17.801530 Epoch [034/250], Step [0050/0060], Loss1: -0.9757 Loss2: -0.9748 Loss3: -0.9861\n",
            "2022-08-02 20:53:22.799459 Epoch [034/250], Step [0060/0060], Loss1: -0.9734 Loss2: -0.9779 Loss3: -0.9849\n",
            "Epoch: 34 MAE: 58.466625272916446 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:53:28.461349 Epoch [035/250], Step [0001/0060], Loss1: -0.9792 Loss2: -0.9818 Loss3: -0.9891\n",
            "2022-08-02 20:53:52.915713 Epoch [035/250], Step [0050/0060], Loss1: -0.9757 Loss2: -0.9762 Loss3: -0.9864\n",
            "2022-08-02 20:53:57.899834 Epoch [035/250], Step [0060/0060], Loss1: -0.9820 Loss2: -0.9827 Loss3: -0.9889\n",
            "Epoch: 35 MAE: 58.57127323705079 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "2022-08-02 20:54:05.569791 Epoch [036/250], Step [0001/0060], Loss1: -0.9725 Loss2: -0.9785 Loss3: -0.9853\n",
            "2022-08-02 20:54:30.141112 Epoch [036/250], Step [0050/0060], Loss1: -0.9767 Loss2: -0.9826 Loss3: -0.9884\n",
            "2022-08-02 20:54:35.115861 Epoch [036/250], Step [0060/0060], Loss1: -0.9677 Loss2: -0.9743 Loss3: -0.9822\n",
            "Epoch: 36 MAE: 58.34067055138351 ####  bestMAE: 58.35630302916197 bestEpoch: 9\n",
            "best epoch:36\n",
            "2022-08-02 20:54:42.735279 Epoch [037/250], Step [0001/0060], Loss1: -0.9732 Loss2: -0.9744 Loss3: -0.9843\n",
            "2022-08-02 20:55:07.451798 Epoch [037/250], Step [0050/0060], Loss1: -0.9849 Loss2: -0.9815 Loss3: -0.9905\n",
            "2022-08-02 20:55:12.428050 Epoch [037/250], Step [0060/0060], Loss1: -0.9833 Loss2: -0.9795 Loss3: -0.9886\n",
            "Epoch: 37 MAE: 58.49360092705516 ####  bestMAE: 58.34067055138351 bestEpoch: 36\n",
            "2022-08-02 20:55:17.977305 Epoch [038/250], Step [0001/0060], Loss1: -0.9844 Loss2: -0.9838 Loss3: -0.9904\n",
            "2022-08-02 20:55:42.392717 Epoch [038/250], Step [0050/0060], Loss1: -0.9831 Loss2: -0.9798 Loss3: -0.9894\n",
            "2022-08-02 20:55:47.386891 Epoch [038/250], Step [0060/0060], Loss1: -0.9850 Loss2: -0.9829 Loss3: -0.9899\n",
            "Epoch: 38 MAE: 58.59109150986775 ####  bestMAE: 58.34067055138351 bestEpoch: 36\n",
            "2022-08-02 20:55:52.926894 Epoch [039/250], Step [0001/0060], Loss1: -0.9745 Loss2: -0.9782 Loss3: -0.9856\n",
            "2022-08-02 20:56:17.333453 Epoch [039/250], Step [0050/0060], Loss1: -0.9828 Loss2: -0.9815 Loss3: -0.9882\n",
            "2022-08-02 20:56:22.307033 Epoch [039/250], Step [0060/0060], Loss1: -0.9806 Loss2: -0.9818 Loss3: -0.9885\n",
            "Epoch: 39 MAE: 58.49852991309605 ####  bestMAE: 58.34067055138351 bestEpoch: 36\n",
            "2022-08-02 20:56:27.879585 Epoch [040/250], Step [0001/0060], Loss1: -0.9800 Loss2: -0.9844 Loss3: -0.9893\n",
            "2022-08-02 20:56:52.310652 Epoch [040/250], Step [0050/0060], Loss1: -0.9778 Loss2: -0.9797 Loss3: -0.9867\n",
            "2022-08-02 20:56:57.289598 Epoch [040/250], Step [0060/0060], Loss1: -0.9764 Loss2: -0.9814 Loss3: -0.9872\n",
            "Epoch: 40 MAE: 58.45204486557839 ####  bestMAE: 58.34067055138351 bestEpoch: 36\n",
            "2022-08-02 20:57:04.999049 Epoch [041/250], Step [0001/0060], Loss1: -0.9799 Loss2: -0.9771 Loss3: -0.9878\n",
            "2022-08-02 20:57:29.494149 Epoch [041/250], Step [0050/0060], Loss1: -0.9798 Loss2: -0.9824 Loss3: -0.9890\n",
            "2022-08-02 20:57:34.473150 Epoch [041/250], Step [0060/0060], Loss1: -0.9803 Loss2: -0.9839 Loss3: -0.9897\n",
            "Epoch: 41 MAE: 58.59577984754452 ####  bestMAE: 58.34067055138351 bestEpoch: 36\n",
            "2022-08-02 20:57:40.013512 Epoch [042/250], Step [0001/0060], Loss1: -0.9809 Loss2: -0.9837 Loss3: -0.9896\n",
            "2022-08-02 20:58:04.406279 Epoch [042/250], Step [0050/0060], Loss1: -0.9677 Loss2: -0.9738 Loss3: -0.9832\n",
            "2022-08-02 20:58:09.382363 Epoch [042/250], Step [0060/0060], Loss1: -0.9817 Loss2: -0.9819 Loss3: -0.9895\n",
            "Epoch: 42 MAE: 58.3638715402372 ####  bestMAE: 58.34067055138351 bestEpoch: 36\n",
            "2022-08-02 20:58:14.907763 Epoch [043/250], Step [0001/0060], Loss1: -0.9789 Loss2: -0.9821 Loss3: -0.9883\n",
            "2022-08-02 20:58:39.343305 Epoch [043/250], Step [0050/0060], Loss1: -0.9824 Loss2: -0.9855 Loss3: -0.9900\n",
            "2022-08-02 20:58:44.318345 Epoch [043/250], Step [0060/0060], Loss1: -0.9791 Loss2: -0.9798 Loss3: -0.9874\n",
            "Epoch: 43 MAE: 58.30667537152914 ####  bestMAE: 58.34067055138351 bestEpoch: 36\n",
            "best epoch:43\n",
            "2022-08-02 20:58:52.122519 Epoch [044/250], Step [0001/0060], Loss1: -0.9796 Loss2: -0.9793 Loss3: -0.9877\n",
            "2022-08-02 20:59:16.770735 Epoch [044/250], Step [0050/0060], Loss1: -0.9713 Loss2: -0.9727 Loss3: -0.9836\n",
            "2022-08-02 20:59:21.749493 Epoch [044/250], Step [0060/0060], Loss1: -0.9749 Loss2: -0.9778 Loss3: -0.9860\n",
            "Epoch: 44 MAE: 58.332970010623235 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 20:59:27.249166 Epoch [045/250], Step [0001/0060], Loss1: -0.9815 Loss2: -0.9831 Loss3: -0.9887\n",
            "2022-08-02 20:59:51.676011 Epoch [045/250], Step [0050/0060], Loss1: -0.9817 Loss2: -0.9820 Loss3: -0.9885\n",
            "2022-08-02 20:59:56.659362 Epoch [045/250], Step [0060/0060], Loss1: -0.9831 Loss2: -0.9820 Loss3: -0.9897\n",
            "Epoch: 45 MAE: 58.487556761382685 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:00:04.202010 Epoch [046/250], Step [0001/0060], Loss1: -0.9829 Loss2: -0.9840 Loss3: -0.9900\n",
            "2022-08-02 21:00:28.893094 Epoch [046/250], Step [0050/0060], Loss1: -0.9813 Loss2: -0.9837 Loss3: -0.9891\n",
            "2022-08-02 21:00:33.901759 Epoch [046/250], Step [0060/0060], Loss1: -0.9844 Loss2: -0.9838 Loss3: -0.9886\n",
            "Epoch: 46 MAE: 58.50535199370657 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:00:39.541741 Epoch [047/250], Step [0001/0060], Loss1: -0.9683 Loss2: -0.9763 Loss3: -0.9831\n",
            "2022-08-02 21:01:03.957829 Epoch [047/250], Step [0050/0060], Loss1: -0.9834 Loss2: -0.9817 Loss3: -0.9891\n",
            "2022-08-02 21:01:08.940363 Epoch [047/250], Step [0060/0060], Loss1: -0.9817 Loss2: -0.9795 Loss3: -0.9878\n",
            "Epoch: 47 MAE: 58.37183175710487 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:01:14.497583 Epoch [048/250], Step [0001/0060], Loss1: -0.9795 Loss2: -0.9842 Loss3: -0.9901\n",
            "2022-08-02 21:01:38.859009 Epoch [048/250], Step [0050/0060], Loss1: -0.9802 Loss2: -0.9842 Loss3: -0.9875\n",
            "2022-08-02 21:01:43.839260 Epoch [048/250], Step [0060/0060], Loss1: -0.9828 Loss2: -0.9839 Loss3: -0.9890\n",
            "Epoch: 48 MAE: 58.49384529686144 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:01:49.352225 Epoch [049/250], Step [0001/0060], Loss1: -0.9829 Loss2: -0.9855 Loss3: -0.9895\n",
            "2022-08-02 21:02:13.768177 Epoch [049/250], Step [0050/0060], Loss1: -0.9843 Loss2: -0.9823 Loss3: -0.9897\n",
            "2022-08-02 21:02:18.748621 Epoch [049/250], Step [0060/0060], Loss1: -0.9844 Loss2: -0.9846 Loss3: -0.9903\n",
            "Epoch: 49 MAE: 58.696861126328926 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:02:24.334490 Epoch [050/250], Step [0001/0060], Loss1: -0.9740 Loss2: -0.9773 Loss3: -0.9841\n",
            "2022-08-02 21:02:48.751742 Epoch [050/250], Step [0050/0060], Loss1: -0.9837 Loss2: -0.9830 Loss3: -0.9898\n",
            "2022-08-02 21:02:53.738107 Epoch [050/250], Step [0060/0060], Loss1: -0.9813 Loss2: -0.9827 Loss3: -0.9893\n",
            "Epoch: 50 MAE: 58.46104353143324 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:03:01.346037 Epoch [051/250], Step [0001/0060], Loss1: -0.9840 Loss2: -0.9855 Loss3: -0.9908\n",
            "2022-08-02 21:03:26.008026 Epoch [051/250], Step [0050/0060], Loss1: -0.9756 Loss2: -0.9736 Loss3: -0.9839\n",
            "2022-08-02 21:03:30.986175 Epoch [051/250], Step [0060/0060], Loss1: -0.9831 Loss2: -0.9838 Loss3: -0.9904\n",
            "Epoch: 51 MAE: 58.52748121863633 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:03:36.516212 Epoch [052/250], Step [0001/0060], Loss1: -0.9828 Loss2: -0.9806 Loss3: -0.9894\n",
            "2022-08-02 21:04:00.921821 Epoch [052/250], Step [0050/0060], Loss1: -0.9816 Loss2: -0.9786 Loss3: -0.9863\n",
            "2022-08-02 21:04:05.902267 Epoch [052/250], Step [0060/0060], Loss1: -0.9849 Loss2: -0.9851 Loss3: -0.9901\n",
            "Epoch: 52 MAE: 58.567396561115075 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:04:11.481518 Epoch [053/250], Step [0001/0060], Loss1: -0.9829 Loss2: -0.9813 Loss3: -0.9872\n",
            "2022-08-02 21:04:35.864132 Epoch [053/250], Step [0050/0060], Loss1: -0.9842 Loss2: -0.9862 Loss3: -0.9903\n",
            "2022-08-02 21:04:40.838925 Epoch [053/250], Step [0060/0060], Loss1: -0.9786 Loss2: -0.9830 Loss3: -0.9884\n",
            "Epoch: 53 MAE: 58.49696438315412 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:04:46.404541 Epoch [054/250], Step [0001/0060], Loss1: -0.9803 Loss2: -0.9834 Loss3: -0.9890\n",
            "2022-08-02 21:05:10.858005 Epoch [054/250], Step [0050/0060], Loss1: -0.9838 Loss2: -0.9858 Loss3: -0.9907\n",
            "2022-08-02 21:05:15.842110 Epoch [054/250], Step [0060/0060], Loss1: -0.9830 Loss2: -0.9820 Loss3: -0.9898\n",
            "Epoch: 54 MAE: 58.54433736993264 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:05:21.484600 Epoch [055/250], Step [0001/0060], Loss1: -0.9794 Loss2: -0.9836 Loss3: -0.9885\n",
            "2022-08-02 21:05:45.909910 Epoch [055/250], Step [0050/0060], Loss1: -0.9859 Loss2: -0.9834 Loss3: -0.9899\n",
            "2022-08-02 21:05:50.891584 Epoch [055/250], Step [0060/0060], Loss1: -0.9830 Loss2: -0.9855 Loss3: -0.9908\n",
            "Epoch: 55 MAE: 58.413320074771654 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:05:58.392967 Epoch [056/250], Step [0001/0060], Loss1: -0.9790 Loss2: -0.9844 Loss3: -0.9887\n",
            "2022-08-02 21:06:22.934183 Epoch [056/250], Step [0050/0060], Loss1: -0.9838 Loss2: -0.9849 Loss3: -0.9879\n",
            "2022-08-02 21:06:27.911520 Epoch [056/250], Step [0060/0060], Loss1: -0.9849 Loss2: -0.9855 Loss3: -0.9907\n",
            "Epoch: 56 MAE: 58.40294190848441 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:06:33.413949 Epoch [057/250], Step [0001/0060], Loss1: -0.9845 Loss2: -0.9821 Loss3: -0.9896\n",
            "2022-08-02 21:06:57.831955 Epoch [057/250], Step [0050/0060], Loss1: -0.9767 Loss2: -0.9787 Loss3: -0.9861\n",
            "2022-08-02 21:07:02.795217 Epoch [057/250], Step [0060/0060], Loss1: -0.9838 Loss2: -0.9832 Loss3: -0.9898\n",
            "Epoch: 57 MAE: 58.54985284144074 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:07:08.186528 Epoch [058/250], Step [0001/0060], Loss1: -0.9740 Loss2: -0.9758 Loss3: -0.9842\n",
            "2022-08-02 21:07:32.681426 Epoch [058/250], Step [0050/0060], Loss1: -0.9829 Loss2: -0.9806 Loss3: -0.9902\n",
            "2022-08-02 21:07:37.678888 Epoch [058/250], Step [0060/0060], Loss1: -0.9849 Loss2: -0.9863 Loss3: -0.9910\n",
            "Epoch: 58 MAE: 58.4450431557983 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:07:43.294976 Epoch [059/250], Step [0001/0060], Loss1: -0.9837 Loss2: -0.9851 Loss3: -0.9901\n",
            "2022-08-02 21:08:07.745124 Epoch [059/250], Step [0050/0060], Loss1: -0.9765 Loss2: -0.9811 Loss3: -0.9873\n",
            "2022-08-02 21:08:12.729891 Epoch [059/250], Step [0060/0060], Loss1: -0.9808 Loss2: -0.9807 Loss3: -0.9880\n",
            "Epoch: 59 MAE: 58.423800166471686 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:08:18.218750 Epoch [060/250], Step [0001/0060], Loss1: -0.9830 Loss2: -0.9838 Loss3: -0.9899\n",
            "2022-08-02 21:08:42.704987 Epoch [060/250], Step [0050/0060], Loss1: -0.9849 Loss2: -0.9858 Loss3: -0.9910\n",
            "2022-08-02 21:08:47.679958 Epoch [060/250], Step [0060/0060], Loss1: -0.9789 Loss2: -0.9833 Loss3: -0.9887\n",
            "Epoch: 60 MAE: 58.36237830615033 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:08:55.333956 Epoch [061/250], Step [0001/0060], Loss1: -0.9843 Loss2: -0.9834 Loss3: -0.9901\n",
            "2022-08-02 21:09:19.950731 Epoch [061/250], Step [0050/0060], Loss1: -0.9742 Loss2: -0.9787 Loss3: -0.9859\n",
            "2022-08-02 21:09:24.936896 Epoch [061/250], Step [0060/0060], Loss1: -0.9824 Loss2: -0.9810 Loss3: -0.9883\n",
            "Epoch: 61 MAE: 58.406345499318924 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:09:30.390456 Epoch [062/250], Step [0001/0060], Loss1: -0.9777 Loss2: -0.9822 Loss3: -0.9877\n",
            "2022-08-02 21:09:54.789658 Epoch [062/250], Step [0050/0060], Loss1: -0.9847 Loss2: -0.9872 Loss3: -0.9909\n",
            "2022-08-02 21:09:59.764155 Epoch [062/250], Step [0060/0060], Loss1: -0.9849 Loss2: -0.9860 Loss3: -0.9916\n",
            "Epoch: 62 MAE: 58.57906730762528 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:10:05.272770 Epoch [063/250], Step [0001/0060], Loss1: -0.9766 Loss2: -0.9756 Loss3: -0.9857\n",
            "2022-08-02 21:10:29.710395 Epoch [063/250], Step [0050/0060], Loss1: -0.9861 Loss2: -0.9820 Loss3: -0.9905\n",
            "2022-08-02 21:10:34.691979 Epoch [063/250], Step [0060/0060], Loss1: -0.9818 Loss2: -0.9857 Loss3: -0.9904\n",
            "Epoch: 63 MAE: 58.68851010741881 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:10:40.063826 Epoch [064/250], Step [0001/0060], Loss1: -0.9782 Loss2: -0.9812 Loss3: -0.9874\n",
            "2022-08-02 21:11:04.482340 Epoch [064/250], Step [0050/0060], Loss1: -0.9774 Loss2: -0.9818 Loss3: -0.9884\n",
            "2022-08-02 21:11:09.467688 Epoch [064/250], Step [0060/0060], Loss1: -0.9820 Loss2: -0.9821 Loss3: -0.9895\n",
            "Epoch: 64 MAE: 58.37855837477917 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:11:15.106930 Epoch [065/250], Step [0001/0060], Loss1: -0.9862 Loss2: -0.9881 Loss3: -0.9921\n",
            "2022-08-02 21:11:39.536241 Epoch [065/250], Step [0050/0060], Loss1: -0.9837 Loss2: -0.9837 Loss3: -0.9903\n",
            "2022-08-02 21:11:44.549838 Epoch [065/250], Step [0060/0060], Loss1: -0.9827 Loss2: -0.9817 Loss3: -0.9901\n",
            "Epoch: 65 MAE: 58.59158473575685 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:11:52.347788 Epoch [066/250], Step [0001/0060], Loss1: -0.9832 Loss2: -0.9829 Loss3: -0.9894\n",
            "2022-08-02 21:12:16.908386 Epoch [066/250], Step [0050/0060], Loss1: -0.9807 Loss2: -0.9799 Loss3: -0.9872\n",
            "2022-08-02 21:12:21.887462 Epoch [066/250], Step [0060/0060], Loss1: -0.9858 Loss2: -0.9841 Loss3: -0.9906\n",
            "Epoch: 66 MAE: 58.46994306219688 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:12:27.428834 Epoch [067/250], Step [0001/0060], Loss1: -0.9882 Loss2: -0.9891 Loss3: -0.9928\n",
            "2022-08-02 21:12:51.845182 Epoch [067/250], Step [0050/0060], Loss1: -0.9857 Loss2: -0.9850 Loss3: -0.9909\n",
            "2022-08-02 21:12:56.852518 Epoch [067/250], Step [0060/0060], Loss1: -0.9854 Loss2: -0.9834 Loss3: -0.9899\n",
            "Epoch: 67 MAE: 58.45507813827898 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:13:02.469891 Epoch [068/250], Step [0001/0060], Loss1: -0.9770 Loss2: -0.9799 Loss3: -0.9867\n",
            "2022-08-02 21:13:26.926294 Epoch [068/250], Step [0050/0060], Loss1: -0.9862 Loss2: -0.9844 Loss3: -0.9907\n",
            "2022-08-02 21:13:31.910427 Epoch [068/250], Step [0060/0060], Loss1: -0.9868 Loss2: -0.9868 Loss3: -0.9916\n",
            "Epoch: 68 MAE: 58.58617954497491 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:13:37.491379 Epoch [069/250], Step [0001/0060], Loss1: -0.9868 Loss2: -0.9849 Loss3: -0.9910\n",
            "2022-08-02 21:14:01.862220 Epoch [069/250], Step [0050/0060], Loss1: -0.9816 Loss2: -0.9815 Loss3: -0.9886\n",
            "2022-08-02 21:14:06.826969 Epoch [069/250], Step [0060/0060], Loss1: -0.9830 Loss2: -0.9868 Loss3: -0.9909\n",
            "Epoch: 69 MAE: 58.37143909373941 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:14:12.271590 Epoch [070/250], Step [0001/0060], Loss1: -0.9848 Loss2: -0.9832 Loss3: -0.9906\n",
            "2022-08-02 21:14:36.764596 Epoch [070/250], Step [0050/0060], Loss1: -0.9784 Loss2: -0.9807 Loss3: -0.9884\n",
            "2022-08-02 21:14:41.757684 Epoch [070/250], Step [0060/0060], Loss1: -0.9850 Loss2: -0.9862 Loss3: -0.9907\n",
            "Epoch: 70 MAE: 58.350879090604586 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:14:49.303880 Epoch [071/250], Step [0001/0060], Loss1: -0.9799 Loss2: -0.9816 Loss3: -0.9884\n",
            "2022-08-02 21:15:13.919886 Epoch [071/250], Step [0050/0060], Loss1: -0.9798 Loss2: -0.9843 Loss3: -0.9892\n",
            "2022-08-02 21:15:18.918714 Epoch [071/250], Step [0060/0060], Loss1: -0.9838 Loss2: -0.9843 Loss3: -0.9901\n",
            "Epoch: 71 MAE: 58.376457813959945 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:15:24.532894 Epoch [072/250], Step [0001/0060], Loss1: -0.9863 Loss2: -0.9878 Loss3: -0.9921\n",
            "2022-08-02 21:15:49.083406 Epoch [072/250], Step [0050/0060], Loss1: -0.9877 Loss2: -0.9882 Loss3: -0.9928\n",
            "2022-08-02 21:15:54.093957 Epoch [072/250], Step [0060/0060], Loss1: -0.9844 Loss2: -0.9859 Loss3: -0.9907\n",
            "Epoch: 72 MAE: 58.487191507410586 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:15:59.819548 Epoch [073/250], Step [0001/0060], Loss1: -0.9815 Loss2: -0.9803 Loss3: -0.9883\n",
            "2022-08-02 21:16:24.307366 Epoch [073/250], Step [0050/0060], Loss1: -0.9851 Loss2: -0.9857 Loss3: -0.9910\n",
            "2022-08-02 21:16:29.305767 Epoch [073/250], Step [0060/0060], Loss1: -0.9837 Loss2: -0.9822 Loss3: -0.9893\n",
            "Epoch: 73 MAE: 58.4394704188584 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:16:34.940347 Epoch [074/250], Step [0001/0060], Loss1: -0.9861 Loss2: -0.9844 Loss3: -0.9905\n",
            "2022-08-02 21:16:59.384158 Epoch [074/250], Step [0050/0060], Loss1: -0.9646 Loss2: -0.9680 Loss3: -0.9807\n",
            "2022-08-02 21:17:04.385212 Epoch [074/250], Step [0060/0060], Loss1: -0.9842 Loss2: -0.9839 Loss3: -0.9894\n",
            "Epoch: 74 MAE: 58.307002272968944 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:17:10.066350 Epoch [075/250], Step [0001/0060], Loss1: -0.9848 Loss2: -0.9826 Loss3: -0.9891\n",
            "2022-08-02 21:17:34.689740 Epoch [075/250], Step [0050/0060], Loss1: -0.9747 Loss2: -0.9760 Loss3: -0.9858\n",
            "2022-08-02 21:17:39.696321 Epoch [075/250], Step [0060/0060], Loss1: -0.9817 Loss2: -0.9826 Loss3: -0.9893\n",
            "Epoch: 75 MAE: 58.36535719118408 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:17:47.372984 Epoch [076/250], Step [0001/0060], Loss1: -0.9847 Loss2: -0.9830 Loss3: -0.9907\n",
            "2022-08-02 21:18:12.228686 Epoch [076/250], Step [0050/0060], Loss1: -0.9848 Loss2: -0.9818 Loss3: -0.9900\n",
            "2022-08-02 21:18:17.220094 Epoch [076/250], Step [0060/0060], Loss1: -0.9869 Loss2: -0.9856 Loss3: -0.9915\n",
            "Epoch: 76 MAE: 58.57575156974399 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:18:22.885264 Epoch [077/250], Step [0001/0060], Loss1: -0.9846 Loss2: -0.9866 Loss3: -0.9907\n",
            "2022-08-02 21:18:47.367502 Epoch [077/250], Step [0050/0060], Loss1: -0.9847 Loss2: -0.9854 Loss3: -0.9907\n",
            "2022-08-02 21:18:52.353516 Epoch [077/250], Step [0060/0060], Loss1: -0.9846 Loss2: -0.9851 Loss3: -0.9913\n",
            "Epoch: 77 MAE: 58.483891782788504 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:18:57.865721 Epoch [078/250], Step [0001/0060], Loss1: -0.9846 Loss2: -0.9852 Loss3: -0.9904\n",
            "2022-08-02 21:19:22.343478 Epoch [078/250], Step [0050/0060], Loss1: -0.9842 Loss2: -0.9838 Loss3: -0.9902\n",
            "2022-08-02 21:19:27.334343 Epoch [078/250], Step [0060/0060], Loss1: -0.9875 Loss2: -0.9876 Loss3: -0.9923\n",
            "Epoch: 78 MAE: 58.55288555031403 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:19:32.965547 Epoch [079/250], Step [0001/0060], Loss1: -0.9716 Loss2: -0.9756 Loss3: -0.9846\n",
            "2022-08-02 21:19:57.453611 Epoch [079/250], Step [0050/0060], Loss1: -0.9822 Loss2: -0.9838 Loss3: -0.9899\n",
            "2022-08-02 21:20:02.443930 Epoch [079/250], Step [0060/0060], Loss1: -0.9842 Loss2: -0.9866 Loss3: -0.9910\n",
            "Epoch: 79 MAE: 58.35685350302684 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:20:08.073940 Epoch [080/250], Step [0001/0060], Loss1: -0.9805 Loss2: -0.9782 Loss3: -0.9874\n",
            "2022-08-02 21:20:32.580358 Epoch [080/250], Step [0050/0060], Loss1: -0.9869 Loss2: -0.9860 Loss3: -0.9915\n",
            "2022-08-02 21:20:37.582852 Epoch [080/250], Step [0060/0060], Loss1: -0.9808 Loss2: -0.9834 Loss3: -0.9894\n",
            "Epoch: 80 MAE: 58.527956196675085 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:20:45.389970 Epoch [081/250], Step [0001/0060], Loss1: -0.9764 Loss2: -0.9814 Loss3: -0.9875\n",
            "2022-08-02 21:21:10.103437 Epoch [081/250], Step [0050/0060], Loss1: -0.9870 Loss2: -0.9877 Loss3: -0.9920\n",
            "2022-08-02 21:21:15.120898 Epoch [081/250], Step [0060/0060], Loss1: -0.9764 Loss2: -0.9814 Loss3: -0.9881\n",
            "Epoch: 81 MAE: 58.45851072953764 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:21:20.793592 Epoch [082/250], Step [0001/0060], Loss1: -0.9826 Loss2: -0.9858 Loss3: -0.9905\n",
            "2022-08-02 21:21:45.262114 Epoch [082/250], Step [0050/0060], Loss1: -0.9865 Loss2: -0.9865 Loss3: -0.9918\n",
            "2022-08-02 21:21:50.261019 Epoch [082/250], Step [0060/0060], Loss1: -0.9872 Loss2: -0.9848 Loss3: -0.9911\n",
            "Epoch: 82 MAE: 58.389763917685144 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:21:55.913928 Epoch [083/250], Step [0001/0060], Loss1: -0.9789 Loss2: -0.9802 Loss3: -0.9876\n",
            "2022-08-02 21:22:20.414455 Epoch [083/250], Step [0050/0060], Loss1: -0.9790 Loss2: -0.9797 Loss3: -0.9872\n",
            "2022-08-02 21:22:25.416684 Epoch [083/250], Step [0060/0060], Loss1: -0.9787 Loss2: -0.9807 Loss3: -0.9879\n",
            "Epoch: 83 MAE: 58.45537848357679 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:22:31.065251 Epoch [084/250], Step [0001/0060], Loss1: -0.9833 Loss2: -0.9864 Loss3: -0.9909\n",
            "2022-08-02 21:22:55.589612 Epoch [084/250], Step [0050/0060], Loss1: -0.9847 Loss2: -0.9852 Loss3: -0.9911\n",
            "2022-08-02 21:23:00.586324 Epoch [084/250], Step [0060/0060], Loss1: -0.9804 Loss2: -0.9854 Loss3: -0.9900\n",
            "Epoch: 84 MAE: 58.45187376795866 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:23:06.292123 Epoch [085/250], Step [0001/0060], Loss1: -0.9835 Loss2: -0.9814 Loss3: -0.9883\n",
            "2022-08-02 21:23:30.783270 Epoch [085/250], Step [0050/0060], Loss1: -0.9830 Loss2: -0.9848 Loss3: -0.9906\n",
            "2022-08-02 21:23:35.784031 Epoch [085/250], Step [0060/0060], Loss1: -0.9836 Loss2: -0.9861 Loss3: -0.9913\n",
            "Epoch: 85 MAE: 58.487376488980686 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:23:43.478147 Epoch [086/250], Step [0001/0060], Loss1: -0.9820 Loss2: -0.9841 Loss3: -0.9897\n",
            "2022-08-02 21:24:08.344022 Epoch [086/250], Step [0050/0060], Loss1: -0.9853 Loss2: -0.9834 Loss3: -0.9901\n",
            "2022-08-02 21:24:13.339725 Epoch [086/250], Step [0060/0060], Loss1: -0.9852 Loss2: -0.9844 Loss3: -0.9901\n",
            "Epoch: 86 MAE: 58.43021591690925 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:24:19.057896 Epoch [087/250], Step [0001/0060], Loss1: -0.9859 Loss2: -0.9822 Loss3: -0.9897\n",
            "2022-08-02 21:24:43.532208 Epoch [087/250], Step [0050/0060], Loss1: -0.9793 Loss2: -0.9814 Loss3: -0.9880\n",
            "2022-08-02 21:24:48.520298 Epoch [087/250], Step [0060/0060], Loss1: -0.9849 Loss2: -0.9839 Loss3: -0.9903\n",
            "Epoch: 87 MAE: 58.55655400640406 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "2022-08-02 21:24:54.102669 Epoch [088/250], Step [0001/0060], Loss1: -0.9787 Loss2: -0.9849 Loss3: -0.9895\n",
            "2022-08-02 21:25:18.610023 Epoch [088/250], Step [0050/0060], Loss1: -0.9832 Loss2: -0.9808 Loss3: -0.9887\n",
            "2022-08-02 21:25:23.601151 Epoch [088/250], Step [0060/0060], Loss1: -0.9881 Loss2: -0.9859 Loss3: -0.9918\n",
            "Epoch: 88 MAE: 58.29650858227651 ####  bestMAE: 58.30667537152914 bestEpoch: 43\n",
            "best epoch:88\n",
            "2022-08-02 21:25:31.529567 Epoch [089/250], Step [0001/0060], Loss1: -0.9858 Loss2: -0.9840 Loss3: -0.9903\n",
            "2022-08-02 21:25:56.153234 Epoch [089/250], Step [0050/0060], Loss1: -0.9733 Loss2: -0.9786 Loss3: -0.9859\n",
            "2022-08-02 21:26:01.159115 Epoch [089/250], Step [0060/0060], Loss1: -0.9855 Loss2: -0.9840 Loss3: -0.9903\n",
            "Epoch: 89 MAE: 58.518756713256636 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:26:06.796013 Epoch [090/250], Step [0001/0060], Loss1: -0.9830 Loss2: -0.9841 Loss3: -0.9895\n",
            "2022-08-02 21:26:31.305623 Epoch [090/250], Step [0050/0060], Loss1: -0.9842 Loss2: -0.9848 Loss3: -0.9908\n",
            "2022-08-02 21:26:36.310225 Epoch [090/250], Step [0060/0060], Loss1: -0.9862 Loss2: -0.9855 Loss3: -0.9916\n",
            "Epoch: 90 MAE: 58.495432912600336 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:26:44.021860 Epoch [091/250], Step [0001/0060], Loss1: -0.9851 Loss2: -0.9855 Loss3: -0.9909\n",
            "2022-08-02 21:27:08.598242 Epoch [091/250], Step [0050/0060], Loss1: -0.9819 Loss2: -0.9830 Loss3: -0.9886\n",
            "2022-08-02 21:27:13.591621 Epoch [091/250], Step [0060/0060], Loss1: -0.9836 Loss2: -0.9867 Loss3: -0.9912\n",
            "Epoch: 91 MAE: 58.483062211384286 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:27:19.059240 Epoch [092/250], Step [0001/0060], Loss1: -0.9866 Loss2: -0.9839 Loss3: -0.9910\n",
            "2022-08-02 21:27:43.483133 Epoch [092/250], Step [0050/0060], Loss1: -0.9797 Loss2: -0.9802 Loss3: -0.9876\n",
            "2022-08-02 21:27:48.460308 Epoch [092/250], Step [0060/0060], Loss1: -0.9867 Loss2: -0.9863 Loss3: -0.9918\n",
            "Epoch: 92 MAE: 58.50189802111321 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:27:54.049080 Epoch [093/250], Step [0001/0060], Loss1: -0.9864 Loss2: -0.9837 Loss3: -0.9909\n",
            "2022-08-02 21:28:18.481272 Epoch [093/250], Step [0050/0060], Loss1: -0.9824 Loss2: -0.9823 Loss3: -0.9894\n",
            "2022-08-02 21:28:23.463288 Epoch [093/250], Step [0060/0060], Loss1: -0.9761 Loss2: -0.9807 Loss3: -0.9876\n",
            "Epoch: 93 MAE: 58.468969126720054 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:28:29.129412 Epoch [094/250], Step [0001/0060], Loss1: -0.9855 Loss2: -0.9861 Loss3: -0.9911\n",
            "2022-08-02 21:28:53.560792 Epoch [094/250], Step [0050/0060], Loss1: -0.9876 Loss2: -0.9870 Loss3: -0.9920\n",
            "2022-08-02 21:28:58.540095 Epoch [094/250], Step [0060/0060], Loss1: -0.9820 Loss2: -0.9815 Loss3: -0.9876\n",
            "Epoch: 94 MAE: 58.32208644492572 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:29:04.177160 Epoch [095/250], Step [0001/0060], Loss1: -0.9827 Loss2: -0.9815 Loss3: -0.9887\n",
            "2022-08-02 21:29:28.675754 Epoch [095/250], Step [0050/0060], Loss1: -0.9841 Loss2: -0.9836 Loss3: -0.9900\n",
            "2022-08-02 21:29:33.671547 Epoch [095/250], Step [0060/0060], Loss1: -0.9872 Loss2: -0.9868 Loss3: -0.9916\n",
            "Epoch: 95 MAE: 58.51531933212429 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:29:41.345496 Epoch [096/250], Step [0001/0060], Loss1: -0.9858 Loss2: -0.9865 Loss3: -0.9919\n",
            "2022-08-02 21:30:05.956434 Epoch [096/250], Step [0050/0060], Loss1: -0.9866 Loss2: -0.9861 Loss3: -0.9908\n",
            "2022-08-02 21:30:10.928905 Epoch [096/250], Step [0060/0060], Loss1: -0.9851 Loss2: -0.9859 Loss3: -0.9914\n",
            "Epoch: 96 MAE: 58.29886959531945 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:30:16.534099 Epoch [097/250], Step [0001/0060], Loss1: -0.9743 Loss2: -0.9779 Loss3: -0.9856\n",
            "2022-08-02 21:30:40.926724 Epoch [097/250], Step [0050/0060], Loss1: -0.9839 Loss2: -0.9843 Loss3: -0.9902\n",
            "2022-08-02 21:30:45.910926 Epoch [097/250], Step [0060/0060], Loss1: -0.9772 Loss2: -0.9793 Loss3: -0.9866\n",
            "Epoch: 97 MAE: 58.525996497455736 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:30:51.405911 Epoch [098/250], Step [0001/0060], Loss1: -0.9828 Loss2: -0.9861 Loss3: -0.9905\n",
            "2022-08-02 21:31:15.840020 Epoch [098/250], Step [0050/0060], Loss1: -0.9852 Loss2: -0.9841 Loss3: -0.9899\n",
            "2022-08-02 21:31:20.820397 Epoch [098/250], Step [0060/0060], Loss1: -0.9851 Loss2: -0.9846 Loss3: -0.9906\n",
            "Epoch: 98 MAE: 58.48454966294627 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:31:26.417432 Epoch [099/250], Step [0001/0060], Loss1: -0.9757 Loss2: -0.9808 Loss3: -0.9870\n",
            "2022-08-02 21:31:50.828305 Epoch [099/250], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9865 Loss3: -0.9919\n",
            "2022-08-02 21:31:55.821227 Epoch [099/250], Step [0060/0060], Loss1: -0.9867 Loss2: -0.9861 Loss3: -0.9921\n",
            "Epoch: 99 MAE: 58.61136076722498 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:32:01.456885 Epoch [100/250], Step [0001/0060], Loss1: -0.9845 Loss2: -0.9812 Loss3: -0.9899\n",
            "2022-08-02 21:32:25.889433 Epoch [100/250], Step [0050/0060], Loss1: -0.9859 Loss2: -0.9873 Loss3: -0.9917\n",
            "2022-08-02 21:32:30.873139 Epoch [100/250], Step [0060/0060], Loss1: -0.9816 Loss2: -0.9850 Loss3: -0.9902\n",
            "Epoch: 100 MAE: 58.653225540036665 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:32:38.499799 Epoch [101/250], Step [0001/0060], Loss1: -0.9863 Loss2: -0.9845 Loss3: -0.9904\n",
            "2022-08-02 21:33:03.122805 Epoch [101/250], Step [0050/0060], Loss1: -0.9826 Loss2: -0.9805 Loss3: -0.9889\n",
            "2022-08-02 21:33:08.098333 Epoch [101/250], Step [0060/0060], Loss1: -0.9862 Loss2: -0.9871 Loss3: -0.9920\n",
            "Epoch: 101 MAE: 58.36880875226711 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:33:13.585919 Epoch [102/250], Step [0001/0060], Loss1: -0.9726 Loss2: -0.9800 Loss3: -0.9867\n",
            "2022-08-02 21:33:38.117318 Epoch [102/250], Step [0050/0060], Loss1: -0.9876 Loss2: -0.9885 Loss3: -0.9927\n",
            "2022-08-02 21:33:43.124828 Epoch [102/250], Step [0060/0060], Loss1: -0.9865 Loss2: -0.9861 Loss3: -0.9915\n",
            "Epoch: 102 MAE: 58.57992191060536 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:33:48.878917 Epoch [103/250], Step [0001/0060], Loss1: -0.9827 Loss2: -0.9838 Loss3: -0.9901\n",
            "2022-08-02 21:34:13.316112 Epoch [103/250], Step [0050/0060], Loss1: -0.9848 Loss2: -0.9845 Loss3: -0.9909\n",
            "2022-08-02 21:34:18.291781 Epoch [103/250], Step [0060/0060], Loss1: -0.9880 Loss2: -0.9869 Loss3: -0.9921\n",
            "Epoch: 103 MAE: 58.63666023130534 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:34:23.842358 Epoch [104/250], Step [0001/0060], Loss1: -0.9884 Loss2: -0.9855 Loss3: -0.9916\n",
            "2022-08-02 21:34:48.279879 Epoch [104/250], Step [0050/0060], Loss1: -0.9807 Loss2: -0.9800 Loss3: -0.9884\n",
            "2022-08-02 21:34:53.270706 Epoch [104/250], Step [0060/0060], Loss1: -0.9828 Loss2: -0.9841 Loss3: -0.9901\n",
            "Epoch: 104 MAE: 58.50850704621551 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:34:58.784257 Epoch [105/250], Step [0001/0060], Loss1: -0.9859 Loss2: -0.9861 Loss3: -0.9910\n",
            "2022-08-02 21:35:23.263492 Epoch [105/250], Step [0050/0060], Loss1: -0.9849 Loss2: -0.9815 Loss3: -0.9899\n",
            "2022-08-02 21:35:28.242168 Epoch [105/250], Step [0060/0060], Loss1: -0.9863 Loss2: -0.9861 Loss3: -0.9914\n",
            "Epoch: 105 MAE: 58.45678212411742 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:35:35.768442 Epoch [106/250], Step [0001/0060], Loss1: -0.9754 Loss2: -0.9804 Loss3: -0.9868\n",
            "2022-08-02 21:36:00.266860 Epoch [106/250], Step [0050/0060], Loss1: -0.9821 Loss2: -0.9834 Loss3: -0.9894\n",
            "2022-08-02 21:36:05.258472 Epoch [106/250], Step [0060/0060], Loss1: -0.9875 Loss2: -0.9873 Loss3: -0.9922\n",
            "Epoch: 106 MAE: 58.45051345409366 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:36:10.821141 Epoch [107/250], Step [0001/0060], Loss1: -0.9835 Loss2: -0.9800 Loss3: -0.9884\n",
            "2022-08-02 21:36:35.200765 Epoch [107/250], Step [0050/0060], Loss1: -0.9844 Loss2: -0.9831 Loss3: -0.9904\n",
            "2022-08-02 21:36:40.178905 Epoch [107/250], Step [0060/0060], Loss1: -0.9845 Loss2: -0.9860 Loss3: -0.9910\n",
            "Epoch: 107 MAE: 58.52481653162302 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:36:45.733244 Epoch [108/250], Step [0001/0060], Loss1: -0.9855 Loss2: -0.9861 Loss3: -0.9914\n",
            "2022-08-02 21:37:10.113896 Epoch [108/250], Step [0050/0060], Loss1: -0.9865 Loss2: -0.9865 Loss3: -0.9917\n",
            "2022-08-02 21:37:15.092898 Epoch [108/250], Step [0060/0060], Loss1: -0.9834 Loss2: -0.9820 Loss3: -0.9889\n",
            "Epoch: 108 MAE: 58.40876286290659 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:37:20.652376 Epoch [109/250], Step [0001/0060], Loss1: -0.9879 Loss2: -0.9870 Loss3: -0.9924\n",
            "2022-08-02 21:37:45.095391 Epoch [109/250], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9838 Loss3: -0.9905\n",
            "2022-08-02 21:37:50.068375 Epoch [109/250], Step [0060/0060], Loss1: -0.9848 Loss2: -0.9856 Loss3: -0.9907\n",
            "Epoch: 109 MAE: 58.45960265392641 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:37:55.479435 Epoch [110/250], Step [0001/0060], Loss1: -0.9844 Loss2: -0.9842 Loss3: -0.9899\n",
            "2022-08-02 21:38:19.862019 Epoch [110/250], Step [0050/0060], Loss1: -0.9830 Loss2: -0.9841 Loss3: -0.9899\n",
            "2022-08-02 21:38:24.833949 Epoch [110/250], Step [0060/0060], Loss1: -0.9839 Loss2: -0.9872 Loss3: -0.9917\n",
            "Epoch: 110 MAE: 58.58162286256323 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:38:32.465740 Epoch [111/250], Step [0001/0060], Loss1: -0.9873 Loss2: -0.9846 Loss3: -0.9916\n",
            "2022-08-02 21:38:57.098875 Epoch [111/250], Step [0050/0060], Loss1: -0.9846 Loss2: -0.9854 Loss3: -0.9909\n",
            "2022-08-02 21:39:02.079779 Epoch [111/250], Step [0060/0060], Loss1: -0.9862 Loss2: -0.9870 Loss3: -0.9923\n",
            "Epoch: 111 MAE: 58.44940232004989 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:39:07.529153 Epoch [112/250], Step [0001/0060], Loss1: -0.9847 Loss2: -0.9849 Loss3: -0.9910\n",
            "2022-08-02 21:39:32.004811 Epoch [112/250], Step [0050/0060], Loss1: -0.9858 Loss2: -0.9875 Loss3: -0.9921\n",
            "2022-08-02 21:39:36.984385 Epoch [112/250], Step [0060/0060], Loss1: -0.9811 Loss2: -0.9822 Loss3: -0.9895\n",
            "Epoch: 112 MAE: 58.484252573287 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:39:42.453071 Epoch [113/250], Step [0001/0060], Loss1: -0.9871 Loss2: -0.9859 Loss3: -0.9912\n",
            "2022-08-02 21:40:06.889723 Epoch [113/250], Step [0050/0060], Loss1: -0.9877 Loss2: -0.9877 Loss3: -0.9918\n",
            "2022-08-02 21:40:11.870407 Epoch [113/250], Step [0060/0060], Loss1: -0.9821 Loss2: -0.9823 Loss3: -0.9892\n",
            "Epoch: 113 MAE: 58.34497466522244 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:40:17.330515 Epoch [114/250], Step [0001/0060], Loss1: -0.9848 Loss2: -0.9835 Loss3: -0.9901\n",
            "2022-08-02 21:40:41.791533 Epoch [114/250], Step [0050/0060], Loss1: -0.9821 Loss2: -0.9847 Loss3: -0.9896\n",
            "2022-08-02 21:40:46.788851 Epoch [114/250], Step [0060/0060], Loss1: -0.9864 Loss2: -0.9853 Loss3: -0.9913\n",
            "Epoch: 114 MAE: 58.484401241570836 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:40:52.424718 Epoch [115/250], Step [0001/0060], Loss1: -0.9869 Loss2: -0.9879 Loss3: -0.9922\n",
            "2022-08-02 21:41:16.852256 Epoch [115/250], Step [0050/0060], Loss1: -0.9870 Loss2: -0.9885 Loss3: -0.9924\n",
            "2022-08-02 21:41:21.836133 Epoch [115/250], Step [0060/0060], Loss1: -0.9856 Loss2: -0.9864 Loss3: -0.9911\n",
            "Epoch: 115 MAE: 58.49231821271823 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:41:29.477446 Epoch [116/250], Step [0001/0060], Loss1: -0.9837 Loss2: -0.9862 Loss3: -0.9905\n",
            "2022-08-02 21:41:54.038864 Epoch [116/250], Step [0050/0060], Loss1: -0.9860 Loss2: -0.9859 Loss3: -0.9916\n",
            "2022-08-02 21:41:59.012411 Epoch [116/250], Step [0060/0060], Loss1: -0.9856 Loss2: -0.9863 Loss3: -0.9913\n",
            "Epoch: 116 MAE: 58.46849499643648 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:42:04.524138 Epoch [117/250], Step [0001/0060], Loss1: -0.9865 Loss2: -0.9867 Loss3: -0.9921\n",
            "2022-08-02 21:42:28.906371 Epoch [117/250], Step [0050/0060], Loss1: -0.9721 Loss2: -0.9794 Loss3: -0.9851\n",
            "2022-08-02 21:42:33.885492 Epoch [117/250], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9863 Loss3: -0.9918\n",
            "Epoch: 117 MAE: 58.42522619688849 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:42:39.387092 Epoch [118/250], Step [0001/0060], Loss1: -0.9881 Loss2: -0.9867 Loss3: -0.9923\n",
            "2022-08-02 21:43:03.795312 Epoch [118/250], Step [0050/0060], Loss1: -0.9880 Loss2: -0.9865 Loss3: -0.9917\n",
            "2022-08-02 21:43:08.781815 Epoch [118/250], Step [0060/0060], Loss1: -0.9852 Loss2: -0.9847 Loss3: -0.9902\n",
            "Epoch: 118 MAE: 58.52810647461505 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:43:14.295314 Epoch [119/250], Step [0001/0060], Loss1: -0.9857 Loss2: -0.9856 Loss3: -0.9911\n",
            "2022-08-02 21:43:38.712878 Epoch [119/250], Step [0050/0060], Loss1: -0.9866 Loss2: -0.9851 Loss3: -0.9915\n",
            "2022-08-02 21:43:43.682927 Epoch [119/250], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9875 Loss3: -0.9925\n",
            "Epoch: 119 MAE: 58.382713734828336 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:43:49.197494 Epoch [120/250], Step [0001/0060], Loss1: -0.9830 Loss2: -0.9811 Loss3: -0.9889\n",
            "2022-08-02 21:44:13.662505 Epoch [120/250], Step [0050/0060], Loss1: -0.9871 Loss2: -0.9875 Loss3: -0.9921\n",
            "2022-08-02 21:44:18.643465 Epoch [120/250], Step [0060/0060], Loss1: -0.9781 Loss2: -0.9807 Loss3: -0.9872\n",
            "Epoch: 120 MAE: 58.42778507039885 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:44:26.266846 Epoch [121/250], Step [0001/0060], Loss1: -0.9796 Loss2: -0.9821 Loss3: -0.9886\n",
            "2022-08-02 21:44:50.717594 Epoch [121/250], Step [0050/0060], Loss1: -0.9865 Loss2: -0.9865 Loss3: -0.9913\n",
            "2022-08-02 21:44:55.707922 Epoch [121/250], Step [0060/0060], Loss1: -0.9799 Loss2: -0.9825 Loss3: -0.9889\n",
            "Epoch: 121 MAE: 58.47352455367279 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:45:01.121977 Epoch [122/250], Step [0001/0060], Loss1: -0.9837 Loss2: -0.9849 Loss3: -0.9907\n",
            "2022-08-02 21:45:25.571897 Epoch [122/250], Step [0050/0060], Loss1: -0.9598 Loss2: -0.9743 Loss3: -0.9827\n",
            "2022-08-02 21:45:30.567814 Epoch [122/250], Step [0060/0060], Loss1: -0.9737 Loss2: -0.9783 Loss3: -0.9851\n",
            "Epoch: 122 MAE: 58.45679139516802 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:45:36.121547 Epoch [123/250], Step [0001/0060], Loss1: -0.9863 Loss2: -0.9871 Loss3: -0.9921\n",
            "2022-08-02 21:46:00.519567 Epoch [123/250], Step [0050/0060], Loss1: -0.9866 Loss2: -0.9866 Loss3: -0.9913\n",
            "2022-08-02 21:46:05.490101 Epoch [123/250], Step [0060/0060], Loss1: -0.9868 Loss2: -0.9858 Loss3: -0.9912\n",
            "Epoch: 123 MAE: 58.4501835574159 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:46:11.023216 Epoch [124/250], Step [0001/0060], Loss1: -0.9874 Loss2: -0.9854 Loss3: -0.9916\n",
            "2022-08-02 21:46:35.479404 Epoch [124/250], Step [0050/0060], Loss1: -0.9806 Loss2: -0.9815 Loss3: -0.9885\n",
            "2022-08-02 21:46:40.457890 Epoch [124/250], Step [0060/0060], Loss1: -0.9866 Loss2: -0.9837 Loss3: -0.9917\n",
            "Epoch: 124 MAE: 58.55553457127142 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:46:46.055756 Epoch [125/250], Step [0001/0060], Loss1: -0.9845 Loss2: -0.9853 Loss3: -0.9905\n",
            "2022-08-02 21:47:10.439534 Epoch [125/250], Step [0050/0060], Loss1: -0.9856 Loss2: -0.9845 Loss3: -0.9907\n",
            "2022-08-02 21:47:15.397347 Epoch [125/250], Step [0060/0060], Loss1: -0.9831 Loss2: -0.9863 Loss3: -0.9907\n",
            "Epoch: 125 MAE: 58.51122250281441 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:47:23.003920 Epoch [126/250], Step [0001/0060], Loss1: -0.9801 Loss2: -0.9804 Loss3: -0.9873\n",
            "2022-08-02 21:47:47.612921 Epoch [126/250], Step [0050/0060], Loss1: -0.9863 Loss2: -0.9853 Loss3: -0.9910\n",
            "2022-08-02 21:47:52.620402 Epoch [126/250], Step [0060/0060], Loss1: -0.9776 Loss2: -0.9797 Loss3: -0.9872\n",
            "Epoch: 126 MAE: 58.304914376367094 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:47:58.095720 Epoch [127/250], Step [0001/0060], Loss1: -0.9783 Loss2: -0.9817 Loss3: -0.9882\n",
            "2022-08-02 21:48:22.587309 Epoch [127/250], Step [0050/0060], Loss1: -0.9870 Loss2: -0.9882 Loss3: -0.9921\n",
            "2022-08-02 21:48:27.581124 Epoch [127/250], Step [0060/0060], Loss1: -0.9881 Loss2: -0.9882 Loss3: -0.9925\n",
            "Epoch: 127 MAE: 58.552953954244906 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:48:33.106180 Epoch [128/250], Step [0001/0060], Loss1: -0.9809 Loss2: -0.9815 Loss3: -0.9879\n",
            "2022-08-02 21:48:57.558889 Epoch [128/250], Step [0050/0060], Loss1: -0.9791 Loss2: -0.9837 Loss3: -0.9894\n",
            "2022-08-02 21:49:02.546442 Epoch [128/250], Step [0060/0060], Loss1: -0.9870 Loss2: -0.9861 Loss3: -0.9911\n",
            "Epoch: 128 MAE: 58.4137714913119 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:49:08.116835 Epoch [129/250], Step [0001/0060], Loss1: -0.9876 Loss2: -0.9867 Loss3: -0.9915\n",
            "2022-08-02 21:49:32.679906 Epoch [129/250], Step [0050/0060], Loss1: -0.9762 Loss2: -0.9812 Loss3: -0.9877\n",
            "2022-08-02 21:49:37.664271 Epoch [129/250], Step [0060/0060], Loss1: -0.9885 Loss2: -0.9872 Loss3: -0.9922\n",
            "Epoch: 129 MAE: 58.46194157082949 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:49:43.156736 Epoch [130/250], Step [0001/0060], Loss1: -0.9849 Loss2: -0.9849 Loss3: -0.9904\n",
            "2022-08-02 21:50:07.628933 Epoch [130/250], Step [0050/0060], Loss1: -0.9802 Loss2: -0.9827 Loss3: -0.9885\n",
            "2022-08-02 21:50:12.612804 Epoch [130/250], Step [0060/0060], Loss1: -0.9866 Loss2: -0.9852 Loss3: -0.9913\n",
            "Epoch: 130 MAE: 58.588947465463775 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:50:20.259195 Epoch [131/250], Step [0001/0060], Loss1: -0.9703 Loss2: -0.9791 Loss3: -0.9858\n",
            "2022-08-02 21:50:44.856281 Epoch [131/250], Step [0050/0060], Loss1: -0.9824 Loss2: -0.9822 Loss3: -0.9895\n",
            "2022-08-02 21:50:49.855852 Epoch [131/250], Step [0060/0060], Loss1: -0.9840 Loss2: -0.9863 Loss3: -0.9915\n",
            "Epoch: 131 MAE: 58.32287579202591 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:50:55.368361 Epoch [132/250], Step [0001/0060], Loss1: -0.9885 Loss2: -0.9892 Loss3: -0.9929\n",
            "2022-08-02 21:51:19.818431 Epoch [132/250], Step [0050/0060], Loss1: -0.9871 Loss2: -0.9875 Loss3: -0.9920\n",
            "2022-08-02 21:51:24.802172 Epoch [132/250], Step [0060/0060], Loss1: -0.9818 Loss2: -0.9812 Loss3: -0.9886\n",
            "Epoch: 132 MAE: 58.45681182457178 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:51:30.343655 Epoch [133/250], Step [0001/0060], Loss1: -0.9870 Loss2: -0.9889 Loss3: -0.9929\n",
            "2022-08-02 21:51:54.759267 Epoch [133/250], Step [0050/0060], Loss1: -0.9821 Loss2: -0.9815 Loss3: -0.9883\n",
            "2022-08-02 21:51:59.730930 Epoch [133/250], Step [0060/0060], Loss1: -0.9859 Loss2: -0.9872 Loss3: -0.9913\n",
            "Epoch: 133 MAE: 58.441721642893754 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:52:05.305947 Epoch [134/250], Step [0001/0060], Loss1: -0.9888 Loss2: -0.9858 Loss3: -0.9922\n",
            "2022-08-02 21:52:29.746375 Epoch [134/250], Step [0050/0060], Loss1: -0.9829 Loss2: -0.9847 Loss3: -0.9903\n",
            "2022-08-02 21:52:34.729190 Epoch [134/250], Step [0060/0060], Loss1: -0.9821 Loss2: -0.9813 Loss3: -0.9885\n",
            "Epoch: 134 MAE: 58.563129496987 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:52:40.340225 Epoch [135/250], Step [0001/0060], Loss1: -0.9815 Loss2: -0.9808 Loss3: -0.9888\n",
            "2022-08-02 21:53:04.744391 Epoch [135/250], Step [0050/0060], Loss1: -0.9711 Loss2: -0.9740 Loss3: -0.9837\n",
            "2022-08-02 21:53:09.725438 Epoch [135/250], Step [0060/0060], Loss1: -0.9833 Loss2: -0.9823 Loss3: -0.9898\n",
            "Epoch: 135 MAE: 58.59322672649751 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:53:17.406407 Epoch [136/250], Step [0001/0060], Loss1: -0.9817 Loss2: -0.9785 Loss3: -0.9874\n",
            "2022-08-02 21:53:42.103209 Epoch [136/250], Step [0050/0060], Loss1: -0.9884 Loss2: -0.9866 Loss3: -0.9925\n",
            "2022-08-02 21:53:47.087544 Epoch [136/250], Step [0060/0060], Loss1: -0.9868 Loss2: -0.9840 Loss3: -0.9907\n",
            "Epoch: 136 MAE: 58.365917708062355 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:53:52.717924 Epoch [137/250], Step [0001/0060], Loss1: -0.9873 Loss2: -0.9856 Loss3: -0.9921\n",
            "2022-08-02 21:54:17.114198 Epoch [137/250], Step [0050/0060], Loss1: -0.9882 Loss2: -0.9861 Loss3: -0.9922\n",
            "2022-08-02 21:54:22.115313 Epoch [137/250], Step [0060/0060], Loss1: -0.9880 Loss2: -0.9871 Loss3: -0.9921\n",
            "Epoch: 137 MAE: 58.4887253551936 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:54:27.748183 Epoch [138/250], Step [0001/0060], Loss1: -0.9854 Loss2: -0.9862 Loss3: -0.9909\n",
            "2022-08-02 21:54:52.268711 Epoch [138/250], Step [0050/0060], Loss1: -0.9873 Loss2: -0.9865 Loss3: -0.9912\n",
            "2022-08-02 21:54:57.260971 Epoch [138/250], Step [0060/0060], Loss1: -0.9826 Loss2: -0.9812 Loss3: -0.9886\n",
            "Epoch: 138 MAE: 58.38224730505202 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:55:02.886852 Epoch [139/250], Step [0001/0060], Loss1: -0.9835 Loss2: -0.9848 Loss3: -0.9905\n",
            "2022-08-02 21:55:27.344323 Epoch [139/250], Step [0050/0060], Loss1: -0.9804 Loss2: -0.9836 Loss3: -0.9888\n",
            "2022-08-02 21:55:32.325225 Epoch [139/250], Step [0060/0060], Loss1: -0.9885 Loss2: -0.9876 Loss3: -0.9930\n",
            "Epoch: 139 MAE: 58.44636088164392 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:55:37.845076 Epoch [140/250], Step [0001/0060], Loss1: -0.9840 Loss2: -0.9841 Loss3: -0.9897\n",
            "2022-08-02 21:56:02.259214 Epoch [140/250], Step [0050/0060], Loss1: -0.9842 Loss2: -0.9843 Loss3: -0.9895\n",
            "2022-08-02 21:56:07.247095 Epoch [140/250], Step [0060/0060], Loss1: -0.9840 Loss2: -0.9835 Loss3: -0.9890\n",
            "Epoch: 140 MAE: 58.30402254654079 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:56:14.801268 Epoch [141/250], Step [0001/0060], Loss1: -0.9805 Loss2: -0.9841 Loss3: -0.9901\n",
            "2022-08-02 21:56:39.398964 Epoch [141/250], Step [0050/0060], Loss1: -0.9853 Loss2: -0.9869 Loss3: -0.9914\n",
            "2022-08-02 21:56:44.371213 Epoch [141/250], Step [0060/0060], Loss1: -0.9874 Loss2: -0.9872 Loss3: -0.9916\n",
            "Epoch: 141 MAE: 58.37040845578356 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:56:49.824761 Epoch [142/250], Step [0001/0060], Loss1: -0.9883 Loss2: -0.9894 Loss3: -0.9929\n",
            "2022-08-02 21:57:14.213678 Epoch [142/250], Step [0050/0060], Loss1: -0.9884 Loss2: -0.9877 Loss3: -0.9925\n",
            "2022-08-02 21:57:19.188246 Epoch [142/250], Step [0060/0060], Loss1: -0.9867 Loss2: -0.9858 Loss3: -0.9907\n",
            "Epoch: 142 MAE: 58.50207772743437 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:57:24.636911 Epoch [143/250], Step [0001/0060], Loss1: -0.9800 Loss2: -0.9827 Loss3: -0.9892\n",
            "2022-08-02 21:57:49.159320 Epoch [143/250], Step [0050/0060], Loss1: -0.9811 Loss2: -0.9805 Loss3: -0.9887\n",
            "2022-08-02 21:57:54.142690 Epoch [143/250], Step [0060/0060], Loss1: -0.9878 Loss2: -0.9868 Loss3: -0.9919\n",
            "Epoch: 143 MAE: 58.5667433340251 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:57:59.575440 Epoch [144/250], Step [0001/0060], Loss1: -0.9807 Loss2: -0.9814 Loss3: -0.9886\n",
            "2022-08-02 21:58:24.015617 Epoch [144/250], Step [0050/0060], Loss1: -0.9828 Loss2: -0.9858 Loss3: -0.9905\n",
            "2022-08-02 21:58:28.992813 Epoch [144/250], Step [0060/0060], Loss1: -0.9875 Loss2: -0.9870 Loss3: -0.9919\n",
            "Epoch: 144 MAE: 58.379314174926044 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:58:34.426258 Epoch [145/250], Step [0001/0060], Loss1: -0.9872 Loss2: -0.9873 Loss3: -0.9920\n",
            "2022-08-02 21:58:58.974349 Epoch [145/250], Step [0050/0060], Loss1: -0.9877 Loss2: -0.9887 Loss3: -0.9926\n",
            "2022-08-02 21:59:03.953460 Epoch [145/250], Step [0060/0060], Loss1: -0.9858 Loss2: -0.9857 Loss3: -0.9911\n",
            "Epoch: 145 MAE: 58.482528410289184 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:59:11.600669 Epoch [146/250], Step [0001/0060], Loss1: -0.9829 Loss2: -0.9833 Loss3: -0.9901\n",
            "2022-08-02 21:59:36.349192 Epoch [146/250], Step [0050/0060], Loss1: -0.9852 Loss2: -0.9838 Loss3: -0.9904\n",
            "2022-08-02 21:59:41.330444 Epoch [146/250], Step [0060/0060], Loss1: -0.9861 Loss2: -0.9860 Loss3: -0.9913\n",
            "Epoch: 146 MAE: 58.42739654770483 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 21:59:46.773402 Epoch [147/250], Step [0001/0060], Loss1: -0.9764 Loss2: -0.9818 Loss3: -0.9877\n",
            "2022-08-02 22:00:11.244617 Epoch [147/250], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9881 Loss3: -0.9928\n",
            "2022-08-02 22:00:16.238350 Epoch [147/250], Step [0060/0060], Loss1: -0.9854 Loss2: -0.9861 Loss3: -0.9910\n",
            "Epoch: 147 MAE: 58.44457401138627 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:00:21.777753 Epoch [148/250], Step [0001/0060], Loss1: -0.9844 Loss2: -0.9835 Loss3: -0.9891\n",
            "2022-08-02 22:00:46.204947 Epoch [148/250], Step [0050/0060], Loss1: -0.9844 Loss2: -0.9851 Loss3: -0.9908\n",
            "2022-08-02 22:00:51.184938 Epoch [148/250], Step [0060/0060], Loss1: -0.9858 Loss2: -0.9841 Loss3: -0.9911\n",
            "Epoch: 148 MAE: 58.4550281508538 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:00:56.729570 Epoch [149/250], Step [0001/0060], Loss1: -0.9847 Loss2: -0.9852 Loss3: -0.9904\n",
            "2022-08-02 22:01:21.138233 Epoch [149/250], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9862 Loss3: -0.9909\n",
            "2022-08-02 22:01:26.168637 Epoch [149/250], Step [0060/0060], Loss1: -0.9863 Loss2: -0.9845 Loss3: -0.9905\n",
            "Epoch: 149 MAE: 58.5405904868608 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:01:31.745453 Epoch [150/250], Step [0001/0060], Loss1: -0.9840 Loss2: -0.9871 Loss3: -0.9909\n",
            "2022-08-02 22:01:56.289425 Epoch [150/250], Step [0050/0060], Loss1: -0.9838 Loss2: -0.9845 Loss3: -0.9900\n",
            "2022-08-02 22:02:01.281421 Epoch [150/250], Step [0060/0060], Loss1: -0.9880 Loss2: -0.9864 Loss3: -0.9918\n",
            "Epoch: 150 MAE: 58.57823788084993 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:02:09.332513 Epoch [151/250], Step [0001/0060], Loss1: -0.9863 Loss2: -0.9866 Loss3: -0.9913\n",
            "2022-08-02 22:02:33.882321 Epoch [151/250], Step [0050/0060], Loss1: -0.9830 Loss2: -0.9846 Loss3: -0.9897\n",
            "2022-08-02 22:02:38.884447 Epoch [151/250], Step [0060/0060], Loss1: -0.9819 Loss2: -0.9807 Loss3: -0.9888\n",
            "Epoch: 151 MAE: 58.627345255546416 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:02:44.528187 Epoch [152/250], Step [0001/0060], Loss1: -0.9799 Loss2: -0.9786 Loss3: -0.9877\n",
            "2022-08-02 22:03:09.178701 Epoch [152/250], Step [0050/0060], Loss1: -0.9881 Loss2: -0.9871 Loss3: -0.9919\n",
            "2022-08-02 22:03:14.185231 Epoch [152/250], Step [0060/0060], Loss1: -0.9860 Loss2: -0.9844 Loss3: -0.9908\n",
            "Epoch: 152 MAE: 58.568082557271076 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:03:19.797374 Epoch [153/250], Step [0001/0060], Loss1: -0.9837 Loss2: -0.9811 Loss3: -0.9888\n",
            "2022-08-02 22:03:44.318660 Epoch [153/250], Step [0050/0060], Loss1: -0.9809 Loss2: -0.9749 Loss3: -0.9862\n",
            "2022-08-02 22:03:49.317818 Epoch [153/250], Step [0060/0060], Loss1: -0.9824 Loss2: -0.9857 Loss3: -0.9905\n",
            "Epoch: 153 MAE: 58.52261834888553 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:03:54.888496 Epoch [154/250], Step [0001/0060], Loss1: -0.9872 Loss2: -0.9859 Loss3: -0.9911\n",
            "2022-08-02 22:04:19.384829 Epoch [154/250], Step [0050/0060], Loss1: -0.9878 Loss2: -0.9877 Loss3: -0.9921\n",
            "2022-08-02 22:04:24.401236 Epoch [154/250], Step [0060/0060], Loss1: -0.9874 Loss2: -0.9880 Loss3: -0.9918\n",
            "Epoch: 154 MAE: 58.46523852390218 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:04:30.051872 Epoch [155/250], Step [0001/0060], Loss1: -0.9878 Loss2: -0.9868 Loss3: -0.9918\n",
            "2022-08-02 22:04:54.588736 Epoch [155/250], Step [0050/0060], Loss1: -0.9842 Loss2: -0.9824 Loss3: -0.9895\n",
            "2022-08-02 22:04:59.590936 Epoch [155/250], Step [0060/0060], Loss1: -0.9863 Loss2: -0.9879 Loss3: -0.9923\n",
            "Epoch: 155 MAE: 58.59361036128495 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:05:07.351252 Epoch [156/250], Step [0001/0060], Loss1: -0.9863 Loss2: -0.9871 Loss3: -0.9920\n",
            "2022-08-02 22:05:31.947431 Epoch [156/250], Step [0050/0060], Loss1: -0.9864 Loss2: -0.9867 Loss3: -0.9915\n",
            "2022-08-02 22:05:36.954376 Epoch [156/250], Step [0060/0060], Loss1: -0.9891 Loss2: -0.9872 Loss3: -0.9927\n",
            "Epoch: 156 MAE: 58.367362589610295 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:05:42.530093 Epoch [157/250], Step [0001/0060], Loss1: -0.9876 Loss2: -0.9867 Loss3: -0.9922\n",
            "2022-08-02 22:06:07.000356 Epoch [157/250], Step [0050/0060], Loss1: -0.9874 Loss2: -0.9872 Loss3: -0.9919\n",
            "2022-08-02 22:06:11.990744 Epoch [157/250], Step [0060/0060], Loss1: -0.9844 Loss2: -0.9822 Loss3: -0.9898\n",
            "Epoch: 157 MAE: 58.336703629631295 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:06:17.540473 Epoch [158/250], Step [0001/0060], Loss1: -0.9833 Loss2: -0.9828 Loss3: -0.9892\n",
            "2022-08-02 22:06:42.028718 Epoch [158/250], Step [0050/0060], Loss1: -0.9884 Loss2: -0.9885 Loss3: -0.9924\n",
            "2022-08-02 22:06:47.026685 Epoch [158/250], Step [0060/0060], Loss1: -0.9868 Loss2: -0.9842 Loss3: -0.9907\n",
            "Epoch: 158 MAE: 58.58277982862433 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:06:52.566764 Epoch [159/250], Step [0001/0060], Loss1: -0.9797 Loss2: -0.9826 Loss3: -0.9889\n",
            "2022-08-02 22:07:17.121617 Epoch [159/250], Step [0050/0060], Loss1: -0.9852 Loss2: -0.9843 Loss3: -0.9905\n",
            "2022-08-02 22:07:22.146236 Epoch [159/250], Step [0060/0060], Loss1: -0.9860 Loss2: -0.9861 Loss3: -0.9915\n",
            "Epoch: 159 MAE: 58.53441888608467 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:07:27.729818 Epoch [160/250], Step [0001/0060], Loss1: -0.9818 Loss2: -0.9855 Loss3: -0.9899\n",
            "2022-08-02 22:07:52.224463 Epoch [160/250], Step [0050/0060], Loss1: -0.9859 Loss2: -0.9855 Loss3: -0.9909\n",
            "2022-08-02 22:07:57.210708 Epoch [160/250], Step [0060/0060], Loss1: -0.9728 Loss2: -0.9770 Loss3: -0.9857\n",
            "Epoch: 160 MAE: 58.39427021311844 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:08:05.098547 Epoch [161/250], Step [0001/0060], Loss1: -0.9862 Loss2: -0.9869 Loss3: -0.9914\n",
            "2022-08-02 22:08:29.752285 Epoch [161/250], Step [0050/0060], Loss1: -0.9886 Loss2: -0.9885 Loss3: -0.9926\n",
            "2022-08-02 22:08:34.748961 Epoch [161/250], Step [0060/0060], Loss1: -0.9868 Loss2: -0.9829 Loss3: -0.9906\n",
            "Epoch: 161 MAE: 58.40488166588045 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:08:40.341076 Epoch [162/250], Step [0001/0060], Loss1: -0.9812 Loss2: -0.9830 Loss3: -0.9888\n",
            "2022-08-02 22:09:04.857658 Epoch [162/250], Step [0050/0060], Loss1: -0.9814 Loss2: -0.9832 Loss3: -0.9885\n",
            "2022-08-02 22:09:09.860213 Epoch [162/250], Step [0060/0060], Loss1: -0.9890 Loss2: -0.9897 Loss3: -0.9933\n",
            "Epoch: 162 MAE: 58.45128298029566 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:09:15.430856 Epoch [163/250], Step [0001/0060], Loss1: -0.9859 Loss2: -0.9862 Loss3: -0.9916\n",
            "2022-08-02 22:09:39.928745 Epoch [163/250], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9862 Loss3: -0.9913\n",
            "2022-08-02 22:09:44.924825 Epoch [163/250], Step [0060/0060], Loss1: -0.9779 Loss2: -0.9766 Loss3: -0.9856\n",
            "Epoch: 163 MAE: 58.373611619060554 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:09:50.506732 Epoch [164/250], Step [0001/0060], Loss1: -0.9811 Loss2: -0.9820 Loss3: -0.9885\n",
            "2022-08-02 22:10:14.980764 Epoch [164/250], Step [0050/0060], Loss1: -0.9850 Loss2: -0.9851 Loss3: -0.9904\n",
            "2022-08-02 22:10:19.981819 Epoch [164/250], Step [0060/0060], Loss1: -0.9827 Loss2: -0.9841 Loss3: -0.9892\n",
            "Epoch: 164 MAE: 58.39994817145257 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:10:25.619783 Epoch [165/250], Step [0001/0060], Loss1: -0.9844 Loss2: -0.9831 Loss3: -0.9897\n",
            "2022-08-02 22:10:50.116067 Epoch [165/250], Step [0050/0060], Loss1: -0.9857 Loss2: -0.9884 Loss3: -0.9922\n",
            "2022-08-02 22:10:55.121816 Epoch [165/250], Step [0060/0060], Loss1: -0.9837 Loss2: -0.9827 Loss3: -0.9896\n",
            "Epoch: 165 MAE: 58.531292231195344 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:11:02.831648 Epoch [166/250], Step [0001/0060], Loss1: -0.9865 Loss2: -0.9871 Loss3: -0.9919\n",
            "2022-08-02 22:11:27.418102 Epoch [166/250], Step [0050/0060], Loss1: -0.9808 Loss2: -0.9827 Loss3: -0.9888\n",
            "2022-08-02 22:11:32.415772 Epoch [166/250], Step [0060/0060], Loss1: -0.9817 Loss2: -0.9829 Loss3: -0.9892\n",
            "Epoch: 166 MAE: 58.4275672722354 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:11:37.968945 Epoch [167/250], Step [0001/0060], Loss1: -0.9849 Loss2: -0.9856 Loss3: -0.9913\n",
            "2022-08-02 22:12:02.480100 Epoch [167/250], Step [0050/0060], Loss1: -0.9815 Loss2: -0.9814 Loss3: -0.9888\n",
            "2022-08-02 22:12:07.481502 Epoch [167/250], Step [0060/0060], Loss1: -0.9857 Loss2: -0.9868 Loss3: -0.9915\n",
            "Epoch: 167 MAE: 58.503675911234694 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:12:13.116438 Epoch [168/250], Step [0001/0060], Loss1: -0.9845 Loss2: -0.9811 Loss3: -0.9893\n",
            "2022-08-02 22:12:37.667309 Epoch [168/250], Step [0050/0060], Loss1: -0.9873 Loss2: -0.9873 Loss3: -0.9917\n",
            "2022-08-02 22:12:42.671274 Epoch [168/250], Step [0060/0060], Loss1: -0.9789 Loss2: -0.9803 Loss3: -0.9877\n",
            "Epoch: 168 MAE: 58.40059639143356 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:12:48.350634 Epoch [169/250], Step [0001/0060], Loss1: -0.9830 Loss2: -0.9827 Loss3: -0.9889\n",
            "2022-08-02 22:13:12.986199 Epoch [169/250], Step [0050/0060], Loss1: -0.9885 Loss2: -0.9878 Loss3: -0.9924\n",
            "2022-08-02 22:13:17.992290 Epoch [169/250], Step [0060/0060], Loss1: -0.9866 Loss2: -0.9858 Loss3: -0.9917\n",
            "Epoch: 169 MAE: 58.59914153844617 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:13:23.642634 Epoch [170/250], Step [0001/0060], Loss1: -0.9855 Loss2: -0.9845 Loss3: -0.9904\n",
            "2022-08-02 22:13:48.204941 Epoch [170/250], Step [0050/0060], Loss1: -0.9818 Loss2: -0.9846 Loss3: -0.9895\n",
            "2022-08-02 22:13:53.198560 Epoch [170/250], Step [0060/0060], Loss1: -0.9875 Loss2: -0.9879 Loss3: -0.9923\n",
            "Epoch: 170 MAE: 58.56273724194 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:14:00.692274 Epoch [171/250], Step [0001/0060], Loss1: -0.9860 Loss2: -0.9866 Loss3: -0.9913\n",
            "2022-08-02 22:14:25.409735 Epoch [171/250], Step [0050/0060], Loss1: -0.9887 Loss2: -0.9866 Loss3: -0.9924\n",
            "2022-08-02 22:14:30.398929 Epoch [171/250], Step [0060/0060], Loss1: -0.9874 Loss2: -0.9898 Loss3: -0.9931\n",
            "Epoch: 171 MAE: 58.441324781834375 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:14:35.882432 Epoch [172/250], Step [0001/0060], Loss1: -0.9866 Loss2: -0.9883 Loss3: -0.9924\n",
            "2022-08-02 22:15:00.334535 Epoch [172/250], Step [0050/0060], Loss1: -0.9843 Loss2: -0.9841 Loss3: -0.9904\n",
            "2022-08-02 22:15:05.325086 Epoch [172/250], Step [0060/0060], Loss1: -0.9878 Loss2: -0.9852 Loss3: -0.9912\n",
            "Epoch: 172 MAE: 58.39784819384268 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:15:10.814371 Epoch [173/250], Step [0001/0060], Loss1: -0.9882 Loss2: -0.9882 Loss3: -0.9923\n",
            "2022-08-02 22:15:35.223074 Epoch [173/250], Step [0050/0060], Loss1: -0.9861 Loss2: -0.9869 Loss3: -0.9915\n",
            "2022-08-02 22:15:40.206949 Epoch [173/250], Step [0060/0060], Loss1: -0.9812 Loss2: -0.9820 Loss3: -0.9879\n",
            "Epoch: 173 MAE: 58.33411343590185 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:15:45.689409 Epoch [174/250], Step [0001/0060], Loss1: -0.9862 Loss2: -0.9871 Loss3: -0.9917\n",
            "2022-08-02 22:16:10.159282 Epoch [174/250], Step [0050/0060], Loss1: -0.9804 Loss2: -0.9858 Loss3: -0.9897\n",
            "2022-08-02 22:16:15.156526 Epoch [174/250], Step [0060/0060], Loss1: -0.9826 Loss2: -0.9832 Loss3: -0.9898\n",
            "Epoch: 174 MAE: 58.42888807225439 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:16:20.687988 Epoch [175/250], Step [0001/0060], Loss1: -0.9884 Loss2: -0.9857 Loss3: -0.9925\n",
            "2022-08-02 22:16:45.124532 Epoch [175/250], Step [0050/0060], Loss1: -0.9848 Loss2: -0.9846 Loss3: -0.9906\n",
            "2022-08-02 22:16:50.102554 Epoch [175/250], Step [0060/0060], Loss1: -0.9876 Loss2: -0.9864 Loss3: -0.9912\n",
            "Epoch: 175 MAE: 58.43164340719502 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:16:57.610115 Epoch [176/250], Step [0001/0060], Loss1: -0.9881 Loss2: -0.9865 Loss3: -0.9920\n",
            "2022-08-02 22:17:22.187153 Epoch [176/250], Step [0050/0060], Loss1: -0.9881 Loss2: -0.9876 Loss3: -0.9921\n",
            "2022-08-02 22:17:27.174719 Epoch [176/250], Step [0060/0060], Loss1: -0.9868 Loss2: -0.9841 Loss3: -0.9902\n",
            "Epoch: 176 MAE: 58.46386016299798 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:17:32.823581 Epoch [177/250], Step [0001/0060], Loss1: -0.9871 Loss2: -0.9851 Loss3: -0.9913\n",
            "2022-08-02 22:17:57.374314 Epoch [177/250], Step [0050/0060], Loss1: -0.9876 Loss2: -0.9871 Loss3: -0.9923\n",
            "2022-08-02 22:18:02.356484 Epoch [177/250], Step [0060/0060], Loss1: -0.9865 Loss2: -0.9849 Loss3: -0.9910\n",
            "Epoch: 177 MAE: 58.484709325721035 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:18:07.843863 Epoch [178/250], Step [0001/0060], Loss1: -0.9869 Loss2: -0.9866 Loss3: -0.9916\n",
            "2022-08-02 22:18:32.258745 Epoch [178/250], Step [0050/0060], Loss1: -0.9883 Loss2: -0.9875 Loss3: -0.9924\n",
            "2022-08-02 22:18:37.243756 Epoch [178/250], Step [0060/0060], Loss1: -0.9846 Loss2: -0.9854 Loss3: -0.9915\n",
            "Epoch: 178 MAE: 58.490221909328625 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:18:42.718945 Epoch [179/250], Step [0001/0060], Loss1: -0.9840 Loss2: -0.9834 Loss3: -0.9899\n",
            "2022-08-02 22:19:07.197850 Epoch [179/250], Step [0050/0060], Loss1: -0.9779 Loss2: -0.9799 Loss3: -0.9874\n",
            "2022-08-02 22:19:12.175073 Epoch [179/250], Step [0060/0060], Loss1: -0.9874 Loss2: -0.9870 Loss3: -0.9917\n",
            "Epoch: 179 MAE: 58.58297629876207 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:19:17.640768 Epoch [180/250], Step [0001/0060], Loss1: -0.9801 Loss2: -0.9853 Loss3: -0.9899\n",
            "2022-08-02 22:19:42.092693 Epoch [180/250], Step [0050/0060], Loss1: -0.9830 Loss2: -0.9848 Loss3: -0.9906\n",
            "2022-08-02 22:19:47.081177 Epoch [180/250], Step [0060/0060], Loss1: -0.9889 Loss2: -0.9878 Loss3: -0.9925\n",
            "Epoch: 180 MAE: 58.40600732105042 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:19:54.677127 Epoch [181/250], Step [0001/0060], Loss1: -0.9859 Loss2: -0.9850 Loss3: -0.9912\n",
            "2022-08-02 22:20:19.477922 Epoch [181/250], Step [0050/0060], Loss1: -0.9847 Loss2: -0.9839 Loss3: -0.9901\n",
            "2022-08-02 22:20:24.482402 Epoch [181/250], Step [0060/0060], Loss1: -0.9875 Loss2: -0.9869 Loss3: -0.9920\n",
            "Epoch: 181 MAE: 58.54279200690573 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:20:30.082727 Epoch [182/250], Step [0001/0060], Loss1: -0.9814 Loss2: -0.9838 Loss3: -0.9887\n",
            "2022-08-02 22:20:54.604329 Epoch [182/250], Step [0050/0060], Loss1: -0.9876 Loss2: -0.9859 Loss3: -0.9921\n",
            "2022-08-02 22:20:59.603543 Epoch [182/250], Step [0060/0060], Loss1: -0.9872 Loss2: -0.9870 Loss3: -0.9917\n",
            "Epoch: 182 MAE: 58.50246979746631 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:21:05.151035 Epoch [183/250], Step [0001/0060], Loss1: -0.9845 Loss2: -0.9875 Loss3: -0.9917\n",
            "2022-08-02 22:21:29.603499 Epoch [183/250], Step [0050/0060], Loss1: -0.9833 Loss2: -0.9837 Loss3: -0.9895\n",
            "2022-08-02 22:21:34.583359 Epoch [183/250], Step [0060/0060], Loss1: -0.9861 Loss2: -0.9847 Loss3: -0.9915\n",
            "Epoch: 183 MAE: 58.50302071077993 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:21:40.118926 Epoch [184/250], Step [0001/0060], Loss1: -0.9890 Loss2: -0.9882 Loss3: -0.9929\n",
            "2022-08-02 22:22:04.609285 Epoch [184/250], Step [0050/0060], Loss1: -0.9837 Loss2: -0.9854 Loss3: -0.9907\n",
            "2022-08-02 22:22:09.606749 Epoch [184/250], Step [0060/0060], Loss1: -0.9859 Loss2: -0.9847 Loss3: -0.9910\n",
            "Epoch: 184 MAE: 58.523860299850845 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:22:15.085752 Epoch [185/250], Step [0001/0060], Loss1: -0.9866 Loss2: -0.9864 Loss3: -0.9920\n",
            "2022-08-02 22:22:39.535517 Epoch [185/250], Step [0050/0060], Loss1: -0.9893 Loss2: -0.9889 Loss3: -0.9932\n",
            "2022-08-02 22:22:44.514316 Epoch [185/250], Step [0060/0060], Loss1: -0.9874 Loss2: -0.9877 Loss3: -0.9922\n",
            "Epoch: 185 MAE: 58.485381516848676 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:22:52.162674 Epoch [186/250], Step [0001/0060], Loss1: -0.9881 Loss2: -0.9869 Loss3: -0.9921\n",
            "2022-08-02 22:23:16.714258 Epoch [186/250], Step [0050/0060], Loss1: -0.9816 Loss2: -0.9813 Loss3: -0.9887\n",
            "2022-08-02 22:23:21.695329 Epoch [186/250], Step [0060/0060], Loss1: -0.9868 Loss2: -0.9883 Loss3: -0.9918\n",
            "Epoch: 186 MAE: 58.51061462639542 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:23:27.160235 Epoch [187/250], Step [0001/0060], Loss1: -0.9810 Loss2: -0.9835 Loss3: -0.9888\n",
            "2022-08-02 22:23:51.604437 Epoch [187/250], Step [0050/0060], Loss1: -0.9702 Loss2: -0.9774 Loss3: -0.9856\n",
            "2022-08-02 22:23:56.595448 Epoch [187/250], Step [0060/0060], Loss1: -0.9703 Loss2: -0.9793 Loss3: -0.9859\n",
            "Epoch: 187 MAE: 58.3470468783117 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:24:02.063475 Epoch [188/250], Step [0001/0060], Loss1: -0.9859 Loss2: -0.9877 Loss3: -0.9919\n",
            "2022-08-02 22:24:26.482541 Epoch [188/250], Step [0050/0060], Loss1: -0.9871 Loss2: -0.9866 Loss3: -0.9921\n",
            "2022-08-02 22:24:31.465500 Epoch [188/250], Step [0060/0060], Loss1: -0.9874 Loss2: -0.9856 Loss3: -0.9915\n",
            "Epoch: 188 MAE: 58.36406572190872 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:24:36.995057 Epoch [189/250], Step [0001/0060], Loss1: -0.9886 Loss2: -0.9867 Loss3: -0.9923\n",
            "2022-08-02 22:25:01.398241 Epoch [189/250], Step [0050/0060], Loss1: -0.9861 Loss2: -0.9865 Loss3: -0.9917\n",
            "2022-08-02 22:25:06.384246 Epoch [189/250], Step [0060/0060], Loss1: -0.9764 Loss2: -0.9785 Loss3: -0.9864\n",
            "Epoch: 189 MAE: 58.38821088871228 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:25:11.896070 Epoch [190/250], Step [0001/0060], Loss1: -0.9859 Loss2: -0.9840 Loss3: -0.9907\n",
            "2022-08-02 22:25:36.345862 Epoch [190/250], Step [0050/0060], Loss1: -0.9736 Loss2: -0.9766 Loss3: -0.9858\n",
            "2022-08-02 22:25:41.328405 Epoch [190/250], Step [0060/0060], Loss1: -0.9858 Loss2: -0.9868 Loss3: -0.9915\n",
            "Epoch: 190 MAE: 58.351355908811584 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:25:48.890758 Epoch [191/250], Step [0001/0060], Loss1: -0.9882 Loss2: -0.9879 Loss3: -0.9924\n",
            "2022-08-02 22:26:13.521240 Epoch [191/250], Step [0050/0060], Loss1: -0.9880 Loss2: -0.9886 Loss3: -0.9931\n",
            "2022-08-02 22:26:18.500093 Epoch [191/250], Step [0060/0060], Loss1: -0.9889 Loss2: -0.9869 Loss3: -0.9923\n",
            "Epoch: 191 MAE: 58.45835092375947 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:26:23.963906 Epoch [192/250], Step [0001/0060], Loss1: -0.9831 Loss2: -0.9867 Loss3: -0.9908\n",
            "2022-08-02 22:26:48.377659 Epoch [192/250], Step [0050/0060], Loss1: -0.9876 Loss2: -0.9874 Loss3: -0.9918\n",
            "2022-08-02 22:26:53.357378 Epoch [192/250], Step [0060/0060], Loss1: -0.9792 Loss2: -0.9829 Loss3: -0.9889\n",
            "Epoch: 192 MAE: 58.335648328383094 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:26:58.851131 Epoch [193/250], Step [0001/0060], Loss1: -0.9877 Loss2: -0.9866 Loss3: -0.9918\n",
            "2022-08-02 22:27:23.265353 Epoch [193/250], Step [0050/0060], Loss1: -0.9866 Loss2: -0.9879 Loss3: -0.9922\n",
            "2022-08-02 22:27:28.260997 Epoch [193/250], Step [0060/0060], Loss1: -0.9872 Loss2: -0.9856 Loss3: -0.9917\n",
            "Epoch: 193 MAE: 58.41934304378874 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:27:33.890633 Epoch [194/250], Step [0001/0060], Loss1: -0.9882 Loss2: -0.9848 Loss3: -0.9914\n",
            "2022-08-02 22:27:58.367068 Epoch [194/250], Step [0050/0060], Loss1: -0.9860 Loss2: -0.9870 Loss3: -0.9919\n",
            "2022-08-02 22:28:03.445449 Epoch [194/250], Step [0060/0060], Loss1: -0.9838 Loss2: -0.9836 Loss3: -0.9896\n",
            "Epoch: 194 MAE: 58.54380255206758 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:28:08.997177 Epoch [195/250], Step [0001/0060], Loss1: -0.9855 Loss2: -0.9878 Loss3: -0.9913\n",
            "2022-08-02 22:28:33.441746 Epoch [195/250], Step [0050/0060], Loss1: -0.9844 Loss2: -0.9844 Loss3: -0.9903\n",
            "2022-08-02 22:28:38.425225 Epoch [195/250], Step [0060/0060], Loss1: -0.9870 Loss2: -0.9867 Loss3: -0.9919\n",
            "Epoch: 195 MAE: 58.45852643188669 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:28:45.942746 Epoch [196/250], Step [0001/0060], Loss1: -0.9869 Loss2: -0.9859 Loss3: -0.9908\n",
            "2022-08-02 22:29:10.654343 Epoch [196/250], Step [0050/0060], Loss1: -0.9872 Loss2: -0.9889 Loss3: -0.9927\n",
            "2022-08-02 22:29:15.631898 Epoch [196/250], Step [0060/0060], Loss1: -0.9813 Loss2: -0.9786 Loss3: -0.9871\n",
            "Epoch: 196 MAE: 58.420468588463194 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:29:21.055744 Epoch [197/250], Step [0001/0060], Loss1: -0.9884 Loss2: -0.9883 Loss3: -0.9922\n",
            "2022-08-02 22:29:45.489333 Epoch [197/250], Step [0050/0060], Loss1: -0.9863 Loss2: -0.9865 Loss3: -0.9917\n",
            "2022-08-02 22:29:50.479874 Epoch [197/250], Step [0060/0060], Loss1: -0.9887 Loss2: -0.9873 Loss3: -0.9921\n",
            "Epoch: 197 MAE: 58.47950939377348 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:29:55.942393 Epoch [198/250], Step [0001/0060], Loss1: -0.9836 Loss2: -0.9837 Loss3: -0.9904\n",
            "2022-08-02 22:30:20.403240 Epoch [198/250], Step [0050/0060], Loss1: -0.9852 Loss2: -0.9852 Loss3: -0.9904\n",
            "2022-08-02 22:30:25.396215 Epoch [198/250], Step [0060/0060], Loss1: -0.9869 Loss2: -0.9872 Loss3: -0.9920\n",
            "Epoch: 198 MAE: 58.4517213144545 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:30:30.888441 Epoch [199/250], Step [0001/0060], Loss1: -0.9889 Loss2: -0.9873 Loss3: -0.9929\n",
            "2022-08-02 22:30:55.313729 Epoch [199/250], Step [0050/0060], Loss1: -0.9877 Loss2: -0.9867 Loss3: -0.9917\n",
            "2022-08-02 22:31:00.301097 Epoch [199/250], Step [0060/0060], Loss1: -0.9867 Loss2: -0.9878 Loss3: -0.9919\n",
            "Epoch: 199 MAE: 58.39729911311217 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:31:05.745172 Epoch [200/250], Step [0001/0060], Loss1: -0.9850 Loss2: -0.9857 Loss3: -0.9905\n",
            "2022-08-02 22:31:30.177285 Epoch [200/250], Step [0050/0060], Loss1: -0.9887 Loss2: -0.9877 Loss3: -0.9924\n",
            "2022-08-02 22:31:35.158795 Epoch [200/250], Step [0060/0060], Loss1: -0.9855 Loss2: -0.9862 Loss3: -0.9907\n",
            "Epoch: 200 MAE: 58.51759033511252 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:31:42.840796 Epoch [201/250], Step [0001/0060], Loss1: -0.9871 Loss2: -0.9875 Loss3: -0.9924\n",
            "2022-08-02 22:32:07.442440 Epoch [201/250], Step [0050/0060], Loss1: -0.9858 Loss2: -0.9869 Loss3: -0.9919\n",
            "2022-08-02 22:32:12.425161 Epoch [201/250], Step [0060/0060], Loss1: -0.9844 Loss2: -0.9861 Loss3: -0.9911\n",
            "Epoch: 201 MAE: 58.421673008735624 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:32:18.021448 Epoch [202/250], Step [0001/0060], Loss1: -0.9815 Loss2: -0.9840 Loss3: -0.9898\n",
            "2022-08-02 22:32:42.458460 Epoch [202/250], Step [0050/0060], Loss1: -0.9865 Loss2: -0.9851 Loss3: -0.9910\n",
            "2022-08-02 22:32:47.431645 Epoch [202/250], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9859 Loss3: -0.9915\n",
            "Epoch: 202 MAE: 58.411954323200185 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:32:52.873623 Epoch [203/250], Step [0001/0060], Loss1: -0.9833 Loss2: -0.9829 Loss3: -0.9891\n",
            "2022-08-02 22:33:17.298894 Epoch [203/250], Step [0050/0060], Loss1: -0.9865 Loss2: -0.9863 Loss3: -0.9914\n",
            "2022-08-02 22:33:22.286993 Epoch [203/250], Step [0060/0060], Loss1: -0.9891 Loss2: -0.9891 Loss3: -0.9933\n",
            "Epoch: 203 MAE: 58.69600604997637 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:33:27.798074 Epoch [204/250], Step [0001/0060], Loss1: -0.9867 Loss2: -0.9854 Loss3: -0.9908\n",
            "2022-08-02 22:33:52.213237 Epoch [204/250], Step [0050/0060], Loss1: -0.9879 Loss2: -0.9852 Loss3: -0.9914\n",
            "2022-08-02 22:33:57.190057 Epoch [204/250], Step [0060/0060], Loss1: -0.9876 Loss2: -0.9875 Loss3: -0.9924\n",
            "Epoch: 204 MAE: 58.49798116987303 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "2022-08-02 22:34:02.624198 Epoch [205/250], Step [0001/0060], Loss1: -0.9864 Loss2: -0.9864 Loss3: -0.9910\n",
            "2022-08-02 22:34:27.040618 Epoch [205/250], Step [0050/0060], Loss1: -0.9866 Loss2: -0.9871 Loss3: -0.9915\n",
            "2022-08-02 22:34:32.035771 Epoch [205/250], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9866 Loss3: -0.9921\n",
            "Epoch: 205 MAE: 58.29551136376226 ####  bestMAE: 58.29650858227651 bestEpoch: 88\n",
            "best epoch:205\n",
            "2022-08-02 22:34:41.891201 Epoch [206/250], Step [0001/0060], Loss1: -0.9806 Loss2: -0.9822 Loss3: -0.9889\n",
            "2022-08-02 22:35:06.668047 Epoch [206/250], Step [0050/0060], Loss1: -0.9860 Loss2: -0.9881 Loss3: -0.9924\n",
            "2022-08-02 22:35:11.757548 Epoch [206/250], Step [0060/0060], Loss1: -0.9871 Loss2: -0.9863 Loss3: -0.9921\n",
            "Epoch: 206 MAE: 58.62462001842951 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:35:17.254677 Epoch [207/250], Step [0001/0060], Loss1: -0.9881 Loss2: -0.9870 Loss3: -0.9923\n",
            "2022-08-02 22:35:41.808183 Epoch [207/250], Step [0050/0060], Loss1: -0.9876 Loss2: -0.9878 Loss3: -0.9924\n",
            "2022-08-02 22:35:46.789627 Epoch [207/250], Step [0060/0060], Loss1: -0.9836 Loss2: -0.9841 Loss3: -0.9896\n",
            "Epoch: 207 MAE: 58.48876072315667 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:35:52.261050 Epoch [208/250], Step [0001/0060], Loss1: -0.9804 Loss2: -0.9834 Loss3: -0.9897\n",
            "2022-08-02 22:36:16.675543 Epoch [208/250], Step [0050/0060], Loss1: -0.9876 Loss2: -0.9862 Loss3: -0.9919\n",
            "2022-08-02 22:36:21.655541 Epoch [208/250], Step [0060/0060], Loss1: -0.9833 Loss2: -0.9844 Loss3: -0.9901\n",
            "Epoch: 208 MAE: 58.34349347086315 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:36:27.178802 Epoch [209/250], Step [0001/0060], Loss1: -0.9880 Loss2: -0.9860 Loss3: -0.9914\n",
            "2022-08-02 22:36:51.670051 Epoch [209/250], Step [0050/0060], Loss1: -0.9825 Loss2: -0.9854 Loss3: -0.9906\n",
            "2022-08-02 22:36:56.659342 Epoch [209/250], Step [0060/0060], Loss1: -0.9867 Loss2: -0.9870 Loss3: -0.9922\n",
            "Epoch: 209 MAE: 58.442750800786 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:37:02.138488 Epoch [210/250], Step [0001/0060], Loss1: -0.9834 Loss2: -0.9834 Loss3: -0.9893\n",
            "2022-08-02 22:37:26.564600 Epoch [210/250], Step [0050/0060], Loss1: -0.9866 Loss2: -0.9864 Loss3: -0.9914\n",
            "2022-08-02 22:37:31.551349 Epoch [210/250], Step [0060/0060], Loss1: -0.9874 Loss2: -0.9870 Loss3: -0.9920\n",
            "Epoch: 210 MAE: 58.3694274159173 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:37:39.104823 Epoch [211/250], Step [0001/0060], Loss1: -0.9884 Loss2: -0.9865 Loss3: -0.9915\n",
            "2022-08-02 22:38:03.674805 Epoch [211/250], Step [0050/0060], Loss1: -0.9853 Loss2: -0.9837 Loss3: -0.9897\n",
            "2022-08-02 22:38:08.668573 Epoch [211/250], Step [0060/0060], Loss1: -0.9800 Loss2: -0.9788 Loss3: -0.9869\n",
            "Epoch: 211 MAE: 58.34790798717277 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:38:14.093473 Epoch [212/250], Step [0001/0060], Loss1: -0.9881 Loss2: -0.9840 Loss3: -0.9915\n",
            "2022-08-02 22:38:38.538027 Epoch [212/250], Step [0050/0060], Loss1: -0.9784 Loss2: -0.9823 Loss3: -0.9882\n",
            "2022-08-02 22:38:43.532107 Epoch [212/250], Step [0060/0060], Loss1: -0.9882 Loss2: -0.9890 Loss3: -0.9927\n",
            "Epoch: 212 MAE: 58.49618634214726 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:38:49.017077 Epoch [213/250], Step [0001/0060], Loss1: -0.9823 Loss2: -0.9840 Loss3: -0.9900\n",
            "2022-08-02 22:39:13.431883 Epoch [213/250], Step [0050/0060], Loss1: -0.9857 Loss2: -0.9845 Loss3: -0.9899\n",
            "2022-08-02 22:39:18.415017 Epoch [213/250], Step [0060/0060], Loss1: -0.9788 Loss2: -0.9825 Loss3: -0.9886\n",
            "Epoch: 213 MAE: 58.325784228288256 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:39:23.907470 Epoch [214/250], Step [0001/0060], Loss1: -0.9862 Loss2: -0.9868 Loss3: -0.9915\n",
            "2022-08-02 22:39:48.310595 Epoch [214/250], Step [0050/0060], Loss1: -0.9744 Loss2: -0.9780 Loss3: -0.9860\n",
            "2022-08-02 22:39:53.296047 Epoch [214/250], Step [0060/0060], Loss1: -0.9841 Loss2: -0.9849 Loss3: -0.9905\n",
            "Epoch: 214 MAE: 58.38288997556244 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:39:58.779288 Epoch [215/250], Step [0001/0060], Loss1: -0.9835 Loss2: -0.9837 Loss3: -0.9897\n",
            "2022-08-02 22:40:23.221207 Epoch [215/250], Step [0050/0060], Loss1: -0.9853 Loss2: -0.9858 Loss3: -0.9912\n",
            "2022-08-02 22:40:28.205605 Epoch [215/250], Step [0060/0060], Loss1: -0.9882 Loss2: -0.9867 Loss3: -0.9921\n",
            "Epoch: 215 MAE: 58.51216234470678 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:40:36.007474 Epoch [216/250], Step [0001/0060], Loss1: -0.9839 Loss2: -0.9853 Loss3: -0.9908\n",
            "2022-08-02 22:41:00.598808 Epoch [216/250], Step [0050/0060], Loss1: -0.9858 Loss2: -0.9833 Loss3: -0.9900\n",
            "2022-08-02 22:41:05.591015 Epoch [216/250], Step [0060/0060], Loss1: -0.9838 Loss2: -0.9859 Loss3: -0.9910\n",
            "Epoch: 216 MAE: 58.59975901080536 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:41:11.011170 Epoch [217/250], Step [0001/0060], Loss1: -0.9830 Loss2: -0.9830 Loss3: -0.9890\n",
            "2022-08-02 22:41:35.452765 Epoch [217/250], Step [0050/0060], Loss1: -0.9850 Loss2: -0.9820 Loss3: -0.9907\n",
            "2022-08-02 22:41:40.444986 Epoch [217/250], Step [0060/0060], Loss1: -0.9840 Loss2: -0.9842 Loss3: -0.9897\n",
            "Epoch: 217 MAE: 58.385459819956445 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:41:46.012312 Epoch [218/250], Step [0001/0060], Loss1: -0.9793 Loss2: -0.9813 Loss3: -0.9883\n",
            "2022-08-02 22:42:10.499616 Epoch [218/250], Step [0050/0060], Loss1: -0.9862 Loss2: -0.9870 Loss3: -0.9920\n",
            "2022-08-02 22:42:15.479542 Epoch [218/250], Step [0060/0060], Loss1: -0.9715 Loss2: -0.9769 Loss3: -0.9850\n",
            "Epoch: 218 MAE: 58.3980108529847 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:42:20.924713 Epoch [219/250], Step [0001/0060], Loss1: -0.9864 Loss2: -0.9831 Loss3: -0.9896\n",
            "2022-08-02 22:42:45.346415 Epoch [219/250], Step [0050/0060], Loss1: -0.9857 Loss2: -0.9868 Loss3: -0.9917\n",
            "2022-08-02 22:42:50.333215 Epoch [219/250], Step [0060/0060], Loss1: -0.9740 Loss2: -0.9787 Loss3: -0.9862\n",
            "Epoch: 219 MAE: 58.40026129125173 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:42:55.884715 Epoch [220/250], Step [0001/0060], Loss1: -0.9859 Loss2: -0.9839 Loss3: -0.9903\n",
            "2022-08-02 22:43:20.339072 Epoch [220/250], Step [0050/0060], Loss1: -0.9877 Loss2: -0.9869 Loss3: -0.9914\n",
            "2022-08-02 22:43:25.321178 Epoch [220/250], Step [0060/0060], Loss1: -0.9854 Loss2: -0.9841 Loss3: -0.9905\n",
            "Epoch: 220 MAE: 58.45376963562047 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:43:32.880675 Epoch [221/250], Step [0001/0060], Loss1: -0.9884 Loss2: -0.9875 Loss3: -0.9924\n",
            "2022-08-02 22:43:57.358245 Epoch [221/250], Step [0050/0060], Loss1: -0.9861 Loss2: -0.9861 Loss3: -0.9914\n",
            "2022-08-02 22:44:02.327260 Epoch [221/250], Step [0060/0060], Loss1: -0.9864 Loss2: -0.9860 Loss3: -0.9915\n",
            "Epoch: 221 MAE: 58.552945870790936 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:44:07.858410 Epoch [222/250], Step [0001/0060], Loss1: -0.9883 Loss2: -0.9854 Loss3: -0.9917\n",
            "2022-08-02 22:44:32.281101 Epoch [222/250], Step [0050/0060], Loss1: -0.9881 Loss2: -0.9867 Loss3: -0.9915\n",
            "2022-08-02 22:44:37.275107 Epoch [222/250], Step [0060/0060], Loss1: -0.9862 Loss2: -0.9872 Loss3: -0.9915\n",
            "Epoch: 222 MAE: 58.493423828675866 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:44:42.856912 Epoch [223/250], Step [0001/0060], Loss1: -0.9832 Loss2: -0.9822 Loss3: -0.9891\n",
            "2022-08-02 22:45:07.267448 Epoch [223/250], Step [0050/0060], Loss1: -0.9873 Loss2: -0.9851 Loss3: -0.9910\n",
            "2022-08-02 22:45:12.255954 Epoch [223/250], Step [0060/0060], Loss1: -0.9870 Loss2: -0.9855 Loss3: -0.9913\n",
            "Epoch: 223 MAE: 58.46810328041413 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:45:17.759258 Epoch [224/250], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9889 Loss3: -0.9931\n",
            "2022-08-02 22:45:42.197397 Epoch [224/250], Step [0050/0060], Loss1: -0.9849 Loss2: -0.9842 Loss3: -0.9905\n",
            "2022-08-02 22:45:47.180724 Epoch [224/250], Step [0060/0060], Loss1: -0.9874 Loss2: -0.9874 Loss3: -0.9924\n",
            "Epoch: 224 MAE: 58.576811293004965 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:45:52.661957 Epoch [225/250], Step [0001/0060], Loss1: -0.9874 Loss2: -0.9843 Loss3: -0.9915\n",
            "2022-08-02 22:46:17.167720 Epoch [225/250], Step [0050/0060], Loss1: -0.9852 Loss2: -0.9861 Loss3: -0.9909\n",
            "2022-08-02 22:46:22.151906 Epoch [225/250], Step [0060/0060], Loss1: -0.9870 Loss2: -0.9865 Loss3: -0.9918\n",
            "Epoch: 225 MAE: 58.47714760701457 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:46:29.833938 Epoch [226/250], Step [0001/0060], Loss1: -0.9874 Loss2: -0.9873 Loss3: -0.9923\n",
            "2022-08-02 22:46:54.494090 Epoch [226/250], Step [0050/0060], Loss1: -0.9745 Loss2: -0.9794 Loss3: -0.9868\n",
            "2022-08-02 22:46:59.478969 Epoch [226/250], Step [0060/0060], Loss1: -0.9861 Loss2: -0.9855 Loss3: -0.9916\n",
            "Epoch: 226 MAE: 58.53582299259384 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:47:05.373907 Epoch [227/250], Step [0001/0060], Loss1: -0.9842 Loss2: -0.9843 Loss3: -0.9897\n",
            "2022-08-02 22:47:29.860339 Epoch [227/250], Step [0050/0060], Loss1: -0.9893 Loss2: -0.9886 Loss3: -0.9931\n",
            "2022-08-02 22:47:34.846860 Epoch [227/250], Step [0060/0060], Loss1: -0.9852 Loss2: -0.9871 Loss3: -0.9909\n",
            "Epoch: 227 MAE: 58.46294654513799 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:47:40.397107 Epoch [228/250], Step [0001/0060], Loss1: -0.9869 Loss2: -0.9864 Loss3: -0.9912\n",
            "2022-08-02 22:48:04.799849 Epoch [228/250], Step [0050/0060], Loss1: -0.9878 Loss2: -0.9877 Loss3: -0.9923\n",
            "2022-08-02 22:48:09.781000 Epoch [228/250], Step [0060/0060], Loss1: -0.9868 Loss2: -0.9845 Loss3: -0.9910\n",
            "Epoch: 228 MAE: 58.40955546435494 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:48:15.262510 Epoch [229/250], Step [0001/0060], Loss1: -0.9869 Loss2: -0.9864 Loss3: -0.9910\n",
            "2022-08-02 22:48:39.708601 Epoch [229/250], Step [0050/0060], Loss1: -0.9822 Loss2: -0.9836 Loss3: -0.9895\n",
            "2022-08-02 22:48:44.695614 Epoch [229/250], Step [0060/0060], Loss1: -0.9853 Loss2: -0.9849 Loss3: -0.9908\n",
            "Epoch: 229 MAE: 58.470161308968684 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:48:50.231306 Epoch [230/250], Step [0001/0060], Loss1: -0.9834 Loss2: -0.9871 Loss3: -0.9907\n",
            "2022-08-02 22:49:14.690958 Epoch [230/250], Step [0050/0060], Loss1: -0.9875 Loss2: -0.9876 Loss3: -0.9926\n",
            "2022-08-02 22:49:19.677913 Epoch [230/250], Step [0060/0060], Loss1: -0.9860 Loss2: -0.9859 Loss3: -0.9908\n",
            "Epoch: 230 MAE: 58.42867731877302 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:49:27.286012 Epoch [231/250], Step [0001/0060], Loss1: -0.9875 Loss2: -0.9869 Loss3: -0.9922\n",
            "2022-08-02 22:49:51.978785 Epoch [231/250], Step [0050/0060], Loss1: -0.9839 Loss2: -0.9854 Loss3: -0.9899\n",
            "2022-08-02 22:49:56.987246 Epoch [231/250], Step [0060/0060], Loss1: -0.9845 Loss2: -0.9857 Loss3: -0.9913\n",
            "Epoch: 231 MAE: 58.57667002840504 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:50:02.606063 Epoch [232/250], Step [0001/0060], Loss1: -0.9857 Loss2: -0.9872 Loss3: -0.9919\n",
            "2022-08-02 22:50:27.089946 Epoch [232/250], Step [0050/0060], Loss1: -0.9860 Loss2: -0.9875 Loss3: -0.9916\n",
            "2022-08-02 22:50:32.098736 Epoch [232/250], Step [0060/0060], Loss1: -0.9815 Loss2: -0.9818 Loss3: -0.9881\n",
            "Epoch: 232 MAE: 58.34075166274701 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:50:37.629211 Epoch [233/250], Step [0001/0060], Loss1: -0.9864 Loss2: -0.9853 Loss3: -0.9912\n",
            "2022-08-02 22:51:02.115389 Epoch [233/250], Step [0050/0060], Loss1: -0.9875 Loss2: -0.9855 Loss3: -0.9914\n",
            "2022-08-02 22:51:07.119954 Epoch [233/250], Step [0060/0060], Loss1: -0.9825 Loss2: -0.9826 Loss3: -0.9885\n",
            "Epoch: 233 MAE: 58.45229775054311 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:51:12.666687 Epoch [234/250], Step [0001/0060], Loss1: -0.9891 Loss2: -0.9892 Loss3: -0.9929\n",
            "2022-08-02 22:51:37.182027 Epoch [234/250], Step [0050/0060], Loss1: -0.9835 Loss2: -0.9827 Loss3: -0.9897\n",
            "2022-08-02 22:51:42.187938 Epoch [234/250], Step [0060/0060], Loss1: -0.9852 Loss2: -0.9850 Loss3: -0.9906\n",
            "Epoch: 234 MAE: 58.527145131221765 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:51:47.788961 Epoch [235/250], Step [0001/0060], Loss1: -0.9870 Loss2: -0.9842 Loss3: -0.9908\n",
            "2022-08-02 22:52:12.384850 Epoch [235/250], Step [0050/0060], Loss1: -0.9866 Loss2: -0.9847 Loss3: -0.9906\n",
            "2022-08-02 22:52:17.384159 Epoch [235/250], Step [0060/0060], Loss1: -0.9862 Loss2: -0.9865 Loss3: -0.9915\n",
            "Epoch: 235 MAE: 58.496454389871474 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:52:25.023064 Epoch [236/250], Step [0001/0060], Loss1: -0.9815 Loss2: -0.9798 Loss3: -0.9880\n",
            "2022-08-02 22:52:49.823478 Epoch [236/250], Step [0050/0060], Loss1: -0.9797 Loss2: -0.9740 Loss3: -0.9861\n",
            "2022-08-02 22:52:54.816860 Epoch [236/250], Step [0060/0060], Loss1: -0.9885 Loss2: -0.9872 Loss3: -0.9926\n",
            "Epoch: 236 MAE: 58.546507765617164 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:53:00.386412 Epoch [237/250], Step [0001/0060], Loss1: -0.9870 Loss2: -0.9860 Loss3: -0.9913\n",
            "2022-08-02 22:53:24.826615 Epoch [237/250], Step [0050/0060], Loss1: -0.9853 Loss2: -0.9852 Loss3: -0.9906\n",
            "2022-08-02 22:53:29.820796 Epoch [237/250], Step [0060/0060], Loss1: -0.9849 Loss2: -0.9868 Loss3: -0.9912\n",
            "Epoch: 237 MAE: 58.4237061059845 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:53:35.298837 Epoch [238/250], Step [0001/0060], Loss1: -0.9886 Loss2: -0.9880 Loss3: -0.9922\n",
            "2022-08-02 22:53:59.755008 Epoch [238/250], Step [0050/0060], Loss1: -0.9861 Loss2: -0.9863 Loss3: -0.9913\n",
            "2022-08-02 22:54:04.756919 Epoch [238/250], Step [0060/0060], Loss1: -0.9845 Loss2: -0.9830 Loss3: -0.9898\n",
            "Epoch: 238 MAE: 58.47696932444856 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:54:10.201632 Epoch [239/250], Step [0001/0060], Loss1: -0.9822 Loss2: -0.9835 Loss3: -0.9898\n",
            "2022-08-02 22:54:34.681936 Epoch [239/250], Step [0050/0060], Loss1: -0.9861 Loss2: -0.9861 Loss3: -0.9911\n",
            "2022-08-02 22:54:39.677088 Epoch [239/250], Step [0060/0060], Loss1: -0.9864 Loss2: -0.9849 Loss3: -0.9908\n",
            "Epoch: 239 MAE: 58.40948338795766 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "2022-08-02 22:54:45.254742 Epoch [240/250], Step [0001/0060], Loss1: -0.9884 Loss2: -0.9865 Loss3: -0.9926\n",
            "2022-08-02 22:55:09.690781 Epoch [240/250], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9873 Loss3: -0.9923\n",
            "2022-08-02 22:55:14.691309 Epoch [240/250], Step [0060/0060], Loss1: -0.9846 Loss2: -0.9849 Loss3: -0.9900\n",
            "Epoch: 240 MAE: 58.24960715212021 ####  bestMAE: 58.29551136376226 bestEpoch: 205\n",
            "best epoch:240\n",
            "2022-08-02 22:55:24.617901 Epoch [241/250], Step [0001/0060], Loss1: -0.9856 Loss2: -0.9865 Loss3: -0.9914\n",
            "2022-08-02 22:55:49.478864 Epoch [241/250], Step [0050/0060], Loss1: -0.9881 Loss2: -0.9872 Loss3: -0.9929\n",
            "2022-08-02 22:55:54.550241 Epoch [241/250], Step [0060/0060], Loss1: -0.9859 Loss2: -0.9850 Loss3: -0.9910\n",
            "Epoch: 241 MAE: 58.43987966251908 ####  bestMAE: 58.24960715212021 bestEpoch: 240\n",
            "2022-08-02 22:56:00.074524 Epoch [242/250], Step [0001/0060], Loss1: -0.9855 Loss2: -0.9864 Loss3: -0.9914\n",
            "2022-08-02 22:56:24.600436 Epoch [242/250], Step [0050/0060], Loss1: -0.9821 Loss2: -0.9829 Loss3: -0.9890\n",
            "2022-08-02 22:56:29.613061 Epoch [242/250], Step [0060/0060], Loss1: -0.9875 Loss2: -0.9859 Loss3: -0.9914\n",
            "Epoch: 242 MAE: 58.48480374598342 ####  bestMAE: 58.24960715212021 bestEpoch: 240\n",
            "2022-08-02 22:56:35.246960 Epoch [243/250], Step [0001/0060], Loss1: -0.9864 Loss2: -0.9844 Loss3: -0.9905\n",
            "2022-08-02 22:56:59.746260 Epoch [243/250], Step [0050/0060], Loss1: -0.9842 Loss2: -0.9846 Loss3: -0.9903\n",
            "2022-08-02 22:57:04.742911 Epoch [243/250], Step [0060/0060], Loss1: -0.9865 Loss2: -0.9842 Loss3: -0.9913\n",
            "Epoch: 243 MAE: 58.51744561430706 ####  bestMAE: 58.24960715212021 bestEpoch: 240\n",
            "2022-08-02 22:57:10.154616 Epoch [244/250], Step [0001/0060], Loss1: -0.9818 Loss2: -0.9842 Loss3: -0.9897\n",
            "2022-08-02 22:57:34.684628 Epoch [244/250], Step [0050/0060], Loss1: -0.9873 Loss2: -0.9870 Loss3: -0.9917\n",
            "2022-08-02 22:57:39.686676 Epoch [244/250], Step [0060/0060], Loss1: -0.9882 Loss2: -0.9868 Loss3: -0.9920\n",
            "Epoch: 244 MAE: 58.53433546639472 ####  bestMAE: 58.24960715212021 bestEpoch: 240\n",
            "2022-08-02 22:57:45.338497 Epoch [245/250], Step [0001/0060], Loss1: -0.9848 Loss2: -0.9855 Loss3: -0.9907\n",
            "2022-08-02 22:58:09.824904 Epoch [245/250], Step [0050/0060], Loss1: -0.9868 Loss2: -0.9854 Loss3: -0.9912\n",
            "2022-08-02 22:58:14.820282 Epoch [245/250], Step [0060/0060], Loss1: -0.9887 Loss2: -0.9879 Loss3: -0.9924\n",
            "Epoch: 245 MAE: 58.52174441277438 ####  bestMAE: 58.24960715212021 bestEpoch: 240\n",
            "2022-08-02 22:58:22.346881 Epoch [246/250], Step [0001/0060], Loss1: -0.9870 Loss2: -0.9873 Loss3: -0.9923\n",
            "2022-08-02 22:58:46.894200 Epoch [246/250], Step [0050/0060], Loss1: -0.9856 Loss2: -0.9856 Loss3: -0.9914\n",
            "2022-08-02 22:58:51.886905 Epoch [246/250], Step [0060/0060], Loss1: -0.9808 Loss2: -0.9837 Loss3: -0.9895\n",
            "Epoch: 246 MAE: 58.45925925174391 ####  bestMAE: 58.24960715212021 bestEpoch: 240\n",
            "2022-08-02 22:58:57.480142 Epoch [247/250], Step [0001/0060], Loss1: -0.9881 Loss2: -0.9876 Loss3: -0.9929\n",
            "2022-08-02 22:59:21.929860 Epoch [247/250], Step [0050/0060], Loss1: -0.9816 Loss2: -0.9836 Loss3: -0.9893\n",
            "2022-08-02 22:59:26.937819 Epoch [247/250], Step [0060/0060], Loss1: -0.9858 Loss2: -0.9857 Loss3: -0.9913\n",
            "Epoch: 247 MAE: 58.601431448067025 ####  bestMAE: 58.24960715212021 bestEpoch: 240\n",
            "2022-08-02 22:59:32.564809 Epoch [248/250], Step [0001/0060], Loss1: -0.9854 Loss2: -0.9856 Loss3: -0.9911\n",
            "2022-08-02 22:59:57.076974 Epoch [248/250], Step [0050/0060], Loss1: -0.9884 Loss2: -0.9867 Loss3: -0.9920\n",
            "2022-08-02 23:00:02.084542 Epoch [248/250], Step [0060/0060], Loss1: -0.9889 Loss2: -0.9891 Loss3: -0.9929\n",
            "Epoch: 248 MAE: 58.43229270541315 ####  bestMAE: 58.24960715212021 bestEpoch: 240\n",
            "2022-08-02 23:00:07.685887 Epoch [249/250], Step [0001/0060], Loss1: -0.9814 Loss2: -0.9804 Loss3: -0.9877\n",
            "2022-08-02 23:00:32.215632 Epoch [249/250], Step [0050/0060], Loss1: -0.9846 Loss2: -0.9818 Loss3: -0.9900\n",
            "2022-08-02 23:00:37.225384 Epoch [249/250], Step [0060/0060], Loss1: -0.9872 Loss2: -0.9859 Loss3: -0.9920\n",
            "Epoch: 249 MAE: 58.667729020697585 ####  bestMAE: 58.24960715212021 bestEpoch: 240\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEWCAYAAACNJFuYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhU9Z3v8fe3lq5mtVkVRGQJLiBItEEMSYgx4z5RM24ZFZyZXMd5zCRejVcNJuLcMFHjzRiMCZLE3Rm3aMZEDRm8KuINIjgtLggBFGkERASalt6q6nv/OKebpk+D1U0X1d31eT1PP111TtWp769Od33qd5bfMXdHRESkuVihCxARkc5H4SAiIhEKBxERiVA4iIhIhMJBREQiFA4iIhKhcBDZCzN7zsxmFLoOkUIwnecg3YmZVTe72xOoAzLh/X9094cPUB3vA99y9wUH4vVEOlqi0AWIdCR37914e18f0GaWcPf0gaxNpCvRZiUpCmb2FTOrNLPrzGwTcK+Z9TOzP5jZFjPbFt4e1uw5L5rZt8Lbl5nZIjO7PXzse2Z2ejvqSJnZHWb2Yfhzh5mlwnkDwxq2m9knZvaymcXCedeZ2QYz22lmK83s5HB6zMyuN7M1ZrbVzB4zs/7hvFIzeyicvt3MXjOzgzvg7ZQioHCQYnII0B84HLic4O//3vD+cKAG+Pk+nn8CsBIYCNwG/MbMrI01zASmABOBY4HJwI3hvGuASmAQcDDwfcDN7Ejg28Akd+8DnAq8Hz7nn4FzgGnAUGAbcFc4bwZwEHAYMAC4ImyjyGdSOEgxyQI3uXudu9e4+1Z3/62773L3ncBsgg/ZvVnn7r9y9wxwPzCE4EO8LS4G/sXdP3L3LcDNwKXhvIZwmYe7e4O7v+zBTsEMkALGmlnS3d939zXhc64AZrp7pbvXAbOA88wsES5vAPA5d8+4+zJ3r2pjvVKkFA5STLa4e23jHTPraWZ3m9k6M6sCFgJlZhbfy/M3Nd5w913hzd57eezeDAXWNbu/LpwG8BNgNfAnM1trZteHr7UauIrgg/8jM3vEzBqfczjwVLjZaDuwgiBMDgYeBOYDj4SbsG4zs2Qb65UipXCQYtLy0LxrgCOBE9y9L/DlcHpbNxW1xYcEH+iNhofTcPed7n6Nu48Cvg5c3bhvwd3/3d2/GD7XgVvD568HTnf3smY/pe6+Iex93OzuY4EvAGcB0/PYNulGFA5SzPoQbIPfHu7EvamDl58Mdwo3/iSA/wBuNLNBZjYQ+CHwEICZnWVmnwv3Y+wg6AFkzexIM/tquOO6Nqw5G77GXGC2mR0eLmOQmZ0d3j7JzMaHPaEqgs1MWURyoHCQYnYH0AP4GFgM/LGDl/8swQd5488s4EfAUmA58CbwejgNYAywAKgG/gz8wt1fINjfcEtY5yZgMHBD+JyfAU8TbIraGbbjhHDeIcATBMGwAniJYFOTyGfSSXAiIhKhnoOIiEQoHEREJELhICIiEQoHERGJ6BYD7w0cONBHjBhR6DJERLqUZcuWfezug1qb1y3CYcSIESxdurTQZYiIdClmtm5v87RZSUREIhQOIiISoXAQEZEIhYOIiER02nAws9PCK16tbhy6WEREDoxOGQ7hKJJ3AacDY4FvmtnYwlYlIlI8OmU4EFw6cbW7r3X3euAR4OwC1yQiUjQ6azgcSnARk0aV4bQmZna5mS01s6Vbtmxp14t8tPIV5t94GltX/7n9lYqIdENd9iQ4d58HzAMoLy9v17jjbz3xS4Y/sY4Pn/x71qQgE4Ns44+xx/XAvMW1wTzHeZ1Kh9fVMQts+X595lLbs7Y76zoR2U/pE0dx6i1/6PDldtZw2AAc1uz+sHBah/rKDQ+wqvxBNvznA2Q/rcEyWchmIZPFMo7j4QdR+GnU7EPJGqe3/KDq0MtjdMDC2rmIfT6tA68B0vIzW1cXEWmbHn3L8rLczhoOrwFjzGwkQShcBPxtR79ILBbjqFNncNSpMzp60SIiXVqnDAd3T5vZt4H5QBy4x93fLnBZIiJFo1OGA4C7P0twDV4RETnAOuvRSiIiUkAKBxERiVA4iIhIhMJBREQiFA4iIhKhcBARkQiFg4iIRCgcREQkQuEgIiIRCgcREYlQOIiISITCQUREIhQOIiISoXAQEZEIhYOIiEQoHEREJELhICIiEQoHERGJUDiIiEiEwkFERCIUDiIiEqFwEBGRCIWDiIhEKBxERCRC4SAiIhEKBxERiVA4iIhIhMJBREQiFA4iIhKhcBARkQiFg4iIRCgcREQkQuEgIiIRCgcREYlQOIiISERBwsHMfmJm75rZcjN7yszKms27wcxWm9lKMzu1EPWJiBS7QvUc/gs4xt0nAKuAGwDMbCxwETAOOA34hZnFC1SjiEjRKkg4uPuf3D0d3l0MDAtvnw084u517v4esBqYXIgaRUSKWWfY5/D3wHPh7UOB9c3mVYbTIszscjNbamZLt2zZkucSRUSKSyJfCzazBcAhrcya6e7/GT5mJpAGHm7r8t19HjAPoLy83PejVBERaSFv4eDuX9vXfDO7DDgLONndGz/cNwCHNXvYsHCaiIgcQIU6Wuk04H8BX3f3Xc1mPQ1cZGYpMxsJjAGWFKJGEZFilreew2f4OZAC/svMABa7+xXu/raZPQa8Q7C56Up3zxSoRhGRolWQcHD3z+1j3mxg9gEsR0REWugMRyuJiEgno3AQEZEIhYOIiEQoHEREJELhICIiEQoHERGJUDiIiEiEwkFERCIUDiIiEqFwEBGRCIWDiIhEKBxERCRC4SAiIhEKBxERiVA4iIhIhMJBREQiFA4iIhKhcBARkYhCXUNaRLqghoYGKisrqa2tLXQp0galpaUMGzaMZDKZ83MUDiKSs8rKSvr06cOIESMws0KXIzlwd7Zu3UplZSUjR47M+XnarCQiOautrWXAgAEKhi7EzBgwYECbe3sKBxFpEwVD19OedaZwEBGRCIWDiIhEKBxEpMvZtGkTF110EaNHj+b444/njDPOYNWqVfu1zMsuu4wnnngiMn3p0qV85zvf2a9lN7rvvvv49re/vdf5s2bN4vbbb++Q19pfOlpJRLoUd+fcc89lxowZPPLIIwC88cYbbN68mSOOOKLDX6+8vJzy8vIOX25np3AQkXa5+fdv886HVR26zLFD+3LTX4/b52NeeOEFkskkV1xxRdO0Y489Fnfn2muv5bnnnsPMuPHGG7nwwgt58cUXuemmmygrK+PNN9/kggsuYPz48fzsZz+jpqaG3/3ud4wePRqABQsWcMstt1BVVcVPf/pTzjrrLF588UVuv/12/vCHPzBr1iw++OAD1q5dywcffMBVV13V1Kt46KGHmDNnDvX19Zxwwgn84he/IB6Pc++99/LjH/+YsrIyjj32WFKpVE7vRUVFBVdccQW7du1i9OjR3HPPPfTr1485c+Ywd+5cEokEY8eO5ZFHHuGll17iu9/9LhDsfF64cCF9+vRpzypoos1KItKlvPXWWxx//PGR6U8++SQVFRW88cYbLFiwgGuvvZaNGzcCQc9i7ty5rFixggcffJBVq1axZMkSvvWtb3HnnXc2LeP9999nyZIlPPPMM1xxxRWtHv757rvvMn/+fJYsWcLNN99MQ0MDK1as4NFHH+WVV16hoqKCeDzOww8/zMaNG7npppt45ZVXWLRoEe+8807O7Zw+fTq33nory5cvZ/z48dx8880A3HLLLfz3f/83y5cvZ+7cuQDcfvvt3HXXXVRUVPDyyy/To0ePNr2nrVHPQUTa5bO+4R9oixYt4pvf/CbxeJyDDz6YadOm8dprr9G3b18mTZrEkCFDABg9ejSnnHIKAOPHj+eFF15oWsYFF1xALBZjzJgxjBo1infffTfyOmeeeSapVIpUKsXgwYPZvHkzzz//PMuWLWPSpEkA1NTUMHjwYF599VW+8pWvMGjQIAAuvPDCnPaN7Nixg+3btzNt2jQAZsyYwfnnnw/AhAkTuPjiiznnnHM455xzAJg6dSpXX301F198Md/4xjcYNmxYe9/GJuo5iEiXMm7cOJYtW9am5zTflBOLxZrux2Ix0ul007yW5wO0dn5A82XF43HS6TTuzowZM6ioqKCiooKVK1cya9asNtWYq2eeeYYrr7yS119/nUmTJpFOp7n++uv59a9/TU1NDVOnTm011NpK4SAiXcpXv/pV6urqmDdvXtO05cuXU1ZWxqOPPkomk2HLli0sXLiQyZMnt2nZjz/+ONlsljVr1rB27VqOPPLInJ538skn88QTT/DRRx8B8Mknn7Bu3TpOOOEEXnrpJbZu3UpDQwOPP/54Tss76KCD6NevHy+//DIADz74INOmTSObzbJ+/XpOOukkbr31Vnbs2EF1dTVr1qxh/PjxXHfddUyaNKlDwkGblUSkSzEznnrqKa666ipuvfVWSktLGTFiBHfccQfV1dUce+yxmBm33XYbhxxySJs+KIcPH87kyZOpqqpi7ty5lJaW5vS8sWPH8qMf/YhTTjmFbDZLMpnkrrvuYsqUKcyaNYsTTzyRsrIyJk6cmHMt999/f9MO6VGjRnHvvfeSyWS45JJL2LFjB+7Od77zHcrKyvjBD37ACy+8QCwWY9y4cZx++uk5v87emLvv90IKrby83JcuXVroMkS6vRUrVnD00UcXugxph9bWnZktc/dWj9PVZiUREYnQZiURkQNs9uzZkf0P559/PjNnzixQRVEFDQczuwa4HRjk7h9bcGjAz4AzgF3AZe7+eiFrFBHpaDNnzuxUQdCagm1WMrPDgFOAD5pNPh0YE/5cDvyyAKWJiBS9NoeDmfUzswkd8Nr/BvwvoPke8bOBBzywGCgzsyEd8FoiItIGOYWDmb1oZn3NrD/wOvArM/tpe1/UzM4GNrj7Gy1mHQqsb3a/MpzW2jIuN7OlZrZ0y5Yt7S1FRERakWvP4SB3rwK+QfDN/gTga/t6gpktMLO3Wvk5G/g+8MP9Kdzd57l7ubuXN56aLiLdX+/evfOy3NNOO42ysjLOOuusvCy/q8l1h3Qi3LxzAZDTXhR3bzU8zGw8MBJ4Izw1fRjwuplNBjYAhzV7+LBwmohIXl177bXs2rWLu+++u9CldAq59hz+BZgPrHH318xsFPCX9rygu7/p7oPdfYS7jyDYdHScu28CngamW2AKsMPdN7bndUSkeFRUVDBlyhQmTJjAueeey7Zt2wCYM2cOY8eOZcKECVx00UUAvPTSS0ycOJGJEyfy+c9/np07dwLBEBj7O8x1d5JTz8HdHwceb3Z/LfA3eajnWYLDWFcTHMr6d3l4DRHpCM9dD5ve7NhlHjIeTr+lzU+bPn06d955J9OmTeOHP/whN998M3fccQe33HIL7733HqlUiu3btwO7h7eeOnUq1dXVOQ+RUWxy3SF9hJk9b2ZvhfcnmNmNHVFA2IP4OLzt7n6lu4929/HurjExRGSfWhveeuHChcDu4a0feughEongu3Dj8NZz5sxh+/btTdNlT7m+K78CrgXuBnD35Wb278CP8lWYiHRy7fiGf6A988wzLFy4kN///vfMnj2bN998k+uvv54zzzyTZ599lqlTpzJ//nyOOuqoQpfa6eS6z6Gnuy9pMS3d6iNFRA6gzjC8dXeUa8/hYzMbTXjCmpmdB2hHsYgccLt27drjSmdXX311hwxv/aUvfYl3332X6upqhg0bxm9+8xtOPfXUQjWz4HINhyuBecBRZrYBeA+4JG9ViYjsRTabbXX64sWLI9MWLVoUmdb8mtHNNfY8JJDr0Uprga+ZWS8g5u4781uWiIgUUq5HK33XzPoSHF76b2b2upmdkt/SRESkUHLdIf334fAZpwADgEuBzn+ogoiItEuu4WDh7zMIxlZ6u9k0ERHpZnINh2Vm9ieCcJhvZn2A1vcKiYhIl5fr0Ur/AEwE1rr7rnDobg1tISLSTeXaczgRWOnu283sEuBGYEf+yhIRaV0+huyuqKjgxBNPZNy4cUyYMIFHH320w1+jq8k1HH4J7DKzY4FrgDXAA3mrSkTkAOrZsycPPPAAb7/9Nn/84x+56qqrmgbqK1a5hkPa3Z3gMp4/d/e7AI1tKyKdwv4O2X3EEUcwZswYAIYOHcrgwYMp9itM5rrPYaeZ3UBwCOuXzCwGJPNXloh0drcuuZV3P+nYcYmO6n8U102+rs3P68ghu5csWUJ9fT2jR4/ukDZ1Vbn2HC4E6gjOd9hEcIW2n+StKhGRHHXkkN0bN27k0ksv5d577yUWy/XjsXvKdfiMTWb2MDDJzM4Clri79jmIFLH2fMM/0NoyZHdVVRVnnnkms2fPZsqUKYUuveByHT7jAmAJcD7BdaRfDUdmFREpqI4Ysru+vp5zzz2X6dOnc955+miD3Pc5zAQmuftHAGY2CFgAPJGvwkREWpOPIbsfe+wxFi5cyNatW7nvvvsAuO+++5g4cWKBWll4FhyE9BkPMnvT3cc3ux8D3mg+rZDKy8t96VJdUVQk31asWMHRRx9d6DKkHVpbd2a2zN3LW3t8rj2HP5rZfOA/wvsXAs+2u0oREenUct0hfa2Z/Q0wNZw0z92fyl9ZIiJSSLn2HHD33wK/zWMtIiLSSewzHMxsJ+F1o1vOAtzd++alKhERKah9hoO7a4gMEZEiVNynAIqISKsUDiLSpeRjyO5169Zx3HHHMXHiRMaNG8fcuXM7/DW6mpx3SIuIdFdDhgzhz3/+M6lUiurqao455hi+/vWvM3To0EKXVjDqOYhIl7e/Q3aXlJSQSqUAqKurI5vVVZCLuufw6tqt3PXiGn78jfEcWtaj0OWIdCmb/vVfqVvRsUN2p44+ikO+//02P68jhuxev349Z555JqtXr+YnP/lJUfcaoMh7Dls/rWfhqi3srG0odCki0k4dNWT3YYcdxvLly1m9ejX3338/mzdvLkyDOomi7jkkYgZAOvPZ40uJyJ7a8w3/QGvLkN2Nhg4dyjHHHMPLL79c1CO0FnXPIZkIml+f0fZFka6qI4bsrqyspKamBoBt27axaNEijjzyyEI2q+CKuueQDK/0pJ6DSNeRjyG7Fy5cyDXXXIOZ4e5873vfY/z4TjHodMEUdTgk4o2bldRzEOkq9nYk0eLFiyPTFi1aFJl25513Rqb91V/9FcuXL9//4rqR4t6sFIZDQ1Y9BxGR5goWDmb2z2b2rpm9bWa3NZt+g5mtNrOVZnZqPmtING1WUs9BRKS5gmxWMrOTgLOBY929zswGh9PHAhcB44ChwAIzO8LdM/moo3GzUoP2OYjkzN0xs0KXIW2QyxU/WypUz+GfgFvcvQ6g8drUBIHxiLvXuft7wGpgcr6KSMaD5jeo5yCSk9LSUrZu3dquDxspDHdn69atTSf75apQO6SPAL5kZrOBWuB77v4acCjQfK9SZTgtwswuBy4HGD58eLuKaAyHtE6VF8nJsGHDqKysZMuWLYUuRdqgtLR0jyO8cpG3cDCzBcAhrcyaGb5uf2AKMAl4zMxGtWX57j4PmAdQXl7erq8xjSfBabOSSG6SySQjR44sdBlyAOQtHNz9a3ubZ2b/BDzpQd90iZllgYHABuCwZg8dFk7Li6aeg8JBRGQPhdrn8DvgJAAzOwIoAT4GngYuMrOUmY0ExgBL8lVE03kO2qwkIrKHQu1zuAe4x8zeAuqBGWEv4m0zewx4B0gDV+brSCXYfYa0NiuJiOypIOHg7vXAJXuZNxuYfSDq2H0oq3oOIiLNFfkZ0joJTkSkNUUeDjpaSUSkNUUdDmZGPGbaIS0i0kJRhwME5zroUFYRkT0VfTgk4zFtVhIRaaHowyER12YlEZGWFA6xmA5lFRFpoejDoSRu2qwkItJC0YdDIh7TeQ4iIi0oHOKmy4SKiLRQ9OGQjKnnICLSUtGHQyKu8xxERFpSOMRj1KvnICKyh6IPhxL1HEREIoo+HBKxmE6CExFpQeGg8xxERCKKPhyScfUcRERaKvpw0KisIiJRRR8OSR2tJCISUfThoPMcRESiij4ckhpbSUQkQuGgsZVERCKKPhwSGltJRCRC4aB9DiIiEUUfDjpaSUQkqujDIREz0trnICKyh6IPh2Q8RibruCsgREQaKRziBqDxlUREmin6cEjEg7dA4yuJiOymcIip5yAi0lLRh0OyseegI5ZERJoUfTgktM9BRCSi6MMhGQveggb1HEREmigcEkHPQec6iIjsVvThkIhpn4OISEsFCQczm2hmi82swsyWmtnkcLqZ2RwzW21my83suHzXovMcRESiCtVzuA242d0nAj8M7wOcDowJfy4HfpnvQpp6DjrPQUSkSaHCwYG+4e2DgA/D22cDD3hgMVBmZkPyWcjuo5UUDiIijRIFet2rgPlmdjtBQH0hnH4osL7Z4yrDaRtbLsDMLifoXTB8+PB2F9J4noM2K4mI7Ja3cDCzBcAhrcyaCZwM/E93/62ZXQD8BvhaW5bv7vOAeQDl5eXt/mTffRKcwkFEpFHewsHd9/phb2YPAN8N7z4O/Dq8vQE4rNlDh4XT8qZps5L2OYiINCnUPocPgWnh7a8CfwlvPw1MD49amgLscPfIJqWOlIyp5yAi0lKh9jn8D+BnZpYAagn3HQDPAmcAq4FdwN/lu5DGnoPOcxAR2a0g4eDui4DjW5nuwJUHspbG8xx0qVARkd10hrQ2K4mIRCgcdJ6DiEhE0YfDwN4pUokYqzZXF7oUEZFOo+jDoTQZZ/LI/ixavaXQpYiIdBpFHw4AX/zcQFZtrmbTjtpClyIi0ikoHIAvjhkIwKLVHxe4EhGRzkHhABx9SF8G9k4x/+1NhS5FRKRTUDgAsZhx4aRhLFixmXVbPy10OSIiBadwCE0/cQSJmHH3wrUE5+KJiBSvQg2f0ekc3LeU844fxr+/+gHLK7czsHeKH5w1ltGDehe6NBGRA049h2b+99nHMOuvx5JKxFn2/jaueewNMln1IkSk+CgcmknEY1w2dSS//acv8KNzj6Fi/Xam3/MqD7+6jo+qdJiriBQP6w7b18vLy33p0qUdukx35+f/dzWPLVvP+k9qKInHuGTK4Zw67mB21Wfo2yPB+EPLKEkoX0WkazKzZe5e3uo8hcO+uTurNlfz65fX8sTrlTR/u/qWJjjpqMHEzJgyqj/D+/eiZ0mcMQf3pmdJgnQmSyKu8BCRzknh0EG2VtexvHIHfUoTfFxdxx/f2sT/W7MVB7bsrGt6nBkM6p3i4+o6BvZOMWJAL/r2SJKMGx9ur6F/rxIG9UnRO5WkrGeSYf160DuVIJWMUxKPkUrGKInHKE3GSCXilCRi9C1N0qMknvc2ikjx2Fc46GilNhjQO8VJRw1uun/aMUOAoHfx9odVVNU2UFWTZuWmnazftovBfVJs2lHLhztq+HB7DbXpDEMP6sHmqjpWbNxJdV2a6rp0zq/fv1cJybgRM6M0GadHMk4sBlU1acYO6cun9Wk+rUvToySYl4zH2LC9hlQixsF9S0nEjFjMMAwzqE9nyWSdVDJGVU2aow7pw4iBvchks6SzTtZhWL8e9C1NkHXIhtPcg99Zd7LuTb2poWU96JWKU58Onh8ziFlQbzxm1GeyVNU00Kc0SX06SzxmOE51bZph/XoSjxnpbJZ0JlhmKhnj07o0ZkZJIkYyZsHrE7w+gBGEcXA7aJeFM5rfN7Omx1owc6/zPq6uo6Yhw+EDelJdmyYeC97vmAX1NbanIRO0IZWI4+40ZJx0NktDxknGjZ4lu/+90pksTnDN8sYvZNZYuOSFu1PbkKU0GcPMwr9fz7k335DJ0pDJ7rEec33d7rBuFQ4dwMw45tCDmu6fdswhOT+3tiHDhu011NRnqEtnqEtnqUtnqQ9/1zVkqM9k+aS6no1VtWQyTsadunSWmvo0maxzeP9evLlhBwf1SHJQjyS1DRm272qgtiHD0LIe1DZkeOfDKjLuTdet8PCfJBk3ahuy9CyJ88LKj3R0VjvEDFp72xIxI+tO3x5JqmvTZNzpVZJo+kLQGJ6dQWcowzAScSMZb7zGSpaGrJPNOvFY8AUhZtb0hSTbGLLsDniaBX5NQ4b6dJYeyTj9e5Ww9dM66tJZDuqRpG9pkk/r0lTVNpCIxehdGnwUugehUJ/OUtOQAaBfz2RTTZ8l6862XQ2kEjF6liTIZLNN/1NmwZeVTMapy2SJm5GIhQU3/v0Y9EjGicesaXnpjNOQCb5wpbNOOpMl6xCPBV9S/vHLo7jmlCM7YA3sSeFQYKXJeKc5l6KqtoEduxqa/ugAPvhkFzX1mbAHEPyBxyw4q3z3/eAfdv0nu6hryFKSiJGIW7NehpPJBh+WfXsk2FmbpiQea/pA7ZmKs2FbTVNgJWK7r87XM9yU1tgbMRpfd3fd7sH/loe9isb7uO+e3vw2NH1792Y9kcYPnH49SyhNxlj/SQ0H9Qh6TbXpDNmsk4zHyLiTyQS1ZrJZahuCHkQybk31N2ScqtoG4mbsqGmgd2mCkniMqtoG+qQSEH6TdQofxp1ly3LWw0DIZLGwd5aIBx+g6YxTn8mSzXr4txeGAdF1D8H6LU3G6dsjybZP6/m4uo4BvVP0SiXY9mk9O2sb6JVK0LdHknQmGwZ2sMSSeBBEvVIJkvEYH26vaQqiz2Jm9OuZpKY+CJfGnn5jTY2PSSVjTUHU9FyC/6Pahkyz4NsdmImYEY8byViMWCz4+0lnneOG99vv9741Cgdp0rc0+EbV3MF9S3N+fr7+SEXkwNOhNCIiEqFwEBGRCIWDiIhEKBxERCRC4SAiIhEKBxERiVA4iIhIhMJBREQiusXAe2a2BVjXzqcPBD7uwHK6imJsdzG2GYqz3Wpzbg5390GtzegW4bA/zGzp3kYl7M6Ksd3F2GYoznarzftPm5VERCRC4SAiIhEKB5hX6AIKpBjbXYxthuJst9q8n4p+n4OIiESp5yAiIhEKBxERiSjqcDCz08xspZmtNrPrC11PvpjZ+2b2pplVmNnScFp/M/svM/tL+LvLX6nHzO4xs4/M7K1m01ptpwXmhOt+uZkdV7jK228vbZ5lZhvC9V1hZmc0m3dD2OaVZnZqYareP2Z2mJm9YGbvmNnbZvbdcHq3XUvWajkAAARVSURBVNf7aHP+1rW7F+UPEAfWAKOAEuANYGyh68pTW98HBraYdhtwfXj7euDWQtfZAe38MnAc8NZntRM4A3iO4NqQU4BXC11/B7Z5FvC9Vh47Nvw7TwEjw7//eKHb0I42DwGOC2/3AVaFbeu263ofbc7bui7mnsNkYLW7r3X3euAR4OwC13QgnQ3cH96+HzingLV0CHdfCHzSYvLe2nk28IAHFgNlZjbkwFTacfbS5r05G3jE3evc/T1gNcH/QZfi7hvd/fXw9k5gBXAo3Xhd76PNe7Pf67qYw+FQYH2z+5Xs+83uyhz4k5ktM7PLw2kHu/vG8PYm4ODClJZ3e2tnd1//3w43odzTbJNht2uzmY0APg+8SpGs6xZthjyt62IOh2LyRXc/DjgduNLMvtx8pgf90G5/THOxtBP4JTAamAhsBP5PYcvJDzPrDfwWuMrdq5rP667rupU2521dF3M4bAAOa3Z/WDit23H3DeHvj4CnCLqXmxu71uHvjwpXYV7trZ3ddv27+2Z3z7h7FvgVuzcndJs2m1mS4EPyYXd/Mpzcrdd1a23O57ou5nB4DRhjZiPNrAS4CHi6wDV1ODPrZWZ9Gm8DpwBvEbR1RviwGcB/FqbCvNtbO58GpodHskwBdjTbJNGltdiefi7B+oagzReZWcrMRgJjgCUHur79ZWYG/AZY4e4/bTar267rvbU5r+u60HvhC/lDcBTDKoI9+TMLXU+e2jiK4KiFN4C3G9sJDACeB/4CLAD6F7rWDmjrfxB0rRsItrH+w97aSXDkyl3hun8TKC90/R3Y5gfDNi0PPySGNHv8zLDNK4HTC11/O9v8RYJNRsuBivDnjO68rvfR5rytaw2fISIiEcW8WUlERPZC4SAiIhEKBxERiVA4iIhIhMJBREQiFA4iBWZmXzGzPxS6DpHmFA4iIhKhcBDJkZldYmZLwnHz7zazuJlVm9m/hWPsP29mg8LHTjSzxeGAaE81u7bA58xsgZm9YWavm9nocPG9zewJM3vXzB4Oz4gVKRiFg0gOzOxo4EJgqrtPBDLAxUAvYKm7jwNeAm4Kn/IAcJ27TyA4g7Vx+sPAXe5+LPAFgrObIRhl8yqCcfhHAVPz3iiRfUgUugCRLuJk4HjgtfBLfQ+Cgd2ywKPhYx4CnjSzg4Ayd38pnH4/8Hg4xtWh7v4UgLvXAoTLW+LuleH9CmAEsCj/zRJpncJBJDcG3O/uN+wx0ewHLR7X3vFo6prdzqD/TSkwbVYSyc3zwHlmNhiarld8OMH/0HnhY/4WWOTuO4BtZvalcPqlwEseXMGr0szOCZeRMrOeB7QVIjnStxORHLj7O2Z2I8EV9WIEo6BeCXwKTA7nfUSwXwKCIaPnhh/+a4G/C6dfCtxtZv8SLuP8A9gMkZxpVFaR/WBm1e7eu9B1iHQ0bVYSEZEI9RxERCRCPQcREYlQOIiISITCQUREIhQOIiISoXAQEZGI/w9MnV2uenUJawAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from urllib.request import ProxyBasicAuthHandler\n",
        "import torch.nn.functional as nnf\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "train_accu = []\n",
        "train_losses = []\n",
        "train_accu1 = []\n",
        "train_accu2 = []\n",
        "train_accu3 = []\n",
        "train_losses1 = []\n",
        "train_losses2 = []\n",
        "train_losses3 = []\n",
        "val_accu = []\n",
        "val_losses = []\n",
        "\n",
        "# PSNR metrics\n",
        "def psnr(target, ref):\n",
        "         \n",
        "    # assume RGB image\n",
        "    target_data = torch.tensor(target, dtype=float)\n",
        "    ref_data = torch.tensor(ref, dtype=float) \n",
        "    diff = ref_data - target_data\n",
        "    \n",
        "    diff = diff.flatten()\n",
        "    \n",
        "    rmse = math.sqrt(torch.mean(diff ** 2.))\n",
        "\n",
        "    return 20 * math.log10(255. / rmse)\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    running_loss = 0\n",
        "    running_loss1 = 0\n",
        "    running_loss2 = 0\n",
        "    running_loss3 = 0\n",
        "    total = 0\n",
        "    total1 = 0\n",
        "    total2 = 0\n",
        "    total3 = 0\n",
        "    correct = 0\n",
        "    correct1 = 0\n",
        "    correct2 = 0\n",
        "    correct3 = 0\n",
        "\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = fun_ssim(gts, pre_res[0]) \n",
        "            loss2    = fun_ssim(gts, pre_res[1])\n",
        "            loss3    = fun_ssim(gts, pre_res[2])\n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "\n",
        "            #loss graph\n",
        "            running_loss1 += loss1.item()\n",
        "            running_loss2 += loss2.item()\n",
        "            running_loss3 += loss3.item()\n",
        "            predicted1 = pre_res[0]\n",
        "            predicted2 = pre_res[1]\n",
        "            predicted3 = pre_res[2]\n",
        "            total1 += images.size(0)\n",
        "            total2 += gts.size(0)\n",
        "            total3 += depths.size(0)\n",
        "            #correct1 += float(torch.sum(predicted1 == gts.data))\n",
        "            #correct2 += float(torch.sum(predicted2 == gts.data))\n",
        "            #correct3 += float(torch.sum(predicted3 == gts.data))\n",
        "            correct1 += predicted1.eq(images).sum().item()\n",
        "            correct2 += predicted2.eq(gts).sum().item()\n",
        "            correct3 += predicted3.eq(depths).sum().item()\n",
        "\n",
        "            running_loss += loss_all.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = torch.sum(gt + loss + predicted)\n",
        "            total += images.size(0)\n",
        "            correct += float(correct1 + correct2 + correct3)\n",
        "            \n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "\n",
        "        train_loss = running_loss/len(train_loader)\n",
        "        train_loss1=running_loss1/len(train_loader)\n",
        "        train_loss2=running_loss2/len(train_loader)\n",
        "        train_loss3=running_loss3/len(train_loader)\n",
        "        accu1= correct1/total1\n",
        "        accu2= correct2/total2\n",
        "        accu3= correct3/total3 \n",
        "        accu = correct/total\n",
        "           \n",
        "        train_accu1.append(round(accu1, 3))\n",
        "        train_accu2.append(round(accu2, 3))\n",
        "        train_accu3.append(round(accu3, 3))\n",
        "        train_losses1.append(float(train_loss1))\n",
        "        train_losses2.append(float(train_loss2))\n",
        "        train_losses3.append(float(train_loss3))\n",
        "        train_accu.append(round(accu, 3))\n",
        "        train_losses.append(float(train_loss))\n",
        "\n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "           \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0.0\n",
        "\n",
        "    correct1 = 0.0\n",
        "    correct2 = 0.0\n",
        "    correct3 = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-4)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            #res     = (res - res.min()) / (res.max() - res.min() + 1e-4)\n",
        "            #mae = np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "            #mae = np.mean((gt - res)**2)\n",
        "            mse = psnr(res, gt)\n",
        "            mae_sum += mse\n",
        "\n",
        "            #loss graph\n",
        "            running_loss += mae_sum\n",
        "            pre1, pre2, predicted = pre_res\n",
        "            #outputs = float(torch.sum(gt + depth + predicted))\n",
        "            total += test_loader.size\n",
        "\n",
        "            #correct1 += float(torch.sum(pre1 == image.data))\n",
        "            #correct2 += float(torch.sum(pre2 == image.data))\n",
        "            #correct3 += float(torch.sum(predicted == image.data))\n",
        "\n",
        "            correct += predicted.eq(image).sum().item()\n",
        "            #correct += float(torch.sum(predicted == image).item())\n",
        "\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "       \n",
        "        val_loss=running_loss/len(test_loader)\n",
        "        accu= 100 * correct/total\n",
        "        val_accu.append(round(accu, 3))\n",
        "        val_losses.append(float(val_loss))\n",
        "\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                #torch.save(model.state_dict(), save_path+'SPNet_epoch_best_Combine_Loss_only_with_RGB_as_depth.pth')\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_psnr_ssim1.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n",
        "\n",
        "plt.plot(train_losses, '-')\n",
        "plt.plot(train_losses1,'-')\n",
        "plt.plot(train_losses2,'-')\n",
        "plt.plot(train_losses3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Combined_loss','Loss1', 'Loss2', 'Loss3'])\n",
        "plt.title('Train Losses')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_accu, '-')\n",
        "plt.plot(train_accu1,'-')\n",
        "plt.plot(train_accu2,'-')\n",
        "plt.plot(train_accu3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Acc')\n",
        "plt.legend(['Combined_Accuracy','Acc1', 'Acc2', 'Acc3'])\n",
        "plt.title('Train Accuracy')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(val_losses,'-')\n",
        "plt.plot(val_accu,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Losses','Accuracy'])\n",
        "plt.title('Test Losses and Accuracy')\n",
        " \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2V0EtsSkH8Z"
      },
      "source": [
        "### Training with MS-SSIM Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUek5bsikM12"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCz5s8d-kNgo"
      },
      "source": [
        "### Training with L1 loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YJJ1jTonkP8r",
        "outputId": "babf57dc-4731-4419-8046-9927594dea7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USE GPU 0\n",
            "load data...\n",
            "/content/tmp/traindataset/RGB/ /content/tmp/traindataset/GT/ /content/tmp/traindataset/depth/\n",
            "/content/tmp/traindataset/RGB/ /content/tmp/traindataset/GT/ /content/tmp/traindataset/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/traindataset/RGB/RGB_00.png', '/content/tmp/traindataset/RGB/RGB_01.png', '/content/tmp/traindataset/RGB/RGB_02.png', '/content/tmp/traindataset/RGB/RGB_10.png', '/content/tmp/traindataset/RGB/RGB_100.png', '/content/tmp/traindataset/RGB/RGB_101.png', '/content/tmp/traindataset/RGB/RGB_102.png', '/content/tmp/traindataset/RGB/RGB_11.png', '/content/tmp/traindataset/RGB/RGB_110.png', '/content/tmp/traindataset/RGB/RGB_111.png', '/content/tmp/traindataset/RGB/RGB_112.png', '/content/tmp/traindataset/RGB/RGB_12.png', '/content/tmp/traindataset/RGB/RGB_120.png', '/content/tmp/traindataset/RGB/RGB_121.png', '/content/tmp/traindataset/RGB/RGB_122.png', '/content/tmp/traindataset/RGB/RGB_130.png', '/content/tmp/traindataset/RGB/RGB_131.png', '/content/tmp/traindataset/RGB/RGB_132.png', '/content/tmp/traindataset/RGB/RGB_140.png', '/content/tmp/traindataset/RGB/RGB_141.png', '/content/tmp/traindataset/RGB/RGB_142.png', '/content/tmp/traindataset/RGB/RGB_150.png', '/content/tmp/traindataset/RGB/RGB_151.png', '/content/tmp/traindataset/RGB/RGB_152.png', '/content/tmp/traindataset/RGB/RGB_160.png', '/content/tmp/traindataset/RGB/RGB_161.png', '/content/tmp/traindataset/RGB/RGB_162.png', '/content/tmp/traindataset/RGB/RGB_170.png', '/content/tmp/traindataset/RGB/RGB_171.png', '/content/tmp/traindataset/RGB/RGB_172.png', '/content/tmp/traindataset/RGB/RGB_180.png', '/content/tmp/traindataset/RGB/RGB_181.png', '/content/tmp/traindataset/RGB/RGB_182.png', '/content/tmp/traindataset/RGB/RGB_190.png', '/content/tmp/traindataset/RGB/RGB_191.png', '/content/tmp/traindataset/RGB/RGB_192.png', '/content/tmp/traindataset/RGB/RGB_20.png', '/content/tmp/traindataset/RGB/RGB_200.png', '/content/tmp/traindataset/RGB/RGB_201.png', '/content/tmp/traindataset/RGB/RGB_202.png', '/content/tmp/traindataset/RGB/RGB_21.png', '/content/tmp/traindataset/RGB/RGB_210.png', '/content/tmp/traindataset/RGB/RGB_211.png', '/content/tmp/traindataset/RGB/RGB_212.png', '/content/tmp/traindataset/RGB/RGB_22.png', '/content/tmp/traindataset/RGB/RGB_220.png', '/content/tmp/traindataset/RGB/RGB_221.png', '/content/tmp/traindataset/RGB/RGB_222.png', '/content/tmp/traindataset/RGB/RGB_230.png', '/content/tmp/traindataset/RGB/RGB_231.png', '/content/tmp/traindataset/RGB/RGB_232.png', '/content/tmp/traindataset/RGB/RGB_240.png', '/content/tmp/traindataset/RGB/RGB_241.png', '/content/tmp/traindataset/RGB/RGB_242.png', '/content/tmp/traindataset/RGB/RGB_250.png', '/content/tmp/traindataset/RGB/RGB_251.png', '/content/tmp/traindataset/RGB/RGB_252.png', '/content/tmp/traindataset/RGB/RGB_260.png', '/content/tmp/traindataset/RGB/RGB_261.png', '/content/tmp/traindataset/RGB/RGB_262.png', '/content/tmp/traindataset/RGB/RGB_270.png', '/content/tmp/traindataset/RGB/RGB_271.png', '/content/tmp/traindataset/RGB/RGB_272.png', '/content/tmp/traindataset/RGB/RGB_280.png', '/content/tmp/traindataset/RGB/RGB_281.png', '/content/tmp/traindataset/RGB/RGB_282.png', '/content/tmp/traindataset/RGB/RGB_290.png', '/content/tmp/traindataset/RGB/RGB_291.png', '/content/tmp/traindataset/RGB/RGB_292.png', '/content/tmp/traindataset/RGB/RGB_30.png', '/content/tmp/traindataset/RGB/RGB_300.png', '/content/tmp/traindataset/RGB/RGB_301.png', '/content/tmp/traindataset/RGB/RGB_302.png', '/content/tmp/traindataset/RGB/RGB_31.png', '/content/tmp/traindataset/RGB/RGB_310.png', '/content/tmp/traindataset/RGB/RGB_311.png', '/content/tmp/traindataset/RGB/RGB_312.png', '/content/tmp/traindataset/RGB/RGB_32.png', '/content/tmp/traindataset/RGB/RGB_320.png', '/content/tmp/traindataset/RGB/RGB_321.png', '/content/tmp/traindataset/RGB/RGB_322.png', '/content/tmp/traindataset/RGB/RGB_330.png', '/content/tmp/traindataset/RGB/RGB_331.png', '/content/tmp/traindataset/RGB/RGB_332.png', '/content/tmp/traindataset/RGB/RGB_340.png', '/content/tmp/traindataset/RGB/RGB_341.png', '/content/tmp/traindataset/RGB/RGB_342.png', '/content/tmp/traindataset/RGB/RGB_350.png', '/content/tmp/traindataset/RGB/RGB_351.png', '/content/tmp/traindataset/RGB/RGB_352.png', '/content/tmp/traindataset/RGB/RGB_360.png', '/content/tmp/traindataset/RGB/RGB_361.png', '/content/tmp/traindataset/RGB/RGB_362.png', '/content/tmp/traindataset/RGB/RGB_370.png', '/content/tmp/traindataset/RGB/RGB_371.png', '/content/tmp/traindataset/RGB/RGB_372.png', '/content/tmp/traindataset/RGB/RGB_380.png', '/content/tmp/traindataset/RGB/RGB_381.png', '/content/tmp/traindataset/RGB/RGB_382.png', '/content/tmp/traindataset/RGB/RGB_390.png', '/content/tmp/traindataset/RGB/RGB_391.png', '/content/tmp/traindataset/RGB/RGB_392.png', '/content/tmp/traindataset/RGB/RGB_40.png', '/content/tmp/traindataset/RGB/RGB_400.png', '/content/tmp/traindataset/RGB/RGB_401.png', '/content/tmp/traindataset/RGB/RGB_402.png', '/content/tmp/traindataset/RGB/RGB_41.png', '/content/tmp/traindataset/RGB/RGB_410.png', '/content/tmp/traindataset/RGB/RGB_411.png', '/content/tmp/traindataset/RGB/RGB_412.png', '/content/tmp/traindataset/RGB/RGB_42.png', '/content/tmp/traindataset/RGB/RGB_420.png', '/content/tmp/traindataset/RGB/RGB_421.png', '/content/tmp/traindataset/RGB/RGB_422.png', '/content/tmp/traindataset/RGB/RGB_430.png', '/content/tmp/traindataset/RGB/RGB_431.png', '/content/tmp/traindataset/RGB/RGB_432.png', '/content/tmp/traindataset/RGB/RGB_440.png', '/content/tmp/traindataset/RGB/RGB_441.png', '/content/tmp/traindataset/RGB/RGB_442.png', '/content/tmp/traindataset/RGB/RGB_450.png', '/content/tmp/traindataset/RGB/RGB_451.png', '/content/tmp/traindataset/RGB/RGB_452.png', '/content/tmp/traindataset/RGB/RGB_460.png', '/content/tmp/traindataset/RGB/RGB_461.png', '/content/tmp/traindataset/RGB/RGB_462.png', '/content/tmp/traindataset/RGB/RGB_470.png', '/content/tmp/traindataset/RGB/RGB_471.png', '/content/tmp/traindataset/RGB/RGB_472.png', '/content/tmp/traindataset/RGB/RGB_480.png', '/content/tmp/traindataset/RGB/RGB_481.png', '/content/tmp/traindataset/RGB/RGB_482.png', '/content/tmp/traindataset/RGB/RGB_490.png', '/content/tmp/traindataset/RGB/RGB_491.png', '/content/tmp/traindataset/RGB/RGB_492.png', '/content/tmp/traindataset/RGB/RGB_50.png', '/content/tmp/traindataset/RGB/RGB_500.png', '/content/tmp/traindataset/RGB/RGB_501.png', '/content/tmp/traindataset/RGB/RGB_502.png', '/content/tmp/traindataset/RGB/RGB_51.png', '/content/tmp/traindataset/RGB/RGB_510.png', '/content/tmp/traindataset/RGB/RGB_511.png', '/content/tmp/traindataset/RGB/RGB_512.png', '/content/tmp/traindataset/RGB/RGB_52.png', '/content/tmp/traindataset/RGB/RGB_520.png', '/content/tmp/traindataset/RGB/RGB_521.png', '/content/tmp/traindataset/RGB/RGB_522.png', '/content/tmp/traindataset/RGB/RGB_530.png', '/content/tmp/traindataset/RGB/RGB_531.png', '/content/tmp/traindataset/RGB/RGB_532.png', '/content/tmp/traindataset/RGB/RGB_540.png', '/content/tmp/traindataset/RGB/RGB_541.png', '/content/tmp/traindataset/RGB/RGB_542.png', '/content/tmp/traindataset/RGB/RGB_550.png', '/content/tmp/traindataset/RGB/RGB_551.png', '/content/tmp/traindataset/RGB/RGB_552.png', '/content/tmp/traindataset/RGB/RGB_560.png', '/content/tmp/traindataset/RGB/RGB_561.png', '/content/tmp/traindataset/RGB/RGB_562.png', '/content/tmp/traindataset/RGB/RGB_570.png', '/content/tmp/traindataset/RGB/RGB_571.png', '/content/tmp/traindataset/RGB/RGB_572.png', '/content/tmp/traindataset/RGB/RGB_580.png', '/content/tmp/traindataset/RGB/RGB_581.png', '/content/tmp/traindataset/RGB/RGB_582.png', '/content/tmp/traindataset/RGB/RGB_590.png', '/content/tmp/traindataset/RGB/RGB_591.png', '/content/tmp/traindataset/RGB/RGB_592.png', '/content/tmp/traindataset/RGB/RGB_60.png', '/content/tmp/traindataset/RGB/RGB_600.png', '/content/tmp/traindataset/RGB/RGB_601.png', '/content/tmp/traindataset/RGB/RGB_602.png', '/content/tmp/traindataset/RGB/RGB_61.png', '/content/tmp/traindataset/RGB/RGB_610.png', '/content/tmp/traindataset/RGB/RGB_611.png', '/content/tmp/traindataset/RGB/RGB_612.png', '/content/tmp/traindataset/RGB/RGB_62.png', '/content/tmp/traindataset/RGB/RGB_620.png', '/content/tmp/traindataset/RGB/RGB_621.png', '/content/tmp/traindataset/RGB/RGB_622.png', '/content/tmp/traindataset/RGB/RGB_630.png', '/content/tmp/traindataset/RGB/RGB_631.png', '/content/tmp/traindataset/RGB/RGB_632.png', '/content/tmp/traindataset/RGB/RGB_640.png', '/content/tmp/traindataset/RGB/RGB_641.png', '/content/tmp/traindataset/RGB/RGB_642.png', '/content/tmp/traindataset/RGB/RGB_650.png', '/content/tmp/traindataset/RGB/RGB_651.png', '/content/tmp/traindataset/RGB/RGB_652.png', '/content/tmp/traindataset/RGB/RGB_660.png', '/content/tmp/traindataset/RGB/RGB_661.png', '/content/tmp/traindataset/RGB/RGB_662.png', '/content/tmp/traindataset/RGB/RGB_670.png', '/content/tmp/traindataset/RGB/RGB_671.png', '/content/tmp/traindataset/RGB/RGB_672.png', '/content/tmp/traindataset/RGB/RGB_680.png', '/content/tmp/traindataset/RGB/RGB_681.png', '/content/tmp/traindataset/RGB/RGB_682.png', '/content/tmp/traindataset/RGB/RGB_690.png', '/content/tmp/traindataset/RGB/RGB_691.png', '/content/tmp/traindataset/RGB/RGB_692.png', '/content/tmp/traindataset/RGB/RGB_70.png', '/content/tmp/traindataset/RGB/RGB_700.png', '/content/tmp/traindataset/RGB/RGB_701.png', '/content/tmp/traindataset/RGB/RGB_702.png', '/content/tmp/traindataset/RGB/RGB_71.png', '/content/tmp/traindataset/RGB/RGB_710.png', '/content/tmp/traindataset/RGB/RGB_711.png', '/content/tmp/traindataset/RGB/RGB_712.png', '/content/tmp/traindataset/RGB/RGB_72.png', '/content/tmp/traindataset/RGB/RGB_720.png', '/content/tmp/traindataset/RGB/RGB_721.png', '/content/tmp/traindataset/RGB/RGB_722.png', '/content/tmp/traindataset/RGB/RGB_730.png', '/content/tmp/traindataset/RGB/RGB_731.png', '/content/tmp/traindataset/RGB/RGB_732.png', '/content/tmp/traindataset/RGB/RGB_740.png', '/content/tmp/traindataset/RGB/RGB_741.png', '/content/tmp/traindataset/RGB/RGB_742.png', '/content/tmp/traindataset/RGB/RGB_750.png', '/content/tmp/traindataset/RGB/RGB_751.png', '/content/tmp/traindataset/RGB/RGB_752.png', '/content/tmp/traindataset/RGB/RGB_760.png', '/content/tmp/traindataset/RGB/RGB_761.png', '/content/tmp/traindataset/RGB/RGB_762.png', '/content/tmp/traindataset/RGB/RGB_770.png', '/content/tmp/traindataset/RGB/RGB_771.png', '/content/tmp/traindataset/RGB/RGB_772.png', '/content/tmp/traindataset/RGB/RGB_780.png', '/content/tmp/traindataset/RGB/RGB_781.png', '/content/tmp/traindataset/RGB/RGB_782.png', '/content/tmp/traindataset/RGB/RGB_790.png', '/content/tmp/traindataset/RGB/RGB_791.png', '/content/tmp/traindataset/RGB/RGB_792.png', '/content/tmp/traindataset/RGB/RGB_80.png', '/content/tmp/traindataset/RGB/RGB_81.png', '/content/tmp/traindataset/RGB/RGB_82.png', '/content/tmp/traindataset/RGB/RGB_90.png', '/content/tmp/traindataset/RGB/RGB_91.png', '/content/tmp/traindataset/RGB/RGB_92.png'] ['/content/tmp/traindataset/GT/GT_00.png', '/content/tmp/traindataset/GT/GT_01.png', '/content/tmp/traindataset/GT/GT_02.png', '/content/tmp/traindataset/GT/GT_10.png', '/content/tmp/traindataset/GT/GT_100.png', '/content/tmp/traindataset/GT/GT_101.png', '/content/tmp/traindataset/GT/GT_102.png', '/content/tmp/traindataset/GT/GT_11.png', '/content/tmp/traindataset/GT/GT_110.png', '/content/tmp/traindataset/GT/GT_111.png', '/content/tmp/traindataset/GT/GT_112.png', '/content/tmp/traindataset/GT/GT_12.png', '/content/tmp/traindataset/GT/GT_120.png', '/content/tmp/traindataset/GT/GT_121.png', '/content/tmp/traindataset/GT/GT_122.png', '/content/tmp/traindataset/GT/GT_130.png', '/content/tmp/traindataset/GT/GT_131.png', '/content/tmp/traindataset/GT/GT_132.png', '/content/tmp/traindataset/GT/GT_140.png', '/content/tmp/traindataset/GT/GT_141.png', '/content/tmp/traindataset/GT/GT_142.png', '/content/tmp/traindataset/GT/GT_150.png', '/content/tmp/traindataset/GT/GT_151.png', '/content/tmp/traindataset/GT/GT_152.png', '/content/tmp/traindataset/GT/GT_160.png', '/content/tmp/traindataset/GT/GT_161.png', '/content/tmp/traindataset/GT/GT_162.png', '/content/tmp/traindataset/GT/GT_170.png', '/content/tmp/traindataset/GT/GT_171.png', '/content/tmp/traindataset/GT/GT_172.png', '/content/tmp/traindataset/GT/GT_180.png', '/content/tmp/traindataset/GT/GT_181.png', '/content/tmp/traindataset/GT/GT_182.png', '/content/tmp/traindataset/GT/GT_190.png', '/content/tmp/traindataset/GT/GT_191.png', '/content/tmp/traindataset/GT/GT_192.png', '/content/tmp/traindataset/GT/GT_20.png', '/content/tmp/traindataset/GT/GT_200.png', '/content/tmp/traindataset/GT/GT_201.png', '/content/tmp/traindataset/GT/GT_202.png', '/content/tmp/traindataset/GT/GT_21.png', '/content/tmp/traindataset/GT/GT_210.png', '/content/tmp/traindataset/GT/GT_211.png', '/content/tmp/traindataset/GT/GT_212.png', '/content/tmp/traindataset/GT/GT_22.png', '/content/tmp/traindataset/GT/GT_220.png', '/content/tmp/traindataset/GT/GT_221.png', '/content/tmp/traindataset/GT/GT_222.png', '/content/tmp/traindataset/GT/GT_230.png', '/content/tmp/traindataset/GT/GT_231.png', '/content/tmp/traindataset/GT/GT_232.png', '/content/tmp/traindataset/GT/GT_240.png', '/content/tmp/traindataset/GT/GT_241.png', '/content/tmp/traindataset/GT/GT_242.png', '/content/tmp/traindataset/GT/GT_250.png', '/content/tmp/traindataset/GT/GT_251.png', '/content/tmp/traindataset/GT/GT_252.png', '/content/tmp/traindataset/GT/GT_260.png', '/content/tmp/traindataset/GT/GT_261.png', '/content/tmp/traindataset/GT/GT_262.png', '/content/tmp/traindataset/GT/GT_270.png', '/content/tmp/traindataset/GT/GT_271.png', '/content/tmp/traindataset/GT/GT_272.png', '/content/tmp/traindataset/GT/GT_280.png', '/content/tmp/traindataset/GT/GT_281.png', '/content/tmp/traindataset/GT/GT_282.png', '/content/tmp/traindataset/GT/GT_290.png', '/content/tmp/traindataset/GT/GT_291.png', '/content/tmp/traindataset/GT/GT_292.png', '/content/tmp/traindataset/GT/GT_30.png', '/content/tmp/traindataset/GT/GT_300.png', '/content/tmp/traindataset/GT/GT_301.png', '/content/tmp/traindataset/GT/GT_302.png', '/content/tmp/traindataset/GT/GT_31.png', '/content/tmp/traindataset/GT/GT_310.png', '/content/tmp/traindataset/GT/GT_311.png', '/content/tmp/traindataset/GT/GT_312.png', '/content/tmp/traindataset/GT/GT_32.png', '/content/tmp/traindataset/GT/GT_320.png', '/content/tmp/traindataset/GT/GT_321.png', '/content/tmp/traindataset/GT/GT_322.png', '/content/tmp/traindataset/GT/GT_330.png', '/content/tmp/traindataset/GT/GT_331.png', '/content/tmp/traindataset/GT/GT_332.png', '/content/tmp/traindataset/GT/GT_340.png', '/content/tmp/traindataset/GT/GT_341.png', '/content/tmp/traindataset/GT/GT_342.png', '/content/tmp/traindataset/GT/GT_350.png', '/content/tmp/traindataset/GT/GT_351.png', '/content/tmp/traindataset/GT/GT_352.png', '/content/tmp/traindataset/GT/GT_360.png', '/content/tmp/traindataset/GT/GT_361.png', '/content/tmp/traindataset/GT/GT_362.png', '/content/tmp/traindataset/GT/GT_370.png', '/content/tmp/traindataset/GT/GT_371.png', '/content/tmp/traindataset/GT/GT_372.png', '/content/tmp/traindataset/GT/GT_380.png', '/content/tmp/traindataset/GT/GT_381.png', '/content/tmp/traindataset/GT/GT_382.png', '/content/tmp/traindataset/GT/GT_390.png', '/content/tmp/traindataset/GT/GT_391.png', '/content/tmp/traindataset/GT/GT_392.png', '/content/tmp/traindataset/GT/GT_40.png', '/content/tmp/traindataset/GT/GT_400.png', '/content/tmp/traindataset/GT/GT_401.png', '/content/tmp/traindataset/GT/GT_402.png', '/content/tmp/traindataset/GT/GT_41.png', '/content/tmp/traindataset/GT/GT_410.png', '/content/tmp/traindataset/GT/GT_411.png', '/content/tmp/traindataset/GT/GT_412.png', '/content/tmp/traindataset/GT/GT_42.png', '/content/tmp/traindataset/GT/GT_420.png', '/content/tmp/traindataset/GT/GT_421.png', '/content/tmp/traindataset/GT/GT_422.png', '/content/tmp/traindataset/GT/GT_430.png', '/content/tmp/traindataset/GT/GT_431.png', '/content/tmp/traindataset/GT/GT_432.png', '/content/tmp/traindataset/GT/GT_440.png', '/content/tmp/traindataset/GT/GT_441.png', '/content/tmp/traindataset/GT/GT_442.png', '/content/tmp/traindataset/GT/GT_450.png', '/content/tmp/traindataset/GT/GT_451.png', '/content/tmp/traindataset/GT/GT_452.png', '/content/tmp/traindataset/GT/GT_460.png', '/content/tmp/traindataset/GT/GT_461.png', '/content/tmp/traindataset/GT/GT_462.png', '/content/tmp/traindataset/GT/GT_470.png', '/content/tmp/traindataset/GT/GT_471.png', '/content/tmp/traindataset/GT/GT_472.png', '/content/tmp/traindataset/GT/GT_480.png', '/content/tmp/traindataset/GT/GT_481.png', '/content/tmp/traindataset/GT/GT_482.png', '/content/tmp/traindataset/GT/GT_490.png', '/content/tmp/traindataset/GT/GT_491.png', '/content/tmp/traindataset/GT/GT_492.png', '/content/tmp/traindataset/GT/GT_50.png', '/content/tmp/traindataset/GT/GT_500.png', '/content/tmp/traindataset/GT/GT_501.png', '/content/tmp/traindataset/GT/GT_502.png', '/content/tmp/traindataset/GT/GT_51.png', '/content/tmp/traindataset/GT/GT_510.png', '/content/tmp/traindataset/GT/GT_511.png', '/content/tmp/traindataset/GT/GT_512.png', '/content/tmp/traindataset/GT/GT_52.png', '/content/tmp/traindataset/GT/GT_520.png', '/content/tmp/traindataset/GT/GT_521.png', '/content/tmp/traindataset/GT/GT_522.png', '/content/tmp/traindataset/GT/GT_530.png', '/content/tmp/traindataset/GT/GT_531.png', '/content/tmp/traindataset/GT/GT_532.png', '/content/tmp/traindataset/GT/GT_540.png', '/content/tmp/traindataset/GT/GT_541.png', '/content/tmp/traindataset/GT/GT_542.png', '/content/tmp/traindataset/GT/GT_550.png', '/content/tmp/traindataset/GT/GT_551.png', '/content/tmp/traindataset/GT/GT_552.png', '/content/tmp/traindataset/GT/GT_560.png', '/content/tmp/traindataset/GT/GT_561.png', '/content/tmp/traindataset/GT/GT_562.png', '/content/tmp/traindataset/GT/GT_570.png', '/content/tmp/traindataset/GT/GT_571.png', '/content/tmp/traindataset/GT/GT_572.png', '/content/tmp/traindataset/GT/GT_580.png', '/content/tmp/traindataset/GT/GT_581.png', '/content/tmp/traindataset/GT/GT_582.png', '/content/tmp/traindataset/GT/GT_590.png', '/content/tmp/traindataset/GT/GT_591.png', '/content/tmp/traindataset/GT/GT_592.png', '/content/tmp/traindataset/GT/GT_60.png', '/content/tmp/traindataset/GT/GT_600.png', '/content/tmp/traindataset/GT/GT_601.png', '/content/tmp/traindataset/GT/GT_602.png', '/content/tmp/traindataset/GT/GT_61.png', '/content/tmp/traindataset/GT/GT_610.png', '/content/tmp/traindataset/GT/GT_611.png', '/content/tmp/traindataset/GT/GT_612.png', '/content/tmp/traindataset/GT/GT_62.png', '/content/tmp/traindataset/GT/GT_620.png', '/content/tmp/traindataset/GT/GT_621.png', '/content/tmp/traindataset/GT/GT_622.png', '/content/tmp/traindataset/GT/GT_630.png', '/content/tmp/traindataset/GT/GT_631.png', '/content/tmp/traindataset/GT/GT_632.png', '/content/tmp/traindataset/GT/GT_640.png', '/content/tmp/traindataset/GT/GT_641.png', '/content/tmp/traindataset/GT/GT_642.png', '/content/tmp/traindataset/GT/GT_650.png', '/content/tmp/traindataset/GT/GT_651.png', '/content/tmp/traindataset/GT/GT_652.png', '/content/tmp/traindataset/GT/GT_660.png', '/content/tmp/traindataset/GT/GT_661.png', '/content/tmp/traindataset/GT/GT_662.png', '/content/tmp/traindataset/GT/GT_670.png', '/content/tmp/traindataset/GT/GT_671.png', '/content/tmp/traindataset/GT/GT_672.png', '/content/tmp/traindataset/GT/GT_680.png', '/content/tmp/traindataset/GT/GT_681.png', '/content/tmp/traindataset/GT/GT_682.png', '/content/tmp/traindataset/GT/GT_690.png', '/content/tmp/traindataset/GT/GT_691.png', '/content/tmp/traindataset/GT/GT_692.png', '/content/tmp/traindataset/GT/GT_70.png', '/content/tmp/traindataset/GT/GT_700.png', '/content/tmp/traindataset/GT/GT_701.png', '/content/tmp/traindataset/GT/GT_702.png', '/content/tmp/traindataset/GT/GT_71.png', '/content/tmp/traindataset/GT/GT_710.png', '/content/tmp/traindataset/GT/GT_711.png', '/content/tmp/traindataset/GT/GT_712.png', '/content/tmp/traindataset/GT/GT_72.png', '/content/tmp/traindataset/GT/GT_720.png', '/content/tmp/traindataset/GT/GT_721.png', '/content/tmp/traindataset/GT/GT_722.png', '/content/tmp/traindataset/GT/GT_730.png', '/content/tmp/traindataset/GT/GT_731.png', '/content/tmp/traindataset/GT/GT_732.png', '/content/tmp/traindataset/GT/GT_740.png', '/content/tmp/traindataset/GT/GT_741.png', '/content/tmp/traindataset/GT/GT_742.png', '/content/tmp/traindataset/GT/GT_750.png', '/content/tmp/traindataset/GT/GT_751.png', '/content/tmp/traindataset/GT/GT_752.png', '/content/tmp/traindataset/GT/GT_760.png', '/content/tmp/traindataset/GT/GT_761.png', '/content/tmp/traindataset/GT/GT_762.png', '/content/tmp/traindataset/GT/GT_770.png', '/content/tmp/traindataset/GT/GT_771.png', '/content/tmp/traindataset/GT/GT_772.png', '/content/tmp/traindataset/GT/GT_780.png', '/content/tmp/traindataset/GT/GT_781.png', '/content/tmp/traindataset/GT/GT_782.png', '/content/tmp/traindataset/GT/GT_790.png', '/content/tmp/traindataset/GT/GT_791.png', '/content/tmp/traindataset/GT/GT_792.png', '/content/tmp/traindataset/GT/GT_80.png', '/content/tmp/traindataset/GT/GT_81.png', '/content/tmp/traindataset/GT/GT_82.png', '/content/tmp/traindataset/GT/GT_90.png', '/content/tmp/traindataset/GT/GT_91.png', '/content/tmp/traindataset/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7f96c0130890>\n",
            "Start train...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-02 13:12:43.036650 Epoch [001/250], Step [0001/0060], Loss1: 0.4475 Loss2: 0.5678 Loss3: 0.7534\n",
            "2022-08-02 13:13:07.357374 Epoch [001/250], Step [0050/0060], Loss1: 0.1039 Loss2: 0.0892 Loss3: 0.0826\n",
            "2022-08-02 13:13:12.342167 Epoch [001/250], Step [0060/0060], Loss1: 0.1112 Loss2: 0.0917 Loss3: 0.0844\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 MAE: 0.05306897223705337 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-08-02 13:13:17.796786 Epoch [002/250], Step [0001/0060], Loss1: 0.1009 Loss2: 0.0889 Loss3: 0.0812\n",
            "2022-08-02 13:13:42.085481 Epoch [002/250], Step [0050/0060], Loss1: 0.0705 Loss2: 0.0706 Loss3: 0.0523\n",
            "2022-08-02 13:13:47.070802 Epoch [002/250], Step [0060/0060], Loss1: 0.0877 Loss2: 0.0774 Loss3: 0.0788\n",
            "Epoch: 2 MAE: 0.031030991839038 ####  bestMAE: 0.05306897223705337 bestEpoch: 0\n",
            "best epoch:2\n",
            "2022-08-02 13:13:54.529723 Epoch [003/250], Step [0001/0060], Loss1: 0.0752 Loss2: 0.0625 Loss3: 0.0515\n",
            "2022-08-02 13:14:19.010133 Epoch [003/250], Step [0050/0060], Loss1: 0.0701 Loss2: 0.0650 Loss3: 0.0558\n",
            "2022-08-02 13:14:23.973366 Epoch [003/250], Step [0060/0060], Loss1: 0.0602 Loss2: 0.0538 Loss3: 0.0461\n",
            "Epoch: 3 MAE: 0.03554722696306214 ####  bestMAE: 0.031030991839038 bestEpoch: 2\n",
            "2022-08-02 13:14:29.328324 Epoch [004/250], Step [0001/0060], Loss1: 0.0665 Loss2: 0.0525 Loss3: 0.0491\n",
            "2022-08-02 13:14:53.580532 Epoch [004/250], Step [0050/0060], Loss1: 0.0707 Loss2: 0.0698 Loss3: 0.0487\n",
            "2022-08-02 13:14:58.549817 Epoch [004/250], Step [0060/0060], Loss1: 0.0550 Loss2: 0.0540 Loss3: 0.0416\n",
            "Epoch: 4 MAE: 0.03627285506162378 ####  bestMAE: 0.031030991839038 bestEpoch: 2\n",
            "2022-08-02 13:15:03.988166 Epoch [005/250], Step [0001/0060], Loss1: 0.0577 Loss2: 0.0602 Loss3: 0.0453\n",
            "2022-08-02 13:15:28.195070 Epoch [005/250], Step [0050/0060], Loss1: 0.0597 Loss2: 0.0533 Loss3: 0.0468\n",
            "2022-08-02 13:15:33.139351 Epoch [005/250], Step [0060/0060], Loss1: 0.0555 Loss2: 0.0552 Loss3: 0.0409\n",
            "Epoch: 5 MAE: 0.024868016012959064 ####  bestMAE: 0.031030991839038 bestEpoch: 2\n",
            "best epoch:5\n",
            "2022-08-02 13:15:42.703915 Epoch [006/250], Step [0001/0060], Loss1: 0.0613 Loss2: 0.0670 Loss3: 0.0452\n",
            "2022-08-02 13:16:07.220123 Epoch [006/250], Step [0050/0060], Loss1: 0.0532 Loss2: 0.0466 Loss3: 0.0376\n",
            "2022-08-02 13:16:12.178045 Epoch [006/250], Step [0060/0060], Loss1: 0.0503 Loss2: 0.0456 Loss3: 0.0370\n",
            "Epoch: 6 MAE: 0.029239983711805608 ####  bestMAE: 0.024868016012959064 bestEpoch: 5\n",
            "2022-08-02 13:16:17.468865 Epoch [007/250], Step [0001/0060], Loss1: 0.0583 Loss2: 0.0552 Loss3: 0.0444\n",
            "2022-08-02 13:16:41.979310 Epoch [007/250], Step [0050/0060], Loss1: 0.0541 Loss2: 0.0496 Loss3: 0.0453\n",
            "2022-08-02 13:16:46.949010 Epoch [007/250], Step [0060/0060], Loss1: 0.0549 Loss2: 0.0565 Loss3: 0.0420\n",
            "Epoch: 7 MAE: 0.024619388275794567 ####  bestMAE: 0.024868016012959064 bestEpoch: 5\n",
            "best epoch:7\n",
            "2022-08-02 13:16:54.446352 Epoch [008/250], Step [0001/0060], Loss1: 0.0521 Loss2: 0.0480 Loss3: 0.0388\n",
            "2022-08-02 13:17:18.731242 Epoch [008/250], Step [0050/0060], Loss1: 0.0520 Loss2: 0.0490 Loss3: 0.0401\n",
            "2022-08-02 13:17:23.666167 Epoch [008/250], Step [0060/0060], Loss1: 0.0417 Loss2: 0.0379 Loss3: 0.0302\n",
            "Epoch: 8 MAE: 0.02636050320570431 ####  bestMAE: 0.024619388275794567 bestEpoch: 7\n",
            "2022-08-02 13:17:29.030918 Epoch [009/250], Step [0001/0060], Loss1: 0.0451 Loss2: 0.0432 Loss3: 0.0320\n",
            "2022-08-02 13:17:53.326738 Epoch [009/250], Step [0050/0060], Loss1: 0.0440 Loss2: 0.0442 Loss3: 0.0398\n",
            "2022-08-02 13:17:58.286737 Epoch [009/250], Step [0060/0060], Loss1: 0.0465 Loss2: 0.0448 Loss3: 0.0347\n",
            "Epoch: 9 MAE: 0.024593616347937358 ####  bestMAE: 0.024619388275794567 bestEpoch: 7\n",
            "best epoch:9\n",
            "2022-08-02 13:18:05.710285 Epoch [010/250], Step [0001/0060], Loss1: 0.0459 Loss2: 0.0492 Loss3: 0.0435\n",
            "2022-08-02 13:18:30.120654 Epoch [010/250], Step [0050/0060], Loss1: 0.0475 Loss2: 0.0436 Loss3: 0.0362\n",
            "2022-08-02 13:18:35.085062 Epoch [010/250], Step [0060/0060], Loss1: 0.0446 Loss2: 0.0425 Loss3: 0.0338\n",
            "Epoch: 10 MAE: 0.025394251052704122 ####  bestMAE: 0.024593616347937358 bestEpoch: 9\n",
            "2022-08-02 13:18:42.548448 Epoch [011/250], Step [0001/0060], Loss1: 0.0452 Loss2: 0.0408 Loss3: 0.0324\n",
            "2022-08-02 13:19:07.029465 Epoch [011/250], Step [0050/0060], Loss1: 0.0426 Loss2: 0.0401 Loss3: 0.0327\n",
            "2022-08-02 13:19:11.962407 Epoch [011/250], Step [0060/0060], Loss1: 0.0381 Loss2: 0.0389 Loss3: 0.0311\n",
            "Epoch: 11 MAE: 0.024386993712849088 ####  bestMAE: 0.024593616347937358 bestEpoch: 9\n",
            "best epoch:11\n",
            "2022-08-02 13:19:19.392300 Epoch [012/250], Step [0001/0060], Loss1: 0.0381 Loss2: 0.0400 Loss3: 0.0304\n",
            "2022-08-02 13:19:43.841581 Epoch [012/250], Step [0050/0060], Loss1: 0.0412 Loss2: 0.0416 Loss3: 0.0311\n",
            "2022-08-02 13:19:48.785522 Epoch [012/250], Step [0060/0060], Loss1: 0.0400 Loss2: 0.0384 Loss3: 0.0307\n",
            "Epoch: 12 MAE: 0.021233901292795225 ####  bestMAE: 0.024386993712849088 bestEpoch: 11\n",
            "best epoch:12\n",
            "2022-08-02 13:19:56.196869 Epoch [013/250], Step [0001/0060], Loss1: 0.0387 Loss2: 0.0349 Loss3: 0.0280\n",
            "2022-08-02 13:20:20.538847 Epoch [013/250], Step [0050/0060], Loss1: 0.0517 Loss2: 0.0363 Loss3: 0.0358\n",
            "2022-08-02 13:20:25.515667 Epoch [013/250], Step [0060/0060], Loss1: 0.0442 Loss2: 0.0384 Loss3: 0.0319\n",
            "Epoch: 13 MAE: 0.02493964517045589 ####  bestMAE: 0.021233901292795225 bestEpoch: 12\n",
            "2022-08-02 13:20:30.890379 Epoch [014/250], Step [0001/0060], Loss1: 0.0364 Loss2: 0.0346 Loss3: 0.0274\n",
            "2022-08-02 13:20:55.092595 Epoch [014/250], Step [0050/0060], Loss1: 0.0375 Loss2: 0.0354 Loss3: 0.0285\n",
            "2022-08-02 13:21:00.030273 Epoch [014/250], Step [0060/0060], Loss1: 0.0380 Loss2: 0.0366 Loss3: 0.0284\n",
            "Epoch: 14 MAE: 0.021610498738785584 ####  bestMAE: 0.021233901292795225 bestEpoch: 12\n",
            "2022-08-02 13:21:05.296548 Epoch [015/250], Step [0001/0060], Loss1: 0.0352 Loss2: 0.0387 Loss3: 0.0305\n",
            "2022-08-02 13:21:29.639160 Epoch [015/250], Step [0050/0060], Loss1: 0.0443 Loss2: 0.0398 Loss3: 0.0357\n",
            "2022-08-02 13:21:34.606418 Epoch [015/250], Step [0060/0060], Loss1: 0.0377 Loss2: 0.0379 Loss3: 0.0291\n",
            "Epoch: 15 MAE: 0.02191167354347214 ####  bestMAE: 0.021233901292795225 bestEpoch: 12\n",
            "2022-08-02 13:21:42.071592 Epoch [016/250], Step [0001/0060], Loss1: 0.0371 Loss2: 0.0372 Loss3: 0.0286\n",
            "2022-08-02 13:22:06.668548 Epoch [016/250], Step [0050/0060], Loss1: 0.0384 Loss2: 0.0372 Loss3: 0.0288\n",
            "2022-08-02 13:22:11.627345 Epoch [016/250], Step [0060/0060], Loss1: 0.0419 Loss2: 0.0390 Loss3: 0.0345\n",
            "Epoch: 16 MAE: 0.02038073180509465 ####  bestMAE: 0.021233901292795225 bestEpoch: 12\n",
            "best epoch:16\n",
            "2022-08-02 13:22:19.007160 Epoch [017/250], Step [0001/0060], Loss1: 0.0388 Loss2: 0.0391 Loss3: 0.0305\n",
            "2022-08-02 13:22:43.469504 Epoch [017/250], Step [0050/0060], Loss1: 0.0413 Loss2: 0.0362 Loss3: 0.0300\n",
            "2022-08-02 13:22:48.493575 Epoch [017/250], Step [0060/0060], Loss1: 0.0384 Loss2: 0.0325 Loss3: 0.0273\n",
            "Epoch: 17 MAE: 0.019449089299000445 ####  bestMAE: 0.02038073180509465 bestEpoch: 16\n",
            "best epoch:17\n",
            "2022-08-02 13:22:55.976301 Epoch [018/250], Step [0001/0060], Loss1: 0.0425 Loss2: 0.0403 Loss3: 0.0334\n",
            "2022-08-02 13:23:20.496331 Epoch [018/250], Step [0050/0060], Loss1: 0.0371 Loss2: 0.0327 Loss3: 0.0295\n",
            "2022-08-02 13:23:25.492507 Epoch [018/250], Step [0060/0060], Loss1: 0.0390 Loss2: 0.0362 Loss3: 0.0295\n",
            "Epoch: 18 MAE: 0.019062340909999514 ####  bestMAE: 0.019449089299000445 bestEpoch: 17\n",
            "best epoch:18\n",
            "2022-08-02 13:23:33.074250 Epoch [019/250], Step [0001/0060], Loss1: 0.0395 Loss2: 0.0366 Loss3: 0.0292\n",
            "2022-08-02 13:23:57.481645 Epoch [019/250], Step [0050/0060], Loss1: 0.0372 Loss2: 0.0361 Loss3: 0.0289\n",
            "2022-08-02 13:24:02.491510 Epoch [019/250], Step [0060/0060], Loss1: 0.0368 Loss2: 0.0341 Loss3: 0.0266\n",
            "Epoch: 19 MAE: 0.018519074663460727 ####  bestMAE: 0.019062340909999514 bestEpoch: 18\n",
            "best epoch:19\n",
            "2022-08-02 13:24:12.677719 Epoch [020/250], Step [0001/0060], Loss1: 0.0388 Loss2: 0.0359 Loss3: 0.0308\n",
            "2022-08-02 13:24:37.049429 Epoch [020/250], Step [0050/0060], Loss1: 0.0354 Loss2: 0.0343 Loss3: 0.0283\n",
            "2022-08-02 13:24:41.985982 Epoch [020/250], Step [0060/0060], Loss1: 0.0380 Loss2: 0.0355 Loss3: 0.0282\n",
            "Epoch: 20 MAE: 0.020487192249487318 ####  bestMAE: 0.018519074663460727 bestEpoch: 19\n",
            "2022-08-02 13:24:49.476838 Epoch [021/250], Step [0001/0060], Loss1: 0.0359 Loss2: 0.0324 Loss3: 0.0260\n",
            "2022-08-02 13:25:13.920126 Epoch [021/250], Step [0050/0060], Loss1: 0.0346 Loss2: 0.0327 Loss3: 0.0261\n",
            "2022-08-02 13:25:18.941931 Epoch [021/250], Step [0060/0060], Loss1: 0.0447 Loss2: 0.0376 Loss3: 0.0307\n",
            "Epoch: 21 MAE: 0.017456131536395303 ####  bestMAE: 0.018519074663460727 bestEpoch: 19\n",
            "best epoch:21\n",
            "2022-08-02 13:25:26.321661 Epoch [022/250], Step [0001/0060], Loss1: 0.0360 Loss2: 0.0345 Loss3: 0.0287\n",
            "2022-08-02 13:25:50.658092 Epoch [022/250], Step [0050/0060], Loss1: 0.0306 Loss2: 0.0325 Loss3: 0.0248\n",
            "2022-08-02 13:25:55.634838 Epoch [022/250], Step [0060/0060], Loss1: 0.0374 Loss2: 0.0322 Loss3: 0.0276\n",
            "Epoch: 22 MAE: 0.01628115422107161 ####  bestMAE: 0.017456131536395303 bestEpoch: 21\n",
            "best epoch:22\n",
            "2022-08-02 13:26:03.067563 Epoch [023/250], Step [0001/0060], Loss1: 0.0400 Loss2: 0.0359 Loss3: 0.0285\n",
            "2022-08-02 13:26:27.471207 Epoch [023/250], Step [0050/0060], Loss1: 0.0363 Loss2: 0.0355 Loss3: 0.0284\n",
            "2022-08-02 13:26:32.493222 Epoch [023/250], Step [0060/0060], Loss1: 0.0358 Loss2: 0.0363 Loss3: 0.0297\n",
            "Epoch: 23 MAE: 0.017568709735300333 ####  bestMAE: 0.01628115422107161 bestEpoch: 22\n",
            "2022-08-02 13:26:37.785725 Epoch [024/250], Step [0001/0060], Loss1: 0.0367 Loss2: 0.0359 Loss3: 0.0317\n",
            "2022-08-02 13:27:02.143685 Epoch [024/250], Step [0050/0060], Loss1: 0.0429 Loss2: 0.0385 Loss3: 0.0311\n",
            "2022-08-02 13:27:07.188677 Epoch [024/250], Step [0060/0060], Loss1: 0.0392 Loss2: 0.0325 Loss3: 0.0284\n",
            "Epoch: 24 MAE: 0.015753988265281633 ####  bestMAE: 0.01628115422107161 bestEpoch: 22\n",
            "best epoch:24\n",
            "2022-08-02 13:27:14.755411 Epoch [025/250], Step [0001/0060], Loss1: 0.0339 Loss2: 0.0343 Loss3: 0.0258\n",
            "2022-08-02 13:27:39.320951 Epoch [025/250], Step [0050/0060], Loss1: 0.0346 Loss2: 0.0322 Loss3: 0.0250\n",
            "2022-08-02 13:27:44.247250 Epoch [025/250], Step [0060/0060], Loss1: 0.0315 Loss2: 0.0345 Loss3: 0.0263\n",
            "Epoch: 25 MAE: 0.015807869408043133 ####  bestMAE: 0.015753988265281633 bestEpoch: 24\n",
            "2022-08-02 13:27:51.709055 Epoch [026/250], Step [0001/0060], Loss1: 0.0336 Loss2: 0.0299 Loss3: 0.0264\n",
            "2022-08-02 13:28:16.094743 Epoch [026/250], Step [0050/0060], Loss1: 0.0345 Loss2: 0.0346 Loss3: 0.0258\n",
            "2022-08-02 13:28:21.070704 Epoch [026/250], Step [0060/0060], Loss1: 0.0363 Loss2: 0.0334 Loss3: 0.0273\n",
            "Epoch: 26 MAE: 0.01648292275855229 ####  bestMAE: 0.015753988265281633 bestEpoch: 24\n",
            "2022-08-02 13:28:26.405261 Epoch [027/250], Step [0001/0060], Loss1: 0.0363 Loss2: 0.0346 Loss3: 0.0275\n",
            "2022-08-02 13:28:50.891378 Epoch [027/250], Step [0050/0060], Loss1: 0.0345 Loss2: 0.0346 Loss3: 0.0316\n",
            "2022-08-02 13:28:55.855819 Epoch [027/250], Step [0060/0060], Loss1: 0.0374 Loss2: 0.0332 Loss3: 0.0282\n",
            "Epoch: 27 MAE: 0.01610794619080566 ####  bestMAE: 0.015753988265281633 bestEpoch: 24\n",
            "2022-08-02 13:29:01.246531 Epoch [028/250], Step [0001/0060], Loss1: 0.0364 Loss2: 0.0348 Loss3: 0.0287\n",
            "2022-08-02 13:29:25.537410 Epoch [028/250], Step [0050/0060], Loss1: 0.0347 Loss2: 0.0324 Loss3: 0.0255\n",
            "2022-08-02 13:29:30.539240 Epoch [028/250], Step [0060/0060], Loss1: 0.0343 Loss2: 0.0340 Loss3: 0.0254\n",
            "Epoch: 28 MAE: 0.01717264497179597 ####  bestMAE: 0.015753988265281633 bestEpoch: 24\n",
            "2022-08-02 13:29:35.912937 Epoch [029/250], Step [0001/0060], Loss1: 0.0330 Loss2: 0.0332 Loss3: 0.0268\n",
            "2022-08-02 13:30:00.289311 Epoch [029/250], Step [0050/0060], Loss1: 0.0317 Loss2: 0.0315 Loss3: 0.0233\n",
            "2022-08-02 13:30:05.242470 Epoch [029/250], Step [0060/0060], Loss1: 0.0352 Loss2: 0.0339 Loss3: 0.0263\n",
            "Epoch: 29 MAE: 0.01730676412966753 ####  bestMAE: 0.015753988265281633 bestEpoch: 24\n",
            "2022-08-02 13:30:10.679834 Epoch [030/250], Step [0001/0060], Loss1: 0.0335 Loss2: 0.0327 Loss3: 0.0268\n",
            "2022-08-02 13:30:35.047479 Epoch [030/250], Step [0050/0060], Loss1: 0.0379 Loss2: 0.0346 Loss3: 0.0285\n",
            "2022-08-02 13:30:40.040653 Epoch [030/250], Step [0060/0060], Loss1: 0.0319 Loss2: 0.0300 Loss3: 0.0235\n",
            "Epoch: 30 MAE: 0.016910857742740995 ####  bestMAE: 0.015753988265281633 bestEpoch: 24\n",
            "2022-08-02 13:30:47.454019 Epoch [031/250], Step [0001/0060], Loss1: 0.0379 Loss2: 0.0308 Loss3: 0.0274\n",
            "2022-08-02 13:31:12.143899 Epoch [031/250], Step [0050/0060], Loss1: 0.0318 Loss2: 0.0303 Loss3: 0.0242\n",
            "2022-08-02 13:31:17.091366 Epoch [031/250], Step [0060/0060], Loss1: 0.0336 Loss2: 0.0319 Loss3: 0.0267\n",
            "Epoch: 31 MAE: 0.015296212545344754 ####  bestMAE: 0.015753988265281633 bestEpoch: 24\n",
            "best epoch:31\n",
            "2022-08-02 13:31:24.591628 Epoch [032/250], Step [0001/0060], Loss1: 0.0329 Loss2: 0.0293 Loss3: 0.0242\n",
            "2022-08-02 13:31:49.237378 Epoch [032/250], Step [0050/0060], Loss1: 0.0317 Loss2: 0.0324 Loss3: 0.0251\n",
            "2022-08-02 13:31:54.181203 Epoch [032/250], Step [0060/0060], Loss1: 0.0353 Loss2: 0.0301 Loss3: 0.0241\n",
            "Epoch: 32 MAE: 0.015768438880701386 ####  bestMAE: 0.015296212545344754 bestEpoch: 31\n",
            "2022-08-02 13:31:59.552844 Epoch [033/250], Step [0001/0060], Loss1: 0.0318 Loss2: 0.0319 Loss3: 0.0240\n",
            "2022-08-02 13:32:23.948139 Epoch [033/250], Step [0050/0060], Loss1: 0.0309 Loss2: 0.0323 Loss3: 0.0246\n",
            "2022-08-02 13:32:28.948285 Epoch [033/250], Step [0060/0060], Loss1: 0.0321 Loss2: 0.0288 Loss3: 0.0243\n",
            "Epoch: 33 MAE: 0.01664424306225209 ####  bestMAE: 0.015296212545344754 bestEpoch: 31\n",
            "2022-08-02 13:32:34.284977 Epoch [034/250], Step [0001/0060], Loss1: 0.0282 Loss2: 0.0264 Loss3: 0.0220\n",
            "2022-08-02 13:32:58.656140 Epoch [034/250], Step [0050/0060], Loss1: 0.0329 Loss2: 0.0300 Loss3: 0.0264\n",
            "2022-08-02 13:33:03.619018 Epoch [034/250], Step [0060/0060], Loss1: 0.0317 Loss2: 0.0308 Loss3: 0.0249\n",
            "Epoch: 34 MAE: 0.016055618708450643 ####  bestMAE: 0.015296212545344754 bestEpoch: 31\n",
            "2022-08-02 13:33:08.968222 Epoch [035/250], Step [0001/0060], Loss1: 0.0341 Loss2: 0.0310 Loss3: 0.0273\n",
            "2022-08-02 13:33:33.326447 Epoch [035/250], Step [0050/0060], Loss1: 0.0298 Loss2: 0.0301 Loss3: 0.0228\n",
            "2022-08-02 13:33:38.356382 Epoch [035/250], Step [0060/0060], Loss1: 0.0357 Loss2: 0.0310 Loss3: 0.0259\n",
            "Epoch: 35 MAE: 0.014168026465331279 ####  bestMAE: 0.015296212545344754 bestEpoch: 31\n",
            "best epoch:35\n",
            "2022-08-02 13:33:47.990481 Epoch [036/250], Step [0001/0060], Loss1: 0.0281 Loss2: 0.0303 Loss3: 0.0221\n",
            "2022-08-02 13:34:12.827017 Epoch [036/250], Step [0050/0060], Loss1: 0.0344 Loss2: 0.0315 Loss3: 0.0251\n",
            "2022-08-02 13:34:17.779514 Epoch [036/250], Step [0060/0060], Loss1: 0.0333 Loss2: 0.0330 Loss3: 0.0249\n",
            "Epoch: 36 MAE: 0.014044139778152817 ####  bestMAE: 0.014168026465331279 bestEpoch: 35\n",
            "best epoch:36\n",
            "2022-08-02 13:34:25.287253 Epoch [037/250], Step [0001/0060], Loss1: 0.0324 Loss2: 0.0323 Loss3: 0.0280\n",
            "2022-08-02 13:34:49.854901 Epoch [037/250], Step [0050/0060], Loss1: 0.0343 Loss2: 0.0342 Loss3: 0.0265\n",
            "2022-08-02 13:34:54.839340 Epoch [037/250], Step [0060/0060], Loss1: 0.0291 Loss2: 0.0280 Loss3: 0.0224\n",
            "Epoch: 37 MAE: 0.014557187024149158 ####  bestMAE: 0.014044139778152817 bestEpoch: 36\n",
            "2022-08-02 13:35:00.246253 Epoch [038/250], Step [0001/0060], Loss1: 0.0313 Loss2: 0.0298 Loss3: 0.0237\n",
            "2022-08-02 13:35:24.609012 Epoch [038/250], Step [0050/0060], Loss1: 0.0360 Loss2: 0.0314 Loss3: 0.0248\n",
            "2022-08-02 13:35:29.571826 Epoch [038/250], Step [0060/0060], Loss1: 0.0285 Loss2: 0.0315 Loss3: 0.0225\n",
            "Epoch: 38 MAE: 0.013225887458594073 ####  bestMAE: 0.014044139778152817 bestEpoch: 36\n",
            "best epoch:38\n",
            "2022-08-02 13:35:37.278622 Epoch [039/250], Step [0001/0060], Loss1: 0.0284 Loss2: 0.0293 Loss3: 0.0219\n",
            "2022-08-02 13:36:01.825171 Epoch [039/250], Step [0050/0060], Loss1: 0.0280 Loss2: 0.0279 Loss3: 0.0224\n",
            "2022-08-02 13:36:06.813939 Epoch [039/250], Step [0060/0060], Loss1: 0.0364 Loss2: 0.0346 Loss3: 0.0278\n",
            "Epoch: 39 MAE: 0.015424036450447544 ####  bestMAE: 0.013225887458594073 bestEpoch: 38\n",
            "2022-08-02 13:36:12.269239 Epoch [040/250], Step [0001/0060], Loss1: 0.0284 Loss2: 0.0310 Loss3: 0.0245\n",
            "2022-08-02 13:36:36.803664 Epoch [040/250], Step [0050/0060], Loss1: 0.0308 Loss2: 0.0264 Loss3: 0.0226\n",
            "2022-08-02 13:36:41.798659 Epoch [040/250], Step [0060/0060], Loss1: 0.0304 Loss2: 0.0276 Loss3: 0.0225\n",
            "Epoch: 40 MAE: 0.013950568934281668 ####  bestMAE: 0.013225887458594073 bestEpoch: 38\n",
            "2022-08-02 13:36:49.455792 Epoch [041/250], Step [0001/0060], Loss1: 0.0304 Loss2: 0.0295 Loss3: 0.0224\n",
            "2022-08-02 13:37:14.166073 Epoch [041/250], Step [0050/0060], Loss1: 0.0300 Loss2: 0.0292 Loss3: 0.0254\n",
            "2022-08-02 13:37:19.122355 Epoch [041/250], Step [0060/0060], Loss1: 0.0359 Loss2: 0.0291 Loss3: 0.0292\n",
            "Epoch: 41 MAE: 0.01161027822406992 ####  bestMAE: 0.013225887458594073 bestEpoch: 38\n",
            "best epoch:41\n",
            "2022-08-02 13:37:26.812996 Epoch [042/250], Step [0001/0060], Loss1: 0.0306 Loss2: 0.0309 Loss3: 0.0277\n",
            "2022-08-02 13:37:51.563757 Epoch [042/250], Step [0050/0060], Loss1: 0.0283 Loss2: 0.0286 Loss3: 0.0237\n",
            "2022-08-02 13:37:56.562513 Epoch [042/250], Step [0060/0060], Loss1: 0.0294 Loss2: 0.0292 Loss3: 0.0222\n",
            "Epoch: 42 MAE: 0.014371854275287617 ####  bestMAE: 0.01161027822406992 bestEpoch: 41\n",
            "2022-08-02 13:38:02.044341 Epoch [043/250], Step [0001/0060], Loss1: 0.0289 Loss2: 0.0288 Loss3: 0.0230\n",
            "2022-08-02 13:38:26.617555 Epoch [043/250], Step [0050/0060], Loss1: 0.0337 Loss2: 0.0329 Loss3: 0.0259\n",
            "2022-08-02 13:38:31.613991 Epoch [043/250], Step [0060/0060], Loss1: 0.0320 Loss2: 0.0322 Loss3: 0.0256\n",
            "Epoch: 43 MAE: 0.01342408015348372 ####  bestMAE: 0.01161027822406992 bestEpoch: 41\n",
            "2022-08-02 13:38:37.051142 Epoch [044/250], Step [0001/0060], Loss1: 0.0305 Loss2: 0.0296 Loss3: 0.0235\n",
            "2022-08-02 13:39:01.551884 Epoch [044/250], Step [0050/0060], Loss1: 0.0331 Loss2: 0.0315 Loss3: 0.0264\n",
            "2022-08-02 13:39:06.558005 Epoch [044/250], Step [0060/0060], Loss1: 0.0317 Loss2: 0.0314 Loss3: 0.0237\n",
            "Epoch: 44 MAE: 0.01179407424633465 ####  bestMAE: 0.01161027822406992 bestEpoch: 41\n",
            "2022-08-02 13:39:12.038978 Epoch [045/250], Step [0001/0060], Loss1: 0.0279 Loss2: 0.0276 Loss3: 0.0220\n",
            "2022-08-02 13:39:36.604383 Epoch [045/250], Step [0050/0060], Loss1: 0.0341 Loss2: 0.0334 Loss3: 0.0250\n",
            "2022-08-02 13:39:41.575920 Epoch [045/250], Step [0060/0060], Loss1: 0.0288 Loss2: 0.0286 Loss3: 0.0221\n",
            "Epoch: 45 MAE: 0.013096700370725658 ####  bestMAE: 0.01161027822406992 bestEpoch: 41\n",
            "2022-08-02 13:39:49.096926 Epoch [046/250], Step [0001/0060], Loss1: 0.0335 Loss2: 0.0310 Loss3: 0.0264\n",
            "2022-08-02 13:40:13.521006 Epoch [046/250], Step [0050/0060], Loss1: 0.0301 Loss2: 0.0290 Loss3: 0.0243\n",
            "2022-08-02 13:40:18.491141 Epoch [046/250], Step [0060/0060], Loss1: 0.0269 Loss2: 0.0284 Loss3: 0.0212\n",
            "Epoch: 46 MAE: 0.013759980429082162 ####  bestMAE: 0.01161027822406992 bestEpoch: 41\n",
            "2022-08-02 13:40:23.908821 Epoch [047/250], Step [0001/0060], Loss1: 0.0315 Loss2: 0.0299 Loss3: 0.0248\n",
            "2022-08-02 13:40:48.368998 Epoch [047/250], Step [0050/0060], Loss1: 0.0301 Loss2: 0.0284 Loss3: 0.0237\n",
            "2022-08-02 13:40:53.324901 Epoch [047/250], Step [0060/0060], Loss1: 0.0290 Loss2: 0.0320 Loss3: 0.0245\n",
            "Epoch: 47 MAE: 0.014777638624230075 ####  bestMAE: 0.01161027822406992 bestEpoch: 41\n",
            "2022-08-02 13:40:58.831504 Epoch [048/250], Step [0001/0060], Loss1: 0.0302 Loss2: 0.0272 Loss3: 0.0230\n",
            "2022-08-02 13:41:23.548878 Epoch [048/250], Step [0050/0060], Loss1: 0.0289 Loss2: 0.0288 Loss3: 0.0217\n",
            "2022-08-02 13:41:28.553536 Epoch [048/250], Step [0060/0060], Loss1: 0.0273 Loss2: 0.0286 Loss3: 0.0215\n",
            "Epoch: 48 MAE: 0.012228501798023306 ####  bestMAE: 0.01161027822406992 bestEpoch: 41\n",
            "2022-08-02 13:41:34.030970 Epoch [049/250], Step [0001/0060], Loss1: 0.0277 Loss2: 0.0275 Loss3: 0.0214\n",
            "2022-08-02 13:41:58.523958 Epoch [049/250], Step [0050/0060], Loss1: 0.0329 Loss2: 0.0287 Loss3: 0.0239\n",
            "2022-08-02 13:42:03.642921 Epoch [049/250], Step [0060/0060], Loss1: 0.0318 Loss2: 0.0325 Loss3: 0.0269\n",
            "Epoch: 49 MAE: 0.012924468913485133 ####  bestMAE: 0.01161027822406992 bestEpoch: 41\n",
            "2022-08-02 13:42:09.152491 Epoch [050/250], Step [0001/0060], Loss1: 0.0260 Loss2: 0.0283 Loss3: 0.0207\n",
            "2022-08-02 13:42:33.558918 Epoch [050/250], Step [0050/0060], Loss1: 0.0271 Loss2: 0.0260 Loss3: 0.0214\n",
            "2022-08-02 13:42:38.532841 Epoch [050/250], Step [0060/0060], Loss1: 0.0271 Loss2: 0.0318 Loss3: 0.0234\n",
            "Epoch: 50 MAE: 0.01389131708336728 ####  bestMAE: 0.01161027822406992 bestEpoch: 41\n",
            "2022-08-02 13:42:46.148853 Epoch [051/250], Step [0001/0060], Loss1: 0.0283 Loss2: 0.0287 Loss3: 0.0237\n",
            "2022-08-02 13:43:10.696357 Epoch [051/250], Step [0050/0060], Loss1: 0.0317 Loss2: 0.0293 Loss3: 0.0228\n",
            "2022-08-02 13:43:15.688773 Epoch [051/250], Step [0060/0060], Loss1: 0.0295 Loss2: 0.0294 Loss3: 0.0235\n",
            "Epoch: 51 MAE: 0.014452055614027712 ####  bestMAE: 0.01161027822406992 bestEpoch: 41\n",
            "2022-08-02 13:43:21.253134 Epoch [052/250], Step [0001/0060], Loss1: 0.0296 Loss2: 0.0286 Loss3: 0.0231\n",
            "2022-08-02 13:43:45.650324 Epoch [052/250], Step [0050/0060], Loss1: 0.0309 Loss2: 0.0273 Loss3: 0.0228\n",
            "2022-08-02 13:43:50.629069 Epoch [052/250], Step [0060/0060], Loss1: 0.0290 Loss2: 0.0292 Loss3: 0.0227\n",
            "Epoch: 52 MAE: 0.012875646360159393 ####  bestMAE: 0.01161027822406992 bestEpoch: 41\n",
            "2022-08-02 13:43:56.081060 Epoch [053/250], Step [0001/0060], Loss1: 0.0339 Loss2: 0.0312 Loss3: 0.0251\n",
            "2022-08-02 13:44:20.495246 Epoch [053/250], Step [0050/0060], Loss1: 0.0262 Loss2: 0.0312 Loss3: 0.0235\n",
            "2022-08-02 13:44:25.485356 Epoch [053/250], Step [0060/0060], Loss1: 0.0284 Loss2: 0.0299 Loss3: 0.0223\n",
            "Epoch: 53 MAE: 0.011698001833070838 ####  bestMAE: 0.01161027822406992 bestEpoch: 41\n",
            "2022-08-02 13:44:30.999209 Epoch [054/250], Step [0001/0060], Loss1: 0.0321 Loss2: 0.0334 Loss3: 0.0248\n",
            "2022-08-02 13:44:55.510976 Epoch [054/250], Step [0050/0060], Loss1: 0.0261 Loss2: 0.0283 Loss3: 0.0223\n",
            "2022-08-02 13:45:00.537145 Epoch [054/250], Step [0060/0060], Loss1: 0.0308 Loss2: 0.0354 Loss3: 0.0287\n",
            "Epoch: 54 MAE: 0.011401212382470332 ####  bestMAE: 0.01161027822406992 bestEpoch: 41\n",
            "best epoch:54\n",
            "2022-08-02 13:45:08.301524 Epoch [055/250], Step [0001/0060], Loss1: 0.0273 Loss2: 0.0282 Loss3: 0.0226\n",
            "2022-08-02 13:45:33.018570 Epoch [055/250], Step [0050/0060], Loss1: 0.0276 Loss2: 0.0259 Loss3: 0.0216\n",
            "2022-08-02 13:45:37.995093 Epoch [055/250], Step [0060/0060], Loss1: 0.0282 Loss2: 0.0286 Loss3: 0.0233\n",
            "Epoch: 55 MAE: 0.01256108723048653 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:45:45.556770 Epoch [056/250], Step [0001/0060], Loss1: 0.0290 Loss2: 0.0291 Loss3: 0.0231\n",
            "2022-08-02 13:46:10.042838 Epoch [056/250], Step [0050/0060], Loss1: 0.0318 Loss2: 0.0297 Loss3: 0.0246\n",
            "2022-08-02 13:46:15.000460 Epoch [056/250], Step [0060/0060], Loss1: 0.0279 Loss2: 0.0289 Loss3: 0.0235\n",
            "Epoch: 56 MAE: 0.012717162842847525 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:46:20.417249 Epoch [057/250], Step [0001/0060], Loss1: 0.0255 Loss2: 0.0282 Loss3: 0.0241\n",
            "2022-08-02 13:46:44.792428 Epoch [057/250], Step [0050/0060], Loss1: 0.0305 Loss2: 0.0266 Loss3: 0.0214\n",
            "2022-08-02 13:46:49.781318 Epoch [057/250], Step [0060/0060], Loss1: 0.0309 Loss2: 0.0276 Loss3: 0.0222\n",
            "Epoch: 57 MAE: 0.01263998859813289 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:46:55.200020 Epoch [058/250], Step [0001/0060], Loss1: 0.0303 Loss2: 0.0279 Loss3: 0.0217\n",
            "2022-08-02 13:47:19.616196 Epoch [058/250], Step [0050/0060], Loss1: 0.0282 Loss2: 0.0292 Loss3: 0.0225\n",
            "2022-08-02 13:47:24.598650 Epoch [058/250], Step [0060/0060], Loss1: 0.0257 Loss2: 0.0245 Loss3: 0.0204\n",
            "Epoch: 58 MAE: 0.013246128283854988 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:47:30.082084 Epoch [059/250], Step [0001/0060], Loss1: 0.0292 Loss2: 0.0279 Loss3: 0.0219\n",
            "2022-08-02 13:47:54.509682 Epoch [059/250], Step [0050/0060], Loss1: 0.0305 Loss2: 0.0291 Loss3: 0.0225\n",
            "2022-08-02 13:47:59.494417 Epoch [059/250], Step [0060/0060], Loss1: 0.0268 Loss2: 0.0259 Loss3: 0.0204\n",
            "Epoch: 59 MAE: 0.011476247371839625 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:48:04.958738 Epoch [060/250], Step [0001/0060], Loss1: 0.0280 Loss2: 0.0270 Loss3: 0.0217\n",
            "2022-08-02 13:48:29.279718 Epoch [060/250], Step [0050/0060], Loss1: 0.0245 Loss2: 0.0255 Loss3: 0.0192\n",
            "2022-08-02 13:48:34.233189 Epoch [060/250], Step [0060/0060], Loss1: 0.0271 Loss2: 0.0257 Loss3: 0.0209\n",
            "Epoch: 60 MAE: 0.012617241302948622 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:48:41.808145 Epoch [061/250], Step [0001/0060], Loss1: 0.0287 Loss2: 0.0274 Loss3: 0.0218\n",
            "2022-08-02 13:49:06.520026 Epoch [061/250], Step [0050/0060], Loss1: 0.0272 Loss2: 0.0274 Loss3: 0.0203\n",
            "2022-08-02 13:49:11.543418 Epoch [061/250], Step [0060/0060], Loss1: 0.0317 Loss2: 0.0301 Loss3: 0.0234\n",
            "Epoch: 61 MAE: 0.012184224379736753 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:49:16.917373 Epoch [062/250], Step [0001/0060], Loss1: 0.0261 Loss2: 0.0276 Loss3: 0.0203\n",
            "2022-08-02 13:49:41.335226 Epoch [062/250], Step [0050/0060], Loss1: 0.0248 Loss2: 0.0268 Loss3: 0.0199\n",
            "2022-08-02 13:49:46.320911 Epoch [062/250], Step [0060/0060], Loss1: 0.0280 Loss2: 0.0276 Loss3: 0.0209\n",
            "Epoch: 62 MAE: 0.012002663169470098 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:49:51.708724 Epoch [063/250], Step [0001/0060], Loss1: 0.0279 Loss2: 0.0267 Loss3: 0.0208\n",
            "2022-08-02 13:50:16.066068 Epoch [063/250], Step [0050/0060], Loss1: 0.0232 Loss2: 0.0256 Loss3: 0.0188\n",
            "2022-08-02 13:50:21.038672 Epoch [063/250], Step [0060/0060], Loss1: 0.0261 Loss2: 0.0252 Loss3: 0.0196\n",
            "Epoch: 63 MAE: 0.011993243957736663 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:50:26.363057 Epoch [064/250], Step [0001/0060], Loss1: 0.0258 Loss2: 0.0264 Loss3: 0.0200\n",
            "2022-08-02 13:50:50.746660 Epoch [064/250], Step [0050/0060], Loss1: 0.0298 Loss2: 0.0278 Loss3: 0.0216\n",
            "2022-08-02 13:50:55.684069 Epoch [064/250], Step [0060/0060], Loss1: 0.0270 Loss2: 0.0266 Loss3: 0.0204\n",
            "Epoch: 64 MAE: 0.012655916468550762 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:51:01.116896 Epoch [065/250], Step [0001/0060], Loss1: 0.0262 Loss2: 0.0288 Loss3: 0.0210\n",
            "2022-08-02 13:51:25.535078 Epoch [065/250], Step [0050/0060], Loss1: 0.0278 Loss2: 0.0284 Loss3: 0.0214\n",
            "2022-08-02 13:51:30.492547 Epoch [065/250], Step [0060/0060], Loss1: 0.0270 Loss2: 0.0267 Loss3: 0.0207\n",
            "Epoch: 65 MAE: 0.012066239683282754 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:51:37.846734 Epoch [066/250], Step [0001/0060], Loss1: 0.0301 Loss2: 0.0289 Loss3: 0.0222\n",
            "2022-08-02 13:52:02.306640 Epoch [066/250], Step [0050/0060], Loss1: 0.0261 Loss2: 0.0263 Loss3: 0.0202\n",
            "2022-08-02 13:52:07.265628 Epoch [066/250], Step [0060/0060], Loss1: 0.0311 Loss2: 0.0295 Loss3: 0.0226\n",
            "Epoch: 66 MAE: 0.012212466182453292 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:52:12.590118 Epoch [067/250], Step [0001/0060], Loss1: 0.0289 Loss2: 0.0296 Loss3: 0.0220\n",
            "2022-08-02 13:52:37.013160 Epoch [067/250], Step [0050/0060], Loss1: 0.0265 Loss2: 0.0263 Loss3: 0.0199\n",
            "2022-08-02 13:52:41.965270 Epoch [067/250], Step [0060/0060], Loss1: 0.0258 Loss2: 0.0261 Loss3: 0.0204\n",
            "Epoch: 67 MAE: 0.012462245389109566 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:52:47.490680 Epoch [068/250], Step [0001/0060], Loss1: 0.0309 Loss2: 0.0293 Loss3: 0.0227\n",
            "2022-08-02 13:53:11.923815 Epoch [068/250], Step [0050/0060], Loss1: 0.0268 Loss2: 0.0243 Loss3: 0.0196\n",
            "2022-08-02 13:53:16.891322 Epoch [068/250], Step [0060/0060], Loss1: 0.0278 Loss2: 0.0268 Loss3: 0.0211\n",
            "Epoch: 68 MAE: 0.01249209829857425 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:53:22.270982 Epoch [069/250], Step [0001/0060], Loss1: 0.0282 Loss2: 0.0280 Loss3: 0.0213\n",
            "2022-08-02 13:53:46.590776 Epoch [069/250], Step [0050/0060], Loss1: 0.0266 Loss2: 0.0271 Loss3: 0.0205\n",
            "2022-08-02 13:53:51.542693 Epoch [069/250], Step [0060/0060], Loss1: 0.0283 Loss2: 0.0292 Loss3: 0.0217\n",
            "Epoch: 69 MAE: 0.012268445121922664 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:53:56.954583 Epoch [070/250], Step [0001/0060], Loss1: 0.0295 Loss2: 0.0283 Loss3: 0.0217\n",
            "2022-08-02 13:54:21.491580 Epoch [070/250], Step [0050/0060], Loss1: 0.0252 Loss2: 0.0286 Loss3: 0.0207\n",
            "2022-08-02 13:54:26.494168 Epoch [070/250], Step [0060/0060], Loss1: 0.0292 Loss2: 0.0260 Loss3: 0.0212\n",
            "Epoch: 70 MAE: 0.011894862788418928 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:54:33.958488 Epoch [071/250], Step [0001/0060], Loss1: 0.0295 Loss2: 0.0289 Loss3: 0.0224\n",
            "2022-08-02 13:54:58.448304 Epoch [071/250], Step [0050/0060], Loss1: 0.0239 Loss2: 0.0267 Loss3: 0.0198\n",
            "2022-08-02 13:55:03.412151 Epoch [071/250], Step [0060/0060], Loss1: 0.0279 Loss2: 0.0264 Loss3: 0.0204\n",
            "Epoch: 71 MAE: 0.012290424046417078 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:55:08.760774 Epoch [072/250], Step [0001/0060], Loss1: 0.0295 Loss2: 0.0280 Loss3: 0.0222\n",
            "2022-08-02 13:55:33.080750 Epoch [072/250], Step [0050/0060], Loss1: 0.0268 Loss2: 0.0255 Loss3: 0.0200\n",
            "2022-08-02 13:55:38.072877 Epoch [072/250], Step [0060/0060], Loss1: 0.0244 Loss2: 0.0266 Loss3: 0.0199\n",
            "Epoch: 72 MAE: 0.012312948533762542 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:55:43.450462 Epoch [073/250], Step [0001/0060], Loss1: 0.0277 Loss2: 0.0290 Loss3: 0.0213\n",
            "2022-08-02 13:56:07.963154 Epoch [073/250], Step [0050/0060], Loss1: 0.0281 Loss2: 0.0287 Loss3: 0.0213\n",
            "2022-08-02 13:56:12.946107 Epoch [073/250], Step [0060/0060], Loss1: 0.0294 Loss2: 0.0289 Loss3: 0.0216\n",
            "Epoch: 73 MAE: 0.012100797715700336 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:56:18.255341 Epoch [074/250], Step [0001/0060], Loss1: 0.0288 Loss2: 0.0270 Loss3: 0.0211\n",
            "2022-08-02 13:56:42.667388 Epoch [074/250], Step [0050/0060], Loss1: 0.0293 Loss2: 0.0302 Loss3: 0.0223\n",
            "2022-08-02 13:56:47.669812 Epoch [074/250], Step [0060/0060], Loss1: 0.0280 Loss2: 0.0272 Loss3: 0.0211\n",
            "Epoch: 74 MAE: 0.01203744432016734 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:56:53.090557 Epoch [075/250], Step [0001/0060], Loss1: 0.0264 Loss2: 0.0258 Loss3: 0.0202\n",
            "2022-08-02 13:57:17.564874 Epoch [075/250], Step [0050/0060], Loss1: 0.0265 Loss2: 0.0283 Loss3: 0.0206\n",
            "2022-08-02 13:57:22.514318 Epoch [075/250], Step [0060/0060], Loss1: 0.0279 Loss2: 0.0284 Loss3: 0.0218\n",
            "Epoch: 75 MAE: 0.011629816152096267 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:57:30.112239 Epoch [076/250], Step [0001/0060], Loss1: 0.0237 Loss2: 0.0265 Loss3: 0.0193\n",
            "2022-08-02 13:57:54.606577 Epoch [076/250], Step [0050/0060], Loss1: 0.0265 Loss2: 0.0263 Loss3: 0.0199\n",
            "2022-08-02 13:57:59.564037 Epoch [076/250], Step [0060/0060], Loss1: 0.0286 Loss2: 0.0290 Loss3: 0.0218\n",
            "Epoch: 76 MAE: 0.0120179880528696 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:58:05.079487 Epoch [077/250], Step [0001/0060], Loss1: 0.0292 Loss2: 0.0289 Loss3: 0.0219\n",
            "2022-08-02 13:58:29.556090 Epoch [077/250], Step [0050/0060], Loss1: 0.0276 Loss2: 0.0286 Loss3: 0.0210\n",
            "2022-08-02 13:58:34.549433 Epoch [077/250], Step [0060/0060], Loss1: 0.0283 Loss2: 0.0297 Loss3: 0.0222\n",
            "Epoch: 77 MAE: 0.012037080062168932 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:58:39.983185 Epoch [078/250], Step [0001/0060], Loss1: 0.0226 Loss2: 0.0242 Loss3: 0.0186\n",
            "2022-08-02 13:59:04.492677 Epoch [078/250], Step [0050/0060], Loss1: 0.0272 Loss2: 0.0275 Loss3: 0.0212\n",
            "2022-08-02 13:59:09.446875 Epoch [078/250], Step [0060/0060], Loss1: 0.0269 Loss2: 0.0246 Loss3: 0.0196\n",
            "Epoch: 78 MAE: 0.011852161973596566 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:59:14.833221 Epoch [079/250], Step [0001/0060], Loss1: 0.0283 Loss2: 0.0297 Loss3: 0.0223\n",
            "2022-08-02 13:59:39.226419 Epoch [079/250], Step [0050/0060], Loss1: 0.0295 Loss2: 0.0273 Loss3: 0.0218\n",
            "2022-08-02 13:59:44.181709 Epoch [079/250], Step [0060/0060], Loss1: 0.0260 Loss2: 0.0253 Loss3: 0.0196\n",
            "Epoch: 79 MAE: 0.01223682284000374 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 13:59:49.595290 Epoch [080/250], Step [0001/0060], Loss1: 0.0257 Loss2: 0.0251 Loss3: 0.0193\n",
            "2022-08-02 14:00:13.962590 Epoch [080/250], Step [0050/0060], Loss1: 0.0236 Loss2: 0.0245 Loss3: 0.0186\n",
            "2022-08-02 14:00:18.931142 Epoch [080/250], Step [0060/0060], Loss1: 0.0256 Loss2: 0.0260 Loss3: 0.0197\n",
            "Epoch: 80 MAE: 0.011940129249105378 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:00:26.462957 Epoch [081/250], Step [0001/0060], Loss1: 0.0229 Loss2: 0.0247 Loss3: 0.0189\n",
            "2022-08-02 14:00:51.136183 Epoch [081/250], Step [0050/0060], Loss1: 0.0287 Loss2: 0.0280 Loss3: 0.0215\n",
            "2022-08-02 14:00:56.120985 Epoch [081/250], Step [0060/0060], Loss1: 0.0252 Loss2: 0.0268 Loss3: 0.0201\n",
            "Epoch: 81 MAE: 0.012156691720029192 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:01:01.546382 Epoch [082/250], Step [0001/0060], Loss1: 0.0257 Loss2: 0.0272 Loss3: 0.0204\n",
            "2022-08-02 14:01:25.972706 Epoch [082/250], Step [0050/0060], Loss1: 0.0314 Loss2: 0.0288 Loss3: 0.0231\n",
            "2022-08-02 14:01:30.931793 Epoch [082/250], Step [0060/0060], Loss1: 0.0256 Loss2: 0.0251 Loss3: 0.0196\n",
            "Epoch: 82 MAE: 0.011925740507505243 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:01:36.335853 Epoch [083/250], Step [0001/0060], Loss1: 0.0243 Loss2: 0.0266 Loss3: 0.0197\n",
            "2022-08-02 14:02:00.669144 Epoch [083/250], Step [0050/0060], Loss1: 0.0278 Loss2: 0.0283 Loss3: 0.0215\n",
            "2022-08-02 14:02:05.661786 Epoch [083/250], Step [0060/0060], Loss1: 0.0242 Loss2: 0.0249 Loss3: 0.0190\n",
            "Epoch: 83 MAE: 0.011925091819157676 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:02:11.107153 Epoch [084/250], Step [0001/0060], Loss1: 0.0243 Loss2: 0.0254 Loss3: 0.0194\n",
            "2022-08-02 14:02:35.645567 Epoch [084/250], Step [0050/0060], Loss1: 0.0239 Loss2: 0.0248 Loss3: 0.0189\n",
            "2022-08-02 14:02:40.601046 Epoch [084/250], Step [0060/0060], Loss1: 0.0238 Loss2: 0.0256 Loss3: 0.0188\n",
            "Epoch: 84 MAE: 0.012055004473834757 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:02:45.958541 Epoch [085/250], Step [0001/0060], Loss1: 0.0256 Loss2: 0.0255 Loss3: 0.0199\n",
            "2022-08-02 14:03:10.472472 Epoch [085/250], Step [0050/0060], Loss1: 0.0274 Loss2: 0.0265 Loss3: 0.0203\n",
            "2022-08-02 14:03:15.472116 Epoch [085/250], Step [0060/0060], Loss1: 0.0290 Loss2: 0.0287 Loss3: 0.0219\n",
            "Epoch: 85 MAE: 0.012400786872834914 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:03:22.993863 Epoch [086/250], Step [0001/0060], Loss1: 0.0283 Loss2: 0.0280 Loss3: 0.0209\n",
            "2022-08-02 14:03:47.537579 Epoch [086/250], Step [0050/0060], Loss1: 0.0239 Loss2: 0.0254 Loss3: 0.0188\n",
            "2022-08-02 14:03:52.567049 Epoch [086/250], Step [0060/0060], Loss1: 0.0293 Loss2: 0.0305 Loss3: 0.0225\n",
            "Epoch: 86 MAE: 0.012323819647824008 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:03:57.942068 Epoch [087/250], Step [0001/0060], Loss1: 0.0249 Loss2: 0.0270 Loss3: 0.0201\n",
            "2022-08-02 14:04:22.274156 Epoch [087/250], Step [0050/0060], Loss1: 0.0267 Loss2: 0.0288 Loss3: 0.0211\n",
            "2022-08-02 14:04:27.232747 Epoch [087/250], Step [0060/0060], Loss1: 0.0294 Loss2: 0.0275 Loss3: 0.0212\n",
            "Epoch: 87 MAE: 0.012307623053886114 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:04:32.658941 Epoch [088/250], Step [0001/0060], Loss1: 0.0242 Loss2: 0.0241 Loss3: 0.0188\n",
            "2022-08-02 14:04:56.962658 Epoch [088/250], Step [0050/0060], Loss1: 0.0279 Loss2: 0.0282 Loss3: 0.0218\n",
            "2022-08-02 14:05:01.928804 Epoch [088/250], Step [0060/0060], Loss1: 0.0238 Loss2: 0.0251 Loss3: 0.0189\n",
            "Epoch: 88 MAE: 0.011863386679795525 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:05:07.288183 Epoch [089/250], Step [0001/0060], Loss1: 0.0274 Loss2: 0.0285 Loss3: 0.0211\n",
            "2022-08-02 14:05:31.641801 Epoch [089/250], Step [0050/0060], Loss1: 0.0227 Loss2: 0.0251 Loss3: 0.0187\n",
            "2022-08-02 14:05:36.584472 Epoch [089/250], Step [0060/0060], Loss1: 0.0268 Loss2: 0.0266 Loss3: 0.0203\n",
            "Epoch: 89 MAE: 0.011891833706093686 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:05:42.009933 Epoch [090/250], Step [0001/0060], Loss1: 0.0241 Loss2: 0.0251 Loss3: 0.0191\n",
            "2022-08-02 14:06:06.475642 Epoch [090/250], Step [0050/0060], Loss1: 0.0276 Loss2: 0.0265 Loss3: 0.0209\n",
            "2022-08-02 14:06:11.500596 Epoch [090/250], Step [0060/0060], Loss1: 0.0239 Loss2: 0.0257 Loss3: 0.0194\n",
            "Epoch: 90 MAE: 0.011936995622125409 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:06:19.018402 Epoch [091/250], Step [0001/0060], Loss1: 0.0232 Loss2: 0.0252 Loss3: 0.0191\n",
            "2022-08-02 14:06:43.757781 Epoch [091/250], Step [0050/0060], Loss1: 0.0273 Loss2: 0.0267 Loss3: 0.0208\n",
            "2022-08-02 14:06:48.766599 Epoch [091/250], Step [0060/0060], Loss1: 0.0243 Loss2: 0.0262 Loss3: 0.0192\n",
            "Epoch: 91 MAE: 0.01194178523673188 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:06:54.062513 Epoch [092/250], Step [0001/0060], Loss1: 0.0241 Loss2: 0.0248 Loss3: 0.0185\n",
            "2022-08-02 14:07:18.496181 Epoch [092/250], Step [0050/0060], Loss1: 0.0255 Loss2: 0.0261 Loss3: 0.0198\n",
            "2022-08-02 14:07:23.444966 Epoch [092/250], Step [0060/0060], Loss1: 0.0272 Loss2: 0.0262 Loss3: 0.0204\n",
            "Epoch: 92 MAE: 0.012115438424405597 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:07:28.875404 Epoch [093/250], Step [0001/0060], Loss1: 0.0255 Loss2: 0.0263 Loss3: 0.0199\n",
            "2022-08-02 14:07:53.437988 Epoch [093/250], Step [0050/0060], Loss1: 0.0266 Loss2: 0.0264 Loss3: 0.0200\n",
            "2022-08-02 14:07:58.399563 Epoch [093/250], Step [0060/0060], Loss1: 0.0246 Loss2: 0.0251 Loss3: 0.0192\n",
            "Epoch: 93 MAE: 0.011944602080990397 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:08:03.745993 Epoch [094/250], Step [0001/0060], Loss1: 0.0243 Loss2: 0.0248 Loss3: 0.0199\n",
            "2022-08-02 14:08:28.137656 Epoch [094/250], Step [0050/0060], Loss1: 0.0275 Loss2: 0.0279 Loss3: 0.0212\n",
            "2022-08-02 14:08:33.108431 Epoch [094/250], Step [0060/0060], Loss1: 0.0260 Loss2: 0.0252 Loss3: 0.0198\n",
            "Epoch: 94 MAE: 0.012259613389947585 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:08:38.502539 Epoch [095/250], Step [0001/0060], Loss1: 0.0272 Loss2: 0.0248 Loss3: 0.0198\n",
            "2022-08-02 14:09:02.979784 Epoch [095/250], Step [0050/0060], Loss1: 0.0288 Loss2: 0.0300 Loss3: 0.0225\n",
            "2022-08-02 14:09:07.951333 Epoch [095/250], Step [0060/0060], Loss1: 0.0266 Loss2: 0.0255 Loss3: 0.0200\n",
            "Epoch: 95 MAE: 0.011822098053045689 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:09:15.389894 Epoch [096/250], Step [0001/0060], Loss1: 0.0285 Loss2: 0.0281 Loss3: 0.0216\n",
            "2022-08-02 14:09:39.926109 Epoch [096/250], Step [0050/0060], Loss1: 0.0239 Loss2: 0.0256 Loss3: 0.0191\n",
            "2022-08-02 14:09:44.917857 Epoch [096/250], Step [0060/0060], Loss1: 0.0268 Loss2: 0.0244 Loss3: 0.0195\n",
            "Epoch: 96 MAE: 0.012108310517514981 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:09:50.294056 Epoch [097/250], Step [0001/0060], Loss1: 0.0261 Loss2: 0.0273 Loss3: 0.0204\n",
            "2022-08-02 14:10:14.659145 Epoch [097/250], Step [0050/0060], Loss1: 0.0252 Loss2: 0.0255 Loss3: 0.0194\n",
            "2022-08-02 14:10:19.619028 Epoch [097/250], Step [0060/0060], Loss1: 0.0249 Loss2: 0.0281 Loss3: 0.0207\n",
            "Epoch: 97 MAE: 0.012378983480471468 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:10:25.080999 Epoch [098/250], Step [0001/0060], Loss1: 0.0272 Loss2: 0.0281 Loss3: 0.0214\n",
            "2022-08-02 14:10:49.459829 Epoch [098/250], Step [0050/0060], Loss1: 0.0267 Loss2: 0.0291 Loss3: 0.0212\n",
            "2022-08-02 14:10:54.454048 Epoch [098/250], Step [0060/0060], Loss1: 0.0254 Loss2: 0.0264 Loss3: 0.0199\n",
            "Epoch: 98 MAE: 0.012180738328468232 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:10:59.990039 Epoch [099/250], Step [0001/0060], Loss1: 0.0276 Loss2: 0.0285 Loss3: 0.0210\n",
            "2022-08-02 14:11:24.278977 Epoch [099/250], Step [0050/0060], Loss1: 0.0279 Loss2: 0.0285 Loss3: 0.0216\n",
            "2022-08-02 14:11:29.232411 Epoch [099/250], Step [0060/0060], Loss1: 0.0267 Loss2: 0.0278 Loss3: 0.0209\n",
            "Epoch: 99 MAE: 0.012312924969823115 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:11:34.621202 Epoch [100/250], Step [0001/0060], Loss1: 0.0278 Loss2: 0.0280 Loss3: 0.0213\n",
            "2022-08-02 14:11:59.020845 Epoch [100/250], Step [0050/0060], Loss1: 0.0264 Loss2: 0.0301 Loss3: 0.0212\n",
            "2022-08-02 14:12:04.073227 Epoch [100/250], Step [0060/0060], Loss1: 0.0270 Loss2: 0.0269 Loss3: 0.0202\n",
            "Epoch: 100 MAE: 0.01196747792825576 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:12:11.652474 Epoch [101/250], Step [0001/0060], Loss1: 0.0256 Loss2: 0.0259 Loss3: 0.0198\n",
            "2022-08-02 14:12:36.193550 Epoch [101/250], Step [0050/0060], Loss1: 0.0243 Loss2: 0.0244 Loss3: 0.0185\n",
            "2022-08-02 14:12:41.149267 Epoch [101/250], Step [0060/0060], Loss1: 0.0246 Loss2: 0.0289 Loss3: 0.0204\n",
            "Epoch: 101 MAE: 0.01202352030114049 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:12:46.507951 Epoch [102/250], Step [0001/0060], Loss1: 0.0271 Loss2: 0.0293 Loss3: 0.0217\n",
            "2022-08-02 14:13:10.875684 Epoch [102/250], Step [0050/0060], Loss1: 0.0288 Loss2: 0.0278 Loss3: 0.0217\n",
            "2022-08-02 14:13:15.835007 Epoch [102/250], Step [0060/0060], Loss1: 0.0238 Loss2: 0.0257 Loss3: 0.0195\n",
            "Epoch: 102 MAE: 0.012465488394751909 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:13:21.115182 Epoch [103/250], Step [0001/0060], Loss1: 0.0290 Loss2: 0.0297 Loss3: 0.0224\n",
            "2022-08-02 14:13:45.545271 Epoch [103/250], Step [0050/0060], Loss1: 0.0260 Loss2: 0.0283 Loss3: 0.0207\n",
            "2022-08-02 14:13:50.532359 Epoch [103/250], Step [0060/0060], Loss1: 0.0247 Loss2: 0.0284 Loss3: 0.0201\n",
            "Epoch: 103 MAE: 0.012460450663985241 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:13:55.945735 Epoch [104/250], Step [0001/0060], Loss1: 0.0284 Loss2: 0.0261 Loss3: 0.0206\n",
            "2022-08-02 14:14:20.464411 Epoch [104/250], Step [0050/0060], Loss1: 0.0266 Loss2: 0.0268 Loss3: 0.0205\n",
            "2022-08-02 14:14:25.451146 Epoch [104/250], Step [0060/0060], Loss1: 0.0247 Loss2: 0.0264 Loss3: 0.0197\n",
            "Epoch: 104 MAE: 0.011724806893321256 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:14:30.830900 Epoch [105/250], Step [0001/0060], Loss1: 0.0254 Loss2: 0.0246 Loss3: 0.0192\n",
            "2022-08-02 14:14:55.194798 Epoch [105/250], Step [0050/0060], Loss1: 0.0263 Loss2: 0.0248 Loss3: 0.0198\n",
            "2022-08-02 14:15:00.172447 Epoch [105/250], Step [0060/0060], Loss1: 0.0319 Loss2: 0.0287 Loss3: 0.0229\n",
            "Epoch: 105 MAE: 0.011910811295762422 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:15:07.663564 Epoch [106/250], Step [0001/0060], Loss1: 0.0234 Loss2: 0.0251 Loss3: 0.0190\n",
            "2022-08-02 14:15:32.213592 Epoch [106/250], Step [0050/0060], Loss1: 0.0248 Loss2: 0.0265 Loss3: 0.0201\n",
            "2022-08-02 14:15:37.214057 Epoch [106/250], Step [0060/0060], Loss1: 0.0251 Loss2: 0.0271 Loss3: 0.0205\n",
            "Epoch: 106 MAE: 0.011615272071803845 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:15:42.568038 Epoch [107/250], Step [0001/0060], Loss1: 0.0276 Loss2: 0.0287 Loss3: 0.0214\n",
            "2022-08-02 14:16:07.081262 Epoch [107/250], Step [0050/0060], Loss1: 0.0282 Loss2: 0.0266 Loss3: 0.0208\n",
            "2022-08-02 14:16:12.098662 Epoch [107/250], Step [0060/0060], Loss1: 0.0310 Loss2: 0.0317 Loss3: 0.0241\n",
            "Epoch: 107 MAE: 0.011608249766545163 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:16:17.501651 Epoch [108/250], Step [0001/0060], Loss1: 0.0298 Loss2: 0.0291 Loss3: 0.0222\n",
            "2022-08-02 14:16:41.878312 Epoch [108/250], Step [0050/0060], Loss1: 0.0230 Loss2: 0.0262 Loss3: 0.0190\n",
            "2022-08-02 14:16:46.843658 Epoch [108/250], Step [0060/0060], Loss1: 0.0227 Loss2: 0.0233 Loss3: 0.0180\n",
            "Epoch: 108 MAE: 0.011674222004200732 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:16:52.331907 Epoch [109/250], Step [0001/0060], Loss1: 0.0248 Loss2: 0.0254 Loss3: 0.0197\n",
            "2022-08-02 14:17:16.666982 Epoch [109/250], Step [0050/0060], Loss1: 0.0247 Loss2: 0.0247 Loss3: 0.0198\n",
            "2022-08-02 14:17:21.617674 Epoch [109/250], Step [0060/0060], Loss1: 0.0275 Loss2: 0.0296 Loss3: 0.0218\n",
            "Epoch: 109 MAE: 0.01193019197071119 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:17:26.998344 Epoch [110/250], Step [0001/0060], Loss1: 0.0264 Loss2: 0.0260 Loss3: 0.0199\n",
            "2022-08-02 14:17:51.352635 Epoch [110/250], Step [0050/0060], Loss1: 0.0260 Loss2: 0.0264 Loss3: 0.0199\n",
            "2022-08-02 14:17:56.325618 Epoch [110/250], Step [0060/0060], Loss1: 0.0263 Loss2: 0.0256 Loss3: 0.0199\n",
            "Epoch: 110 MAE: 0.012102768867320958 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:18:03.890897 Epoch [111/250], Step [0001/0060], Loss1: 0.0256 Loss2: 0.0277 Loss3: 0.0202\n",
            "2022-08-02 14:18:28.516848 Epoch [111/250], Step [0050/0060], Loss1: 0.0245 Loss2: 0.0285 Loss3: 0.0202\n",
            "2022-08-02 14:18:33.497843 Epoch [111/250], Step [0060/0060], Loss1: 0.0280 Loss2: 0.0246 Loss3: 0.0202\n",
            "Epoch: 111 MAE: 0.012005652825806349 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:18:38.884943 Epoch [112/250], Step [0001/0060], Loss1: 0.0248 Loss2: 0.0268 Loss3: 0.0197\n",
            "2022-08-02 14:19:03.331786 Epoch [112/250], Step [0050/0060], Loss1: 0.0244 Loss2: 0.0262 Loss3: 0.0196\n",
            "2022-08-02 14:19:08.317985 Epoch [112/250], Step [0060/0060], Loss1: 0.0254 Loss2: 0.0281 Loss3: 0.0204\n",
            "Epoch: 112 MAE: 0.01195220947117796 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:19:13.605841 Epoch [113/250], Step [0001/0060], Loss1: 0.0280 Loss2: 0.0275 Loss3: 0.0210\n",
            "2022-08-02 14:19:38.063448 Epoch [113/250], Step [0050/0060], Loss1: 0.0232 Loss2: 0.0237 Loss3: 0.0181\n",
            "2022-08-02 14:19:43.095420 Epoch [113/250], Step [0060/0060], Loss1: 0.0272 Loss2: 0.0274 Loss3: 0.0209\n",
            "Epoch: 113 MAE: 0.01220172050128144 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:19:48.389232 Epoch [114/250], Step [0001/0060], Loss1: 0.0273 Loss2: 0.0247 Loss3: 0.0199\n",
            "2022-08-02 14:20:12.957346 Epoch [114/250], Step [0050/0060], Loss1: 0.0251 Loss2: 0.0271 Loss3: 0.0199\n",
            "2022-08-02 14:20:17.991579 Epoch [114/250], Step [0060/0060], Loss1: 0.0229 Loss2: 0.0250 Loss3: 0.0186\n",
            "Epoch: 114 MAE: 0.012008368673305663 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:20:23.328809 Epoch [115/250], Step [0001/0060], Loss1: 0.0235 Loss2: 0.0230 Loss3: 0.0180\n",
            "2022-08-02 14:20:47.695244 Epoch [115/250], Step [0050/0060], Loss1: 0.0249 Loss2: 0.0236 Loss3: 0.0184\n",
            "2022-08-02 14:20:52.677774 Epoch [115/250], Step [0060/0060], Loss1: 0.0259 Loss2: 0.0262 Loss3: 0.0199\n",
            "Epoch: 115 MAE: 0.01156573152051322 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:21:00.238797 Epoch [116/250], Step [0001/0060], Loss1: 0.0296 Loss2: 0.0285 Loss3: 0.0219\n",
            "2022-08-02 14:21:24.836495 Epoch [116/250], Step [0050/0060], Loss1: 0.0256 Loss2: 0.0280 Loss3: 0.0206\n",
            "2022-08-02 14:21:29.787295 Epoch [116/250], Step [0060/0060], Loss1: 0.0251 Loss2: 0.0272 Loss3: 0.0200\n",
            "Epoch: 116 MAE: 0.011888794438351714 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:21:35.085324 Epoch [117/250], Step [0001/0060], Loss1: 0.0286 Loss2: 0.0296 Loss3: 0.0222\n",
            "2022-08-02 14:21:59.597844 Epoch [117/250], Step [0050/0060], Loss1: 0.0251 Loss2: 0.0266 Loss3: 0.0197\n",
            "2022-08-02 14:22:04.578667 Epoch [117/250], Step [0060/0060], Loss1: 0.0265 Loss2: 0.0273 Loss3: 0.0206\n",
            "Epoch: 117 MAE: 0.01176368309155343 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:22:09.847547 Epoch [118/250], Step [0001/0060], Loss1: 0.0221 Loss2: 0.0234 Loss3: 0.0176\n",
            "2022-08-02 14:22:34.256984 Epoch [118/250], Step [0050/0060], Loss1: 0.0230 Loss2: 0.0249 Loss3: 0.0190\n",
            "2022-08-02 14:22:39.211871 Epoch [118/250], Step [0060/0060], Loss1: 0.0274 Loss2: 0.0261 Loss3: 0.0206\n",
            "Epoch: 118 MAE: 0.012313548704638841 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:22:44.600355 Epoch [119/250], Step [0001/0060], Loss1: 0.0277 Loss2: 0.0263 Loss3: 0.0203\n",
            "2022-08-02 14:23:09.033142 Epoch [119/250], Step [0050/0060], Loss1: 0.0236 Loss2: 0.0254 Loss3: 0.0191\n",
            "2022-08-02 14:23:14.091588 Epoch [119/250], Step [0060/0060], Loss1: 0.0268 Loss2: 0.0297 Loss3: 0.0213\n",
            "Epoch: 119 MAE: 0.012054426270344901 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:23:19.435362 Epoch [120/250], Step [0001/0060], Loss1: 0.0262 Loss2: 0.0252 Loss3: 0.0197\n",
            "2022-08-02 14:23:43.957553 Epoch [120/250], Step [0050/0060], Loss1: 0.0226 Loss2: 0.0245 Loss3: 0.0185\n",
            "2022-08-02 14:23:49.002818 Epoch [120/250], Step [0060/0060], Loss1: 0.0244 Loss2: 0.0265 Loss3: 0.0198\n",
            "Epoch: 120 MAE: 0.01214678655008948 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:23:56.556625 Epoch [121/250], Step [0001/0060], Loss1: 0.0270 Loss2: 0.0285 Loss3: 0.0209\n",
            "2022-08-02 14:24:21.366375 Epoch [121/250], Step [0050/0060], Loss1: 0.0259 Loss2: 0.0263 Loss3: 0.0200\n",
            "2022-08-02 14:24:26.380638 Epoch [121/250], Step [0060/0060], Loss1: 0.0239 Loss2: 0.0255 Loss3: 0.0187\n",
            "Epoch: 121 MAE: 0.012251769939053154 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:24:31.722453 Epoch [122/250], Step [0001/0060], Loss1: 0.0324 Loss2: 0.0283 Loss3: 0.0229\n",
            "2022-08-02 14:24:56.173031 Epoch [122/250], Step [0050/0060], Loss1: 0.0282 Loss2: 0.0268 Loss3: 0.0208\n",
            "2022-08-02 14:25:01.209890 Epoch [122/250], Step [0060/0060], Loss1: 0.0259 Loss2: 0.0272 Loss3: 0.0204\n",
            "Epoch: 122 MAE: 0.012126058731819428 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:25:06.607785 Epoch [123/250], Step [0001/0060], Loss1: 0.0247 Loss2: 0.0273 Loss3: 0.0199\n",
            "2022-08-02 14:25:31.156245 Epoch [123/250], Step [0050/0060], Loss1: 0.0235 Loss2: 0.0256 Loss3: 0.0191\n",
            "2022-08-02 14:25:36.124697 Epoch [123/250], Step [0060/0060], Loss1: 0.0258 Loss2: 0.0266 Loss3: 0.0200\n",
            "Epoch: 123 MAE: 0.012308858933725528 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:25:41.460620 Epoch [124/250], Step [0001/0060], Loss1: 0.0263 Loss2: 0.0275 Loss3: 0.0205\n",
            "2022-08-02 14:26:05.991241 Epoch [124/250], Step [0050/0060], Loss1: 0.0259 Loss2: 0.0267 Loss3: 0.0203\n",
            "2022-08-02 14:26:11.005627 Epoch [124/250], Step [0060/0060], Loss1: 0.0273 Loss2: 0.0305 Loss3: 0.0220\n",
            "Epoch: 124 MAE: 0.012066495989168447 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:26:16.344874 Epoch [125/250], Step [0001/0060], Loss1: 0.0266 Loss2: 0.0255 Loss3: 0.0199\n",
            "2022-08-02 14:26:40.692915 Epoch [125/250], Step [0050/0060], Loss1: 0.0262 Loss2: 0.0266 Loss3: 0.0204\n",
            "2022-08-02 14:26:45.673441 Epoch [125/250], Step [0060/0060], Loss1: 0.0244 Loss2: 0.0256 Loss3: 0.0192\n",
            "Epoch: 125 MAE: 0.01197084253062568 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:26:53.152532 Epoch [126/250], Step [0001/0060], Loss1: 0.0257 Loss2: 0.0283 Loss3: 0.0205\n",
            "2022-08-02 14:27:17.560496 Epoch [126/250], Step [0050/0060], Loss1: 0.0265 Loss2: 0.0264 Loss3: 0.0203\n",
            "2022-08-02 14:27:22.573173 Epoch [126/250], Step [0060/0060], Loss1: 0.0257 Loss2: 0.0258 Loss3: 0.0195\n",
            "Epoch: 126 MAE: 0.012120086921467668 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:27:28.150899 Epoch [127/250], Step [0001/0060], Loss1: 0.0241 Loss2: 0.0262 Loss3: 0.0194\n",
            "2022-08-02 14:27:52.776033 Epoch [127/250], Step [0050/0060], Loss1: 0.0227 Loss2: 0.0241 Loss3: 0.0180\n",
            "2022-08-02 14:27:57.829491 Epoch [127/250], Step [0060/0060], Loss1: 0.0239 Loss2: 0.0246 Loss3: 0.0189\n",
            "Epoch: 127 MAE: 0.012160447537012044 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:28:03.503540 Epoch [128/250], Step [0001/0060], Loss1: 0.0257 Loss2: 0.0259 Loss3: 0.0198\n",
            "2022-08-02 14:28:28.180267 Epoch [128/250], Step [0050/0060], Loss1: 0.0255 Loss2: 0.0267 Loss3: 0.0200\n",
            "2022-08-02 14:28:33.181540 Epoch [128/250], Step [0060/0060], Loss1: 0.0258 Loss2: 0.0288 Loss3: 0.0207\n",
            "Epoch: 128 MAE: 0.012041396690562131 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:28:38.788157 Epoch [129/250], Step [0001/0060], Loss1: 0.0271 Loss2: 0.0276 Loss3: 0.0209\n",
            "2022-08-02 14:29:03.415865 Epoch [129/250], Step [0050/0060], Loss1: 0.0262 Loss2: 0.0260 Loss3: 0.0200\n",
            "2022-08-02 14:29:08.512230 Epoch [129/250], Step [0060/0060], Loss1: 0.0290 Loss2: 0.0282 Loss3: 0.0217\n",
            "Epoch: 129 MAE: 0.012005517754467234 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:29:13.938407 Epoch [130/250], Step [0001/0060], Loss1: 0.0265 Loss2: 0.0257 Loss3: 0.0201\n",
            "2022-08-02 14:29:38.597697 Epoch [130/250], Step [0050/0060], Loss1: 0.0245 Loss2: 0.0263 Loss3: 0.0193\n",
            "2022-08-02 14:29:43.654643 Epoch [130/250], Step [0060/0060], Loss1: 0.0247 Loss2: 0.0261 Loss3: 0.0196\n",
            "Epoch: 130 MAE: 0.01217142686927839 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:29:51.351596 Epoch [131/250], Step [0001/0060], Loss1: 0.0256 Loss2: 0.0284 Loss3: 0.0204\n",
            "2022-08-02 14:30:16.099678 Epoch [131/250], Step [0050/0060], Loss1: 0.0283 Loss2: 0.0284 Loss3: 0.0215\n",
            "2022-08-02 14:30:21.157595 Epoch [131/250], Step [0060/0060], Loss1: 0.0240 Loss2: 0.0284 Loss3: 0.0199\n",
            "Epoch: 131 MAE: 0.012045278967846008 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:30:26.691604 Epoch [132/250], Step [0001/0060], Loss1: 0.0240 Loss2: 0.0257 Loss3: 0.0190\n",
            "2022-08-02 14:30:51.193074 Epoch [132/250], Step [0050/0060], Loss1: 0.0219 Loss2: 0.0268 Loss3: 0.0187\n",
            "2022-08-02 14:30:56.154759 Epoch [132/250], Step [0060/0060], Loss1: 0.0242 Loss2: 0.0251 Loss3: 0.0191\n",
            "Epoch: 132 MAE: 0.012169253125431993 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:31:01.617503 Epoch [133/250], Step [0001/0060], Loss1: 0.0262 Loss2: 0.0293 Loss3: 0.0206\n",
            "2022-08-02 14:31:26.106067 Epoch [133/250], Step [0050/0060], Loss1: 0.0251 Loss2: 0.0258 Loss3: 0.0195\n",
            "2022-08-02 14:31:31.093358 Epoch [133/250], Step [0060/0060], Loss1: 0.0246 Loss2: 0.0249 Loss3: 0.0194\n",
            "Epoch: 133 MAE: 0.01234631355674494 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:31:36.618484 Epoch [134/250], Step [0001/0060], Loss1: 0.0265 Loss2: 0.0258 Loss3: 0.0200\n",
            "2022-08-02 14:32:01.134866 Epoch [134/250], Step [0050/0060], Loss1: 0.0255 Loss2: 0.0261 Loss3: 0.0195\n",
            "2022-08-02 14:32:06.145972 Epoch [134/250], Step [0060/0060], Loss1: 0.0285 Loss2: 0.0301 Loss3: 0.0223\n",
            "Epoch: 134 MAE: 0.012131635129215225 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:32:11.652295 Epoch [135/250], Step [0001/0060], Loss1: 0.0273 Loss2: 0.0258 Loss3: 0.0204\n",
            "2022-08-02 14:32:36.192221 Epoch [135/250], Step [0050/0060], Loss1: 0.0282 Loss2: 0.0272 Loss3: 0.0213\n",
            "2022-08-02 14:32:41.167823 Epoch [135/250], Step [0060/0060], Loss1: 0.0267 Loss2: 0.0295 Loss3: 0.0211\n",
            "Epoch: 135 MAE: 0.011954570174335486 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:32:48.708158 Epoch [136/250], Step [0001/0060], Loss1: 0.0254 Loss2: 0.0266 Loss3: 0.0197\n",
            "2022-08-02 14:33:13.330865 Epoch [136/250], Step [0050/0060], Loss1: 0.0252 Loss2: 0.0263 Loss3: 0.0193\n",
            "2022-08-02 14:33:18.358366 Epoch [136/250], Step [0060/0060], Loss1: 0.0261 Loss2: 0.0273 Loss3: 0.0205\n",
            "Epoch: 136 MAE: 0.011962837081343408 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:33:23.645215 Epoch [137/250], Step [0001/0060], Loss1: 0.0257 Loss2: 0.0272 Loss3: 0.0206\n",
            "2022-08-02 14:33:48.187560 Epoch [137/250], Step [0050/0060], Loss1: 0.0281 Loss2: 0.0300 Loss3: 0.0219\n",
            "2022-08-02 14:33:53.151404 Epoch [137/250], Step [0060/0060], Loss1: 0.0246 Loss2: 0.0241 Loss3: 0.0185\n",
            "Epoch: 137 MAE: 0.012041416255727647 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:33:58.553267 Epoch [138/250], Step [0001/0060], Loss1: 0.0259 Loss2: 0.0239 Loss3: 0.0191\n",
            "2022-08-02 14:34:23.060915 Epoch [138/250], Step [0050/0060], Loss1: 0.0241 Loss2: 0.0263 Loss3: 0.0194\n",
            "2022-08-02 14:34:28.070546 Epoch [138/250], Step [0060/0060], Loss1: 0.0242 Loss2: 0.0269 Loss3: 0.0200\n",
            "Epoch: 138 MAE: 0.011829860641488008 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:34:33.453791 Epoch [139/250], Step [0001/0060], Loss1: 0.0265 Loss2: 0.0293 Loss3: 0.0213\n",
            "2022-08-02 14:34:57.995291 Epoch [139/250], Step [0050/0060], Loss1: 0.0266 Loss2: 0.0272 Loss3: 0.0207\n",
            "2022-08-02 14:35:02.989628 Epoch [139/250], Step [0060/0060], Loss1: 0.0264 Loss2: 0.0270 Loss3: 0.0202\n",
            "Epoch: 139 MAE: 0.012090368455068933 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:35:08.215572 Epoch [140/250], Step [0001/0060], Loss1: 0.0250 Loss2: 0.0255 Loss3: 0.0199\n",
            "2022-08-02 14:35:32.548957 Epoch [140/250], Step [0050/0060], Loss1: 0.0245 Loss2: 0.0269 Loss3: 0.0199\n",
            "2022-08-02 14:35:37.515536 Epoch [140/250], Step [0060/0060], Loss1: 0.0235 Loss2: 0.0272 Loss3: 0.0193\n",
            "Epoch: 140 MAE: 0.012254842682667667 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:35:44.969275 Epoch [141/250], Step [0001/0060], Loss1: 0.0247 Loss2: 0.0238 Loss3: 0.0188\n",
            "2022-08-02 14:36:09.585521 Epoch [141/250], Step [0050/0060], Loss1: 0.0231 Loss2: 0.0250 Loss3: 0.0185\n",
            "2022-08-02 14:36:14.565389 Epoch [141/250], Step [0060/0060], Loss1: 0.0280 Loss2: 0.0283 Loss3: 0.0212\n",
            "Epoch: 141 MAE: 0.012179656456860284 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:36:19.838931 Epoch [142/250], Step [0001/0060], Loss1: 0.0235 Loss2: 0.0269 Loss3: 0.0191\n",
            "2022-08-02 14:36:44.178538 Epoch [142/250], Step [0050/0060], Loss1: 0.0243 Loss2: 0.0266 Loss3: 0.0193\n",
            "2022-08-02 14:36:49.120272 Epoch [142/250], Step [0060/0060], Loss1: 0.0308 Loss2: 0.0311 Loss3: 0.0239\n",
            "Epoch: 142 MAE: 0.012145984333954633 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:36:54.372035 Epoch [143/250], Step [0001/0060], Loss1: 0.0259 Loss2: 0.0253 Loss3: 0.0199\n",
            "2022-08-02 14:37:18.789894 Epoch [143/250], Step [0050/0060], Loss1: 0.0274 Loss2: 0.0262 Loss3: 0.0204\n",
            "2022-08-02 14:37:23.763709 Epoch [143/250], Step [0060/0060], Loss1: 0.0246 Loss2: 0.0269 Loss3: 0.0201\n",
            "Epoch: 143 MAE: 0.012061214769288661 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:37:28.980928 Epoch [144/250], Step [0001/0060], Loss1: 0.0236 Loss2: 0.0256 Loss3: 0.0191\n",
            "2022-08-02 14:37:53.484770 Epoch [144/250], Step [0050/0060], Loss1: 0.0276 Loss2: 0.0263 Loss3: 0.0203\n",
            "2022-08-02 14:37:58.484910 Epoch [144/250], Step [0060/0060], Loss1: 0.0249 Loss2: 0.0261 Loss3: 0.0194\n",
            "Epoch: 144 MAE: 0.011938770168593951 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:38:03.749123 Epoch [145/250], Step [0001/0060], Loss1: 0.0252 Loss2: 0.0270 Loss3: 0.0201\n",
            "2022-08-02 14:38:28.130777 Epoch [145/250], Step [0050/0060], Loss1: 0.0263 Loss2: 0.0255 Loss3: 0.0198\n",
            "2022-08-02 14:38:33.126853 Epoch [145/250], Step [0060/0060], Loss1: 0.0240 Loss2: 0.0254 Loss3: 0.0192\n",
            "Epoch: 145 MAE: 0.012105316138042816 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:38:40.401856 Epoch [146/250], Step [0001/0060], Loss1: 0.0234 Loss2: 0.0234 Loss3: 0.0179\n",
            "2022-08-02 14:39:05.013725 Epoch [146/250], Step [0050/0060], Loss1: 0.0270 Loss2: 0.0277 Loss3: 0.0211\n",
            "2022-08-02 14:39:10.008065 Epoch [146/250], Step [0060/0060], Loss1: 0.0261 Loss2: 0.0254 Loss3: 0.0195\n",
            "Epoch: 146 MAE: 0.012063911458152153 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:39:15.217282 Epoch [147/250], Step [0001/0060], Loss1: 0.0248 Loss2: 0.0243 Loss3: 0.0191\n",
            "2022-08-02 14:39:39.586016 Epoch [147/250], Step [0050/0060], Loss1: 0.0260 Loss2: 0.0284 Loss3: 0.0203\n",
            "2022-08-02 14:39:44.554291 Epoch [147/250], Step [0060/0060], Loss1: 0.0290 Loss2: 0.0327 Loss3: 0.0228\n",
            "Epoch: 147 MAE: 0.01214378716660634 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:39:49.796918 Epoch [148/250], Step [0001/0060], Loss1: 0.0251 Loss2: 0.0256 Loss3: 0.0197\n",
            "2022-08-02 14:40:14.088958 Epoch [148/250], Step [0050/0060], Loss1: 0.0251 Loss2: 0.0258 Loss3: 0.0196\n",
            "2022-08-02 14:40:19.062545 Epoch [148/250], Step [0060/0060], Loss1: 0.0282 Loss2: 0.0269 Loss3: 0.0211\n",
            "Epoch: 148 MAE: 0.011968033454780067 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:40:24.264974 Epoch [149/250], Step [0001/0060], Loss1: 0.0240 Loss2: 0.0239 Loss3: 0.0187\n",
            "2022-08-02 14:40:48.596155 Epoch [149/250], Step [0050/0060], Loss1: 0.0266 Loss2: 0.0263 Loss3: 0.0202\n",
            "2022-08-02 14:40:53.555075 Epoch [149/250], Step [0060/0060], Loss1: 0.0231 Loss2: 0.0244 Loss3: 0.0184\n",
            "Epoch: 149 MAE: 0.011928972093358872 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:40:58.838432 Epoch [150/250], Step [0001/0060], Loss1: 0.0253 Loss2: 0.0267 Loss3: 0.0197\n",
            "2022-08-02 14:41:23.143801 Epoch [150/250], Step [0050/0060], Loss1: 0.0264 Loss2: 0.0264 Loss3: 0.0201\n",
            "2022-08-02 14:41:28.100076 Epoch [150/250], Step [0060/0060], Loss1: 0.0238 Loss2: 0.0235 Loss3: 0.0184\n",
            "Epoch: 150 MAE: 0.012060418311092589 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:41:37.950595 Epoch [151/250], Step [0001/0060], Loss1: 0.0261 Loss2: 0.0250 Loss3: 0.0197\n",
            "2022-08-02 14:42:02.489426 Epoch [151/250], Step [0050/0060], Loss1: 0.0241 Loss2: 0.0245 Loss3: 0.0186\n",
            "2022-08-02 14:42:07.540570 Epoch [151/250], Step [0060/0060], Loss1: 0.0270 Loss2: 0.0278 Loss3: 0.0209\n",
            "Epoch: 151 MAE: 0.011735212597404681 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:42:12.781214 Epoch [152/250], Step [0001/0060], Loss1: 0.0260 Loss2: 0.0261 Loss3: 0.0199\n",
            "2022-08-02 14:42:37.299681 Epoch [152/250], Step [0050/0060], Loss1: 0.0240 Loss2: 0.0261 Loss3: 0.0190\n",
            "2022-08-02 14:42:42.276393 Epoch [152/250], Step [0060/0060], Loss1: 0.0263 Loss2: 0.0282 Loss3: 0.0205\n",
            "Epoch: 152 MAE: 0.01213397593459203 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:42:47.506970 Epoch [153/250], Step [0001/0060], Loss1: 0.0249 Loss2: 0.0239 Loss3: 0.0191\n",
            "2022-08-02 14:43:11.994065 Epoch [153/250], Step [0050/0060], Loss1: 0.0278 Loss2: 0.0242 Loss3: 0.0200\n",
            "2022-08-02 14:43:16.998956 Epoch [153/250], Step [0060/0060], Loss1: 0.0222 Loss2: 0.0251 Loss3: 0.0182\n",
            "Epoch: 153 MAE: 0.011926874363174042 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:43:22.344084 Epoch [154/250], Step [0001/0060], Loss1: 0.0278 Loss2: 0.0270 Loss3: 0.0205\n",
            "2022-08-02 14:43:46.602916 Epoch [154/250], Step [0050/0060], Loss1: 0.0243 Loss2: 0.0261 Loss3: 0.0191\n",
            "2022-08-02 14:43:51.592045 Epoch [154/250], Step [0060/0060], Loss1: 0.0242 Loss2: 0.0259 Loss3: 0.0194\n",
            "Epoch: 154 MAE: 0.011991761957428284 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:43:57.159272 Epoch [155/250], Step [0001/0060], Loss1: 0.0265 Loss2: 0.0263 Loss3: 0.0205\n",
            "2022-08-02 14:44:21.586920 Epoch [155/250], Step [0050/0060], Loss1: 0.0232 Loss2: 0.0258 Loss3: 0.0193\n",
            "2022-08-02 14:44:26.598764 Epoch [155/250], Step [0060/0060], Loss1: 0.0237 Loss2: 0.0231 Loss3: 0.0182\n",
            "Epoch: 155 MAE: 0.012093935028782912 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:44:34.604804 Epoch [156/250], Step [0001/0060], Loss1: 0.0259 Loss2: 0.0257 Loss3: 0.0199\n",
            "2022-08-02 14:44:59.184993 Epoch [156/250], Step [0050/0060], Loss1: 0.0260 Loss2: 0.0251 Loss3: 0.0194\n",
            "2022-08-02 14:45:04.153904 Epoch [156/250], Step [0060/0060], Loss1: 0.0268 Loss2: 0.0256 Loss3: 0.0201\n",
            "Epoch: 156 MAE: 0.012103006531972261 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:45:09.531511 Epoch [157/250], Step [0001/0060], Loss1: 0.0268 Loss2: 0.0250 Loss3: 0.0200\n",
            "2022-08-02 14:45:33.991882 Epoch [157/250], Step [0050/0060], Loss1: 0.0241 Loss2: 0.0246 Loss3: 0.0193\n",
            "2022-08-02 14:45:38.981222 Epoch [157/250], Step [0060/0060], Loss1: 0.0269 Loss2: 0.0278 Loss3: 0.0213\n",
            "Epoch: 157 MAE: 0.011878478946903396 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:45:44.295310 Epoch [158/250], Step [0001/0060], Loss1: 0.0244 Loss2: 0.0251 Loss3: 0.0197\n",
            "2022-08-02 14:46:08.825410 Epoch [158/250], Step [0050/0060], Loss1: 0.0251 Loss2: 0.0244 Loss3: 0.0190\n",
            "2022-08-02 14:46:13.766637 Epoch [158/250], Step [0060/0060], Loss1: 0.0245 Loss2: 0.0262 Loss3: 0.0195\n",
            "Epoch: 158 MAE: 0.01198746542638493 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:46:19.208555 Epoch [159/250], Step [0001/0060], Loss1: 0.0238 Loss2: 0.0265 Loss3: 0.0194\n",
            "2022-08-02 14:46:43.540577 Epoch [159/250], Step [0050/0060], Loss1: 0.0227 Loss2: 0.0251 Loss3: 0.0183\n",
            "2022-08-02 14:46:48.491452 Epoch [159/250], Step [0060/0060], Loss1: 0.0277 Loss2: 0.0274 Loss3: 0.0210\n",
            "Epoch: 159 MAE: 0.012250785989361622 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:46:53.896256 Epoch [160/250], Step [0001/0060], Loss1: 0.0236 Loss2: 0.0255 Loss3: 0.0194\n",
            "2022-08-02 14:47:18.347587 Epoch [160/250], Step [0050/0060], Loss1: 0.0249 Loss2: 0.0264 Loss3: 0.0196\n",
            "2022-08-02 14:47:23.321264 Epoch [160/250], Step [0060/0060], Loss1: 0.0239 Loss2: 0.0266 Loss3: 0.0195\n",
            "Epoch: 160 MAE: 0.012017646922715126 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:47:30.758301 Epoch [161/250], Step [0001/0060], Loss1: 0.0228 Loss2: 0.0242 Loss3: 0.0186\n",
            "2022-08-02 14:47:55.220845 Epoch [161/250], Step [0050/0060], Loss1: 0.0249 Loss2: 0.0259 Loss3: 0.0191\n",
            "2022-08-02 14:48:00.185467 Epoch [161/250], Step [0060/0060], Loss1: 0.0235 Loss2: 0.0274 Loss3: 0.0195\n",
            "Epoch: 161 MAE: 0.01218859977754099 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:48:05.442320 Epoch [162/250], Step [0001/0060], Loss1: 0.0227 Loss2: 0.0229 Loss3: 0.0177\n",
            "2022-08-02 14:48:30.018387 Epoch [162/250], Step [0050/0060], Loss1: 0.0236 Loss2: 0.0242 Loss3: 0.0185\n",
            "2022-08-02 14:48:35.017254 Epoch [162/250], Step [0060/0060], Loss1: 0.0251 Loss2: 0.0249 Loss3: 0.0194\n",
            "Epoch: 162 MAE: 0.011938544396784097 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:48:40.462725 Epoch [163/250], Step [0001/0060], Loss1: 0.0233 Loss2: 0.0245 Loss3: 0.0187\n",
            "2022-08-02 14:49:05.084864 Epoch [163/250], Step [0050/0060], Loss1: 0.0228 Loss2: 0.0233 Loss3: 0.0182\n",
            "2022-08-02 14:49:10.063295 Epoch [163/250], Step [0060/0060], Loss1: 0.0264 Loss2: 0.0267 Loss3: 0.0206\n",
            "Epoch: 163 MAE: 0.01207726870826076 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:49:15.547039 Epoch [164/250], Step [0001/0060], Loss1: 0.0246 Loss2: 0.0240 Loss3: 0.0184\n",
            "2022-08-02 14:49:39.968035 Epoch [164/250], Step [0050/0060], Loss1: 0.0275 Loss2: 0.0270 Loss3: 0.0205\n",
            "2022-08-02 14:49:44.965436 Epoch [164/250], Step [0060/0060], Loss1: 0.0265 Loss2: 0.0262 Loss3: 0.0202\n",
            "Epoch: 164 MAE: 0.011873197416582751 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:49:50.367227 Epoch [165/250], Step [0001/0060], Loss1: 0.0235 Loss2: 0.0245 Loss3: 0.0186\n",
            "2022-08-02 14:50:14.706578 Epoch [165/250], Step [0050/0060], Loss1: 0.0294 Loss2: 0.0265 Loss3: 0.0212\n",
            "2022-08-02 14:50:19.665607 Epoch [165/250], Step [0060/0060], Loss1: 0.0230 Loss2: 0.0233 Loss3: 0.0180\n",
            "Epoch: 165 MAE: 0.012229185876628709 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:50:27.024844 Epoch [166/250], Step [0001/0060], Loss1: 0.0255 Loss2: 0.0256 Loss3: 0.0196\n",
            "2022-08-02 14:50:51.670145 Epoch [166/250], Step [0050/0060], Loss1: 0.0252 Loss2: 0.0256 Loss3: 0.0196\n",
            "2022-08-02 14:50:56.661389 Epoch [166/250], Step [0060/0060], Loss1: 0.0240 Loss2: 0.0247 Loss3: 0.0192\n",
            "Epoch: 166 MAE: 0.012150498727957407 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:51:02.049570 Epoch [167/250], Step [0001/0060], Loss1: 0.0254 Loss2: 0.0250 Loss3: 0.0193\n",
            "2022-08-02 14:51:26.659238 Epoch [167/250], Step [0050/0060], Loss1: 0.0261 Loss2: 0.0293 Loss3: 0.0210\n",
            "2022-08-02 14:51:31.607486 Epoch [167/250], Step [0060/0060], Loss1: 0.0257 Loss2: 0.0257 Loss3: 0.0198\n",
            "Epoch: 167 MAE: 0.0125582871869916 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:51:36.951488 Epoch [168/250], Step [0001/0060], Loss1: 0.0233 Loss2: 0.0246 Loss3: 0.0186\n",
            "2022-08-02 14:52:01.484827 Epoch [168/250], Step [0050/0060], Loss1: 0.0235 Loss2: 0.0251 Loss3: 0.0191\n",
            "2022-08-02 14:52:06.476938 Epoch [168/250], Step [0060/0060], Loss1: 0.0217 Loss2: 0.0250 Loss3: 0.0181\n",
            "Epoch: 168 MAE: 0.012080326292013365 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:52:11.824947 Epoch [169/250], Step [0001/0060], Loss1: 0.0253 Loss2: 0.0258 Loss3: 0.0194\n",
            "2022-08-02 14:52:36.135919 Epoch [169/250], Step [0050/0060], Loss1: 0.0223 Loss2: 0.0239 Loss3: 0.0179\n",
            "2022-08-02 14:52:41.146313 Epoch [169/250], Step [0060/0060], Loss1: 0.0288 Loss2: 0.0275 Loss3: 0.0213\n",
            "Epoch: 169 MAE: 0.012306830956644955 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:52:46.512947 Epoch [170/250], Step [0001/0060], Loss1: 0.0240 Loss2: 0.0262 Loss3: 0.0192\n",
            "2022-08-02 14:53:11.044826 Epoch [170/250], Step [0050/0060], Loss1: 0.0288 Loss2: 0.0281 Loss3: 0.0216\n",
            "2022-08-02 14:53:16.070732 Epoch [170/250], Step [0060/0060], Loss1: 0.0250 Loss2: 0.0254 Loss3: 0.0192\n",
            "Epoch: 170 MAE: 0.011840550073732933 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:53:23.723350 Epoch [171/250], Step [0001/0060], Loss1: 0.0257 Loss2: 0.0246 Loss3: 0.0195\n",
            "2022-08-02 14:53:48.254196 Epoch [171/250], Step [0050/0060], Loss1: 0.0273 Loss2: 0.0258 Loss3: 0.0206\n",
            "2022-08-02 14:53:53.201314 Epoch [171/250], Step [0060/0060], Loss1: 0.0295 Loss2: 0.0268 Loss3: 0.0209\n",
            "Epoch: 171 MAE: 0.012319453614985659 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:53:58.480918 Epoch [172/250], Step [0001/0060], Loss1: 0.0258 Loss2: 0.0257 Loss3: 0.0202\n",
            "2022-08-02 14:54:22.966512 Epoch [172/250], Step [0050/0060], Loss1: 0.0245 Loss2: 0.0256 Loss3: 0.0190\n",
            "2022-08-02 14:54:27.956742 Epoch [172/250], Step [0060/0060], Loss1: 0.0290 Loss2: 0.0317 Loss3: 0.0230\n",
            "Epoch: 172 MAE: 0.01220108550189743 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:54:33.258636 Epoch [173/250], Step [0001/0060], Loss1: 0.0241 Loss2: 0.0258 Loss3: 0.0190\n",
            "2022-08-02 14:54:57.681783 Epoch [173/250], Step [0050/0060], Loss1: 0.0250 Loss2: 0.0255 Loss3: 0.0195\n",
            "2022-08-02 14:55:02.675865 Epoch [173/250], Step [0060/0060], Loss1: 0.0277 Loss2: 0.0261 Loss3: 0.0209\n",
            "Epoch: 173 MAE: 0.012362467339410195 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:55:08.064909 Epoch [174/250], Step [0001/0060], Loss1: 0.0259 Loss2: 0.0272 Loss3: 0.0207\n",
            "2022-08-02 14:55:32.445847 Epoch [174/250], Step [0050/0060], Loss1: 0.0274 Loss2: 0.0281 Loss3: 0.0210\n",
            "2022-08-02 14:55:37.398425 Epoch [174/250], Step [0060/0060], Loss1: 0.0294 Loss2: 0.0277 Loss3: 0.0218\n",
            "Epoch: 174 MAE: 0.012098357133153412 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:55:42.809640 Epoch [175/250], Step [0001/0060], Loss1: 0.0286 Loss2: 0.0284 Loss3: 0.0213\n",
            "2022-08-02 14:56:07.151597 Epoch [175/250], Step [0050/0060], Loss1: 0.0226 Loss2: 0.0244 Loss3: 0.0187\n",
            "2022-08-02 14:56:12.094036 Epoch [175/250], Step [0060/0060], Loss1: 0.0237 Loss2: 0.0255 Loss3: 0.0188\n",
            "Epoch: 175 MAE: 0.012259022258813418 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:56:19.437714 Epoch [176/250], Step [0001/0060], Loss1: 0.0243 Loss2: 0.0247 Loss3: 0.0192\n",
            "2022-08-02 14:56:44.139592 Epoch [176/250], Step [0050/0060], Loss1: 0.0253 Loss2: 0.0262 Loss3: 0.0193\n",
            "2022-08-02 14:56:49.099897 Epoch [176/250], Step [0060/0060], Loss1: 0.0225 Loss2: 0.0237 Loss3: 0.0181\n",
            "Epoch: 176 MAE: 0.012110553460106963 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:56:54.454072 Epoch [177/250], Step [0001/0060], Loss1: 0.0255 Loss2: 0.0277 Loss3: 0.0204\n",
            "2022-08-02 14:57:19.016242 Epoch [177/250], Step [0050/0060], Loss1: 0.0242 Loss2: 0.0262 Loss3: 0.0193\n",
            "2022-08-02 14:57:24.081693 Epoch [177/250], Step [0060/0060], Loss1: 0.0207 Loss2: 0.0227 Loss3: 0.0170\n",
            "Epoch: 177 MAE: 0.012133726598842749 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:57:29.461286 Epoch [178/250], Step [0001/0060], Loss1: 0.0238 Loss2: 0.0249 Loss3: 0.0192\n",
            "2022-08-02 14:57:53.958220 Epoch [178/250], Step [0050/0060], Loss1: 0.0252 Loss2: 0.0254 Loss3: 0.0189\n",
            "2022-08-02 14:57:58.945181 Epoch [178/250], Step [0060/0060], Loss1: 0.0273 Loss2: 0.0264 Loss3: 0.0204\n",
            "Epoch: 178 MAE: 0.012311049138328858 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:58:04.324190 Epoch [179/250], Step [0001/0060], Loss1: 0.0270 Loss2: 0.0273 Loss3: 0.0209\n",
            "2022-08-02 14:58:28.625670 Epoch [179/250], Step [0050/0060], Loss1: 0.0255 Loss2: 0.0302 Loss3: 0.0211\n",
            "2022-08-02 14:58:33.589279 Epoch [179/250], Step [0060/0060], Loss1: 0.0235 Loss2: 0.0242 Loss3: 0.0185\n",
            "Epoch: 179 MAE: 0.012121186887342778 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:58:38.924076 Epoch [180/250], Step [0001/0060], Loss1: 0.0222 Loss2: 0.0233 Loss3: 0.0182\n",
            "2022-08-02 14:59:03.461229 Epoch [180/250], Step [0050/0060], Loss1: 0.0254 Loss2: 0.0261 Loss3: 0.0202\n",
            "2022-08-02 14:59:08.448908 Epoch [180/250], Step [0060/0060], Loss1: 0.0260 Loss2: 0.0274 Loss3: 0.0203\n",
            "Epoch: 180 MAE: 0.011810366352576585 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:59:15.774400 Epoch [181/250], Step [0001/0060], Loss1: 0.0274 Loss2: 0.0278 Loss3: 0.0210\n",
            "2022-08-02 14:59:40.222155 Epoch [181/250], Step [0050/0060], Loss1: 0.0240 Loss2: 0.0254 Loss3: 0.0185\n",
            "2022-08-02 14:59:45.179243 Epoch [181/250], Step [0060/0060], Loss1: 0.0211 Loss2: 0.0236 Loss3: 0.0177\n",
            "Epoch: 181 MAE: 0.011977064859358564 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 14:59:50.483807 Epoch [182/250], Step [0001/0060], Loss1: 0.0241 Loss2: 0.0261 Loss3: 0.0196\n",
            "2022-08-02 15:00:15.016823 Epoch [182/250], Step [0050/0060], Loss1: 0.0248 Loss2: 0.0270 Loss3: 0.0198\n",
            "2022-08-02 15:00:19.988945 Epoch [182/250], Step [0060/0060], Loss1: 0.0241 Loss2: 0.0238 Loss3: 0.0188\n",
            "Epoch: 182 MAE: 0.012173850784107806 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:00:25.303492 Epoch [183/250], Step [0001/0060], Loss1: 0.0248 Loss2: 0.0250 Loss3: 0.0191\n",
            "2022-08-02 15:00:49.644610 Epoch [183/250], Step [0050/0060], Loss1: 0.0224 Loss2: 0.0226 Loss3: 0.0178\n",
            "2022-08-02 15:00:54.592622 Epoch [183/250], Step [0060/0060], Loss1: 0.0256 Loss2: 0.0263 Loss3: 0.0196\n",
            "Epoch: 183 MAE: 0.011902199045474094 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:00:59.902350 Epoch [184/250], Step [0001/0060], Loss1: 0.0262 Loss2: 0.0272 Loss3: 0.0208\n",
            "2022-08-02 15:01:24.335155 Epoch [184/250], Step [0050/0060], Loss1: 0.0229 Loss2: 0.0245 Loss3: 0.0188\n",
            "2022-08-02 15:01:29.355615 Epoch [184/250], Step [0060/0060], Loss1: 0.0269 Loss2: 0.0305 Loss3: 0.0213\n",
            "Epoch: 184 MAE: 0.012088226849242809 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:01:34.599522 Epoch [185/250], Step [0001/0060], Loss1: 0.0251 Loss2: 0.0268 Loss3: 0.0200\n",
            "2022-08-02 15:01:59.014899 Epoch [185/250], Step [0050/0060], Loss1: 0.0267 Loss2: 0.0282 Loss3: 0.0206\n",
            "2022-08-02 15:02:03.978183 Epoch [185/250], Step [0060/0060], Loss1: 0.0241 Loss2: 0.0265 Loss3: 0.0196\n",
            "Epoch: 185 MAE: 0.011965940950349682 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:02:11.407199 Epoch [186/250], Step [0001/0060], Loss1: 0.0258 Loss2: 0.0279 Loss3: 0.0208\n",
            "2022-08-02 15:02:36.115397 Epoch [186/250], Step [0050/0060], Loss1: 0.0238 Loss2: 0.0260 Loss3: 0.0194\n",
            "2022-08-02 15:02:41.124273 Epoch [186/250], Step [0060/0060], Loss1: 0.0244 Loss2: 0.0270 Loss3: 0.0197\n",
            "Epoch: 186 MAE: 0.011807439723126 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:02:46.439039 Epoch [187/250], Step [0001/0060], Loss1: 0.0297 Loss2: 0.0285 Loss3: 0.0227\n",
            "2022-08-02 15:03:10.854070 Epoch [187/250], Step [0050/0060], Loss1: 0.0230 Loss2: 0.0240 Loss3: 0.0180\n",
            "2022-08-02 15:03:15.817079 Epoch [187/250], Step [0060/0060], Loss1: 0.0252 Loss2: 0.0272 Loss3: 0.0199\n",
            "Epoch: 187 MAE: 0.012073842949041772 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:03:21.071704 Epoch [188/250], Step [0001/0060], Loss1: 0.0239 Loss2: 0.0237 Loss3: 0.0184\n",
            "2022-08-02 15:03:45.447480 Epoch [188/250], Step [0050/0060], Loss1: 0.0295 Loss2: 0.0283 Loss3: 0.0220\n",
            "2022-08-02 15:03:50.390729 Epoch [188/250], Step [0060/0060], Loss1: 0.0245 Loss2: 0.0239 Loss3: 0.0189\n",
            "Epoch: 188 MAE: 0.011949938455862659 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:03:55.639160 Epoch [189/250], Step [0001/0060], Loss1: 0.0256 Loss2: 0.0247 Loss3: 0.0194\n",
            "2022-08-02 15:04:20.013955 Epoch [189/250], Step [0050/0060], Loss1: 0.0216 Loss2: 0.0235 Loss3: 0.0175\n",
            "2022-08-02 15:04:25.010693 Epoch [189/250], Step [0060/0060], Loss1: 0.0260 Loss2: 0.0276 Loss3: 0.0206\n",
            "Epoch: 189 MAE: 0.011978518890423907 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:04:30.319487 Epoch [190/250], Step [0001/0060], Loss1: 0.0240 Loss2: 0.0240 Loss3: 0.0192\n",
            "2022-08-02 15:04:54.628578 Epoch [190/250], Step [0050/0060], Loss1: 0.0239 Loss2: 0.0260 Loss3: 0.0190\n",
            "2022-08-02 15:04:59.595978 Epoch [190/250], Step [0060/0060], Loss1: 0.0244 Loss2: 0.0261 Loss3: 0.0194\n",
            "Epoch: 190 MAE: 0.01214165021000164 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:05:06.960754 Epoch [191/250], Step [0001/0060], Loss1: 0.0263 Loss2: 0.0254 Loss3: 0.0205\n",
            "2022-08-02 15:05:31.663325 Epoch [191/250], Step [0050/0060], Loss1: 0.0245 Loss2: 0.0241 Loss3: 0.0188\n",
            "2022-08-02 15:05:36.654604 Epoch [191/250], Step [0060/0060], Loss1: 0.0268 Loss2: 0.0278 Loss3: 0.0203\n",
            "Epoch: 191 MAE: 0.012120633400858396 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:05:42.086763 Epoch [192/250], Step [0001/0060], Loss1: 0.0276 Loss2: 0.0284 Loss3: 0.0215\n",
            "2022-08-02 15:06:06.398219 Epoch [192/250], Step [0050/0060], Loss1: 0.0260 Loss2: 0.0276 Loss3: 0.0207\n",
            "2022-08-02 15:06:11.356077 Epoch [192/250], Step [0060/0060], Loss1: 0.0231 Loss2: 0.0248 Loss3: 0.0185\n",
            "Epoch: 192 MAE: 0.012000338130054019 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:06:16.632279 Epoch [193/250], Step [0001/0060], Loss1: 0.0265 Loss2: 0.0270 Loss3: 0.0205\n",
            "2022-08-02 15:06:41.099686 Epoch [193/250], Step [0050/0060], Loss1: 0.0226 Loss2: 0.0230 Loss3: 0.0179\n",
            "2022-08-02 15:06:46.058610 Epoch [193/250], Step [0060/0060], Loss1: 0.0240 Loss2: 0.0243 Loss3: 0.0184\n",
            "Epoch: 193 MAE: 0.011918915117839499 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:06:51.378646 Epoch [194/250], Step [0001/0060], Loss1: 0.0263 Loss2: 0.0269 Loss3: 0.0202\n",
            "2022-08-02 15:07:15.823078 Epoch [194/250], Step [0050/0060], Loss1: 0.0261 Loss2: 0.0253 Loss3: 0.0199\n",
            "2022-08-02 15:07:20.803493 Epoch [194/250], Step [0060/0060], Loss1: 0.0255 Loss2: 0.0271 Loss3: 0.0204\n",
            "Epoch: 194 MAE: 0.011800320242487249 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:07:26.075129 Epoch [195/250], Step [0001/0060], Loss1: 0.0268 Loss2: 0.0279 Loss3: 0.0206\n",
            "2022-08-02 15:07:50.504355 Epoch [195/250], Step [0050/0060], Loss1: 0.0234 Loss2: 0.0273 Loss3: 0.0195\n",
            "2022-08-02 15:07:55.445922 Epoch [195/250], Step [0060/0060], Loss1: 0.0234 Loss2: 0.0253 Loss3: 0.0193\n",
            "Epoch: 195 MAE: 0.012341398930561447 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:08:02.837966 Epoch [196/250], Step [0001/0060], Loss1: 0.0235 Loss2: 0.0247 Loss3: 0.0183\n",
            "2022-08-02 15:08:27.365278 Epoch [196/250], Step [0050/0060], Loss1: 0.0239 Loss2: 0.0254 Loss3: 0.0193\n",
            "2022-08-02 15:08:32.376387 Epoch [196/250], Step [0060/0060], Loss1: 0.0250 Loss2: 0.0253 Loss3: 0.0191\n",
            "Epoch: 196 MAE: 0.01198886421376041 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:08:37.667825 Epoch [197/250], Step [0001/0060], Loss1: 0.0261 Loss2: 0.0266 Loss3: 0.0203\n",
            "2022-08-02 15:09:02.046598 Epoch [197/250], Step [0050/0060], Loss1: 0.0247 Loss2: 0.0236 Loss3: 0.0189\n",
            "2022-08-02 15:09:07.005094 Epoch [197/250], Step [0060/0060], Loss1: 0.0251 Loss2: 0.0270 Loss3: 0.0203\n",
            "Epoch: 197 MAE: 0.012066924146243505 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:09:12.343578 Epoch [198/250], Step [0001/0060], Loss1: 0.0245 Loss2: 0.0239 Loss3: 0.0189\n",
            "2022-08-02 15:09:36.728079 Epoch [198/250], Step [0050/0060], Loss1: 0.0235 Loss2: 0.0260 Loss3: 0.0191\n",
            "2022-08-02 15:09:41.693482 Epoch [198/250], Step [0060/0060], Loss1: 0.0243 Loss2: 0.0263 Loss3: 0.0196\n",
            "Epoch: 198 MAE: 0.011919801929108208 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:09:47.057557 Epoch [199/250], Step [0001/0060], Loss1: 0.0250 Loss2: 0.0267 Loss3: 0.0199\n",
            "2022-08-02 15:10:11.495536 Epoch [199/250], Step [0050/0060], Loss1: 0.0270 Loss2: 0.0273 Loss3: 0.0205\n",
            "2022-08-02 15:10:16.532008 Epoch [199/250], Step [0060/0060], Loss1: 0.0284 Loss2: 0.0277 Loss3: 0.0217\n",
            "Epoch: 199 MAE: 0.011928934781324296 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:10:21.854407 Epoch [200/250], Step [0001/0060], Loss1: 0.0270 Loss2: 0.0276 Loss3: 0.0207\n",
            "2022-08-02 15:10:46.526710 Epoch [200/250], Step [0050/0060], Loss1: 0.0204 Loss2: 0.0229 Loss3: 0.0173\n",
            "2022-08-02 15:10:51.520713 Epoch [200/250], Step [0060/0060], Loss1: 0.0238 Loss2: 0.0250 Loss3: 0.0188\n",
            "Epoch: 200 MAE: 0.01191913133250579 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:10:58.832485 Epoch [201/250], Step [0001/0060], Loss1: 0.0269 Loss2: 0.0260 Loss3: 0.0203\n",
            "2022-08-02 15:11:23.110614 Epoch [201/250], Step [0050/0060], Loss1: 0.0268 Loss2: 0.0273 Loss3: 0.0206\n",
            "2022-08-02 15:11:28.102014 Epoch [201/250], Step [0060/0060], Loss1: 0.0292 Loss2: 0.0264 Loss3: 0.0214\n",
            "Epoch: 201 MAE: 0.012081699408886452 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:11:33.411679 Epoch [202/250], Step [0001/0060], Loss1: 0.0243 Loss2: 0.0259 Loss3: 0.0193\n",
            "2022-08-02 15:11:57.665487 Epoch [202/250], Step [0050/0060], Loss1: 0.0234 Loss2: 0.0261 Loss3: 0.0188\n",
            "2022-08-02 15:12:02.590533 Epoch [202/250], Step [0060/0060], Loss1: 0.0233 Loss2: 0.0258 Loss3: 0.0192\n",
            "Epoch: 202 MAE: 0.012160560567050225 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:12:07.923685 Epoch [203/250], Step [0001/0060], Loss1: 0.0295 Loss2: 0.0278 Loss3: 0.0218\n",
            "2022-08-02 15:12:32.378925 Epoch [203/250], Step [0050/0060], Loss1: 0.0256 Loss2: 0.0280 Loss3: 0.0201\n",
            "2022-08-02 15:12:37.437642 Epoch [203/250], Step [0060/0060], Loss1: 0.0258 Loss2: 0.0243 Loss3: 0.0196\n",
            "Epoch: 203 MAE: 0.012006430967991788 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:12:42.718359 Epoch [204/250], Step [0001/0060], Loss1: 0.0268 Loss2: 0.0271 Loss3: 0.0205\n",
            "2022-08-02 15:13:07.049878 Epoch [204/250], Step [0050/0060], Loss1: 0.0224 Loss2: 0.0260 Loss3: 0.0189\n",
            "2022-08-02 15:13:11.992869 Epoch [204/250], Step [0060/0060], Loss1: 0.0241 Loss2: 0.0258 Loss3: 0.0195\n",
            "Epoch: 204 MAE: 0.012189377276670365 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:13:17.320589 Epoch [205/250], Step [0001/0060], Loss1: 0.0229 Loss2: 0.0258 Loss3: 0.0190\n",
            "2022-08-02 15:13:41.649018 Epoch [205/250], Step [0050/0060], Loss1: 0.0286 Loss2: 0.0295 Loss3: 0.0222\n",
            "2022-08-02 15:13:46.601718 Epoch [205/250], Step [0060/0060], Loss1: 0.0221 Loss2: 0.0241 Loss3: 0.0181\n",
            "Epoch: 205 MAE: 0.012062258197970334 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:13:56.256482 Epoch [206/250], Step [0001/0060], Loss1: 0.0294 Loss2: 0.0273 Loss3: 0.0217\n",
            "2022-08-02 15:14:20.716449 Epoch [206/250], Step [0050/0060], Loss1: 0.0283 Loss2: 0.0266 Loss3: 0.0207\n",
            "2022-08-02 15:14:25.675826 Epoch [206/250], Step [0060/0060], Loss1: 0.0259 Loss2: 0.0274 Loss3: 0.0198\n",
            "Epoch: 206 MAE: 0.011966765229959809 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:14:31.081951 Epoch [207/250], Step [0001/0060], Loss1: 0.0278 Loss2: 0.0265 Loss3: 0.0207\n",
            "2022-08-02 15:14:55.457351 Epoch [207/250], Step [0050/0060], Loss1: 0.0253 Loss2: 0.0282 Loss3: 0.0201\n",
            "2022-08-02 15:15:00.448683 Epoch [207/250], Step [0060/0060], Loss1: 0.0258 Loss2: 0.0283 Loss3: 0.0207\n",
            "Epoch: 207 MAE: 0.011994656892345539 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:15:05.664621 Epoch [208/250], Step [0001/0060], Loss1: 0.0270 Loss2: 0.0289 Loss3: 0.0210\n",
            "2022-08-02 15:15:30.014372 Epoch [208/250], Step [0050/0060], Loss1: 0.0275 Loss2: 0.0286 Loss3: 0.0214\n",
            "2022-08-02 15:15:35.063902 Epoch [208/250], Step [0060/0060], Loss1: 0.0233 Loss2: 0.0243 Loss3: 0.0189\n",
            "Epoch: 208 MAE: 0.012302208662269607 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:15:40.604625 Epoch [209/250], Step [0001/0060], Loss1: 0.0264 Loss2: 0.0236 Loss3: 0.0189\n",
            "2022-08-02 15:16:05.102683 Epoch [209/250], Step [0050/0060], Loss1: 0.0272 Loss2: 0.0291 Loss3: 0.0216\n",
            "2022-08-02 15:16:10.076450 Epoch [209/250], Step [0060/0060], Loss1: 0.0259 Loss2: 0.0273 Loss3: 0.0204\n",
            "Epoch: 209 MAE: 0.011871454756825215 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:16:15.523930 Epoch [210/250], Step [0001/0060], Loss1: 0.0291 Loss2: 0.0262 Loss3: 0.0212\n",
            "2022-08-02 15:16:40.045617 Epoch [210/250], Step [0050/0060], Loss1: 0.0298 Loss2: 0.0297 Loss3: 0.0225\n",
            "2022-08-02 15:16:45.056380 Epoch [210/250], Step [0060/0060], Loss1: 0.0249 Loss2: 0.0239 Loss3: 0.0185\n",
            "Epoch: 210 MAE: 0.01195121140381883 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:16:53.223034 Epoch [211/250], Step [0001/0060], Loss1: 0.0260 Loss2: 0.0247 Loss3: 0.0198\n",
            "2022-08-02 15:17:17.596926 Epoch [211/250], Step [0050/0060], Loss1: 0.0233 Loss2: 0.0244 Loss3: 0.0185\n",
            "2022-08-02 15:17:22.546117 Epoch [211/250], Step [0060/0060], Loss1: 0.0278 Loss2: 0.0243 Loss3: 0.0199\n",
            "Epoch: 211 MAE: 0.012239495211000007 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:17:27.874161 Epoch [212/250], Step [0001/0060], Loss1: 0.0232 Loss2: 0.0251 Loss3: 0.0188\n",
            "2022-08-02 15:17:52.314812 Epoch [212/250], Step [0050/0060], Loss1: 0.0239 Loss2: 0.0243 Loss3: 0.0184\n",
            "2022-08-02 15:17:57.317851 Epoch [212/250], Step [0060/0060], Loss1: 0.0282 Loss2: 0.0262 Loss3: 0.0209\n",
            "Epoch: 212 MAE: 0.012127045970705767 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:18:02.665247 Epoch [213/250], Step [0001/0060], Loss1: 0.0274 Loss2: 0.0277 Loss3: 0.0208\n",
            "2022-08-02 15:18:27.075643 Epoch [213/250], Step [0050/0060], Loss1: 0.0268 Loss2: 0.0268 Loss3: 0.0205\n",
            "2022-08-02 15:18:32.027168 Epoch [213/250], Step [0060/0060], Loss1: 0.0234 Loss2: 0.0261 Loss3: 0.0194\n",
            "Epoch: 213 MAE: 0.012253407093267592 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:18:37.330775 Epoch [214/250], Step [0001/0060], Loss1: 0.0267 Loss2: 0.0274 Loss3: 0.0204\n",
            "2022-08-02 15:19:01.612122 Epoch [214/250], Step [0050/0060], Loss1: 0.0220 Loss2: 0.0246 Loss3: 0.0184\n",
            "2022-08-02 15:19:06.572472 Epoch [214/250], Step [0060/0060], Loss1: 0.0245 Loss2: 0.0262 Loss3: 0.0197\n",
            "Epoch: 214 MAE: 0.01204517259011193 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:19:12.003253 Epoch [215/250], Step [0001/0060], Loss1: 0.0237 Loss2: 0.0255 Loss3: 0.0190\n",
            "2022-08-02 15:19:36.478948 Epoch [215/250], Step [0050/0060], Loss1: 0.0281 Loss2: 0.0274 Loss3: 0.0211\n",
            "2022-08-02 15:19:41.479280 Epoch [215/250], Step [0060/0060], Loss1: 0.0238 Loss2: 0.0254 Loss3: 0.0190\n",
            "Epoch: 215 MAE: 0.012233926567234217 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:19:48.911491 Epoch [216/250], Step [0001/0060], Loss1: 0.0259 Loss2: 0.0255 Loss3: 0.0198\n",
            "2022-08-02 15:20:13.480035 Epoch [216/250], Step [0050/0060], Loss1: 0.0236 Loss2: 0.0240 Loss3: 0.0184\n",
            "2022-08-02 15:20:18.444552 Epoch [216/250], Step [0060/0060], Loss1: 0.0248 Loss2: 0.0263 Loss3: 0.0196\n",
            "Epoch: 216 MAE: 0.012016734034414328 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:20:23.745642 Epoch [217/250], Step [0001/0060], Loss1: 0.0249 Loss2: 0.0269 Loss3: 0.0201\n",
            "2022-08-02 15:20:48.087218 Epoch [217/250], Step [0050/0060], Loss1: 0.0255 Loss2: 0.0263 Loss3: 0.0201\n",
            "2022-08-02 15:20:53.079529 Epoch [217/250], Step [0060/0060], Loss1: 0.0240 Loss2: 0.0249 Loss3: 0.0191\n",
            "Epoch: 217 MAE: 0.01205932017829683 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:20:58.460958 Epoch [218/250], Step [0001/0060], Loss1: 0.0252 Loss2: 0.0272 Loss3: 0.0198\n",
            "2022-08-02 15:21:22.967123 Epoch [218/250], Step [0050/0060], Loss1: 0.0277 Loss2: 0.0271 Loss3: 0.0212\n",
            "2022-08-02 15:21:28.007585 Epoch [218/250], Step [0060/0060], Loss1: 0.0282 Loss2: 0.0264 Loss3: 0.0206\n",
            "Epoch: 218 MAE: 0.012142425550827904 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:21:33.529486 Epoch [219/250], Step [0001/0060], Loss1: 0.0243 Loss2: 0.0252 Loss3: 0.0198\n",
            "2022-08-02 15:21:57.969719 Epoch [219/250], Step [0050/0060], Loss1: 0.0280 Loss2: 0.0258 Loss3: 0.0205\n",
            "2022-08-02 15:22:02.970077 Epoch [219/250], Step [0060/0060], Loss1: 0.0243 Loss2: 0.0256 Loss3: 0.0193\n",
            "Epoch: 219 MAE: 0.012127859096619346 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:22:08.247868 Epoch [220/250], Step [0001/0060], Loss1: 0.0240 Loss2: 0.0243 Loss3: 0.0187\n",
            "2022-08-02 15:22:32.590693 Epoch [220/250], Step [0050/0060], Loss1: 0.0255 Loss2: 0.0242 Loss3: 0.0189\n",
            "2022-08-02 15:22:37.584708 Epoch [220/250], Step [0060/0060], Loss1: 0.0263 Loss2: 0.0244 Loss3: 0.0196\n",
            "Epoch: 220 MAE: 0.012248262341710784 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:22:45.051537 Epoch [221/250], Step [0001/0060], Loss1: 0.0252 Loss2: 0.0263 Loss3: 0.0198\n",
            "2022-08-02 15:23:09.562663 Epoch [221/250], Step [0050/0060], Loss1: 0.0233 Loss2: 0.0253 Loss3: 0.0191\n",
            "2022-08-02 15:23:14.520123 Epoch [221/250], Step [0060/0060], Loss1: 0.0254 Loss2: 0.0255 Loss3: 0.0199\n",
            "Epoch: 221 MAE: 0.011823067330710944 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:23:19.778357 Epoch [222/250], Step [0001/0060], Loss1: 0.0267 Loss2: 0.0279 Loss3: 0.0209\n",
            "2022-08-02 15:23:44.118528 Epoch [222/250], Step [0050/0060], Loss1: 0.0258 Loss2: 0.0264 Loss3: 0.0202\n",
            "2022-08-02 15:23:49.059463 Epoch [222/250], Step [0060/0060], Loss1: 0.0248 Loss2: 0.0267 Loss3: 0.0195\n",
            "Epoch: 222 MAE: 0.012026719660276458 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:23:54.460442 Epoch [223/250], Step [0001/0060], Loss1: 0.0273 Loss2: 0.0285 Loss3: 0.0209\n",
            "2022-08-02 15:24:18.910578 Epoch [223/250], Step [0050/0060], Loss1: 0.0243 Loss2: 0.0248 Loss3: 0.0190\n",
            "2022-08-02 15:24:23.898135 Epoch [223/250], Step [0060/0060], Loss1: 0.0252 Loss2: 0.0261 Loss3: 0.0200\n",
            "Epoch: 223 MAE: 0.012308456461935763 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:24:29.171232 Epoch [224/250], Step [0001/0060], Loss1: 0.0279 Loss2: 0.0273 Loss3: 0.0207\n",
            "2022-08-02 15:24:53.539669 Epoch [224/250], Step [0050/0060], Loss1: 0.0276 Loss2: 0.0272 Loss3: 0.0209\n",
            "2022-08-02 15:24:58.536287 Epoch [224/250], Step [0060/0060], Loss1: 0.0283 Loss2: 0.0253 Loss3: 0.0206\n",
            "Epoch: 224 MAE: 0.012404292112305051 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:25:03.906985 Epoch [225/250], Step [0001/0060], Loss1: 0.0248 Loss2: 0.0249 Loss3: 0.0193\n",
            "2022-08-02 15:25:28.345069 Epoch [225/250], Step [0050/0060], Loss1: 0.0269 Loss2: 0.0268 Loss3: 0.0206\n",
            "2022-08-02 15:25:33.324903 Epoch [225/250], Step [0060/0060], Loss1: 0.0226 Loss2: 0.0229 Loss3: 0.0176\n",
            "Epoch: 225 MAE: 0.012072324457149657 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:25:40.839875 Epoch [226/250], Step [0001/0060], Loss1: 0.0215 Loss2: 0.0237 Loss3: 0.0175\n",
            "2022-08-02 15:26:05.481488 Epoch [226/250], Step [0050/0060], Loss1: 0.0251 Loss2: 0.0268 Loss3: 0.0199\n",
            "2022-08-02 15:26:10.442236 Epoch [226/250], Step [0060/0060], Loss1: 0.0250 Loss2: 0.0261 Loss3: 0.0200\n",
            "Epoch: 226 MAE: 0.01192430675118452 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:26:15.824412 Epoch [227/250], Step [0001/0060], Loss1: 0.0263 Loss2: 0.0280 Loss3: 0.0211\n",
            "2022-08-02 15:26:40.141741 Epoch [227/250], Step [0050/0060], Loss1: 0.0276 Loss2: 0.0254 Loss3: 0.0200\n",
            "2022-08-02 15:26:45.094167 Epoch [227/250], Step [0060/0060], Loss1: 0.0291 Loss2: 0.0289 Loss3: 0.0220\n",
            "Epoch: 227 MAE: 0.012090461380365822 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:26:50.438288 Epoch [228/250], Step [0001/0060], Loss1: 0.0270 Loss2: 0.0261 Loss3: 0.0200\n",
            "2022-08-02 15:27:14.981505 Epoch [228/250], Step [0050/0060], Loss1: 0.0263 Loss2: 0.0273 Loss3: 0.0207\n",
            "2022-08-02 15:27:19.993240 Epoch [228/250], Step [0060/0060], Loss1: 0.0249 Loss2: 0.0252 Loss3: 0.0196\n",
            "Epoch: 228 MAE: 0.012029335043200898 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:27:25.262737 Epoch [229/250], Step [0001/0060], Loss1: 0.0285 Loss2: 0.0285 Loss3: 0.0216\n",
            "2022-08-02 15:27:49.553989 Epoch [229/250], Step [0050/0060], Loss1: 0.0259 Loss2: 0.0268 Loss3: 0.0202\n",
            "2022-08-02 15:27:54.510391 Epoch [229/250], Step [0060/0060], Loss1: 0.0262 Loss2: 0.0274 Loss3: 0.0204\n",
            "Epoch: 229 MAE: 0.012269350086590127 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:27:59.844791 Epoch [230/250], Step [0001/0060], Loss1: 0.0266 Loss2: 0.0266 Loss3: 0.0202\n",
            "2022-08-02 15:28:24.207571 Epoch [230/250], Step [0050/0060], Loss1: 0.0241 Loss2: 0.0263 Loss3: 0.0193\n",
            "2022-08-02 15:28:29.154863 Epoch [230/250], Step [0060/0060], Loss1: 0.0269 Loss2: 0.0261 Loss3: 0.0205\n",
            "Epoch: 230 MAE: 0.012290807344788124 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:28:36.803456 Epoch [231/250], Step [0001/0060], Loss1: 0.0253 Loss2: 0.0275 Loss3: 0.0204\n",
            "2022-08-02 15:29:01.288967 Epoch [231/250], Step [0050/0060], Loss1: 0.0278 Loss2: 0.0266 Loss3: 0.0206\n",
            "2022-08-02 15:29:06.308267 Epoch [231/250], Step [0060/0060], Loss1: 0.0288 Loss2: 0.0300 Loss3: 0.0218\n",
            "Epoch: 231 MAE: 0.012051645148959424 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:29:11.584758 Epoch [232/250], Step [0001/0060], Loss1: 0.0230 Loss2: 0.0256 Loss3: 0.0188\n",
            "2022-08-02 15:29:36.011930 Epoch [232/250], Step [0050/0060], Loss1: 0.0270 Loss2: 0.0247 Loss3: 0.0195\n",
            "2022-08-02 15:29:40.989069 Epoch [232/250], Step [0060/0060], Loss1: 0.0258 Loss2: 0.0276 Loss3: 0.0207\n",
            "Epoch: 232 MAE: 0.012015539716692671 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:29:46.311705 Epoch [233/250], Step [0001/0060], Loss1: 0.0232 Loss2: 0.0256 Loss3: 0.0187\n",
            "2022-08-02 15:30:10.582168 Epoch [233/250], Step [0050/0060], Loss1: 0.0285 Loss2: 0.0277 Loss3: 0.0214\n",
            "2022-08-02 15:30:15.601533 Epoch [233/250], Step [0060/0060], Loss1: 0.0249 Loss2: 0.0257 Loss3: 0.0198\n",
            "Epoch: 233 MAE: 0.012104280936043887 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:30:21.027650 Epoch [234/250], Step [0001/0060], Loss1: 0.0248 Loss2: 0.0280 Loss3: 0.0201\n",
            "2022-08-02 15:30:45.662752 Epoch [234/250], Step [0050/0060], Loss1: 0.0255 Loss2: 0.0260 Loss3: 0.0196\n",
            "2022-08-02 15:30:50.621556 Epoch [234/250], Step [0060/0060], Loss1: 0.0219 Loss2: 0.0256 Loss3: 0.0184\n",
            "Epoch: 234 MAE: 0.011944288801815774 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:30:56.020221 Epoch [235/250], Step [0001/0060], Loss1: 0.0256 Loss2: 0.0244 Loss3: 0.0193\n",
            "2022-08-02 15:31:20.588935 Epoch [235/250], Step [0050/0060], Loss1: 0.0282 Loss2: 0.0267 Loss3: 0.0210\n",
            "2022-08-02 15:31:25.557039 Epoch [235/250], Step [0060/0060], Loss1: 0.0300 Loss2: 0.0296 Loss3: 0.0228\n",
            "Epoch: 235 MAE: 0.011915675127908351 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:31:32.894984 Epoch [236/250], Step [0001/0060], Loss1: 0.0272 Loss2: 0.0285 Loss3: 0.0210\n",
            "2022-08-02 15:31:57.353171 Epoch [236/250], Step [0050/0060], Loss1: 0.0265 Loss2: 0.0263 Loss3: 0.0205\n",
            "2022-08-02 15:32:02.291363 Epoch [236/250], Step [0060/0060], Loss1: 0.0262 Loss2: 0.0263 Loss3: 0.0198\n",
            "Epoch: 236 MAE: 0.011848044529971149 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:32:07.567924 Epoch [237/250], Step [0001/0060], Loss1: 0.0234 Loss2: 0.0250 Loss3: 0.0187\n",
            "2022-08-02 15:32:32.387505 Epoch [237/250], Step [0050/0060], Loss1: 0.0254 Loss2: 0.0262 Loss3: 0.0199\n",
            "2022-08-02 15:32:37.341191 Epoch [237/250], Step [0060/0060], Loss1: 0.0255 Loss2: 0.0250 Loss3: 0.0195\n",
            "Epoch: 237 MAE: 0.012048880089192636 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:32:43.102825 Epoch [238/250], Step [0001/0060], Loss1: 0.0265 Loss2: 0.0285 Loss3: 0.0206\n",
            "2022-08-02 15:33:07.597751 Epoch [238/250], Step [0050/0060], Loss1: 0.0280 Loss2: 0.0264 Loss3: 0.0210\n",
            "2022-08-02 15:33:12.569711 Epoch [238/250], Step [0060/0060], Loss1: 0.0229 Loss2: 0.0251 Loss3: 0.0190\n",
            "Epoch: 238 MAE: 0.011929832443240144 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:33:17.812781 Epoch [239/250], Step [0001/0060], Loss1: 0.0254 Loss2: 0.0260 Loss3: 0.0198\n",
            "2022-08-02 15:33:42.102232 Epoch [239/250], Step [0050/0060], Loss1: 0.0278 Loss2: 0.0291 Loss3: 0.0210\n",
            "2022-08-02 15:33:47.070784 Epoch [239/250], Step [0060/0060], Loss1: 0.0260 Loss2: 0.0283 Loss3: 0.0207\n",
            "Epoch: 239 MAE: 0.012149218580729905 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:33:52.381837 Epoch [240/250], Step [0001/0060], Loss1: 0.0249 Loss2: 0.0260 Loss3: 0.0194\n",
            "2022-08-02 15:34:16.758634 Epoch [240/250], Step [0050/0060], Loss1: 0.0237 Loss2: 0.0241 Loss3: 0.0188\n",
            "2022-08-02 15:34:21.698658 Epoch [240/250], Step [0060/0060], Loss1: 0.0239 Loss2: 0.0253 Loss3: 0.0192\n",
            "Epoch: 240 MAE: 0.012143683937629537 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:34:29.148910 Epoch [241/250], Step [0001/0060], Loss1: 0.0284 Loss2: 0.0269 Loss3: 0.0213\n",
            "2022-08-02 15:34:53.781831 Epoch [241/250], Step [0050/0060], Loss1: 0.0224 Loss2: 0.0232 Loss3: 0.0181\n",
            "2022-08-02 15:34:58.736176 Epoch [241/250], Step [0060/0060], Loss1: 0.0264 Loss2: 0.0286 Loss3: 0.0210\n",
            "Epoch: 241 MAE: 0.011902365035244397 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:35:04.041860 Epoch [242/250], Step [0001/0060], Loss1: 0.0266 Loss2: 0.0263 Loss3: 0.0203\n",
            "2022-08-02 15:35:28.548009 Epoch [242/250], Step [0050/0060], Loss1: 0.0240 Loss2: 0.0242 Loss3: 0.0185\n",
            "2022-08-02 15:35:33.525238 Epoch [242/250], Step [0060/0060], Loss1: 0.0231 Loss2: 0.0250 Loss3: 0.0190\n",
            "Epoch: 242 MAE: 0.012183671721094658 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:35:38.869921 Epoch [243/250], Step [0001/0060], Loss1: 0.0243 Loss2: 0.0260 Loss3: 0.0195\n",
            "2022-08-02 15:36:03.252527 Epoch [243/250], Step [0050/0060], Loss1: 0.0240 Loss2: 0.0247 Loss3: 0.0189\n",
            "2022-08-02 15:36:08.201049 Epoch [243/250], Step [0060/0060], Loss1: 0.0274 Loss2: 0.0283 Loss3: 0.0213\n",
            "Epoch: 243 MAE: 0.012220781133879744 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:36:13.481759 Epoch [244/250], Step [0001/0060], Loss1: 0.0244 Loss2: 0.0281 Loss3: 0.0206\n",
            "2022-08-02 15:36:37.997539 Epoch [244/250], Step [0050/0060], Loss1: 0.0250 Loss2: 0.0244 Loss3: 0.0190\n",
            "2022-08-02 15:36:42.975090 Epoch [244/250], Step [0060/0060], Loss1: 0.0221 Loss2: 0.0231 Loss3: 0.0178\n",
            "Epoch: 244 MAE: 0.011841406927458824 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:36:48.284767 Epoch [245/250], Step [0001/0060], Loss1: 0.0246 Loss2: 0.0270 Loss3: 0.0199\n",
            "2022-08-02 15:37:12.570302 Epoch [245/250], Step [0050/0060], Loss1: 0.0264 Loss2: 0.0278 Loss3: 0.0206\n",
            "2022-08-02 15:37:17.540495 Epoch [245/250], Step [0060/0060], Loss1: 0.0263 Loss2: 0.0276 Loss3: 0.0206\n",
            "Epoch: 245 MAE: 0.011803562191152384 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:37:25.090653 Epoch [246/250], Step [0001/0060], Loss1: 0.0242 Loss2: 0.0273 Loss3: 0.0199\n",
            "2022-08-02 15:37:49.698805 Epoch [246/250], Step [0050/0060], Loss1: 0.0249 Loss2: 0.0256 Loss3: 0.0196\n",
            "2022-08-02 15:37:54.640350 Epoch [246/250], Step [0060/0060], Loss1: 0.0248 Loss2: 0.0275 Loss3: 0.0202\n",
            "Epoch: 246 MAE: 0.011946051204133602 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:38:00.163945 Epoch [247/250], Step [0001/0060], Loss1: 0.0273 Loss2: 0.0256 Loss3: 0.0205\n",
            "2022-08-02 15:38:24.575345 Epoch [247/250], Step [0050/0060], Loss1: 0.0238 Loss2: 0.0262 Loss3: 0.0196\n",
            "2022-08-02 15:38:29.569402 Epoch [247/250], Step [0060/0060], Loss1: 0.0239 Loss2: 0.0250 Loss3: 0.0189\n",
            "Epoch: 247 MAE: 0.011910990264917177 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:38:34.870657 Epoch [248/250], Step [0001/0060], Loss1: 0.0258 Loss2: 0.0253 Loss3: 0.0197\n",
            "2022-08-02 15:38:59.288125 Epoch [248/250], Step [0050/0060], Loss1: 0.0286 Loss2: 0.0276 Loss3: 0.0214\n",
            "2022-08-02 15:39:04.291837 Epoch [248/250], Step [0060/0060], Loss1: 0.0239 Loss2: 0.0240 Loss3: 0.0190\n",
            "Epoch: 248 MAE: 0.012135875832644246 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n",
            "2022-08-02 15:39:09.647711 Epoch [249/250], Step [0001/0060], Loss1: 0.0235 Loss2: 0.0258 Loss3: 0.0192\n",
            "2022-08-02 15:39:34.004487 Epoch [249/250], Step [0050/0060], Loss1: 0.0267 Loss2: 0.0275 Loss3: 0.0206\n",
            "2022-08-02 15:39:38.982315 Epoch [249/250], Step [0060/0060], Loss1: 0.0273 Loss2: 0.0280 Loss3: 0.0209\n",
            "Epoch: 249 MAE: 0.011937914394019615 ####  bestMAE: 0.011401212382470332 bestEpoch: 54\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from urllib.request import ProxyBasicAuthHandler\n",
        "import torch.nn.functional as nnf\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "\n",
        "#loss\n",
        "L1Loss = torch.nn.L1Loss()\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "train_accu = []\n",
        "train_losses = []\n",
        "train_accu1 = []\n",
        "train_accu2 = []\n",
        "train_accu3 = []\n",
        "train_losses1 = []\n",
        "train_losses2 = []\n",
        "train_losses3 = []\n",
        "val_accu = []\n",
        "val_losses = []\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    running_loss = 0\n",
        "    running_loss1 = 0\n",
        "    running_loss2 = 0\n",
        "    running_loss3 = 0\n",
        "    total = 0\n",
        "    total1 = 0\n",
        "    total2 = 0\n",
        "    total3 = 0\n",
        "    correct = 0\n",
        "    correct1 = 0\n",
        "    correct2 = 0\n",
        "    correct3 = 0\n",
        "\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = L1Loss(gts, pre_res[0]) \n",
        "            loss2    = L1Loss(gts, pre_res[1])\n",
        "            loss3    = L1Loss(gts, pre_res[2])\n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "\n",
        "            #loss graph\n",
        "            running_loss1 += loss1.item()\n",
        "            running_loss2 += loss2.item()\n",
        "            running_loss3 += loss3.item()\n",
        "            predicted1 = pre_res[0]\n",
        "            predicted2 = pre_res[1]\n",
        "            predicted3 = pre_res[2]\n",
        "            total1 += images.size(0)\n",
        "            total2 += gts.size(0)\n",
        "            total3 += depths.size(0)\n",
        "            #correct1 += float(torch.sum(predicted1 == gts.data))\n",
        "            #correct2 += float(torch.sum(predicted2 == gts.data))\n",
        "            #correct3 += float(torch.sum(predicted3 == gts.data))\n",
        "            correct1 += predicted1.eq(images).sum().item()\n",
        "            correct2 += predicted2.eq(gts).sum().item()\n",
        "            correct3 += predicted3.eq(depths).sum().item()\n",
        "\n",
        "            running_loss += loss_all.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = torch.sum(gt + loss + predicted)\n",
        "            total += images.size(0)\n",
        "            correct += float(correct1 + correct2 + correct3)\n",
        "            \n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "\n",
        "        train_loss = running_loss/len(train_loader)\n",
        "        train_loss1=running_loss1/len(train_loader)\n",
        "        train_loss2=running_loss2/len(train_loader)\n",
        "        train_loss3=running_loss3/len(train_loader)\n",
        "        accu1= correct1/total1\n",
        "        accu2= correct2/total2\n",
        "        accu3= correct3/total3 \n",
        "        accu = correct/total\n",
        "           \n",
        "        train_accu1.append(round(accu1, 3))\n",
        "        train_accu2.append(round(accu2, 3))\n",
        "        train_accu3.append(round(accu3, 3))\n",
        "        train_losses1.append(float(train_loss1))\n",
        "        train_losses2.append(float(train_loss2))\n",
        "        train_losses3.append(float(train_loss3))\n",
        "        train_accu.append(round(accu, 3))\n",
        "        train_losses.append(float(train_loss))\n",
        "\n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "           \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0.0\n",
        "\n",
        "    correct1 = 0.0\n",
        "    correct2 = 0.0\n",
        "    correct3 = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-4)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-4)\n",
        "            mae = np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "            mae = np.mean((gt - res)**2)\n",
        "            mae_sum += mae\n",
        "\n",
        "            #loss graph\n",
        "            running_loss += mae_sum\n",
        "            pre1, pre2, predicted = pre_res\n",
        "            #outputs = float(torch.sum(gt + depth + predicted))\n",
        "            total += test_loader.size\n",
        "\n",
        "            #correct1 += float(torch.sum(pre1 == image.data))\n",
        "            #correct2 += float(torch.sum(pre2 == image.data))\n",
        "            #correct3 += float(torch.sum(predicted == image.data))\n",
        "\n",
        "            correct += predicted.eq(image).sum().item()\n",
        "            #correct += float(torch.sum(predicted == image).item())\n",
        "\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "       \n",
        "        val_loss=running_loss/len(test_loader)\n",
        "        accu= 100 * correct/total\n",
        "        val_accu.append(round(accu, 3))\n",
        "        val_losses.append(float(val_loss))\n",
        "\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                #torch.save(model.state_dict(), save_path+'SPNet_epoch_best_Combine_Loss_only_with_RGB_as_depth.pth')\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_l1_loss.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n",
        "\n",
        "plt.plot(train_losses, '-')\n",
        "plt.plot(train_losses1,'-')\n",
        "plt.plot(train_losses2,'-')\n",
        "plt.plot(train_losses3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Combined_loss','Loss1', 'Loss2', 'Loss3'])\n",
        "plt.title('Train Losses')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_accu, '-')\n",
        "plt.plot(train_accu1,'-')\n",
        "plt.plot(train_accu2,'-')\n",
        "plt.plot(train_accu3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Acc')\n",
        "plt.legend(['Combined_Accuracy','Acc1', 'Acc2', 'Acc3'])\n",
        "plt.title('Train Accuracy')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(val_losses,'-')\n",
        "plt.plot(val_accu,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Losses','Accuracy'])\n",
        "plt.title('Test Losses and Accuracy')\n",
        " \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYonp-XUkQbC"
      },
      "source": [
        "### Training with L2 Loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGQ1tZ3AkT_j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4aab51725d094305b48b1e6ab82923f5",
            "f2bdf7d4bc154a1597accd674deff3cf",
            "96b77619610a444da3d2a37dd1c1cf9b",
            "8b929346dbda497a9a1b45994d4ba7d9",
            "d5ed82d93d574b4d96fb05969330b968",
            "4005bfc2243c485a9ecb69ef8f893de0",
            "03a2c64c771c4ac49fadd72fbedbe079",
            "f3edab5e7c41407e9b36940f85212a6d",
            "ec57cbd665a0402997c9107e3731f6fb",
            "44f6b8c32ea144f8b52f063cbc7c01c2",
            "e7f4eeabae814a58907ad9eb10f7becb"
          ]
        },
        "outputId": "19ad9f0a-d53c-4c11-de1b-a2ef15bde112"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USE GPU 0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://shanghuagao.oss-cn-beijing.aliyuncs.com/res2net/res2net50_v1b_26w_4s-3cf99910.pth\" to /root/.cache/torch/hub/checkpoints/res2net50_v1b_26w_4s-3cf99910.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4aab51725d094305b48b1e6ab82923f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/98.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load data...\n",
            "/content/tmp/traindataset/RGB/ /content/tmp/traindataset/GT/ /content/tmp/traindataset/depth/\n",
            "/content/tmp/traindataset/RGB/ /content/tmp/traindataset/GT/ /content/tmp/traindataset/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/traindataset/RGB/RGB_00.png', '/content/tmp/traindataset/RGB/RGB_01.png', '/content/tmp/traindataset/RGB/RGB_02.png', '/content/tmp/traindataset/RGB/RGB_10.png', '/content/tmp/traindataset/RGB/RGB_100.png', '/content/tmp/traindataset/RGB/RGB_101.png', '/content/tmp/traindataset/RGB/RGB_102.png', '/content/tmp/traindataset/RGB/RGB_11.png', '/content/tmp/traindataset/RGB/RGB_110.png', '/content/tmp/traindataset/RGB/RGB_111.png', '/content/tmp/traindataset/RGB/RGB_112.png', '/content/tmp/traindataset/RGB/RGB_12.png', '/content/tmp/traindataset/RGB/RGB_120.png', '/content/tmp/traindataset/RGB/RGB_121.png', '/content/tmp/traindataset/RGB/RGB_122.png', '/content/tmp/traindataset/RGB/RGB_130.png', '/content/tmp/traindataset/RGB/RGB_131.png', '/content/tmp/traindataset/RGB/RGB_132.png', '/content/tmp/traindataset/RGB/RGB_140.png', '/content/tmp/traindataset/RGB/RGB_141.png', '/content/tmp/traindataset/RGB/RGB_142.png', '/content/tmp/traindataset/RGB/RGB_150.png', '/content/tmp/traindataset/RGB/RGB_151.png', '/content/tmp/traindataset/RGB/RGB_152.png', '/content/tmp/traindataset/RGB/RGB_160.png', '/content/tmp/traindataset/RGB/RGB_161.png', '/content/tmp/traindataset/RGB/RGB_162.png', '/content/tmp/traindataset/RGB/RGB_170.png', '/content/tmp/traindataset/RGB/RGB_171.png', '/content/tmp/traindataset/RGB/RGB_172.png', '/content/tmp/traindataset/RGB/RGB_180.png', '/content/tmp/traindataset/RGB/RGB_181.png', '/content/tmp/traindataset/RGB/RGB_182.png', '/content/tmp/traindataset/RGB/RGB_190.png', '/content/tmp/traindataset/RGB/RGB_191.png', '/content/tmp/traindataset/RGB/RGB_192.png', '/content/tmp/traindataset/RGB/RGB_20.png', '/content/tmp/traindataset/RGB/RGB_200.png', '/content/tmp/traindataset/RGB/RGB_201.png', '/content/tmp/traindataset/RGB/RGB_202.png', '/content/tmp/traindataset/RGB/RGB_21.png', '/content/tmp/traindataset/RGB/RGB_210.png', '/content/tmp/traindataset/RGB/RGB_211.png', '/content/tmp/traindataset/RGB/RGB_212.png', '/content/tmp/traindataset/RGB/RGB_22.png', '/content/tmp/traindataset/RGB/RGB_220.png', '/content/tmp/traindataset/RGB/RGB_221.png', '/content/tmp/traindataset/RGB/RGB_222.png', '/content/tmp/traindataset/RGB/RGB_230.png', '/content/tmp/traindataset/RGB/RGB_231.png', '/content/tmp/traindataset/RGB/RGB_232.png', '/content/tmp/traindataset/RGB/RGB_240.png', '/content/tmp/traindataset/RGB/RGB_241.png', '/content/tmp/traindataset/RGB/RGB_242.png', '/content/tmp/traindataset/RGB/RGB_250.png', '/content/tmp/traindataset/RGB/RGB_251.png', '/content/tmp/traindataset/RGB/RGB_252.png', '/content/tmp/traindataset/RGB/RGB_260.png', '/content/tmp/traindataset/RGB/RGB_261.png', '/content/tmp/traindataset/RGB/RGB_262.png', '/content/tmp/traindataset/RGB/RGB_270.png', '/content/tmp/traindataset/RGB/RGB_271.png', '/content/tmp/traindataset/RGB/RGB_272.png', '/content/tmp/traindataset/RGB/RGB_280.png', '/content/tmp/traindataset/RGB/RGB_281.png', '/content/tmp/traindataset/RGB/RGB_282.png', '/content/tmp/traindataset/RGB/RGB_290.png', '/content/tmp/traindataset/RGB/RGB_291.png', '/content/tmp/traindataset/RGB/RGB_292.png', '/content/tmp/traindataset/RGB/RGB_30.png', '/content/tmp/traindataset/RGB/RGB_300.png', '/content/tmp/traindataset/RGB/RGB_301.png', '/content/tmp/traindataset/RGB/RGB_302.png', '/content/tmp/traindataset/RGB/RGB_31.png', '/content/tmp/traindataset/RGB/RGB_310.png', '/content/tmp/traindataset/RGB/RGB_311.png', '/content/tmp/traindataset/RGB/RGB_312.png', '/content/tmp/traindataset/RGB/RGB_32.png', '/content/tmp/traindataset/RGB/RGB_320.png', '/content/tmp/traindataset/RGB/RGB_321.png', '/content/tmp/traindataset/RGB/RGB_322.png', '/content/tmp/traindataset/RGB/RGB_330.png', '/content/tmp/traindataset/RGB/RGB_331.png', '/content/tmp/traindataset/RGB/RGB_332.png', '/content/tmp/traindataset/RGB/RGB_340.png', '/content/tmp/traindataset/RGB/RGB_341.png', '/content/tmp/traindataset/RGB/RGB_342.png', '/content/tmp/traindataset/RGB/RGB_350.png', '/content/tmp/traindataset/RGB/RGB_351.png', '/content/tmp/traindataset/RGB/RGB_352.png', '/content/tmp/traindataset/RGB/RGB_360.png', '/content/tmp/traindataset/RGB/RGB_361.png', '/content/tmp/traindataset/RGB/RGB_362.png', '/content/tmp/traindataset/RGB/RGB_370.png', '/content/tmp/traindataset/RGB/RGB_371.png', '/content/tmp/traindataset/RGB/RGB_372.png', '/content/tmp/traindataset/RGB/RGB_380.png', '/content/tmp/traindataset/RGB/RGB_381.png', '/content/tmp/traindataset/RGB/RGB_382.png', '/content/tmp/traindataset/RGB/RGB_390.png', '/content/tmp/traindataset/RGB/RGB_391.png', '/content/tmp/traindataset/RGB/RGB_392.png', '/content/tmp/traindataset/RGB/RGB_40.png', '/content/tmp/traindataset/RGB/RGB_400.png', '/content/tmp/traindataset/RGB/RGB_401.png', '/content/tmp/traindataset/RGB/RGB_402.png', '/content/tmp/traindataset/RGB/RGB_41.png', '/content/tmp/traindataset/RGB/RGB_410.png', '/content/tmp/traindataset/RGB/RGB_411.png', '/content/tmp/traindataset/RGB/RGB_412.png', '/content/tmp/traindataset/RGB/RGB_42.png', '/content/tmp/traindataset/RGB/RGB_420.png', '/content/tmp/traindataset/RGB/RGB_421.png', '/content/tmp/traindataset/RGB/RGB_422.png', '/content/tmp/traindataset/RGB/RGB_430.png', '/content/tmp/traindataset/RGB/RGB_431.png', '/content/tmp/traindataset/RGB/RGB_432.png', '/content/tmp/traindataset/RGB/RGB_440.png', '/content/tmp/traindataset/RGB/RGB_441.png', '/content/tmp/traindataset/RGB/RGB_442.png', '/content/tmp/traindataset/RGB/RGB_450.png', '/content/tmp/traindataset/RGB/RGB_451.png', '/content/tmp/traindataset/RGB/RGB_452.png', '/content/tmp/traindataset/RGB/RGB_460.png', '/content/tmp/traindataset/RGB/RGB_461.png', '/content/tmp/traindataset/RGB/RGB_462.png', '/content/tmp/traindataset/RGB/RGB_470.png', '/content/tmp/traindataset/RGB/RGB_471.png', '/content/tmp/traindataset/RGB/RGB_472.png', '/content/tmp/traindataset/RGB/RGB_480.png', '/content/tmp/traindataset/RGB/RGB_481.png', '/content/tmp/traindataset/RGB/RGB_482.png', '/content/tmp/traindataset/RGB/RGB_490.png', '/content/tmp/traindataset/RGB/RGB_491.png', '/content/tmp/traindataset/RGB/RGB_492.png', '/content/tmp/traindataset/RGB/RGB_50.png', '/content/tmp/traindataset/RGB/RGB_500.png', '/content/tmp/traindataset/RGB/RGB_501.png', '/content/tmp/traindataset/RGB/RGB_502.png', '/content/tmp/traindataset/RGB/RGB_51.png', '/content/tmp/traindataset/RGB/RGB_510.png', '/content/tmp/traindataset/RGB/RGB_511.png', '/content/tmp/traindataset/RGB/RGB_512.png', '/content/tmp/traindataset/RGB/RGB_52.png', '/content/tmp/traindataset/RGB/RGB_520.png', '/content/tmp/traindataset/RGB/RGB_521.png', '/content/tmp/traindataset/RGB/RGB_522.png', '/content/tmp/traindataset/RGB/RGB_530.png', '/content/tmp/traindataset/RGB/RGB_531.png', '/content/tmp/traindataset/RGB/RGB_532.png', '/content/tmp/traindataset/RGB/RGB_540.png', '/content/tmp/traindataset/RGB/RGB_541.png', '/content/tmp/traindataset/RGB/RGB_542.png', '/content/tmp/traindataset/RGB/RGB_550.png', '/content/tmp/traindataset/RGB/RGB_551.png', '/content/tmp/traindataset/RGB/RGB_552.png', '/content/tmp/traindataset/RGB/RGB_560.png', '/content/tmp/traindataset/RGB/RGB_561.png', '/content/tmp/traindataset/RGB/RGB_562.png', '/content/tmp/traindataset/RGB/RGB_570.png', '/content/tmp/traindataset/RGB/RGB_571.png', '/content/tmp/traindataset/RGB/RGB_572.png', '/content/tmp/traindataset/RGB/RGB_580.png', '/content/tmp/traindataset/RGB/RGB_581.png', '/content/tmp/traindataset/RGB/RGB_582.png', '/content/tmp/traindataset/RGB/RGB_590.png', '/content/tmp/traindataset/RGB/RGB_591.png', '/content/tmp/traindataset/RGB/RGB_592.png', '/content/tmp/traindataset/RGB/RGB_60.png', '/content/tmp/traindataset/RGB/RGB_600.png', '/content/tmp/traindataset/RGB/RGB_601.png', '/content/tmp/traindataset/RGB/RGB_602.png', '/content/tmp/traindataset/RGB/RGB_61.png', '/content/tmp/traindataset/RGB/RGB_610.png', '/content/tmp/traindataset/RGB/RGB_611.png', '/content/tmp/traindataset/RGB/RGB_612.png', '/content/tmp/traindataset/RGB/RGB_62.png', '/content/tmp/traindataset/RGB/RGB_620.png', '/content/tmp/traindataset/RGB/RGB_621.png', '/content/tmp/traindataset/RGB/RGB_622.png', '/content/tmp/traindataset/RGB/RGB_630.png', '/content/tmp/traindataset/RGB/RGB_631.png', '/content/tmp/traindataset/RGB/RGB_632.png', '/content/tmp/traindataset/RGB/RGB_640.png', '/content/tmp/traindataset/RGB/RGB_641.png', '/content/tmp/traindataset/RGB/RGB_642.png', '/content/tmp/traindataset/RGB/RGB_650.png', '/content/tmp/traindataset/RGB/RGB_651.png', '/content/tmp/traindataset/RGB/RGB_652.png', '/content/tmp/traindataset/RGB/RGB_660.png', '/content/tmp/traindataset/RGB/RGB_661.png', '/content/tmp/traindataset/RGB/RGB_662.png', '/content/tmp/traindataset/RGB/RGB_670.png', '/content/tmp/traindataset/RGB/RGB_671.png', '/content/tmp/traindataset/RGB/RGB_672.png', '/content/tmp/traindataset/RGB/RGB_680.png', '/content/tmp/traindataset/RGB/RGB_681.png', '/content/tmp/traindataset/RGB/RGB_682.png', '/content/tmp/traindataset/RGB/RGB_690.png', '/content/tmp/traindataset/RGB/RGB_691.png', '/content/tmp/traindataset/RGB/RGB_692.png', '/content/tmp/traindataset/RGB/RGB_70.png', '/content/tmp/traindataset/RGB/RGB_700.png', '/content/tmp/traindataset/RGB/RGB_701.png', '/content/tmp/traindataset/RGB/RGB_702.png', '/content/tmp/traindataset/RGB/RGB_71.png', '/content/tmp/traindataset/RGB/RGB_710.png', '/content/tmp/traindataset/RGB/RGB_711.png', '/content/tmp/traindataset/RGB/RGB_712.png', '/content/tmp/traindataset/RGB/RGB_72.png', '/content/tmp/traindataset/RGB/RGB_720.png', '/content/tmp/traindataset/RGB/RGB_721.png', '/content/tmp/traindataset/RGB/RGB_722.png', '/content/tmp/traindataset/RGB/RGB_730.png', '/content/tmp/traindataset/RGB/RGB_731.png', '/content/tmp/traindataset/RGB/RGB_732.png', '/content/tmp/traindataset/RGB/RGB_740.png', '/content/tmp/traindataset/RGB/RGB_741.png', '/content/tmp/traindataset/RGB/RGB_742.png', '/content/tmp/traindataset/RGB/RGB_750.png', '/content/tmp/traindataset/RGB/RGB_751.png', '/content/tmp/traindataset/RGB/RGB_752.png', '/content/tmp/traindataset/RGB/RGB_760.png', '/content/tmp/traindataset/RGB/RGB_761.png', '/content/tmp/traindataset/RGB/RGB_762.png', '/content/tmp/traindataset/RGB/RGB_770.png', '/content/tmp/traindataset/RGB/RGB_771.png', '/content/tmp/traindataset/RGB/RGB_772.png', '/content/tmp/traindataset/RGB/RGB_780.png', '/content/tmp/traindataset/RGB/RGB_781.png', '/content/tmp/traindataset/RGB/RGB_782.png', '/content/tmp/traindataset/RGB/RGB_790.png', '/content/tmp/traindataset/RGB/RGB_791.png', '/content/tmp/traindataset/RGB/RGB_792.png', '/content/tmp/traindataset/RGB/RGB_80.png', '/content/tmp/traindataset/RGB/RGB_81.png', '/content/tmp/traindataset/RGB/RGB_82.png', '/content/tmp/traindataset/RGB/RGB_90.png', '/content/tmp/traindataset/RGB/RGB_91.png', '/content/tmp/traindataset/RGB/RGB_92.png'] ['/content/tmp/traindataset/GT/GT_00.png', '/content/tmp/traindataset/GT/GT_01.png', '/content/tmp/traindataset/GT/GT_02.png', '/content/tmp/traindataset/GT/GT_10.png', '/content/tmp/traindataset/GT/GT_100.png', '/content/tmp/traindataset/GT/GT_101.png', '/content/tmp/traindataset/GT/GT_102.png', '/content/tmp/traindataset/GT/GT_11.png', '/content/tmp/traindataset/GT/GT_110.png', '/content/tmp/traindataset/GT/GT_111.png', '/content/tmp/traindataset/GT/GT_112.png', '/content/tmp/traindataset/GT/GT_12.png', '/content/tmp/traindataset/GT/GT_120.png', '/content/tmp/traindataset/GT/GT_121.png', '/content/tmp/traindataset/GT/GT_122.png', '/content/tmp/traindataset/GT/GT_130.png', '/content/tmp/traindataset/GT/GT_131.png', '/content/tmp/traindataset/GT/GT_132.png', '/content/tmp/traindataset/GT/GT_140.png', '/content/tmp/traindataset/GT/GT_141.png', '/content/tmp/traindataset/GT/GT_142.png', '/content/tmp/traindataset/GT/GT_150.png', '/content/tmp/traindataset/GT/GT_151.png', '/content/tmp/traindataset/GT/GT_152.png', '/content/tmp/traindataset/GT/GT_160.png', '/content/tmp/traindataset/GT/GT_161.png', '/content/tmp/traindataset/GT/GT_162.png', '/content/tmp/traindataset/GT/GT_170.png', '/content/tmp/traindataset/GT/GT_171.png', '/content/tmp/traindataset/GT/GT_172.png', '/content/tmp/traindataset/GT/GT_180.png', '/content/tmp/traindataset/GT/GT_181.png', '/content/tmp/traindataset/GT/GT_182.png', '/content/tmp/traindataset/GT/GT_190.png', '/content/tmp/traindataset/GT/GT_191.png', '/content/tmp/traindataset/GT/GT_192.png', '/content/tmp/traindataset/GT/GT_20.png', '/content/tmp/traindataset/GT/GT_200.png', '/content/tmp/traindataset/GT/GT_201.png', '/content/tmp/traindataset/GT/GT_202.png', '/content/tmp/traindataset/GT/GT_21.png', '/content/tmp/traindataset/GT/GT_210.png', '/content/tmp/traindataset/GT/GT_211.png', '/content/tmp/traindataset/GT/GT_212.png', '/content/tmp/traindataset/GT/GT_22.png', '/content/tmp/traindataset/GT/GT_220.png', '/content/tmp/traindataset/GT/GT_221.png', '/content/tmp/traindataset/GT/GT_222.png', '/content/tmp/traindataset/GT/GT_230.png', '/content/tmp/traindataset/GT/GT_231.png', '/content/tmp/traindataset/GT/GT_232.png', '/content/tmp/traindataset/GT/GT_240.png', '/content/tmp/traindataset/GT/GT_241.png', '/content/tmp/traindataset/GT/GT_242.png', '/content/tmp/traindataset/GT/GT_250.png', '/content/tmp/traindataset/GT/GT_251.png', '/content/tmp/traindataset/GT/GT_252.png', '/content/tmp/traindataset/GT/GT_260.png', '/content/tmp/traindataset/GT/GT_261.png', '/content/tmp/traindataset/GT/GT_262.png', '/content/tmp/traindataset/GT/GT_270.png', '/content/tmp/traindataset/GT/GT_271.png', '/content/tmp/traindataset/GT/GT_272.png', '/content/tmp/traindataset/GT/GT_280.png', '/content/tmp/traindataset/GT/GT_281.png', '/content/tmp/traindataset/GT/GT_282.png', '/content/tmp/traindataset/GT/GT_290.png', '/content/tmp/traindataset/GT/GT_291.png', '/content/tmp/traindataset/GT/GT_292.png', '/content/tmp/traindataset/GT/GT_30.png', '/content/tmp/traindataset/GT/GT_300.png', '/content/tmp/traindataset/GT/GT_301.png', '/content/tmp/traindataset/GT/GT_302.png', '/content/tmp/traindataset/GT/GT_31.png', '/content/tmp/traindataset/GT/GT_310.png', '/content/tmp/traindataset/GT/GT_311.png', '/content/tmp/traindataset/GT/GT_312.png', '/content/tmp/traindataset/GT/GT_32.png', '/content/tmp/traindataset/GT/GT_320.png', '/content/tmp/traindataset/GT/GT_321.png', '/content/tmp/traindataset/GT/GT_322.png', '/content/tmp/traindataset/GT/GT_330.png', '/content/tmp/traindataset/GT/GT_331.png', '/content/tmp/traindataset/GT/GT_332.png', '/content/tmp/traindataset/GT/GT_340.png', '/content/tmp/traindataset/GT/GT_341.png', '/content/tmp/traindataset/GT/GT_342.png', '/content/tmp/traindataset/GT/GT_350.png', '/content/tmp/traindataset/GT/GT_351.png', '/content/tmp/traindataset/GT/GT_352.png', '/content/tmp/traindataset/GT/GT_360.png', '/content/tmp/traindataset/GT/GT_361.png', '/content/tmp/traindataset/GT/GT_362.png', '/content/tmp/traindataset/GT/GT_370.png', '/content/tmp/traindataset/GT/GT_371.png', '/content/tmp/traindataset/GT/GT_372.png', '/content/tmp/traindataset/GT/GT_380.png', '/content/tmp/traindataset/GT/GT_381.png', '/content/tmp/traindataset/GT/GT_382.png', '/content/tmp/traindataset/GT/GT_390.png', '/content/tmp/traindataset/GT/GT_391.png', '/content/tmp/traindataset/GT/GT_392.png', '/content/tmp/traindataset/GT/GT_40.png', '/content/tmp/traindataset/GT/GT_400.png', '/content/tmp/traindataset/GT/GT_401.png', '/content/tmp/traindataset/GT/GT_402.png', '/content/tmp/traindataset/GT/GT_41.png', '/content/tmp/traindataset/GT/GT_410.png', '/content/tmp/traindataset/GT/GT_411.png', '/content/tmp/traindataset/GT/GT_412.png', '/content/tmp/traindataset/GT/GT_42.png', '/content/tmp/traindataset/GT/GT_420.png', '/content/tmp/traindataset/GT/GT_421.png', '/content/tmp/traindataset/GT/GT_422.png', '/content/tmp/traindataset/GT/GT_430.png', '/content/tmp/traindataset/GT/GT_431.png', '/content/tmp/traindataset/GT/GT_432.png', '/content/tmp/traindataset/GT/GT_440.png', '/content/tmp/traindataset/GT/GT_441.png', '/content/tmp/traindataset/GT/GT_442.png', '/content/tmp/traindataset/GT/GT_450.png', '/content/tmp/traindataset/GT/GT_451.png', '/content/tmp/traindataset/GT/GT_452.png', '/content/tmp/traindataset/GT/GT_460.png', '/content/tmp/traindataset/GT/GT_461.png', '/content/tmp/traindataset/GT/GT_462.png', '/content/tmp/traindataset/GT/GT_470.png', '/content/tmp/traindataset/GT/GT_471.png', '/content/tmp/traindataset/GT/GT_472.png', '/content/tmp/traindataset/GT/GT_480.png', '/content/tmp/traindataset/GT/GT_481.png', '/content/tmp/traindataset/GT/GT_482.png', '/content/tmp/traindataset/GT/GT_490.png', '/content/tmp/traindataset/GT/GT_491.png', '/content/tmp/traindataset/GT/GT_492.png', '/content/tmp/traindataset/GT/GT_50.png', '/content/tmp/traindataset/GT/GT_500.png', '/content/tmp/traindataset/GT/GT_501.png', '/content/tmp/traindataset/GT/GT_502.png', '/content/tmp/traindataset/GT/GT_51.png', '/content/tmp/traindataset/GT/GT_510.png', '/content/tmp/traindataset/GT/GT_511.png', '/content/tmp/traindataset/GT/GT_512.png', '/content/tmp/traindataset/GT/GT_52.png', '/content/tmp/traindataset/GT/GT_520.png', '/content/tmp/traindataset/GT/GT_521.png', '/content/tmp/traindataset/GT/GT_522.png', '/content/tmp/traindataset/GT/GT_530.png', '/content/tmp/traindataset/GT/GT_531.png', '/content/tmp/traindataset/GT/GT_532.png', '/content/tmp/traindataset/GT/GT_540.png', '/content/tmp/traindataset/GT/GT_541.png', '/content/tmp/traindataset/GT/GT_542.png', '/content/tmp/traindataset/GT/GT_550.png', '/content/tmp/traindataset/GT/GT_551.png', '/content/tmp/traindataset/GT/GT_552.png', '/content/tmp/traindataset/GT/GT_560.png', '/content/tmp/traindataset/GT/GT_561.png', '/content/tmp/traindataset/GT/GT_562.png', '/content/tmp/traindataset/GT/GT_570.png', '/content/tmp/traindataset/GT/GT_571.png', '/content/tmp/traindataset/GT/GT_572.png', '/content/tmp/traindataset/GT/GT_580.png', '/content/tmp/traindataset/GT/GT_581.png', '/content/tmp/traindataset/GT/GT_582.png', '/content/tmp/traindataset/GT/GT_590.png', '/content/tmp/traindataset/GT/GT_591.png', '/content/tmp/traindataset/GT/GT_592.png', '/content/tmp/traindataset/GT/GT_60.png', '/content/tmp/traindataset/GT/GT_600.png', '/content/tmp/traindataset/GT/GT_601.png', '/content/tmp/traindataset/GT/GT_602.png', '/content/tmp/traindataset/GT/GT_61.png', '/content/tmp/traindataset/GT/GT_610.png', '/content/tmp/traindataset/GT/GT_611.png', '/content/tmp/traindataset/GT/GT_612.png', '/content/tmp/traindataset/GT/GT_62.png', '/content/tmp/traindataset/GT/GT_620.png', '/content/tmp/traindataset/GT/GT_621.png', '/content/tmp/traindataset/GT/GT_622.png', '/content/tmp/traindataset/GT/GT_630.png', '/content/tmp/traindataset/GT/GT_631.png', '/content/tmp/traindataset/GT/GT_632.png', '/content/tmp/traindataset/GT/GT_640.png', '/content/tmp/traindataset/GT/GT_641.png', '/content/tmp/traindataset/GT/GT_642.png', '/content/tmp/traindataset/GT/GT_650.png', '/content/tmp/traindataset/GT/GT_651.png', '/content/tmp/traindataset/GT/GT_652.png', '/content/tmp/traindataset/GT/GT_660.png', '/content/tmp/traindataset/GT/GT_661.png', '/content/tmp/traindataset/GT/GT_662.png', '/content/tmp/traindataset/GT/GT_670.png', '/content/tmp/traindataset/GT/GT_671.png', '/content/tmp/traindataset/GT/GT_672.png', '/content/tmp/traindataset/GT/GT_680.png', '/content/tmp/traindataset/GT/GT_681.png', '/content/tmp/traindataset/GT/GT_682.png', '/content/tmp/traindataset/GT/GT_690.png', '/content/tmp/traindataset/GT/GT_691.png', '/content/tmp/traindataset/GT/GT_692.png', '/content/tmp/traindataset/GT/GT_70.png', '/content/tmp/traindataset/GT/GT_700.png', '/content/tmp/traindataset/GT/GT_701.png', '/content/tmp/traindataset/GT/GT_702.png', '/content/tmp/traindataset/GT/GT_71.png', '/content/tmp/traindataset/GT/GT_710.png', '/content/tmp/traindataset/GT/GT_711.png', '/content/tmp/traindataset/GT/GT_712.png', '/content/tmp/traindataset/GT/GT_72.png', '/content/tmp/traindataset/GT/GT_720.png', '/content/tmp/traindataset/GT/GT_721.png', '/content/tmp/traindataset/GT/GT_722.png', '/content/tmp/traindataset/GT/GT_730.png', '/content/tmp/traindataset/GT/GT_731.png', '/content/tmp/traindataset/GT/GT_732.png', '/content/tmp/traindataset/GT/GT_740.png', '/content/tmp/traindataset/GT/GT_741.png', '/content/tmp/traindataset/GT/GT_742.png', '/content/tmp/traindataset/GT/GT_750.png', '/content/tmp/traindataset/GT/GT_751.png', '/content/tmp/traindataset/GT/GT_752.png', '/content/tmp/traindataset/GT/GT_760.png', '/content/tmp/traindataset/GT/GT_761.png', '/content/tmp/traindataset/GT/GT_762.png', '/content/tmp/traindataset/GT/GT_770.png', '/content/tmp/traindataset/GT/GT_771.png', '/content/tmp/traindataset/GT/GT_772.png', '/content/tmp/traindataset/GT/GT_780.png', '/content/tmp/traindataset/GT/GT_781.png', '/content/tmp/traindataset/GT/GT_782.png', '/content/tmp/traindataset/GT/GT_790.png', '/content/tmp/traindataset/GT/GT_791.png', '/content/tmp/traindataset/GT/GT_792.png', '/content/tmp/traindataset/GT/GT_80.png', '/content/tmp/traindataset/GT/GT_81.png', '/content/tmp/traindataset/GT/GT_82.png', '/content/tmp/traindataset/GT/GT_90.png', '/content/tmp/traindataset/GT/GT_91.png', '/content/tmp/traindataset/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7fab148dc850>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start train...\n",
            "2022-08-03 09:35:51.316715 Epoch [001/250], Step [0001/0060], Loss1: 0.2543 Loss2: 0.2936 Loss3: 0.2222\n",
            "2022-08-03 09:36:15.799959 Epoch [001/250], Step [0050/0060], Loss1: 0.0186 Loss2: 0.0149 Loss3: 0.0125\n",
            "2022-08-03 09:36:20.788220 Epoch [001/250], Step [0060/0060], Loss1: 0.0194 Loss2: 0.0141 Loss3: 0.0137\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 MAE: 0.08137671454321771 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-08-03 09:36:29.665010 Epoch [002/250], Step [0001/0060], Loss1: 0.0169 Loss2: 0.0118 Loss3: 0.0106\n",
            "2022-08-03 09:36:54.263880 Epoch [002/250], Step [0050/0060], Loss1: 0.0139 Loss2: 0.0100 Loss3: 0.0083\n",
            "2022-08-03 09:36:59.253550 Epoch [002/250], Step [0060/0060], Loss1: 0.0126 Loss2: 0.0086 Loss3: 0.0067\n",
            "Epoch: 2 MAE: 0.05887764550390698 ####  bestMAE: 0.08137671454321771 bestEpoch: 0\n",
            "best epoch:2\n",
            "2022-08-03 09:37:06.760345 Epoch [003/250], Step [0001/0060], Loss1: 0.0118 Loss2: 0.0087 Loss3: 0.0064\n",
            "2022-08-03 09:37:31.286859 Epoch [003/250], Step [0050/0060], Loss1: 0.0122 Loss2: 0.0087 Loss3: 0.0079\n",
            "2022-08-03 09:37:36.267495 Epoch [003/250], Step [0060/0060], Loss1: 0.0096 Loss2: 0.0074 Loss3: 0.0059\n",
            "Epoch: 3 MAE: 0.05628481767480335 ####  bestMAE: 0.05887764550390698 bestEpoch: 2\n",
            "best epoch:3\n",
            "2022-08-03 09:37:43.948809 Epoch [004/250], Step [0001/0060], Loss1: 0.0096 Loss2: 0.0070 Loss3: 0.0060\n",
            "2022-08-03 09:38:08.615868 Epoch [004/250], Step [0050/0060], Loss1: 0.0099 Loss2: 0.0057 Loss3: 0.0053\n",
            "2022-08-03 09:38:13.612529 Epoch [004/250], Step [0060/0060], Loss1: 0.0097 Loss2: 0.0067 Loss3: 0.0044\n",
            "Epoch: 4 MAE: 0.051815855656824415 ####  bestMAE: 0.05628481767480335 bestEpoch: 3\n",
            "best epoch:4\n",
            "2022-08-03 09:38:21.403806 Epoch [005/250], Step [0001/0060], Loss1: 0.0167 Loss2: 0.0099 Loss3: 0.0077\n",
            "2022-08-03 09:38:46.135680 Epoch [005/250], Step [0050/0060], Loss1: 0.0080 Loss2: 0.0068 Loss3: 0.0047\n",
            "2022-08-03 09:38:51.115507 Epoch [005/250], Step [0060/0060], Loss1: 0.0071 Loss2: 0.0058 Loss3: 0.0038\n",
            "Epoch: 5 MAE: 0.04839580118774422 ####  bestMAE: 0.051815855656824415 bestEpoch: 4\n",
            "best epoch:5\n",
            "2022-08-03 09:39:01.045772 Epoch [006/250], Step [0001/0060], Loss1: 0.0132 Loss2: 0.0087 Loss3: 0.0063\n",
            "2022-08-03 09:39:26.152105 Epoch [006/250], Step [0050/0060], Loss1: 0.0062 Loss2: 0.0054 Loss3: 0.0036\n",
            "2022-08-03 09:39:31.180836 Epoch [006/250], Step [0060/0060], Loss1: 0.0077 Loss2: 0.0058 Loss3: 0.0048\n",
            "Epoch: 6 MAE: 0.041154176588096315 ####  bestMAE: 0.04839580118774422 bestEpoch: 5\n",
            "best epoch:6\n",
            "2022-08-03 09:39:38.877613 Epoch [007/250], Step [0001/0060], Loss1: 0.0076 Loss2: 0.0058 Loss3: 0.0037\n",
            "2022-08-03 09:40:03.750496 Epoch [007/250], Step [0050/0060], Loss1: 0.0086 Loss2: 0.0053 Loss3: 0.0039\n",
            "2022-08-03 09:40:08.859207 Epoch [007/250], Step [0060/0060], Loss1: 0.0070 Loss2: 0.0057 Loss3: 0.0036\n",
            "Epoch: 7 MAE: 0.042814995768287824 ####  bestMAE: 0.041154176588096315 bestEpoch: 6\n",
            "2022-08-03 09:40:14.398160 Epoch [008/250], Step [0001/0060], Loss1: 0.0071 Loss2: 0.0047 Loss3: 0.0034\n",
            "2022-08-03 09:40:39.172715 Epoch [008/250], Step [0050/0060], Loss1: 0.0065 Loss2: 0.0052 Loss3: 0.0039\n",
            "2022-08-03 09:40:44.193181 Epoch [008/250], Step [0060/0060], Loss1: 0.0057 Loss2: 0.0060 Loss3: 0.0034\n",
            "Epoch: 8 MAE: 0.04051158402765554 ####  bestMAE: 0.041154176588096315 bestEpoch: 6\n",
            "best epoch:8\n",
            "2022-08-03 09:40:52.030650 Epoch [009/250], Step [0001/0060], Loss1: 0.0077 Loss2: 0.0060 Loss3: 0.0040\n",
            "2022-08-03 09:41:16.919848 Epoch [009/250], Step [0050/0060], Loss1: 0.0052 Loss2: 0.0045 Loss3: 0.0033\n",
            "2022-08-03 09:41:21.953921 Epoch [009/250], Step [0060/0060], Loss1: 0.0063 Loss2: 0.0044 Loss3: 0.0031\n",
            "Epoch: 9 MAE: 0.039952786077582646 ####  bestMAE: 0.04051158402765554 bestEpoch: 8\n",
            "best epoch:9\n",
            "2022-08-03 09:41:29.627337 Epoch [010/250], Step [0001/0060], Loss1: 0.0058 Loss2: 0.0051 Loss3: 0.0030\n",
            "2022-08-03 09:41:54.199415 Epoch [010/250], Step [0050/0060], Loss1: 0.0060 Loss2: 0.0053 Loss3: 0.0034\n",
            "2022-08-03 09:41:59.196868 Epoch [010/250], Step [0060/0060], Loss1: 0.0053 Loss2: 0.0045 Loss3: 0.0028\n",
            "Epoch: 10 MAE: 0.04185512898460267 ####  bestMAE: 0.039952786077582646 bestEpoch: 9\n",
            "2022-08-03 09:42:07.004710 Epoch [011/250], Step [0001/0060], Loss1: 0.0056 Loss2: 0.0044 Loss3: 0.0030\n",
            "2022-08-03 09:42:31.669515 Epoch [011/250], Step [0050/0060], Loss1: 0.0063 Loss2: 0.0046 Loss3: 0.0032\n",
            "2022-08-03 09:42:36.726521 Epoch [011/250], Step [0060/0060], Loss1: 0.0068 Loss2: 0.0044 Loss3: 0.0033\n",
            "Epoch: 11 MAE: 0.04092971888917779 ####  bestMAE: 0.039952786077582646 bestEpoch: 9\n",
            "2022-08-03 09:42:42.250869 Epoch [012/250], Step [0001/0060], Loss1: 0.0060 Loss2: 0.0051 Loss3: 0.0033\n",
            "2022-08-03 09:43:06.725465 Epoch [012/250], Step [0050/0060], Loss1: 0.0047 Loss2: 0.0042 Loss3: 0.0028\n",
            "2022-08-03 09:43:11.722677 Epoch [012/250], Step [0060/0060], Loss1: 0.0050 Loss2: 0.0049 Loss3: 0.0029\n",
            "Epoch: 12 MAE: 0.04057571005135301 ####  bestMAE: 0.039952786077582646 bestEpoch: 9\n",
            "2022-08-03 09:43:17.176503 Epoch [013/250], Step [0001/0060], Loss1: 0.0060 Loss2: 0.0043 Loss3: 0.0027\n",
            "2022-08-03 09:43:41.826297 Epoch [013/250], Step [0050/0060], Loss1: 0.0050 Loss2: 0.0047 Loss3: 0.0029\n",
            "2022-08-03 09:43:46.805531 Epoch [013/250], Step [0060/0060], Loss1: 0.0057 Loss2: 0.0035 Loss3: 0.0026\n",
            "Epoch: 13 MAE: 0.03509202951358424 ####  bestMAE: 0.039952786077582646 bestEpoch: 9\n",
            "best epoch:13\n",
            "2022-08-03 09:43:54.730512 Epoch [014/250], Step [0001/0060], Loss1: 0.0047 Loss2: 0.0037 Loss3: 0.0025\n",
            "2022-08-03 09:44:19.533338 Epoch [014/250], Step [0050/0060], Loss1: 0.0043 Loss2: 0.0034 Loss3: 0.0024\n",
            "2022-08-03 09:44:24.587385 Epoch [014/250], Step [0060/0060], Loss1: 0.0059 Loss2: 0.0045 Loss3: 0.0030\n",
            "Epoch: 14 MAE: 0.03602558489711512 ####  bestMAE: 0.03509202951358424 bestEpoch: 13\n",
            "2022-08-03 09:44:30.160407 Epoch [015/250], Step [0001/0060], Loss1: 0.0047 Loss2: 0.0038 Loss3: 0.0027\n",
            "2022-08-03 09:44:54.695602 Epoch [015/250], Step [0050/0060], Loss1: 0.0062 Loss2: 0.0038 Loss3: 0.0030\n",
            "2022-08-03 09:44:59.737633 Epoch [015/250], Step [0060/0060], Loss1: 0.0056 Loss2: 0.0031 Loss3: 0.0024\n",
            "Epoch: 15 MAE: 0.03530671899872167 ####  bestMAE: 0.03509202951358424 bestEpoch: 13\n",
            "2022-08-03 09:45:07.469770 Epoch [016/250], Step [0001/0060], Loss1: 0.0052 Loss2: 0.0036 Loss3: 0.0026\n",
            "2022-08-03 09:45:32.279559 Epoch [016/250], Step [0050/0060], Loss1: 0.0046 Loss2: 0.0039 Loss3: 0.0026\n",
            "2022-08-03 09:45:37.262532 Epoch [016/250], Step [0060/0060], Loss1: 0.0041 Loss2: 0.0040 Loss3: 0.0025\n",
            "Epoch: 16 MAE: 0.033260487980904085 ####  bestMAE: 0.03509202951358424 bestEpoch: 13\n",
            "best epoch:16\n",
            "2022-08-03 09:45:45.071979 Epoch [017/250], Step [0001/0060], Loss1: 0.0051 Loss2: 0.0034 Loss3: 0.0024\n",
            "2022-08-03 09:46:09.980887 Epoch [017/250], Step [0050/0060], Loss1: 0.0045 Loss2: 0.0041 Loss3: 0.0025\n",
            "2022-08-03 09:46:15.013941 Epoch [017/250], Step [0060/0060], Loss1: 0.0043 Loss2: 0.0043 Loss3: 0.0024\n",
            "Epoch: 17 MAE: 0.02939253288602072 ####  bestMAE: 0.033260487980904085 bestEpoch: 16\n",
            "best epoch:17\n",
            "2022-08-03 09:46:22.820182 Epoch [018/250], Step [0001/0060], Loss1: 0.0050 Loss2: 0.0036 Loss3: 0.0026\n",
            "2022-08-03 09:46:47.550760 Epoch [018/250], Step [0050/0060], Loss1: 0.0048 Loss2: 0.0040 Loss3: 0.0026\n",
            "2022-08-03 09:46:52.555533 Epoch [018/250], Step [0060/0060], Loss1: 0.0045 Loss2: 0.0034 Loss3: 0.0023\n",
            "Epoch: 18 MAE: 0.03184033967258911 ####  bestMAE: 0.02939253288602072 bestEpoch: 17\n",
            "2022-08-03 09:46:58.008235 Epoch [019/250], Step [0001/0060], Loss1: 0.0040 Loss2: 0.0036 Loss3: 0.0022\n",
            "2022-08-03 09:47:22.585764 Epoch [019/250], Step [0050/0060], Loss1: 0.0041 Loss2: 0.0033 Loss3: 0.0022\n",
            "2022-08-03 09:47:27.640769 Epoch [019/250], Step [0060/0060], Loss1: 0.0036 Loss2: 0.0032 Loss3: 0.0021\n",
            "Epoch: 19 MAE: 0.0287803958303162 ####  bestMAE: 0.02939253288602072 bestEpoch: 17\n",
            "best epoch:19\n",
            "2022-08-03 09:47:35.417663 Epoch [020/250], Step [0001/0060], Loss1: 0.0049 Loss2: 0.0039 Loss3: 0.0026\n",
            "2022-08-03 09:48:00.168823 Epoch [020/250], Step [0050/0060], Loss1: 0.0037 Loss2: 0.0032 Loss3: 0.0022\n",
            "2022-08-03 09:48:05.154210 Epoch [020/250], Step [0060/0060], Loss1: 0.0064 Loss2: 0.0035 Loss3: 0.0028\n",
            "Epoch: 20 MAE: 0.03062707098526141 ####  bestMAE: 0.0287803958303162 bestEpoch: 19\n",
            "2022-08-03 09:48:12.792843 Epoch [021/250], Step [0001/0060], Loss1: 0.0042 Loss2: 0.0040 Loss3: 0.0025\n",
            "2022-08-03 09:48:37.588674 Epoch [021/250], Step [0050/0060], Loss1: 0.0036 Loss2: 0.0040 Loss3: 0.0023\n",
            "2022-08-03 09:48:42.627218 Epoch [021/250], Step [0060/0060], Loss1: 0.0046 Loss2: 0.0031 Loss3: 0.0022\n",
            "Epoch: 21 MAE: 0.025827953207587438 ####  bestMAE: 0.0287803958303162 bestEpoch: 19\n",
            "best epoch:21\n",
            "2022-08-03 09:48:50.415179 Epoch [022/250], Step [0001/0060], Loss1: 0.0038 Loss2: 0.0031 Loss3: 0.0021\n",
            "2022-08-03 09:49:15.079346 Epoch [022/250], Step [0050/0060], Loss1: 0.0037 Loss2: 0.0030 Loss3: 0.0019\n",
            "2022-08-03 09:49:20.105993 Epoch [022/250], Step [0060/0060], Loss1: 0.0037 Loss2: 0.0027 Loss3: 0.0019\n",
            "Epoch: 22 MAE: 0.02572823278901596 ####  bestMAE: 0.025827953207587438 bestEpoch: 21\n",
            "best epoch:22\n",
            "2022-08-03 09:49:27.908287 Epoch [023/250], Step [0001/0060], Loss1: 0.0037 Loss2: 0.0030 Loss3: 0.0021\n",
            "2022-08-03 09:49:52.636558 Epoch [023/250], Step [0050/0060], Loss1: 0.0037 Loss2: 0.0040 Loss3: 0.0023\n",
            "2022-08-03 09:49:57.677941 Epoch [023/250], Step [0060/0060], Loss1: 0.0040 Loss2: 0.0036 Loss3: 0.0024\n",
            "Epoch: 23 MAE: 0.028072939372606694 ####  bestMAE: 0.02572823278901596 bestEpoch: 22\n",
            "2022-08-03 09:50:03.167477 Epoch [024/250], Step [0001/0060], Loss1: 0.0037 Loss2: 0.0028 Loss3: 0.0019\n",
            "2022-08-03 09:50:27.700464 Epoch [024/250], Step [0050/0060], Loss1: 0.0032 Loss2: 0.0029 Loss3: 0.0022\n",
            "2022-08-03 09:50:32.714174 Epoch [024/250], Step [0060/0060], Loss1: 0.0040 Loss2: 0.0032 Loss3: 0.0021\n",
            "Epoch: 24 MAE: 0.02516202906531001 ####  bestMAE: 0.02572823278901596 bestEpoch: 22\n",
            "best epoch:24\n",
            "2022-08-03 09:50:40.470772 Epoch [025/250], Step [0001/0060], Loss1: 0.0038 Loss2: 0.0033 Loss3: 0.0021\n",
            "2022-08-03 09:51:05.094764 Epoch [025/250], Step [0050/0060], Loss1: 0.0046 Loss2: 0.0034 Loss3: 0.0024\n",
            "2022-08-03 09:51:10.095784 Epoch [025/250], Step [0060/0060], Loss1: 0.0034 Loss2: 0.0029 Loss3: 0.0021\n",
            "Epoch: 25 MAE: 0.025463229784416775 ####  bestMAE: 0.02516202906531001 bestEpoch: 24\n",
            "2022-08-03 09:51:17.794137 Epoch [026/250], Step [0001/0060], Loss1: 0.0041 Loss2: 0.0030 Loss3: 0.0021\n",
            "2022-08-03 09:51:42.893242 Epoch [026/250], Step [0050/0060], Loss1: 0.0035 Loss2: 0.0038 Loss3: 0.0021\n",
            "2022-08-03 09:51:47.962954 Epoch [026/250], Step [0060/0060], Loss1: 0.0043 Loss2: 0.0032 Loss3: 0.0023\n",
            "Epoch: 26 MAE: 0.02642278303761804 ####  bestMAE: 0.02516202906531001 bestEpoch: 24\n",
            "2022-08-03 09:51:53.429855 Epoch [027/250], Step [0001/0060], Loss1: 0.0039 Loss2: 0.0041 Loss3: 0.0023\n",
            "2022-08-03 09:52:18.099654 Epoch [027/250], Step [0050/0060], Loss1: 0.0041 Loss2: 0.0039 Loss3: 0.0024\n",
            "2022-08-03 09:52:23.096799 Epoch [027/250], Step [0060/0060], Loss1: 0.0040 Loss2: 0.0027 Loss3: 0.0020\n",
            "Epoch: 27 MAE: 0.025897792540490627 ####  bestMAE: 0.02516202906531001 bestEpoch: 24\n",
            "2022-08-03 09:52:28.480440 Epoch [028/250], Step [0001/0060], Loss1: 0.0034 Loss2: 0.0026 Loss3: 0.0018\n",
            "2022-08-03 09:52:53.094215 Epoch [028/250], Step [0050/0060], Loss1: 0.0050 Loss2: 0.0032 Loss3: 0.0025\n",
            "2022-08-03 09:52:58.110513 Epoch [028/250], Step [0060/0060], Loss1: 0.0038 Loss2: 0.0032 Loss3: 0.0023\n",
            "Epoch: 28 MAE: 0.02607540694612359 ####  bestMAE: 0.02516202906531001 bestEpoch: 24\n",
            "2022-08-03 09:53:03.588592 Epoch [029/250], Step [0001/0060], Loss1: 0.0034 Loss2: 0.0032 Loss3: 0.0020\n",
            "2022-08-03 09:53:28.104093 Epoch [029/250], Step [0050/0060], Loss1: 0.0032 Loss2: 0.0030 Loss3: 0.0020\n",
            "2022-08-03 09:53:33.135775 Epoch [029/250], Step [0060/0060], Loss1: 0.0042 Loss2: 0.0027 Loss3: 0.0021\n",
            "Epoch: 29 MAE: 0.025200130772732553 ####  bestMAE: 0.02516202906531001 bestEpoch: 24\n",
            "2022-08-03 09:53:38.573513 Epoch [030/250], Step [0001/0060], Loss1: 0.0040 Loss2: 0.0029 Loss3: 0.0022\n",
            "2022-08-03 09:54:03.058395 Epoch [030/250], Step [0050/0060], Loss1: 0.0039 Loss2: 0.0029 Loss3: 0.0020\n",
            "2022-08-03 09:54:08.091728 Epoch [030/250], Step [0060/0060], Loss1: 0.0033 Loss2: 0.0027 Loss3: 0.0017\n",
            "Epoch: 30 MAE: 0.02283255857903333 ####  bestMAE: 0.02516202906531001 bestEpoch: 24\n",
            "best epoch:30\n",
            "2022-08-03 09:54:18.124907 Epoch [031/250], Step [0001/0060], Loss1: 0.0046 Loss2: 0.0033 Loss3: 0.0023\n",
            "2022-08-03 09:54:42.796150 Epoch [031/250], Step [0050/0060], Loss1: 0.0053 Loss2: 0.0034 Loss3: 0.0025\n",
            "2022-08-03 09:54:47.787726 Epoch [031/250], Step [0060/0060], Loss1: 0.0033 Loss2: 0.0029 Loss3: 0.0021\n",
            "Epoch: 31 MAE: 0.02461808259111075 ####  bestMAE: 0.02283255857903333 bestEpoch: 30\n",
            "2022-08-03 09:54:53.319319 Epoch [032/250], Step [0001/0060], Loss1: 0.0038 Loss2: 0.0032 Loss3: 0.0022\n",
            "2022-08-03 09:55:17.725054 Epoch [032/250], Step [0050/0060], Loss1: 0.0037 Loss2: 0.0035 Loss3: 0.0022\n",
            "2022-08-03 09:55:22.694460 Epoch [032/250], Step [0060/0060], Loss1: 0.0034 Loss2: 0.0033 Loss3: 0.0023\n",
            "Epoch: 32 MAE: 0.025396754920837424 ####  bestMAE: 0.02283255857903333 bestEpoch: 30\n",
            "2022-08-03 09:55:28.203457 Epoch [033/250], Step [0001/0060], Loss1: 0.0030 Loss2: 0.0029 Loss3: 0.0019\n",
            "2022-08-03 09:55:52.766418 Epoch [033/250], Step [0050/0060], Loss1: 0.0038 Loss2: 0.0034 Loss3: 0.0022\n",
            "2022-08-03 09:55:57.739802 Epoch [033/250], Step [0060/0060], Loss1: 0.0029 Loss2: 0.0029 Loss3: 0.0019\n",
            "Epoch: 33 MAE: 0.023381451499604043 ####  bestMAE: 0.02283255857903333 bestEpoch: 30\n",
            "2022-08-03 09:56:03.235554 Epoch [034/250], Step [0001/0060], Loss1: 0.0035 Loss2: 0.0031 Loss3: 0.0020\n",
            "2022-08-03 09:56:27.609582 Epoch [034/250], Step [0050/0060], Loss1: 0.0032 Loss2: 0.0030 Loss3: 0.0019\n",
            "2022-08-03 09:56:32.614756 Epoch [034/250], Step [0060/0060], Loss1: 0.0035 Loss2: 0.0030 Loss3: 0.0019\n",
            "Epoch: 34 MAE: 0.022531823003812443 ####  bestMAE: 0.02283255857903333 bestEpoch: 30\n",
            "best epoch:34\n",
            "2022-08-03 09:56:40.291135 Epoch [035/250], Step [0001/0060], Loss1: 0.0031 Loss2: 0.0029 Loss3: 0.0019\n",
            "2022-08-03 09:57:05.246215 Epoch [035/250], Step [0050/0060], Loss1: 0.0032 Loss2: 0.0033 Loss3: 0.0019\n",
            "2022-08-03 09:57:10.241080 Epoch [035/250], Step [0060/0060], Loss1: 0.0039 Loss2: 0.0026 Loss3: 0.0021\n",
            "Epoch: 35 MAE: 0.02195927632292585 ####  bestMAE: 0.022531823003812443 bestEpoch: 34\n",
            "best epoch:35\n",
            "2022-08-03 09:57:19.944281 Epoch [036/250], Step [0001/0060], Loss1: 0.0028 Loss2: 0.0026 Loss3: 0.0016\n",
            "2022-08-03 09:57:44.700277 Epoch [036/250], Step [0050/0060], Loss1: 0.0030 Loss2: 0.0030 Loss3: 0.0018\n",
            "2022-08-03 09:57:49.666561 Epoch [036/250], Step [0060/0060], Loss1: 0.0038 Loss2: 0.0031 Loss3: 0.0021\n",
            "Epoch: 36 MAE: 0.022394421554747083 ####  bestMAE: 0.02195927632292585 bestEpoch: 35\n",
            "2022-08-03 09:57:55.116798 Epoch [037/250], Step [0001/0060], Loss1: 0.0033 Loss2: 0.0029 Loss3: 0.0019\n",
            "2022-08-03 09:58:19.648105 Epoch [037/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0030 Loss3: 0.0019\n",
            "2022-08-03 09:58:24.667080 Epoch [037/250], Step [0060/0060], Loss1: 0.0035 Loss2: 0.0030 Loss3: 0.0019\n",
            "Epoch: 37 MAE: 0.021271479966503287 ####  bestMAE: 0.02195927632292585 bestEpoch: 35\n",
            "best epoch:37\n",
            "2022-08-03 09:58:32.366158 Epoch [038/250], Step [0001/0060], Loss1: 0.0031 Loss2: 0.0029 Loss3: 0.0018\n",
            "2022-08-03 09:58:56.958917 Epoch [038/250], Step [0050/0060], Loss1: 0.0031 Loss2: 0.0029 Loss3: 0.0018\n",
            "2022-08-03 09:59:01.953112 Epoch [038/250], Step [0060/0060], Loss1: 0.0027 Loss2: 0.0028 Loss3: 0.0018\n",
            "Epoch: 38 MAE: 0.022338132847041364 ####  bestMAE: 0.021271479966503287 bestEpoch: 37\n",
            "2022-08-03 09:59:07.325709 Epoch [039/250], Step [0001/0060], Loss1: 0.0032 Loss2: 0.0028 Loss3: 0.0018\n",
            "2022-08-03 09:59:31.805388 Epoch [039/250], Step [0050/0060], Loss1: 0.0030 Loss2: 0.0024 Loss3: 0.0017\n",
            "2022-08-03 09:59:36.764131 Epoch [039/250], Step [0060/0060], Loss1: 0.0034 Loss2: 0.0028 Loss3: 0.0019\n",
            "Epoch: 39 MAE: 0.02128923053128852 ####  bestMAE: 0.021271479966503287 bestEpoch: 37\n",
            "2022-08-03 09:59:42.244272 Epoch [040/250], Step [0001/0060], Loss1: 0.0030 Loss2: 0.0032 Loss3: 0.0020\n",
            "2022-08-03 10:00:06.751547 Epoch [040/250], Step [0050/0060], Loss1: 0.0036 Loss2: 0.0024 Loss3: 0.0018\n",
            "2022-08-03 10:00:11.722032 Epoch [040/250], Step [0060/0060], Loss1: 0.0033 Loss2: 0.0027 Loss3: 0.0018\n",
            "Epoch: 40 MAE: 0.02067554464179372 ####  bestMAE: 0.021271479966503287 bestEpoch: 37\n",
            "best epoch:40\n",
            "2022-08-03 10:00:21.538965 Epoch [041/250], Step [0001/0060], Loss1: 0.0035 Loss2: 0.0027 Loss3: 0.0018\n",
            "2022-08-03 10:00:46.378396 Epoch [041/250], Step [0050/0060], Loss1: 0.0029 Loss2: 0.0027 Loss3: 0.0017\n",
            "2022-08-03 10:00:51.366830 Epoch [041/250], Step [0060/0060], Loss1: 0.0029 Loss2: 0.0025 Loss3: 0.0016\n",
            "Epoch: 41 MAE: 0.022012837778126435 ####  bestMAE: 0.02067554464179372 bestEpoch: 40\n",
            "2022-08-03 10:00:56.816577 Epoch [042/250], Step [0001/0060], Loss1: 0.0028 Loss2: 0.0028 Loss3: 0.0018\n",
            "2022-08-03 10:01:21.450117 Epoch [042/250], Step [0050/0060], Loss1: 0.0035 Loss2: 0.0028 Loss3: 0.0018\n",
            "2022-08-03 10:01:26.513665 Epoch [042/250], Step [0060/0060], Loss1: 0.0035 Loss2: 0.0028 Loss3: 0.0019\n",
            "Epoch: 42 MAE: 0.020413095722832376 ####  bestMAE: 0.02067554464179372 bestEpoch: 40\n",
            "best epoch:42\n",
            "2022-08-03 10:01:34.166752 Epoch [043/250], Step [0001/0060], Loss1: 0.0030 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 10:01:58.859497 Epoch [043/250], Step [0050/0060], Loss1: 0.0033 Loss2: 0.0023 Loss3: 0.0019\n",
            "2022-08-03 10:02:03.833909 Epoch [043/250], Step [0060/0060], Loss1: 0.0035 Loss2: 0.0028 Loss3: 0.0019\n",
            "Epoch: 43 MAE: 0.020795556243568186 ####  bestMAE: 0.020413095722832376 bestEpoch: 42\n",
            "2022-08-03 10:02:09.303917 Epoch [044/250], Step [0001/0060], Loss1: 0.0030 Loss2: 0.0029 Loss3: 0.0019\n",
            "2022-08-03 10:02:33.802641 Epoch [044/250], Step [0050/0060], Loss1: 0.0039 Loss2: 0.0025 Loss3: 0.0019\n",
            "2022-08-03 10:02:38.807079 Epoch [044/250], Step [0060/0060], Loss1: 0.0030 Loss2: 0.0028 Loss3: 0.0018\n",
            "Epoch: 44 MAE: 0.020334769927320025 ####  bestMAE: 0.020413095722832376 bestEpoch: 42\n",
            "best epoch:44\n",
            "2022-08-03 10:02:46.566494 Epoch [045/250], Step [0001/0060], Loss1: 0.0038 Loss2: 0.0027 Loss3: 0.0020\n",
            "2022-08-03 10:03:11.506295 Epoch [045/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0026 Loss3: 0.0017\n",
            "2022-08-03 10:03:16.564307 Epoch [045/250], Step [0060/0060], Loss1: 0.0037 Loss2: 0.0031 Loss3: 0.0021\n",
            "Epoch: 45 MAE: 0.01725474489291036 ####  bestMAE: 0.020334769927320025 bestEpoch: 44\n",
            "best epoch:45\n",
            "2022-08-03 10:03:26.478300 Epoch [046/250], Step [0001/0060], Loss1: 0.0033 Loss2: 0.0026 Loss3: 0.0018\n",
            "2022-08-03 10:03:51.169462 Epoch [046/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0025 Loss3: 0.0018\n",
            "2022-08-03 10:03:56.143676 Epoch [046/250], Step [0060/0060], Loss1: 0.0032 Loss2: 0.0029 Loss3: 0.0020\n",
            "Epoch: 46 MAE: 0.019846808224443405 ####  bestMAE: 0.01725474489291036 bestEpoch: 45\n",
            "2022-08-03 10:04:01.477978 Epoch [047/250], Step [0001/0060], Loss1: 0.0035 Loss2: 0.0029 Loss3: 0.0019\n",
            "2022-08-03 10:04:26.097747 Epoch [047/250], Step [0050/0060], Loss1: 0.0034 Loss2: 0.0031 Loss3: 0.0020\n",
            "2022-08-03 10:04:31.144129 Epoch [047/250], Step [0060/0060], Loss1: 0.0027 Loss2: 0.0029 Loss3: 0.0018\n",
            "Epoch: 47 MAE: 0.018454667062513412 ####  bestMAE: 0.01725474489291036 bestEpoch: 45\n",
            "2022-08-03 10:04:36.608639 Epoch [048/250], Step [0001/0060], Loss1: 0.0030 Loss2: 0.0029 Loss3: 0.0019\n",
            "2022-08-03 10:05:01.073581 Epoch [048/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0025 Loss3: 0.0016\n",
            "2022-08-03 10:05:06.139295 Epoch [048/250], Step [0060/0060], Loss1: 0.0031 Loss2: 0.0026 Loss3: 0.0018\n",
            "Epoch: 48 MAE: 0.020420147386926508 ####  bestMAE: 0.01725474489291036 bestEpoch: 45\n",
            "2022-08-03 10:05:11.666439 Epoch [049/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 10:05:36.162663 Epoch [049/250], Step [0050/0060], Loss1: 0.0029 Loss2: 0.0026 Loss3: 0.0017\n",
            "2022-08-03 10:05:41.170285 Epoch [049/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0025 Loss3: 0.0015\n",
            "Epoch: 49 MAE: 0.019439833386549876 ####  bestMAE: 0.01725474489291036 bestEpoch: 45\n",
            "2022-08-03 10:05:46.642413 Epoch [050/250], Step [0001/0060], Loss1: 0.0029 Loss2: 0.0023 Loss3: 0.0016\n",
            "2022-08-03 10:06:11.253747 Epoch [050/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0024 Loss3: 0.0017\n",
            "2022-08-03 10:06:16.253604 Epoch [050/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0024 Loss3: 0.0016\n",
            "Epoch: 50 MAE: 0.01954164950265771 ####  bestMAE: 0.01725474489291036 bestEpoch: 45\n",
            "2022-08-03 10:06:23.891988 Epoch [051/250], Step [0001/0060], Loss1: 0.0031 Loss2: 0.0024 Loss3: 0.0017\n",
            "2022-08-03 10:06:48.703637 Epoch [051/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0025 Loss3: 0.0016\n",
            "2022-08-03 10:06:53.725651 Epoch [051/250], Step [0060/0060], Loss1: 0.0034 Loss2: 0.0025 Loss3: 0.0018\n",
            "Epoch: 51 MAE: 0.019456005270873742 ####  bestMAE: 0.01725474489291036 bestEpoch: 45\n",
            "2022-08-03 10:06:59.189209 Epoch [052/250], Step [0001/0060], Loss1: 0.0026 Loss2: 0.0027 Loss3: 0.0019\n",
            "2022-08-03 10:07:23.667047 Epoch [052/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0025 Loss3: 0.0016\n",
            "2022-08-03 10:07:28.683904 Epoch [052/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0024 Loss3: 0.0015\n",
            "Epoch: 52 MAE: 0.018541033897134993 ####  bestMAE: 0.01725474489291036 bestEpoch: 45\n",
            "2022-08-03 10:07:34.126074 Epoch [053/250], Step [0001/0060], Loss1: 0.0031 Loss2: 0.0027 Loss3: 0.0019\n",
            "2022-08-03 10:07:58.652584 Epoch [053/250], Step [0050/0060], Loss1: 0.0026 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 10:08:03.629696 Epoch [053/250], Step [0060/0060], Loss1: 0.0028 Loss2: 0.0022 Loss3: 0.0016\n",
            "Epoch: 53 MAE: 0.017983010763095483 ####  bestMAE: 0.01725474489291036 bestEpoch: 45\n",
            "2022-08-03 10:08:09.080510 Epoch [054/250], Step [0001/0060], Loss1: 0.0030 Loss2: 0.0027 Loss3: 0.0017\n",
            "2022-08-03 10:08:33.639217 Epoch [054/250], Step [0050/0060], Loss1: 0.0033 Loss2: 0.0026 Loss3: 0.0018\n",
            "2022-08-03 10:08:38.612222 Epoch [054/250], Step [0060/0060], Loss1: 0.0036 Loss2: 0.0029 Loss3: 0.0019\n",
            "Epoch: 54 MAE: 0.018932731230817144 ####  bestMAE: 0.01725474489291036 bestEpoch: 45\n",
            "2022-08-03 10:08:44.046654 Epoch [055/250], Step [0001/0060], Loss1: 0.0030 Loss2: 0.0025 Loss3: 0.0018\n",
            "2022-08-03 10:09:08.637872 Epoch [055/250], Step [0050/0060], Loss1: 0.0030 Loss2: 0.0030 Loss3: 0.0018\n",
            "2022-08-03 10:09:13.658508 Epoch [055/250], Step [0060/0060], Loss1: 0.0033 Loss2: 0.0027 Loss3: 0.0018\n",
            "Epoch: 55 MAE: 0.017904960772111303 ####  bestMAE: 0.01725474489291036 bestEpoch: 45\n",
            "2022-08-03 10:09:21.354236 Epoch [056/250], Step [0001/0060], Loss1: 0.0027 Loss2: 0.0025 Loss3: 0.0018\n",
            "2022-08-03 10:09:46.092773 Epoch [056/250], Step [0050/0060], Loss1: 0.0033 Loss2: 0.0027 Loss3: 0.0019\n",
            "2022-08-03 10:09:51.092685 Epoch [056/250], Step [0060/0060], Loss1: 0.0041 Loss2: 0.0028 Loss3: 0.0023\n",
            "Epoch: 56 MAE: 0.018734458405228836 ####  bestMAE: 0.01725474489291036 bestEpoch: 45\n",
            "2022-08-03 10:09:56.559432 Epoch [057/250], Step [0001/0060], Loss1: 0.0029 Loss2: 0.0024 Loss3: 0.0018\n",
            "2022-08-03 10:10:21.111606 Epoch [057/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 10:10:26.166892 Epoch [057/250], Step [0060/0060], Loss1: 0.0027 Loss2: 0.0027 Loss3: 0.0018\n",
            "Epoch: 57 MAE: 0.01741494944999142 ####  bestMAE: 0.01725474489291036 bestEpoch: 45\n",
            "2022-08-03 10:10:31.687418 Epoch [058/250], Step [0001/0060], Loss1: 0.0027 Loss2: 0.0026 Loss3: 0.0016\n",
            "2022-08-03 10:10:56.294683 Epoch [058/250], Step [0050/0060], Loss1: 0.0026 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 10:11:01.284641 Epoch [058/250], Step [0060/0060], Loss1: 0.0027 Loss2: 0.0026 Loss3: 0.0018\n",
            "Epoch: 58 MAE: 0.018142605673462625 ####  bestMAE: 0.01725474489291036 bestEpoch: 45\n",
            "2022-08-03 10:11:06.729142 Epoch [059/250], Step [0001/0060], Loss1: 0.0032 Loss2: 0.0030 Loss3: 0.0020\n",
            "2022-08-03 10:11:31.233223 Epoch [059/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0021 Loss3: 0.0015\n",
            "2022-08-03 10:11:36.248497 Epoch [059/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0023 Loss3: 0.0015\n",
            "Epoch: 59 MAE: 0.01713817183756166 ####  bestMAE: 0.01725474489291036 bestEpoch: 45\n",
            "best epoch:59\n",
            "2022-08-03 10:11:43.944758 Epoch [060/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 10:12:08.853225 Epoch [060/250], Step [0050/0060], Loss1: 0.0019 Loss2: 0.0020 Loss3: 0.0012\n",
            "2022-08-03 10:12:13.873988 Epoch [060/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 60 MAE: 0.016819290802001008 ####  bestMAE: 0.01713817183756166 bestEpoch: 59\n",
            "best epoch:60\n",
            "2022-08-03 10:12:23.954142 Epoch [061/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0028 Loss3: 0.0015\n",
            "2022-08-03 10:12:48.968997 Epoch [061/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 10:12:54.002892 Epoch [061/250], Step [0060/0060], Loss1: 0.0030 Loss2: 0.0024 Loss3: 0.0017\n",
            "Epoch: 61 MAE: 0.01681859569535369 ####  bestMAE: 0.016819290802001008 bestEpoch: 60\n",
            "best epoch:61\n",
            "2022-08-03 10:13:01.621284 Epoch [062/250], Step [0001/0060], Loss1: 0.0026 Loss2: 0.0022 Loss3: 0.0016\n",
            "2022-08-03 10:13:26.389318 Epoch [062/250], Step [0050/0060], Loss1: 0.0030 Loss2: 0.0024 Loss3: 0.0017\n",
            "2022-08-03 10:13:31.421108 Epoch [062/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0023 Loss3: 0.0016\n",
            "Epoch: 62 MAE: 0.017455253794434526 ####  bestMAE: 0.01681859569535369 bestEpoch: 61\n",
            "2022-08-03 10:13:36.964042 Epoch [063/250], Step [0001/0060], Loss1: 0.0021 Loss2: 0.0019 Loss3: 0.0014\n",
            "2022-08-03 10:14:01.593359 Epoch [063/250], Step [0050/0060], Loss1: 0.0029 Loss2: 0.0030 Loss3: 0.0018\n",
            "2022-08-03 10:14:06.596227 Epoch [063/250], Step [0060/0060], Loss1: 0.0037 Loss2: 0.0029 Loss3: 0.0018\n",
            "Epoch: 63 MAE: 0.017187361856774677 ####  bestMAE: 0.01681859569535369 bestEpoch: 61\n",
            "2022-08-03 10:14:12.041731 Epoch [064/250], Step [0001/0060], Loss1: 0.0026 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 10:14:36.563961 Epoch [064/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0025 Loss3: 0.0015\n",
            "2022-08-03 10:14:41.549027 Epoch [064/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0025 Loss3: 0.0016\n",
            "Epoch: 64 MAE: 0.017605466975106135 ####  bestMAE: 0.01681859569535369 bestEpoch: 61\n",
            "2022-08-03 10:14:46.988362 Epoch [065/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 10:15:11.531543 Epoch [065/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 10:15:16.530139 Epoch [065/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0025 Loss3: 0.0015\n",
            "Epoch: 65 MAE: 0.01729286980948278 ####  bestMAE: 0.01681859569535369 bestEpoch: 61\n",
            "2022-08-03 10:15:24.154434 Epoch [066/250], Step [0001/0060], Loss1: 0.0027 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 10:15:49.016078 Epoch [066/250], Step [0050/0060], Loss1: 0.0031 Loss2: 0.0020 Loss3: 0.0015\n",
            "2022-08-03 10:15:54.031794 Epoch [066/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0023 Loss3: 0.0015\n",
            "Epoch: 66 MAE: 0.017397370396388903 ####  bestMAE: 0.01681859569535369 bestEpoch: 61\n",
            "2022-08-03 10:15:59.553806 Epoch [067/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 10:16:24.105491 Epoch [067/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 10:16:29.089388 Epoch [067/250], Step [0060/0060], Loss1: 0.0028 Loss2: 0.0022 Loss3: 0.0015\n",
            "Epoch: 67 MAE: 0.017759772283690318 ####  bestMAE: 0.01681859569535369 bestEpoch: 61\n",
            "2022-08-03 10:16:34.437591 Epoch [068/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0025 Loss3: 0.0015\n",
            "2022-08-03 10:16:59.049198 Epoch [068/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 10:17:04.064771 Epoch [068/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0023 Loss3: 0.0014\n",
            "Epoch: 68 MAE: 0.017128824478104 ####  bestMAE: 0.01681859569535369 bestEpoch: 61\n",
            "2022-08-03 10:17:09.608787 Epoch [069/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0027 Loss3: 0.0015\n",
            "2022-08-03 10:17:34.280261 Epoch [069/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 10:17:39.293763 Epoch [069/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0022 Loss3: 0.0015\n",
            "Epoch: 69 MAE: 0.017199509363207553 ####  bestMAE: 0.01681859569535369 bestEpoch: 61\n",
            "2022-08-03 10:17:44.727060 Epoch [070/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 10:18:09.123762 Epoch [070/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 10:18:14.125265 Epoch [070/250], Step [0060/0060], Loss1: 0.0027 Loss2: 0.0022 Loss3: 0.0015\n",
            "Epoch: 70 MAE: 0.016757929357626135 ####  bestMAE: 0.01681859569535369 bestEpoch: 61\n",
            "best epoch:70\n",
            "2022-08-03 10:18:24.007991 Epoch [071/250], Step [0001/0060], Loss1: 0.0033 Loss2: 0.0028 Loss3: 0.0018\n",
            "2022-08-03 10:18:48.604644 Epoch [071/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 10:18:53.580074 Epoch [071/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0020 Loss3: 0.0013\n",
            "Epoch: 71 MAE: 0.017207328067530715 ####  bestMAE: 0.016757929357626135 bestEpoch: 70\n",
            "2022-08-03 10:18:59.028644 Epoch [072/250], Step [0001/0060], Loss1: 0.0027 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 10:19:23.497401 Epoch [072/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 10:19:28.499954 Epoch [072/250], Step [0060/0060], Loss1: 0.0033 Loss2: 0.0026 Loss3: 0.0017\n",
            "Epoch: 72 MAE: 0.01750688651014888 ####  bestMAE: 0.016757929357626135 bestEpoch: 70\n",
            "2022-08-03 10:19:34.011281 Epoch [073/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 10:19:58.665437 Epoch [073/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 10:20:03.641602 Epoch [073/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 73 MAE: 0.017441191828794896 ####  bestMAE: 0.016757929357626135 bestEpoch: 70\n",
            "2022-08-03 10:20:09.160044 Epoch [074/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 10:20:33.693262 Epoch [074/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 10:20:38.681040 Epoch [074/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0020 Loss3: 0.0013\n",
            "Epoch: 74 MAE: 0.01713109619560696 ####  bestMAE: 0.016757929357626135 bestEpoch: 70\n",
            "2022-08-03 10:20:44.273089 Epoch [075/250], Step [0001/0060], Loss1: 0.0019 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 10:21:08.987615 Epoch [075/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 10:21:14.035060 Epoch [075/250], Step [0060/0060], Loss1: 0.0027 Loss2: 0.0021 Loss3: 0.0015\n",
            "Epoch: 75 MAE: 0.01691368513459724 ####  bestMAE: 0.016757929357626135 bestEpoch: 70\n",
            "2022-08-03 10:21:21.842014 Epoch [076/250], Step [0001/0060], Loss1: 0.0026 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 10:21:46.714865 Epoch [076/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0024 Loss3: 0.0014\n",
            "2022-08-03 10:21:51.685920 Epoch [076/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 76 MAE: 0.01684480229954398 ####  bestMAE: 0.016757929357626135 bestEpoch: 70\n",
            "2022-08-03 10:21:57.084268 Epoch [077/250], Step [0001/0060], Loss1: 0.0026 Loss2: 0.0028 Loss3: 0.0016\n",
            "2022-08-03 10:22:21.586409 Epoch [077/250], Step [0050/0060], Loss1: 0.0029 Loss2: 0.0021 Loss3: 0.0015\n",
            "2022-08-03 10:22:26.618261 Epoch [077/250], Step [0060/0060], Loss1: 0.0021 Loss2: 0.0023 Loss3: 0.0014\n",
            "Epoch: 77 MAE: 0.01747490977129293 ####  bestMAE: 0.016757929357626135 bestEpoch: 70\n",
            "2022-08-03 10:22:32.187894 Epoch [078/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0028 Loss3: 0.0016\n",
            "2022-08-03 10:22:56.767204 Epoch [078/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0020 Loss3: 0.0014\n",
            "2022-08-03 10:23:01.753963 Epoch [078/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0021 Loss3: 0.0015\n",
            "Epoch: 78 MAE: 0.01685170881036255 ####  bestMAE: 0.016757929357626135 bestEpoch: 70\n",
            "2022-08-03 10:23:07.310288 Epoch [079/250], Step [0001/0060], Loss1: 0.0032 Loss2: 0.0021 Loss3: 0.0015\n",
            "2022-08-03 10:23:31.842361 Epoch [079/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0025 Loss3: 0.0016\n",
            "2022-08-03 10:23:36.847642 Epoch [079/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0021 Loss3: 0.0014\n",
            "Epoch: 79 MAE: 0.01662677995091866 ####  bestMAE: 0.016757929357626135 bestEpoch: 70\n",
            "best epoch:79\n",
            "2022-08-03 10:23:44.439441 Epoch [080/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0027 Loss3: 0.0015\n",
            "2022-08-03 10:24:09.155954 Epoch [080/250], Step [0050/0060], Loss1: 0.0026 Loss2: 0.0026 Loss3: 0.0016\n",
            "2022-08-03 10:24:14.157740 Epoch [080/250], Step [0060/0060], Loss1: 0.0021 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 80 MAE: 0.01677052972335664 ####  bestMAE: 0.01662677995091866 bestEpoch: 79\n",
            "2022-08-03 10:24:21.966111 Epoch [081/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0023 Loss3: 0.0016\n",
            "2022-08-03 10:24:46.551750 Epoch [081/250], Step [0050/0060], Loss1: 0.0029 Loss2: 0.0026 Loss3: 0.0016\n",
            "2022-08-03 10:24:51.541738 Epoch [081/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0023 Loss3: 0.0015\n",
            "Epoch: 81 MAE: 0.017282005325551072 ####  bestMAE: 0.01662677995091866 bestEpoch: 79\n",
            "2022-08-03 10:24:57.042797 Epoch [082/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 10:25:21.670885 Epoch [082/250], Step [0050/0060], Loss1: 0.0028 Loss2: 0.0026 Loss3: 0.0017\n",
            "2022-08-03 10:25:26.649907 Epoch [082/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0024 Loss3: 0.0015\n",
            "Epoch: 82 MAE: 0.01713320441425793 ####  bestMAE: 0.01662677995091866 bestEpoch: 79\n",
            "2022-08-03 10:25:32.076451 Epoch [083/250], Step [0001/0060], Loss1: 0.0026 Loss2: 0.0021 Loss3: 0.0015\n",
            "2022-08-03 10:25:56.629802 Epoch [083/250], Step [0050/0060], Loss1: 0.0030 Loss2: 0.0024 Loss3: 0.0016\n",
            "2022-08-03 10:26:01.643569 Epoch [083/250], Step [0060/0060], Loss1: 0.0028 Loss2: 0.0028 Loss3: 0.0017\n",
            "Epoch: 83 MAE: 0.01602261056680055 ####  bestMAE: 0.01662677995091866 bestEpoch: 79\n",
            "best epoch:83\n",
            "2022-08-03 10:26:09.596619 Epoch [084/250], Step [0001/0060], Loss1: 0.0031 Loss2: 0.0026 Loss3: 0.0017\n",
            "2022-08-03 10:26:34.314233 Epoch [084/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 10:26:39.328558 Epoch [084/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0019 Loss3: 0.0013\n",
            "Epoch: 84 MAE: 0.017388350285944484 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:26:44.908176 Epoch [085/250], Step [0001/0060], Loss1: 0.0021 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 10:27:09.526714 Epoch [085/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 10:27:14.542332 Epoch [085/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0023 Loss3: 0.0014\n",
            "Epoch: 85 MAE: 0.01692916566712989 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:27:22.214525 Epoch [086/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 10:27:47.037506 Epoch [086/250], Step [0050/0060], Loss1: 0.0026 Loss2: 0.0025 Loss3: 0.0015\n",
            "2022-08-03 10:27:52.068931 Epoch [086/250], Step [0060/0060], Loss1: 0.0027 Loss2: 0.0023 Loss3: 0.0015\n",
            "Epoch: 86 MAE: 0.017470168836769603 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:27:57.729913 Epoch [087/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 10:28:22.252516 Epoch [087/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 10:28:27.255685 Epoch [087/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 87 MAE: 0.01708236676714723 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:28:32.758196 Epoch [088/250], Step [0001/0060], Loss1: 0.0021 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 10:28:57.249024 Epoch [088/250], Step [0050/0060], Loss1: 0.0029 Loss2: 0.0021 Loss3: 0.0015\n",
            "2022-08-03 10:29:02.273249 Epoch [088/250], Step [0060/0060], Loss1: 0.0028 Loss2: 0.0024 Loss3: 0.0015\n",
            "Epoch: 88 MAE: 0.017003864094260194 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:29:07.763143 Epoch [089/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 10:29:32.251821 Epoch [089/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0020 Loss3: 0.0014\n",
            "2022-08-03 10:29:37.273370 Epoch [089/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0026 Loss3: 0.0016\n",
            "Epoch: 89 MAE: 0.016678562106948996 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:29:42.766031 Epoch [090/250], Step [0001/0060], Loss1: 0.0033 Loss2: 0.0021 Loss3: 0.0015\n",
            "2022-08-03 10:30:07.256189 Epoch [090/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 10:30:12.264131 Epoch [090/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0021 Loss3: 0.0014\n",
            "Epoch: 90 MAE: 0.017137991234896673 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:30:20.026724 Epoch [091/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 10:30:44.854050 Epoch [091/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 10:30:49.835522 Epoch [091/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0030 Loss3: 0.0016\n",
            "Epoch: 91 MAE: 0.01709589407971454 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:30:55.315138 Epoch [092/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 10:31:19.791006 Epoch [092/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 10:31:24.810928 Epoch [092/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0021 Loss3: 0.0014\n",
            "Epoch: 92 MAE: 0.01645065112305539 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:31:30.424249 Epoch [093/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 10:31:55.164849 Epoch [093/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 10:32:00.171213 Epoch [093/250], Step [0060/0060], Loss1: 0.0030 Loss2: 0.0023 Loss3: 0.0016\n",
            "Epoch: 93 MAE: 0.01691224950823992 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:32:05.877812 Epoch [094/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 10:32:30.407482 Epoch [094/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 10:32:35.405034 Epoch [094/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0019 Loss3: 0.0013\n",
            "Epoch: 94 MAE: 0.016919256202758304 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:32:40.902810 Epoch [095/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0024 Loss3: 0.0015\n",
            "2022-08-03 10:33:05.504045 Epoch [095/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0024 Loss3: 0.0014\n",
            "2022-08-03 10:33:10.512202 Epoch [095/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0026 Loss3: 0.0017\n",
            "Epoch: 95 MAE: 0.016610676511412577 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:33:18.239367 Epoch [096/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0024 Loss3: 0.0015\n",
            "2022-08-03 10:33:43.066109 Epoch [096/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 10:33:48.061147 Epoch [096/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0023 Loss3: 0.0015\n",
            "Epoch: 96 MAE: 0.017207343426961747 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:33:53.580312 Epoch [097/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 10:34:18.130795 Epoch [097/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0024 Loss3: 0.0016\n",
            "2022-08-03 10:34:23.098874 Epoch [097/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0020 Loss3: 0.0014\n",
            "Epoch: 97 MAE: 0.016625791329831358 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:34:28.578393 Epoch [098/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0019 Loss3: 0.0014\n",
            "2022-08-03 10:34:53.080247 Epoch [098/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0025 Loss3: 0.0016\n",
            "2022-08-03 10:34:58.114164 Epoch [098/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0022 Loss3: 0.0015\n",
            "Epoch: 98 MAE: 0.016755008493505773 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:35:03.622285 Epoch [099/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 10:35:28.133908 Epoch [099/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 10:35:33.133310 Epoch [099/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0024 Loss3: 0.0016\n",
            "Epoch: 99 MAE: 0.016721678158593555 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:35:38.575382 Epoch [100/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 10:36:03.050956 Epoch [100/250], Step [0050/0060], Loss1: 0.0026 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 10:36:08.062810 Epoch [100/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 100 MAE: 0.016730739335928644 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:36:15.851116 Epoch [101/250], Step [0001/0060], Loss1: 0.0027 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 10:36:40.687673 Epoch [101/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0027 Loss3: 0.0015\n",
            "2022-08-03 10:36:45.693238 Epoch [101/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0021 Loss3: 0.0014\n",
            "Epoch: 101 MAE: 0.01634370612483176 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:36:51.248278 Epoch [102/250], Step [0001/0060], Loss1: 0.0030 Loss2: 0.0024 Loss3: 0.0016\n",
            "2022-08-03 10:37:15.739545 Epoch [102/250], Step [0050/0060], Loss1: 0.0029 Loss2: 0.0025 Loss3: 0.0016\n",
            "2022-08-03 10:37:20.783164 Epoch [102/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0021 Loss3: 0.0014\n",
            "Epoch: 102 MAE: 0.016617395235077728 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:37:26.323320 Epoch [103/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0024 Loss3: 0.0015\n",
            "2022-08-03 10:37:50.931407 Epoch [103/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 10:37:55.941323 Epoch [103/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0020 Loss3: 0.0013\n",
            "Epoch: 103 MAE: 0.016898799539794996 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:38:01.451934 Epoch [104/250], Step [0001/0060], Loss1: 0.0030 Loss2: 0.0021 Loss3: 0.0015\n",
            "2022-08-03 10:38:25.993541 Epoch [104/250], Step [0050/0060], Loss1: 0.0028 Loss2: 0.0025 Loss3: 0.0015\n",
            "2022-08-03 10:38:31.039667 Epoch [104/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0025 Loss3: 0.0016\n",
            "Epoch: 104 MAE: 0.016924291967399537 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:38:36.529831 Epoch [105/250], Step [0001/0060], Loss1: 0.0026 Loss2: 0.0024 Loss3: 0.0016\n",
            "2022-08-03 10:39:01.061412 Epoch [105/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 10:39:06.068881 Epoch [105/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0023 Loss3: 0.0015\n",
            "Epoch: 105 MAE: 0.0164031818923023 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:39:13.738056 Epoch [106/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 10:39:38.602943 Epoch [106/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 10:39:43.608882 Epoch [106/250], Step [0060/0060], Loss1: 0.0028 Loss2: 0.0019 Loss3: 0.0014\n",
            "Epoch: 106 MAE: 0.01644619158099568 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:39:49.069801 Epoch [107/250], Step [0001/0060], Loss1: 0.0035 Loss2: 0.0023 Loss3: 0.0017\n",
            "2022-08-03 10:40:13.644590 Epoch [107/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 10:40:18.636237 Epoch [107/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0021 Loss3: 0.0013\n",
            "Epoch: 107 MAE: 0.016634405531462223 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:40:24.129790 Epoch [108/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 10:40:48.608274 Epoch [108/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0024 Loss3: 0.0015\n",
            "2022-08-03 10:40:53.597298 Epoch [108/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0021 Loss3: 0.0013\n",
            "Epoch: 108 MAE: 0.016345097727718808 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:40:59.076512 Epoch [109/250], Step [0001/0060], Loss1: 0.0026 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 10:41:23.562523 Epoch [109/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 10:41:28.546759 Epoch [109/250], Step [0060/0060], Loss1: 0.0028 Loss2: 0.0024 Loss3: 0.0017\n",
            "Epoch: 109 MAE: 0.016259230643747343 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "2022-08-03 10:41:34.034138 Epoch [110/250], Step [0001/0060], Loss1: 0.0026 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 10:41:58.484273 Epoch [110/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 10:42:03.508007 Epoch [110/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0018 Loss3: 0.0013\n",
            "Epoch: 110 MAE: 0.01589607006855427 ####  bestMAE: 0.01602261056680055 bestEpoch: 83\n",
            "best epoch:110\n",
            "2022-08-03 10:42:13.428117 Epoch [111/250], Step [0001/0060], Loss1: 0.0021 Loss2: 0.0018 Loss3: 0.0013\n",
            "2022-08-03 10:42:38.516306 Epoch [111/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0020 Loss3: 0.0014\n",
            "2022-08-03 10:42:43.546800 Epoch [111/250], Step [0060/0060], Loss1: 0.0027 Loss2: 0.0020 Loss3: 0.0014\n",
            "Epoch: 111 MAE: 0.01594461759345399 ####  bestMAE: 0.01589607006855427 bestEpoch: 110\n",
            "2022-08-03 10:42:49.104041 Epoch [112/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 10:43:13.695473 Epoch [112/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 10:43:18.703361 Epoch [112/250], Step [0060/0060], Loss1: 0.0021 Loss2: 0.0023 Loss3: 0.0014\n",
            "Epoch: 112 MAE: 0.016541328591605026 ####  bestMAE: 0.01589607006855427 bestEpoch: 110\n",
            "2022-08-03 10:43:24.241600 Epoch [113/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0024 Loss3: 0.0015\n",
            "2022-08-03 10:43:48.667968 Epoch [113/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 10:43:53.646438 Epoch [113/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0026 Loss3: 0.0015\n",
            "Epoch: 113 MAE: 0.01656290924265271 ####  bestMAE: 0.01589607006855427 bestEpoch: 110\n",
            "2022-08-03 10:43:59.286927 Epoch [114/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0018 Loss3: 0.0013\n",
            "2022-08-03 10:44:23.971244 Epoch [114/250], Step [0050/0060], Loss1: 0.0026 Loss2: 0.0025 Loss3: 0.0015\n",
            "2022-08-03 10:44:29.005973 Epoch [114/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0021 Loss3: 0.0013\n",
            "Epoch: 114 MAE: 0.01605393285197871 ####  bestMAE: 0.01589607006855427 bestEpoch: 110\n",
            "2022-08-03 10:44:34.580175 Epoch [115/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 10:44:59.085906 Epoch [115/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 10:45:04.096756 Epoch [115/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 115 MAE: 0.015497078889951346 ####  bestMAE: 0.01589607006855427 bestEpoch: 110\n",
            "best epoch:115\n",
            "2022-08-03 10:45:13.937434 Epoch [116/250], Step [0001/0060], Loss1: 0.0029 Loss2: 0.0027 Loss3: 0.0017\n",
            "2022-08-03 10:45:38.955139 Epoch [116/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 10:45:43.951578 Epoch [116/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0026 Loss3: 0.0015\n",
            "Epoch: 116 MAE: 0.01598684856342891 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:45:49.476047 Epoch [117/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 10:46:14.090944 Epoch [117/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 10:46:19.133108 Epoch [117/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0023 Loss3: 0.0015\n",
            "Epoch: 117 MAE: 0.01630146424507811 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:46:24.695378 Epoch [118/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 10:46:49.301613 Epoch [118/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 10:46:54.316842 Epoch [118/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0020 Loss3: 0.0013\n",
            "Epoch: 118 MAE: 0.016107537635853365 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:46:59.756920 Epoch [119/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 10:47:24.333726 Epoch [119/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 10:47:29.335501 Epoch [119/250], Step [0060/0060], Loss1: 0.0028 Loss2: 0.0023 Loss3: 0.0015\n",
            "Epoch: 119 MAE: 0.01597093807030765 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:47:34.992947 Epoch [120/250], Step [0001/0060], Loss1: 0.0027 Loss2: 0.0030 Loss3: 0.0016\n",
            "2022-08-03 10:47:59.623224 Epoch [120/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 10:48:04.601577 Epoch [120/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0020 Loss3: 0.0013\n",
            "Epoch: 120 MAE: 0.01652071395859359 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:48:12.337675 Epoch [121/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 10:48:37.099403 Epoch [121/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0025 Loss3: 0.0014\n",
            "2022-08-03 10:48:42.116007 Epoch [121/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 121 MAE: 0.016325889657887203 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:48:47.585449 Epoch [122/250], Step [0001/0060], Loss1: 0.0026 Loss2: 0.0027 Loss3: 0.0015\n",
            "2022-08-03 10:49:12.167134 Epoch [122/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 10:49:17.144516 Epoch [122/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0023 Loss3: 0.0014\n",
            "Epoch: 122 MAE: 0.01623556375621803 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:49:22.673867 Epoch [123/250], Step [0001/0060], Loss1: 0.0021 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 10:49:47.251457 Epoch [123/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 10:49:52.234482 Epoch [123/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0018 Loss3: 0.0013\n",
            "Epoch: 123 MAE: 0.015964283696597532 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:49:57.721940 Epoch [124/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0024 Loss3: 0.0016\n",
            "2022-08-03 10:50:22.220497 Epoch [124/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0023 Loss3: 0.0016\n",
            "2022-08-03 10:50:27.211943 Epoch [124/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0024 Loss3: 0.0016\n",
            "Epoch: 124 MAE: 0.016026216145190928 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:50:32.672305 Epoch [125/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 10:50:57.191838 Epoch [125/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0024 Loss3: 0.0015\n",
            "2022-08-03 10:51:02.219923 Epoch [125/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 125 MAE: 0.016103615407787618 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:51:10.007157 Epoch [126/250], Step [0001/0060], Loss1: 0.0021 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 10:51:34.741061 Epoch [126/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 10:51:39.756486 Epoch [126/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 126 MAE: 0.015715003353617495 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:51:45.366409 Epoch [127/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0020 Loss3: 0.0014\n",
            "2022-08-03 10:52:09.989213 Epoch [127/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 10:52:15.051212 Epoch [127/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 127 MAE: 0.015753307231953218 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:52:20.492520 Epoch [128/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 10:52:45.022597 Epoch [128/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 10:52:50.076347 Epoch [128/250], Step [0060/0060], Loss1: 0.0028 Loss2: 0.0023 Loss3: 0.0015\n",
            "Epoch: 128 MAE: 0.015992742697043077 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:52:55.611506 Epoch [129/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 10:53:20.133979 Epoch [129/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0024 Loss3: 0.0014\n",
            "2022-08-03 10:53:25.138664 Epoch [129/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0020 Loss3: 0.0013\n",
            "Epoch: 129 MAE: 0.016131795454947723 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:53:30.788283 Epoch [130/250], Step [0001/0060], Loss1: 0.0031 Loss2: 0.0023 Loss3: 0.0016\n",
            "2022-08-03 10:53:55.467324 Epoch [130/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0025 Loss3: 0.0016\n",
            "2022-08-03 10:54:00.449736 Epoch [130/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0025 Loss3: 0.0015\n",
            "Epoch: 130 MAE: 0.016178147512532416 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:54:08.078654 Epoch [131/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 10:54:32.763528 Epoch [131/250], Step [0050/0060], Loss1: 0.0019 Loss2: 0.0019 Loss3: 0.0012\n",
            "2022-08-03 10:54:37.793313 Epoch [131/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0023 Loss3: 0.0014\n",
            "Epoch: 131 MAE: 0.01603905198770383 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:54:43.304477 Epoch [132/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 10:55:07.745501 Epoch [132/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 10:55:12.751194 Epoch [132/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0019 Loss3: 0.0012\n",
            "Epoch: 132 MAE: 0.015910728006727166 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:55:18.251392 Epoch [133/250], Step [0001/0060], Loss1: 0.0027 Loss2: 0.0026 Loss3: 0.0016\n",
            "2022-08-03 10:55:42.852677 Epoch [133/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 10:55:47.841853 Epoch [133/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0022 Loss3: 0.0015\n",
            "Epoch: 133 MAE: 0.016045370006135533 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:55:53.327822 Epoch [134/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 10:56:18.006700 Epoch [134/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 10:56:23.035407 Epoch [134/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0021 Loss3: 0.0014\n",
            "Epoch: 134 MAE: 0.01592951804576885 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:56:28.531180 Epoch [135/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 10:56:53.168579 Epoch [135/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0020 Loss3: 0.0014\n",
            "2022-08-03 10:56:58.170813 Epoch [135/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0025 Loss3: 0.0015\n",
            "Epoch: 135 MAE: 0.015624199166066118 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:57:05.835321 Epoch [136/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0024 Loss3: 0.0014\n",
            "2022-08-03 10:57:30.603048 Epoch [136/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 10:57:35.658232 Epoch [136/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 136 MAE: 0.01592235548037385 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:57:41.067664 Epoch [137/250], Step [0001/0060], Loss1: 0.0021 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 10:58:05.738924 Epoch [137/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 10:58:10.732331 Epoch [137/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0018 Loss3: 0.0013\n",
            "Epoch: 137 MAE: 0.016062964360037492 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:58:16.275396 Epoch [138/250], Step [0001/0060], Loss1: 0.0021 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 10:58:40.932850 Epoch [138/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0024 Loss3: 0.0014\n",
            "2022-08-03 10:58:46.006364 Epoch [138/250], Step [0060/0060], Loss1: 0.0027 Loss2: 0.0026 Loss3: 0.0016\n",
            "Epoch: 138 MAE: 0.015900840391478842 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:58:51.553604 Epoch [139/250], Step [0001/0060], Loss1: 0.0019 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 10:59:16.179409 Epoch [139/250], Step [0050/0060], Loss1: 0.0029 Loss2: 0.0026 Loss3: 0.0016\n",
            "2022-08-03 10:59:21.154228 Epoch [139/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0023 Loss3: 0.0014\n",
            "Epoch: 139 MAE: 0.01596507988130999 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "2022-08-03 10:59:26.559773 Epoch [140/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0025 Loss3: 0.0015\n",
            "2022-08-03 10:59:51.106003 Epoch [140/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 10:59:56.082833 Epoch [140/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0023 Loss3: 0.0014\n",
            "Epoch: 140 MAE: 0.01531083413976289 ####  bestMAE: 0.015497078889951346 bestEpoch: 115\n",
            "best epoch:140\n",
            "2022-08-03 11:00:05.947980 Epoch [141/250], Step [0001/0060], Loss1: 0.0019 Loss2: 0.0018 Loss3: 0.0012\n",
            "2022-08-03 11:00:31.094200 Epoch [141/250], Step [0050/0060], Loss1: 0.0026 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:00:36.114859 Epoch [141/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0023 Loss3: 0.0015\n",
            "Epoch: 141 MAE: 0.01594535628008464 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:00:41.612220 Epoch [142/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 11:01:06.166737 Epoch [142/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0026 Loss3: 0.0015\n",
            "2022-08-03 11:01:11.140514 Epoch [142/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0021 Loss3: 0.0014\n",
            "Epoch: 142 MAE: 0.015950591406888433 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:01:16.644510 Epoch [143/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0018 Loss3: 0.0013\n",
            "2022-08-03 11:01:41.313127 Epoch [143/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 11:01:46.344552 Epoch [143/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0027 Loss3: 0.0016\n",
            "Epoch: 143 MAE: 0.01606531302252459 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:01:51.974634 Epoch [144/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0026 Loss3: 0.0015\n",
            "2022-08-03 11:02:16.570731 Epoch [144/250], Step [0050/0060], Loss1: 0.0026 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 11:02:21.548405 Epoch [144/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0021 Loss3: 0.0013\n",
            "Epoch: 144 MAE: 0.01603712070555914 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:02:27.077492 Epoch [145/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:02:51.603343 Epoch [145/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0026 Loss3: 0.0016\n",
            "2022-08-03 11:02:56.603781 Epoch [145/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0020 Loss3: 0.0013\n",
            "Epoch: 145 MAE: 0.01594721505211459 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:03:04.340042 Epoch [146/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 11:03:29.111639 Epoch [146/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:03:34.135528 Epoch [146/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0021 Loss3: 0.0014\n",
            "Epoch: 146 MAE: 0.015963393381781994 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:03:39.645100 Epoch [147/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0019 Loss3: 0.0012\n",
            "2022-08-03 11:04:04.334131 Epoch [147/250], Step [0050/0060], Loss1: 0.0026 Loss2: 0.0025 Loss3: 0.0016\n",
            "2022-08-03 11:04:09.323752 Epoch [147/250], Step [0060/0060], Loss1: 0.0021 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 147 MAE: 0.015837169377990658 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:04:14.738190 Epoch [148/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 11:04:39.311610 Epoch [148/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:04:44.307193 Epoch [148/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0020 Loss3: 0.0014\n",
            "Epoch: 148 MAE: 0.01580038062843775 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:04:49.846400 Epoch [149/250], Step [0001/0060], Loss1: 0.0029 Loss2: 0.0027 Loss3: 0.0017\n",
            "2022-08-03 11:05:14.376432 Epoch [149/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:05:19.395021 Epoch [149/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0023 Loss3: 0.0014\n",
            "Epoch: 149 MAE: 0.015830241779368075 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:05:24.950150 Epoch [150/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 11:05:49.663813 Epoch [150/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:05:54.644404 Epoch [150/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0025 Loss3: 0.0015\n",
            "Epoch: 150 MAE: 0.015534682140227348 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:06:02.396789 Epoch [151/250], Step [0001/0060], Loss1: 0.0021 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 11:06:27.013445 Epoch [151/250], Step [0050/0060], Loss1: 0.0026 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:06:32.032251 Epoch [151/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 151 MAE: 0.015936710945670566 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:06:37.568070 Epoch [152/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 11:07:02.289285 Epoch [152/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 11:07:07.280254 Epoch [152/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0018 Loss3: 0.0013\n",
            "Epoch: 152 MAE: 0.015745381218573405 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:07:12.814073 Epoch [153/250], Step [0001/0060], Loss1: 0.0027 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 11:07:37.282200 Epoch [153/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 11:07:42.307630 Epoch [153/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 153 MAE: 0.015756295062601566 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:07:47.767568 Epoch [154/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:08:12.283607 Epoch [154/250], Step [0050/0060], Loss1: 0.0018 Loss2: 0.0019 Loss3: 0.0012\n",
            "2022-08-03 11:08:17.334173 Epoch [154/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0024 Loss3: 0.0015\n",
            "Epoch: 154 MAE: 0.015973280775286848 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:08:22.963977 Epoch [155/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0024 Loss3: 0.0015\n",
            "2022-08-03 11:08:47.648480 Epoch [155/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 11:08:52.638173 Epoch [155/250], Step [0060/0060], Loss1: 0.0021 Loss2: 0.0020 Loss3: 0.0013\n",
            "Epoch: 155 MAE: 0.01575035031973606 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:09:00.379088 Epoch [156/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 11:09:25.208817 Epoch [156/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:09:30.181907 Epoch [156/250], Step [0060/0060], Loss1: 0.0021 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 156 MAE: 0.01567908607068516 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:09:35.771399 Epoch [157/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 11:10:00.332543 Epoch [157/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:10:05.389522 Epoch [157/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0019 Loss3: 0.0012\n",
            "Epoch: 157 MAE: 0.015637735769684826 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:10:10.877417 Epoch [158/250], Step [0001/0060], Loss1: 0.0019 Loss2: 0.0018 Loss3: 0.0012\n",
            "2022-08-03 11:10:35.657905 Epoch [158/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0020 Loss3: 0.0014\n",
            "2022-08-03 11:10:40.674545 Epoch [158/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0019 Loss3: 0.0012\n",
            "Epoch: 158 MAE: 0.01569139130324835 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:10:46.245430 Epoch [159/250], Step [0001/0060], Loss1: 0.0021 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 11:11:10.844559 Epoch [159/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 11:11:15.835244 Epoch [159/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0020 Loss3: 0.0014\n",
            "Epoch: 159 MAE: 0.016029119521142946 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:11:21.314929 Epoch [160/250], Step [0001/0060], Loss1: 0.0021 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:11:45.888816 Epoch [160/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0018 Loss3: 0.0012\n",
            "2022-08-03 11:11:50.892559 Epoch [160/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0021 Loss3: 0.0014\n",
            "Epoch: 160 MAE: 0.016012563325819514 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:11:58.538841 Epoch [161/250], Step [0001/0060], Loss1: 0.0021 Loss2: 0.0018 Loss3: 0.0012\n",
            "2022-08-03 11:12:23.363469 Epoch [161/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 11:12:28.378652 Epoch [161/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0021 Loss3: 0.0013\n",
            "Epoch: 161 MAE: 0.015462663150318558 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:12:33.761373 Epoch [162/250], Step [0001/0060], Loss1: 0.0021 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 11:12:58.350296 Epoch [162/250], Step [0050/0060], Loss1: 0.0030 Loss2: 0.0025 Loss3: 0.0016\n",
            "2022-08-03 11:13:03.355779 Epoch [162/250], Step [0060/0060], Loss1: 0.0021 Loss2: 0.0021 Loss3: 0.0013\n",
            "Epoch: 162 MAE: 0.015680105477157567 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:13:08.780433 Epoch [163/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 11:13:33.351792 Epoch [163/250], Step [0050/0060], Loss1: 0.0026 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:13:38.322989 Epoch [163/250], Step [0060/0060], Loss1: 0.0019 Loss2: 0.0019 Loss3: 0.0013\n",
            "Epoch: 163 MAE: 0.01568352541191474 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:13:43.824373 Epoch [164/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0020 Loss3: 0.0014\n",
            "2022-08-03 11:14:08.586746 Epoch [164/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0018 Loss3: 0.0013\n",
            "2022-08-03 11:14:13.580822 Epoch [164/250], Step [0060/0060], Loss1: 0.0019 Loss2: 0.0021 Loss3: 0.0013\n",
            "Epoch: 164 MAE: 0.015849253428833827 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:14:18.999216 Epoch [165/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 11:14:43.618652 Epoch [165/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:14:48.610412 Epoch [165/250], Step [0060/0060], Loss1: 0.0021 Loss2: 0.0022 Loss3: 0.0015\n",
            "Epoch: 165 MAE: 0.015551460019889333 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:14:56.650850 Epoch [166/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0025 Loss3: 0.0014\n",
            "2022-08-03 11:15:21.256988 Epoch [166/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 11:15:26.277164 Epoch [166/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0019 Loss3: 0.0013\n",
            "Epoch: 166 MAE: 0.01572711168537064 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:15:31.778660 Epoch [167/250], Step [0001/0060], Loss1: 0.0019 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 11:15:56.390880 Epoch [167/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 11:16:01.430565 Epoch [167/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 167 MAE: 0.015402500628538075 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:16:06.935524 Epoch [168/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:16:31.630799 Epoch [168/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0025 Loss3: 0.0015\n",
            "2022-08-03 11:16:36.633659 Epoch [168/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0026 Loss3: 0.0016\n",
            "Epoch: 168 MAE: 0.01565846497754729 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:16:42.276290 Epoch [169/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0018 Loss3: 0.0013\n",
            "2022-08-03 11:17:06.822265 Epoch [169/250], Step [0050/0060], Loss1: 0.0019 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 11:17:11.839086 Epoch [169/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0023 Loss3: 0.0014\n",
            "Epoch: 169 MAE: 0.015574788704277977 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:17:17.483978 Epoch [170/250], Step [0001/0060], Loss1: 0.0021 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 11:17:42.067728 Epoch [170/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 11:17:47.081924 Epoch [170/250], Step [0060/0060], Loss1: 0.0019 Loss2: 0.0017 Loss3: 0.0012\n",
            "Epoch: 170 MAE: 0.01554693520394346 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:17:54.953203 Epoch [171/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:18:19.519337 Epoch [171/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:18:24.515370 Epoch [171/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0024 Loss3: 0.0015\n",
            "Epoch: 171 MAE: 0.015745854655665064 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:18:30.166175 Epoch [172/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:18:54.789816 Epoch [172/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 11:18:59.864129 Epoch [172/250], Step [0060/0060], Loss1: 0.0027 Loss2: 0.0023 Loss3: 0.0015\n",
            "Epoch: 172 MAE: 0.015895610409123555 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:19:05.547320 Epoch [173/250], Step [0001/0060], Loss1: 0.0027 Loss2: 0.0020 Loss3: 0.0014\n",
            "2022-08-03 11:19:30.035929 Epoch [173/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 11:19:35.100262 Epoch [173/250], Step [0060/0060], Loss1: 0.0018 Loss2: 0.0017 Loss3: 0.0012\n",
            "Epoch: 173 MAE: 0.01557465112723765 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:19:40.790850 Epoch [174/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0020 Loss3: 0.0014\n",
            "2022-08-03 11:20:05.462254 Epoch [174/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0018 Loss3: 0.0013\n",
            "2022-08-03 11:20:10.494550 Epoch [174/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0024 Loss3: 0.0014\n",
            "Epoch: 174 MAE: 0.01583623420447111 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:20:16.092309 Epoch [175/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 11:20:40.695724 Epoch [175/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0018 Loss3: 0.0013\n",
            "2022-08-03 11:20:45.702379 Epoch [175/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 175 MAE: 0.015698954995189394 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:20:53.516882 Epoch [176/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 11:21:18.282515 Epoch [176/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0024 Loss3: 0.0015\n",
            "2022-08-03 11:21:23.281018 Epoch [176/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0026 Loss3: 0.0014\n",
            "Epoch: 176 MAE: 0.01557300053536892 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:21:28.960519 Epoch [177/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:21:53.635058 Epoch [177/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:21:58.642996 Epoch [177/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0021 Loss3: 0.0014\n",
            "Epoch: 177 MAE: 0.01593944284000567 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:22:04.216449 Epoch [178/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:22:28.736948 Epoch [178/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 11:22:33.779557 Epoch [178/250], Step [0060/0060], Loss1: 0.0029 Loss2: 0.0023 Loss3: 0.0016\n",
            "Epoch: 178 MAE: 0.015747256665712313 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:22:39.260563 Epoch [179/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:23:03.765311 Epoch [179/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:23:08.747578 Epoch [179/250], Step [0060/0060], Loss1: 0.0030 Loss2: 0.0022 Loss3: 0.0015\n",
            "Epoch: 179 MAE: 0.015990544214016862 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:23:14.392852 Epoch [180/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 11:23:39.204259 Epoch [180/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:23:44.195869 Epoch [180/250], Step [0060/0060], Loss1: 0.0029 Loss2: 0.0024 Loss3: 0.0016\n",
            "Epoch: 180 MAE: 0.01572049246539199 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:23:52.181572 Epoch [181/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:24:17.058500 Epoch [181/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:24:22.047544 Epoch [181/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0021 Loss3: 0.0013\n",
            "Epoch: 181 MAE: 0.01573314318167312 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:24:27.665862 Epoch [182/250], Step [0001/0060], Loss1: 0.0019 Loss2: 0.0020 Loss3: 0.0012\n",
            "2022-08-03 11:24:52.290956 Epoch [182/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 11:24:57.321929 Epoch [182/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0021 Loss3: 0.0013\n",
            "Epoch: 182 MAE: 0.015827372951048708 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:25:02.915422 Epoch [183/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0024 Loss3: 0.0015\n",
            "2022-08-03 11:25:27.411994 Epoch [183/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 11:25:32.465443 Epoch [183/250], Step [0060/0060], Loss1: 0.0028 Loss2: 0.0021 Loss3: 0.0015\n",
            "Epoch: 183 MAE: 0.01568184091546942 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:25:38.099588 Epoch [184/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0020 Loss3: 0.0012\n",
            "2022-08-03 11:26:02.793301 Epoch [184/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:26:07.768259 Epoch [184/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0025 Loss3: 0.0015\n",
            "Epoch: 184 MAE: 0.01587255055173522 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:26:13.344393 Epoch [185/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 11:26:37.856408 Epoch [185/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 11:26:42.858876 Epoch [185/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0021 Loss3: 0.0014\n",
            "Epoch: 185 MAE: 0.01566309971912276 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:26:50.785355 Epoch [186/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 11:27:15.552893 Epoch [186/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0016 Loss3: 0.0012\n",
            "2022-08-03 11:27:20.560591 Epoch [186/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0020 Loss3: 0.0013\n",
            "Epoch: 186 MAE: 0.015741500057398328 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:27:26.224615 Epoch [187/250], Step [0001/0060], Loss1: 0.0027 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 11:27:50.610325 Epoch [187/250], Step [0050/0060], Loss1: 0.0026 Loss2: 0.0029 Loss3: 0.0016\n",
            "2022-08-03 11:27:55.582232 Epoch [187/250], Step [0060/0060], Loss1: 0.0019 Loss2: 0.0022 Loss3: 0.0013\n",
            "Epoch: 187 MAE: 0.015716550043887563 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:28:01.292753 Epoch [188/250], Step [0001/0060], Loss1: 0.0030 Loss2: 0.0021 Loss3: 0.0015\n",
            "2022-08-03 11:28:25.859194 Epoch [188/250], Step [0050/0060], Loss1: 0.0018 Loss2: 0.0019 Loss3: 0.0012\n",
            "2022-08-03 11:28:30.845577 Epoch [188/250], Step [0060/0060], Loss1: 0.0019 Loss2: 0.0018 Loss3: 0.0012\n",
            "Epoch: 188 MAE: 0.015731624549343473 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:28:36.446248 Epoch [189/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:29:01.005725 Epoch [189/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:29:05.993165 Epoch [189/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0021 Loss3: 0.0014\n",
            "Epoch: 189 MAE: 0.015558846827064241 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:29:11.544181 Epoch [190/250], Step [0001/0060], Loss1: 0.0019 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 11:29:36.081618 Epoch [190/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 11:29:41.069639 Epoch [190/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0023 Loss3: 0.0015\n",
            "Epoch: 190 MAE: 0.015749870459475214 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:29:49.041443 Epoch [191/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 11:30:13.936725 Epoch [191/250], Step [0050/0060], Loss1: 0.0019 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 11:30:18.967363 Epoch [191/250], Step [0060/0060], Loss1: 0.0021 Loss2: 0.0021 Loss3: 0.0013\n",
            "Epoch: 191 MAE: 0.015720811702074514 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:30:24.556971 Epoch [192/250], Step [0001/0060], Loss1: 0.0026 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 11:30:49.101826 Epoch [192/250], Step [0050/0060], Loss1: 0.0019 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 11:30:54.129594 Epoch [192/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0022 Loss3: 0.0015\n",
            "Epoch: 192 MAE: 0.015675427421690927 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:30:59.676844 Epoch [193/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 11:31:24.128608 Epoch [193/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 11:31:29.110144 Epoch [193/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0021 Loss3: 0.0014\n",
            "Epoch: 193 MAE: 0.015646991098210924 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:31:34.669505 Epoch [194/250], Step [0001/0060], Loss1: 0.0027 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 11:31:59.208894 Epoch [194/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0018 Loss3: 0.0013\n",
            "2022-08-03 11:32:04.293176 Epoch [194/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0020 Loss3: 0.0013\n",
            "Epoch: 194 MAE: 0.01578122220696911 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:32:10.011958 Epoch [195/250], Step [0001/0060], Loss1: 0.0032 Loss2: 0.0031 Loss3: 0.0017\n",
            "2022-08-03 11:32:34.626615 Epoch [195/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 11:32:39.677528 Epoch [195/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0018 Loss3: 0.0013\n",
            "Epoch: 195 MAE: 0.01564823312034446 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:32:47.531335 Epoch [196/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:33:12.250123 Epoch [196/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 11:33:17.274999 Epoch [196/250], Step [0060/0060], Loss1: 0.0021 Loss2: 0.0021 Loss3: 0.0013\n",
            "Epoch: 196 MAE: 0.015577436469140508 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:33:22.920593 Epoch [197/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 11:33:47.502661 Epoch [197/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:33:52.524267 Epoch [197/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0020 Loss3: 0.0013\n",
            "Epoch: 197 MAE: 0.015806364649463268 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:33:58.179196 Epoch [198/250], Step [0001/0060], Loss1: 0.0021 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:34:22.646675 Epoch [198/250], Step [0050/0060], Loss1: 0.0019 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 11:34:27.625102 Epoch [198/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0024 Loss3: 0.0014\n",
            "Epoch: 198 MAE: 0.015470775147338234 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:34:33.255767 Epoch [199/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0022 Loss3: 0.0015\n",
            "2022-08-03 11:34:57.935973 Epoch [199/250], Step [0050/0060], Loss1: 0.0018 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 11:35:02.935963 Epoch [199/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0018 Loss3: 0.0012\n",
            "Epoch: 199 MAE: 0.0154694031391825 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:35:08.695948 Epoch [200/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0018 Loss3: 0.0012\n",
            "2022-08-03 11:35:33.310190 Epoch [200/250], Step [0050/0060], Loss1: 0.0019 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 11:35:38.318352 Epoch [200/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0026 Loss3: 0.0015\n",
            "Epoch: 200 MAE: 0.015779108607343266 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "2022-08-03 11:35:46.329227 Epoch [201/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 11:36:10.999131 Epoch [201/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0025 Loss3: 0.0014\n",
            "2022-08-03 11:36:16.013674 Epoch [201/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0026 Loss3: 0.0015\n",
            "Epoch: 201 MAE: 0.015104381057123343 ####  bestMAE: 0.01531083413976289 bestEpoch: 140\n",
            "best epoch:201\n",
            "2022-08-03 11:36:23.968520 Epoch [202/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 11:36:48.699606 Epoch [202/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 11:36:53.688167 Epoch [202/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0024 Loss3: 0.0015\n",
            "Epoch: 202 MAE: 0.015501817052681294 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:36:59.232782 Epoch [203/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 11:37:23.838464 Epoch [203/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0018 Loss3: 0.0012\n",
            "2022-08-03 11:37:28.822053 Epoch [203/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0021 Loss3: 0.0013\n",
            "Epoch: 203 MAE: 0.01608991265178673 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:37:34.261056 Epoch [204/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0019 Loss3: 0.0014\n",
            "2022-08-03 11:37:58.815866 Epoch [204/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 11:38:03.823556 Epoch [204/250], Step [0060/0060], Loss1: 0.0032 Loss2: 0.0025 Loss3: 0.0017\n",
            "Epoch: 204 MAE: 0.015801904619567923 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:38:09.440247 Epoch [205/250], Step [0001/0060], Loss1: 0.0021 Loss2: 0.0017 Loss3: 0.0012\n",
            "2022-08-03 11:38:34.130923 Epoch [205/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 11:38:39.160309 Epoch [205/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0018 Loss3: 0.0013\n",
            "Epoch: 205 MAE: 0.015793382397128478 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:38:47.279124 Epoch [206/250], Step [0001/0060], Loss1: 0.0019 Loss2: 0.0017 Loss3: 0.0012\n",
            "2022-08-03 11:39:12.119022 Epoch [206/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0026 Loss3: 0.0015\n",
            "2022-08-03 11:39:17.182089 Epoch [206/250], Step [0060/0060], Loss1: 0.0019 Loss2: 0.0020 Loss3: 0.0013\n",
            "Epoch: 206 MAE: 0.015685816975458275 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:39:22.672265 Epoch [207/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0016 Loss3: 0.0012\n",
            "2022-08-03 11:39:47.290985 Epoch [207/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 11:39:52.295325 Epoch [207/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0022 Loss3: 0.0015\n",
            "Epoch: 207 MAE: 0.015782512384392912 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:39:57.977124 Epoch [208/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0026 Loss3: 0.0015\n",
            "2022-08-03 11:40:22.592168 Epoch [208/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0018 Loss3: 0.0012\n",
            "2022-08-03 11:40:27.566100 Epoch [208/250], Step [0060/0060], Loss1: 0.0029 Loss2: 0.0022 Loss3: 0.0015\n",
            "Epoch: 208 MAE: 0.015767404728288217 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:40:33.207976 Epoch [209/250], Step [0001/0060], Loss1: 0.0026 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:40:57.733966 Epoch [209/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0024 Loss3: 0.0015\n",
            "2022-08-03 11:41:02.768772 Epoch [209/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 209 MAE: 0.015616452380541771 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:41:08.237101 Epoch [210/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 11:41:32.741170 Epoch [210/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:41:37.734292 Epoch [210/250], Step [0060/0060], Loss1: 0.0021 Loss2: 0.0020 Loss3: 0.0014\n",
            "Epoch: 210 MAE: 0.015811357129779127 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:41:45.686178 Epoch [211/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0020 Loss3: 0.0014\n",
            "2022-08-03 11:42:10.287245 Epoch [211/250], Step [0050/0060], Loss1: 0.0019 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 11:42:15.267502 Epoch [211/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0026 Loss3: 0.0014\n",
            "Epoch: 211 MAE: 0.015597534587695486 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:42:20.813710 Epoch [212/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:42:45.315777 Epoch [212/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 11:42:50.369327 Epoch [212/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0022 Loss3: 0.0015\n",
            "Epoch: 212 MAE: 0.01554620988844406 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:42:55.996734 Epoch [213/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:43:20.545283 Epoch [213/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:43:25.570780 Epoch [213/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0023 Loss3: 0.0014\n",
            "Epoch: 213 MAE: 0.015391184519680719 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:43:31.192582 Epoch [214/250], Step [0001/0060], Loss1: 0.0027 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:43:55.726780 Epoch [214/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:44:00.927237 Epoch [214/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0019 Loss3: 0.0012\n",
            "Epoch: 214 MAE: 0.015437809610000205 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:44:06.541593 Epoch [215/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0024 Loss3: 0.0015\n",
            "2022-08-03 11:44:31.075563 Epoch [215/250], Step [0050/0060], Loss1: 0.0029 Loss2: 0.0021 Loss3: 0.0015\n",
            "2022-08-03 11:44:36.096885 Epoch [215/250], Step [0060/0060], Loss1: 0.0021 Loss2: 0.0022 Loss3: 0.0013\n",
            "Epoch: 215 MAE: 0.01572648620617295 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:44:44.045475 Epoch [216/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0024 Loss3: 0.0014\n",
            "2022-08-03 11:45:08.682091 Epoch [216/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:45:13.661378 Epoch [216/250], Step [0060/0060], Loss1: 0.0021 Loss2: 0.0023 Loss3: 0.0014\n",
            "Epoch: 216 MAE: 0.015644458972568078 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:45:19.281910 Epoch [217/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0025 Loss3: 0.0015\n",
            "2022-08-03 11:45:44.051053 Epoch [217/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 11:45:49.044941 Epoch [217/250], Step [0060/0060], Loss1: 0.0025 Loss2: 0.0022 Loss3: 0.0015\n",
            "Epoch: 217 MAE: 0.015613173452457265 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:45:54.681643 Epoch [218/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 11:46:19.162952 Epoch [218/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0020 Loss3: 0.0014\n",
            "2022-08-03 11:46:24.169187 Epoch [218/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0021 Loss3: 0.0014\n",
            "Epoch: 218 MAE: 0.015451649314768258 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:46:29.948001 Epoch [219/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 11:46:54.648991 Epoch [219/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:46:59.674293 Epoch [219/250], Step [0060/0060], Loss1: 0.0019 Loss2: 0.0019 Loss3: 0.0012\n",
            "Epoch: 219 MAE: 0.015464309610367294 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:47:05.413781 Epoch [220/250], Step [0001/0060], Loss1: 0.0021 Loss2: 0.0017 Loss3: 0.0012\n",
            "2022-08-03 11:47:29.996492 Epoch [220/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:47:34.988159 Epoch [220/250], Step [0060/0060], Loss1: 0.0016 Loss2: 0.0019 Loss3: 0.0012\n",
            "Epoch: 220 MAE: 0.015499927502657686 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:47:43.026728 Epoch [221/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 11:48:07.965828 Epoch [221/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 11:48:13.028140 Epoch [221/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0020 Loss3: 0.0014\n",
            "Epoch: 221 MAE: 0.015513375771069338 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:48:18.713289 Epoch [222/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:48:43.250326 Epoch [222/250], Step [0050/0060], Loss1: 0.0026 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:48:48.221074 Epoch [222/250], Step [0060/0060], Loss1: 0.0028 Loss2: 0.0023 Loss3: 0.0015\n",
            "Epoch: 222 MAE: 0.01571210805651924 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:48:53.871271 Epoch [223/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 11:49:18.508516 Epoch [223/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 11:49:23.567475 Epoch [223/250], Step [0060/0060], Loss1: 0.0026 Loss2: 0.0023 Loss3: 0.0015\n",
            "Epoch: 223 MAE: 0.015603831836155482 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:49:29.160387 Epoch [224/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:49:53.711374 Epoch [224/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 11:49:58.755188 Epoch [224/250], Step [0060/0060], Loss1: 0.0019 Loss2: 0.0019 Loss3: 0.0013\n",
            "Epoch: 224 MAE: 0.015604211549673761 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:50:04.426100 Epoch [225/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:50:28.986295 Epoch [225/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 11:50:34.022395 Epoch [225/250], Step [0060/0060], Loss1: 0.0027 Loss2: 0.0023 Loss3: 0.0015\n",
            "Epoch: 225 MAE: 0.015734650231602174 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:50:42.095470 Epoch [226/250], Step [0001/0060], Loss1: 0.0027 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:51:06.923101 Epoch [226/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:51:11.964221 Epoch [226/250], Step [0060/0060], Loss1: 0.0021 Loss2: 0.0020 Loss3: 0.0014\n",
            "Epoch: 226 MAE: 0.015582678662169547 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:51:17.670486 Epoch [227/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0020 Loss3: 0.0014\n",
            "2022-08-03 11:51:42.202818 Epoch [227/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 11:51:47.202544 Epoch [227/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0020 Loss3: 0.0013\n",
            "Epoch: 227 MAE: 0.01565175513840384 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:51:52.837262 Epoch [228/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:52:17.276669 Epoch [228/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 11:52:22.272097 Epoch [228/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0023 Loss3: 0.0014\n",
            "Epoch: 228 MAE: 0.015799376574004927 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:52:27.885386 Epoch [229/250], Step [0001/0060], Loss1: 0.0021 Loss2: 0.0022 Loss3: 0.0013\n",
            "2022-08-03 11:52:52.485879 Epoch [229/250], Step [0050/0060], Loss1: 0.0026 Loss2: 0.0020 Loss3: 0.0014\n",
            "2022-08-03 11:52:57.492991 Epoch [229/250], Step [0060/0060], Loss1: 0.0021 Loss2: 0.0021 Loss3: 0.0013\n",
            "Epoch: 229 MAE: 0.015712486321313515 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:53:03.208996 Epoch [230/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:53:27.678555 Epoch [230/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0018 Loss3: 0.0013\n",
            "2022-08-03 11:53:32.754256 Epoch [230/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0019 Loss3: 0.0013\n",
            "Epoch: 230 MAE: 0.015853493326594904 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:53:40.761771 Epoch [231/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 11:54:05.566581 Epoch [231/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 11:54:10.554954 Epoch [231/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0021 Loss3: 0.0013\n",
            "Epoch: 231 MAE: 0.01570423416024636 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:54:16.064620 Epoch [232/250], Step [0001/0060], Loss1: 0.0019 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 11:54:40.583954 Epoch [232/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 11:54:45.575064 Epoch [232/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0021 Loss3: 0.0013\n",
            "Epoch: 232 MAE: 0.01552938927142393 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:54:51.273160 Epoch [233/250], Step [0001/0060], Loss1: 0.0027 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 11:55:15.873444 Epoch [233/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0017 Loss3: 0.0012\n",
            "2022-08-03 11:55:20.870514 Epoch [233/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0020 Loss3: 0.0013\n",
            "Epoch: 233 MAE: 0.015406056277690426 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:55:26.546665 Epoch [234/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:55:51.116628 Epoch [234/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 11:55:56.114037 Epoch [234/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 234 MAE: 0.015496781923704676 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:56:01.716579 Epoch [235/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0024 Loss3: 0.0015\n",
            "2022-08-03 11:56:26.157902 Epoch [235/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 11:56:31.143193 Epoch [235/250], Step [0060/0060], Loss1: 0.0029 Loss2: 0.0025 Loss3: 0.0016\n",
            "Epoch: 235 MAE: 0.015445393317985156 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:56:39.245377 Epoch [236/250], Step [0001/0060], Loss1: 0.0027 Loss2: 0.0024 Loss3: 0.0015\n",
            "2022-08-03 11:57:04.191923 Epoch [236/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0024 Loss3: 0.0014\n",
            "2022-08-03 11:57:09.179786 Epoch [236/250], Step [0060/0060], Loss1: 0.0024 Loss2: 0.0023 Loss3: 0.0014\n",
            "Epoch: 236 MAE: 0.015441900340928919 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:57:14.786050 Epoch [237/250], Step [0001/0060], Loss1: 0.0024 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 11:57:39.245405 Epoch [237/250], Step [0050/0060], Loss1: 0.0020 Loss2: 0.0019 Loss3: 0.0012\n",
            "2022-08-03 11:57:44.238277 Epoch [237/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0019 Loss3: 0.0012\n",
            "Epoch: 237 MAE: 0.015782665099120803 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:57:49.986808 Epoch [238/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 11:58:14.625276 Epoch [238/250], Step [0050/0060], Loss1: 0.0021 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 11:58:19.610142 Epoch [238/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0019 Loss3: 0.0013\n",
            "Epoch: 238 MAE: 0.015685456147092203 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:58:25.206591 Epoch [239/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:58:49.675839 Epoch [239/250], Step [0050/0060], Loss1: 0.0026 Loss2: 0.0020 Loss3: 0.0014\n",
            "2022-08-03 11:58:54.645677 Epoch [239/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0026 Loss3: 0.0015\n",
            "Epoch: 239 MAE: 0.015432764229083818 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:59:00.200221 Epoch [240/250], Step [0001/0060], Loss1: 0.0026 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 11:59:24.730431 Epoch [240/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 11:59:29.722040 Epoch [240/250], Step [0060/0060], Loss1: 0.0028 Loss2: 0.0026 Loss3: 0.0016\n",
            "Epoch: 240 MAE: 0.015461472380492423 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 11:59:37.571178 Epoch [241/250], Step [0001/0060], Loss1: 0.0026 Loss2: 0.0020 Loss3: 0.0013\n",
            "2022-08-03 12:00:02.496707 Epoch [241/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0026 Loss3: 0.0016\n",
            "2022-08-03 12:00:07.618238 Epoch [241/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0019 Loss3: 0.0013\n",
            "Epoch: 241 MAE: 0.015568088754893296 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 12:00:13.275545 Epoch [242/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 12:00:37.914668 Epoch [242/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0023 Loss3: 0.0015\n",
            "2022-08-03 12:00:42.940109 Epoch [242/250], Step [0060/0060], Loss1: 0.0022 Loss2: 0.0022 Loss3: 0.0014\n",
            "Epoch: 242 MAE: 0.015290886208060243 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 12:00:48.545747 Epoch [243/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 12:01:13.355392 Epoch [243/250], Step [0050/0060], Loss1: 0.0024 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 12:01:18.372954 Epoch [243/250], Step [0060/0060], Loss1: 0.0027 Loss2: 0.0021 Loss3: 0.0015\n",
            "Epoch: 243 MAE: 0.015446312636846588 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 12:01:23.986117 Epoch [244/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0016 Loss3: 0.0012\n",
            "2022-08-03 12:01:48.618954 Epoch [244/250], Step [0050/0060], Loss1: 0.0025 Loss2: 0.0021 Loss3: 0.0014\n",
            "2022-08-03 12:01:53.612056 Epoch [244/250], Step [0060/0060], Loss1: 0.0027 Loss2: 0.0023 Loss3: 0.0015\n",
            "Epoch: 244 MAE: 0.01558296305556146 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 12:01:59.229397 Epoch [245/250], Step [0001/0060], Loss1: 0.0023 Loss2: 0.0021 Loss3: 0.0013\n",
            "2022-08-03 12:02:23.972931 Epoch [245/250], Step [0050/0060], Loss1: 0.0023 Loss2: 0.0026 Loss3: 0.0015\n",
            "2022-08-03 12:02:28.964528 Epoch [245/250], Step [0060/0060], Loss1: 0.0020 Loss2: 0.0024 Loss3: 0.0014\n",
            "Epoch: 245 MAE: 0.015588190864830737 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 12:02:36.945228 Epoch [246/250], Step [0001/0060], Loss1: 0.0025 Loss2: 0.0027 Loss3: 0.0016\n",
            "2022-08-03 12:03:01.737718 Epoch [246/250], Step [0050/0060], Loss1: 0.0026 Loss2: 0.0019 Loss3: 0.0013\n",
            "2022-08-03 12:03:06.747335 Epoch [246/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0021 Loss3: 0.0014\n",
            "Epoch: 246 MAE: 0.015726446055821956 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 12:03:12.390112 Epoch [247/250], Step [0001/0060], Loss1: 0.0022 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 12:03:37.035745 Epoch [247/250], Step [0050/0060], Loss1: 0.0027 Loss2: 0.0017 Loss3: 0.0013\n",
            "2022-08-03 12:03:42.071249 Epoch [247/250], Step [0060/0060], Loss1: 0.0029 Loss2: 0.0027 Loss3: 0.0016\n",
            "Epoch: 247 MAE: 0.015524252229148433 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 12:03:47.667474 Epoch [248/250], Step [0001/0060], Loss1: 0.0019 Loss2: 0.0022 Loss3: 0.0014\n",
            "2022-08-03 12:04:12.126885 Epoch [248/250], Step [0050/0060], Loss1: 0.0028 Loss2: 0.0024 Loss3: 0.0015\n",
            "2022-08-03 12:04:17.116690 Epoch [248/250], Step [0060/0060], Loss1: 0.0030 Loss2: 0.0028 Loss3: 0.0016\n",
            "Epoch: 248 MAE: 0.015536916279603564 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n",
            "2022-08-03 12:04:22.678924 Epoch [249/250], Step [0001/0060], Loss1: 0.0020 Loss2: 0.0023 Loss3: 0.0013\n",
            "2022-08-03 12:04:47.203152 Epoch [249/250], Step [0050/0060], Loss1: 0.0022 Loss2: 0.0023 Loss3: 0.0014\n",
            "2022-08-03 12:04:52.202199 Epoch [249/250], Step [0060/0060], Loss1: 0.0023 Loss2: 0.0021 Loss3: 0.0013\n",
            "Epoch: 249 MAE: 0.015565756353594008 ####  bestMAE: 0.015104381057123343 bestEpoch: 201\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9ebwcVZk+/pyq6uX2XXKzQBZCDERBZCCBBFBhXHBQ0NEZxgXUYVAHFR0Fx3HGGWUGRnRAf+iMoo7yHQeUJSIgiw6grLIIgQQSEpIASchG9rvf3qvq/P449Z46p7qql3u70/fm1vP55JO+3dVVp6qrznve53kXxjlHjBgxYsSYujDaPYAYMWLEiNFexIYgRowYMaY4YkMQI0aMGFMcsSGIESNGjCmO2BDEiBEjxhRHbAhixIgRY4ojNgQxpgwYY/cxxi5s9zhixJhoYHEeQYyJDMbYqPJnBkARgOP9/VnO+c0HeTyPAlgMYA7nvHgwjx0jRqsQewQxJjQ45130D8B2AO9X3pNGgDFmtXosjLGFAP4UAAfwgVYfL3Dslp9fjKmL2BDEmJRgjL2DMbaTMfZVxtgeANczxqYzxn7LGNvPGBvwXs9XvvMoY+wi7/UnGGNPMMau8bZ9lTF2To3D/g2ApwHcAECjmBhjRzLGfu0du48x9kPls08zxjYwxkYYY+sZYyd773PG2OuV7W5gjH1zHOc3gzF2PWNsl/f5Xd776xhj71e2SzDGDjDGTmrwssc4RBEbghiTGXMAzADwOgCfgbifr/f+XgAgD+CHkd8GTgPwEoBZAL4D4GeMMVZl+78BcLP37z2MsdkAwBgzAfwWwDYACwEcAeCX3mcfBnCF990eCE+ir0XndyMEfXY8gMMB/Kf3/i8A/LWy3XsB7OacP1/nOGIc6uCcx//if5PiH4CtAP7Me/0OACUA6SrbLwEwoPz9KICLvNefALBJ+SwDQfnMidjXGQDKAGZ5f28E8Pfe67cA2A/ACvne7wBcGrFPDuD1yt83APjmWM4PwFwALoDpIdvNAzACoMf7+3YA/9Tu3zP+N3H+xR5BjMmM/ZzzAv3BGMswxn7KGNvGGBsG8BiAXm/FHoY99IJznvNedkVseyGA33POD3h/3wKfHjoSwDbOuR3yvSMBbK7vdCrQyPkdCaCfcz4Q3AnnfBeAJwF8kDHWC+AcCK8mRgwAQCxAxZjMCIa8/QOAYwGcxjnfwxhbAuB5ANXonppgjHUA+AgA0+PrASAFMQkvBrADwALGmBViDHYAWBSx6xyEJ0KYA2Cn8ncj57cDwAzGWC/nfDDkWD8HcBHEM/8U5/y16DOOMdUQewQxDiV0Q/Dmg4yxGQAub9J+/xIiZPVNEHTMEgDHAXgcgvt/BsBuAFczxjoZY2nG2Oned/8HwFcYY0uZwOsZY6/zPlsN4GOMMZMxdjaAt4/1/DjnuwHcB+DHnqicYIy9TfnuXQBOBnAphGYQI4ZEbAhiHEr4LwAdAA5ARPfc36T9Xgjges75ds75HvoHIdR+HGJF/n4Ar4cIcd0J4DwA4JzfBuBbEFTSCMSEPMPb76Xe9wa9/dw1zvO7AELH2AhgH4Av0Qec8zyAOwAcBeDXjZ1+jEMdcUJZjBhTBIyxfwNwDOf8r2tuHGNKIdYIYsSYAvCopL+F8BpixNAQU0MxYhziYIx9GkJMvo9z/li7xxNj4iGmhmLEiBFjiiP2CGLEiBFjimPSaQSzZs3iCxcubPcwYsSIEWNSYdWqVQc454eFfTbpDMHChQuxcuXKdg8jRowYMSYVGGPboj6LqaEYMWLEmOKIDUGMGDFiTHHEhiBGjBgxpjhaphEwxo6EqGkyG6J41nWc8+8HtnkHgLsBvOq99WvO+TcaPVa5XMbOnTtRKBRqbxxjyiGdTmP+/PlIJBLtHkqMGBMSrRSLbQD/wDl/jjHWDWAVY+wBzvn6wHaPc87/fDwH2rlzJ7q7u7Fw4UJU7ysSY6qBc46+vj7s3LkTRx11VLuHEyPGhETLqCHO+W7O+XPe6xEAGyA6NzUdhUIBM2fOjI1AjAowxjBz5szYW4wRowoOikbgNf0+CcCKkI/fwhhbwxi7jzF2fMT3P8MYW8kYW7l///6oYzRruDEOMcT3RowY1dFyQ8AY64Iof/slzvlw4OPnALyOc74YwLWIKMPLOb+Oc76Mc77ssMNC8yFixIgRoyqe3dqPl/aMtHsYExItNQSMsQSEEbiZc15RA51zPsw5H/Ve3wsgwRib1coxxYgRY2risjvX4QcPv9LuYUxItMwQMOGP/wzABs759yK2meNtB8bYqd54+lo1plZjz549OP/887Fo0SIsXboU733ve/Hyyy+Pa5+f+MQncPvtt1e8v3LlSlxyySXj2jfhhhtuwBe+8IWa2y1ZsgTnn39+U44ZI8bBRslxUSy77R7GhEQro4ZOh6h9vpYxttp772sAFgAA5/wnAD4E4HOMMRuiBd/5fJKWQ+Wc49xzz8WFF16IX/7ylwCANWvWYO/evTjmmGOafrxly5Zh2bJlTd9vFDZs2ADHcfD4448jm82is7OzJcexbRuWNekqn8SYBLBdF7YbG4IwtOyJ45w/gRpNwznnP4Ro99c0/PtvXsT6XUEpYnx407weXP7+UB1b4pFHHkEikcDFF18s31u8eDE45/jHf/xH3HfffWCM4bLLLsN5552HRx99FJdffjl6e3uxdu1afOQjH8EJJ5yA73//+8jn87jrrruwaJHoef7ggw/i6quvxvDwML73ve/hz//8z/Hoo4/immuuwW9/+1tcccUV2L59O7Zs2YLt27fjS1/6kvQWbrrpJvzgBz9AqVTCaaedhh//+McwTRPXX389rrrqKvT29mLx4sVIpVJVz2/58uW44IILsGHDBtx999342Mc+BgB49tlncemllyKbzSKVSuGhhx5CJpPBV7/6Vdx///0wDAOf/vSn8cUvflHWiZo1axZWrlyJr3zlK3j00UdxxRVXYPPmzdiyZQsWLFiAq666ChdccAGy2SwA4Ic//CHe+ta3AgC+/e1v46abboJhGDjnnHPw6U9/Gh/+8Ifx3HPPAQBeeeUVnHfeefLvGDEIjsPhuJXrzPW7hpEvO1j6uultGNXEQLz0ahLWrVuHpUuXVrz/61//GqtXr8aaNWtw4MABnHLKKXjb20RP8TVr1mDDhg2YMWMGjj76aFx00UV45pln8P3vfx/XXnst/uu//gsAsHXrVjzzzDPYvHkz3vnOd2LTpk0Vx9m4cSMeeeQRjIyM4Nhjj8XnPvc5bNq0CbfeeiuefPJJJBIJfP7zn8fNN9+Ms846C5dffjlWrVqFadOm4Z3vfCdOOumkqud366234oEHHsDGjRtx7bXX4mMf+xhKpRLOO+883HrrrTjllFMwPDyMjo4OXHfdddi6dStWr14Ny7LQ399f8/qtX78eTzzxBDo6OpDL5fDAAw8gnU7jlVdewUc/+lGsXLkS9913H+6++26sWLECmUwG/f39mDFjBqZNm4bVq1djyZIluP766/HJT36ynp8sxhSD7XKUnUqP4D8ffBl7hwu45wtntGFUEwOHnCGotXI/2HjiiSfw0Y9+FKZpYvbs2Xj729+OZ599Fj09PTjllFMwd+5cAMCiRYvw7ne/GwBwwgkn4JFHHpH7+MhHPgLDMPCGN7wBRx99NDZu3FhxnPe9731IpVJIpVI4/PDDsXfvXjz00ENYtWoVTjnlFABAPp/H4YcfjhUrVuAd73gHKALrvPPOq6pl0Cp+wYIFOOKII/CpT30K/f39eO211zB37ly5/56eHgDCg7n44oslxTNjxozIfRM+8IEPoKOjA4DIFP/CF76A1atXwzRNObYHH3wQn/zkJ5HJZLT9XnTRRbj++uvxve99D7feeiueeeaZmseLMfXguBy2U+kRFG0XJXtqU0aHnCFoF44//vhQUZdzjijZQ6VjDMOQfxuGAdu25WfBOPiwuHh1X6ZpwrZtcM5x4YUX4qqrrtK2veuu0CjdSCxfvhwbN24E9YEYHh7GHXfcgTe/+c0N7ceyLLgeRxtM8FI1h//8z//E7NmzsWbNGriui3Q6XXW/H/zgB/Hv//7vOPPMM7F06VLMnDmzoXE1C/mSg46k2ZZjx6gN2+Uoh1BDjuvCDnl/KiEuOtcknHnmmSgWi7juuuvkey+88AJ4shM33vJLOI6D/fv347HHHsOpp57a0L5vu+02uK4refRjjz22ru+9613vwu233459+/YBAPr7+7Ft2zacdtpp+MMf/oC+vj6Uy2XcdtttkftwXRe/+tWvsHbtWmzduhVbt27F3XffjeXLl+PYY4/F7t278eyzzwIARkZGYNs2zjrrLPz0pz+VxoyooYULF2LVqlUAgDvuuCPymENDQ5g7dy4Mw8CNN94Ix3EAAGeddRauv/565HI5bb/pdBrvec978LnPfa5ttFDfaBGLv/F7PLV50ga9HfJwXQ4nRCwuR2gHUwmxIWgSGGO488478eCDD2LRokU4/vjj8S//8i84+y8+hDe+6XgsXrwYZ555Jr7zne9gzpw5De17wYIFOPXUU3HOOefgJz/5Sc0VMuFNb3oTvvnNb+Ld7343TjzxRJx11lnYvXs35s6diyuuuAJvectbcPrpp+O4446L3Mfjjz+OI444AvPmzZPvve1tb8P69evR19eHW2+9FV/84hexePFinHXWWSgUCrjooouwYMECnHjiiVi8eDFuueUWAMDll1+OSy+9FMuWLYNpRq+cP//5z+PnP/85Fi9ejI0bN0pv4eyzz8YHPvABLFu2DEuWLME111wjv/Pxj38chmFIeu1goz9bQsl28dpgvi3Hj1EbdgQ15LixIZh0zeuXLVvGgx3KNmzYUHUyayfW7xpGV9rCghmZdg/lkMY111yDoaEhXHnllaGft/oe2bhnGGf/1+O46q9OwEdPXdCy48QYO475+n04ckYHHvqHd2jv/8WPnsSBkSKe/Ocz2zOwgwTG2CrOeWjMeawRHARMNmM72XDuuedi8+bNePjhh9s2BlpRhkWlxJgYsF03dOVvO3F+QWwIWgyOyWMEvvWtb1XoBR/+8Ifx9a9/vU0jqg933nlnu4cgJ5ipHn0yUeG6HC4XekAQghpqw6AmEGJD0GpwYLI4BF//+tcn/KQ/UeF7BJPkx55icLyHMGzlb0eIyFMJsVjcYsTTwtSAy2NqaCKDDHWYWCyooan9pMaG4CBgat9iUwM0wcSGYGJCGoIwjcDlcGNDEKOV4IjF4qkAh8fU0ESGLT2CSkPtuDz2CNo9gEMJd911FxhjegmIOo1AX18f3vnOd6Krq6uuktAxJhaIYo49gokJqeFEeARTPY8gNgRNxPLly3HGGWdg+fLlALzyEqiPGkqn07jyyiu1JKkYkwckQsaGYGKCfp8wj8B2XOnRTVXEhqBJGB0dxRNPPIGf/exnsh+B4zj47pX/inP+9FSceOKJuPbaawGI0s1vfetbsXjxYpx66qkYGRlBZ2cnzjjjjLqzhmNMLMRi8cQGrfhdjgo9wHY5eMj7Ew0//cPmlpUwOfTCR+/7Z2DP2ubuc84JwDlXV93k7rvvxtlnn41jjjkGM2fOxKpVq/D0ihXYtXM77nn4j3jjvF709/dHlm6OMblB83/JntiTyWTGc9sHkLIMHD9vWsPfVakf2+VIGqzis+D7Ew3X/P4lXPSnR+Mti5pfVDH2CJqE5cuXyzaO559/PpYvX46HHnwIH/r4J2BZoq7OjBkz8NJLL1WUbo47ck1+xJnFrceVv12P79z/0pi+qxsC/TeiiC93gtNDLgfMkMrDzcChNwPVWLm3Av39/Xj44Yexdu1aMMbgOA4YY1i2TEz2E/z+itEExIag9SjZLoby5TF9V40KCkZ2Sf1gglNDjsvRKocl9giagNtvvx0XXHABtm3bhq1bt2LHjh046qijcOLiE3H7zTegrJRjjirdHGNyw4k1gpbDcTmyxbE9K6pHoL6m0hOAaGU5UUH6hdEiSxAbgiZg+fLlOPfcc7X3PvjBD2L37t2YM28+PvDOt8hyzMlkMrR0MyDq9X/5y1/GDTfcgPnz52P9+vXtOJ0YYwA9qKUJPJlMdtgux+gYDYGaUaxGDqnRQhO58ByNM6aGJjDUtpKESy65BLbjYv3uYaSsq3HsnG752SmnnIKnn3664jtbt25t5TBjtBBEK5TjonMtg+NyjBbG7xGouQSqgZjIIaRO7BFMXvCQVzEOTbhTQCMolB3kSu2jMW3XxWjJHlOYp7byV34j1QuYyEllNHwzNgSTEFz7L8YhjKmgEVx+94u4+Kbn2nZ8xxHx/rmy0/h3XXXyD9cLwgrSTRTQ/RWLxZMQdFtNYI8zRpNgTwGNYO9IAXuHCm07Pl3jsdBDukYQHkE0kcNHJTXUIo0gNgQtxGRqShNjfBgvNcQ5xz1rdk3oxjaOy1Fuo6BKk+FosfEQUk0jcMLpoIkcPkr3V0wNTUYQNTRx768YTYJf735sE+Xtq3bikuXP46antzVzWE2Fy3lbqS+aqEfG4hFE0UGTRCOQUUOxIZh8iMXiqQN3nGWoV20bAABY5sQtceC4vK08uis9gsYNQdTkr0UNTWBD4PKYGpo0CC1DjfrMwAMPPIClS5fihBNOwNKlS9vaiD1G4/A1grGtmF/ZNwoAmNmZatqYmg3Xba8YPh6NQKeGwumgCW0IvMseG4JJgMoy1ND+r4ZZs2bhN7/5DdauXYuf//znuOCCC1o40hjNxnhLTLyyd0TsZwLziA7nbW28Q9d4ZAwegR0RHTRZNAKfGmrN/mND0CSEl6G28d0r/xXnvustNctQn3TSSZg3bx4A4Pjjj0c+n0exWGzb+cRoDFIsHoPY67ocw94qdyKXQnbcdmsE4thjKTMRSQ1NEo1AlpiIM4vrw7ef+TY29m+svWEDeOOMN+Krp3616jZhZaif+ONT2LVzO371u8dx0utm1l2G+o477sDJJ5+MVGri0gQxdMjM4jGsmF8bzFfsZyLC5e3TCNSaQGMKH43QBSaLRuBM1qghxtiRjLFHGGPrGWMvMsYuDdmGMcZ+wBjbxBh7gTF2cqvG02qElaF+5OGHRRlqs/4y1C+++CK++tWv4qc//enBP4kYYwaJeSXHbbhH9cY9I/5+JvhkNJbza8qxlWM2VSyuUp56IqHVYnErPQIbwD9wzp9jjHUDWMUYe4BzrlZSOwfAG7x/pwH4b+//MaPWyr0ViCpDfdLSZQD8Bvasxo+4c+dOnHvuufjFL36BRYsWHYSRtx+24yJXdtCTTrR7KONCkGtONBD989pAzt/PRNYIvHN0XH7Qo5vU6ztejaAc4QVMYDvgG4LJ5hFwzndzzp/zXo8A2ADgiMBmfwHgF1zgaQC9jLG5rRpTqxBVhvqEE0QZaruOMtSDg4N43/veh6uvvhqnn356G8/m4KI/V8K2A9kJvRKuB+oE3iiP3uzIlese24ybVzQ/H4Emo3bQV+oxx0INuRHXOKru0EQDDbNV1UcPiljMGFsI4CQAKwIfHQFgh/L3TlQaCzDGPsMYW8kYW7l///5WDXPMiCpDvWePKEP94XefgSVLllQtQ/3DH/4QmzZtwje+8Q0sWbIES5Yswb59+9p0RgcPrivyryfySrgeqLXsyw22q9RWpU24Dr9Zsxv3r9sz7v0EQeMca4hsM44NjI0a0j2C2nWHJhp8jaA1+2+5WMwY6wJwB4Avcc6Hx7IPzvl1AK4DgGXLlk24XyuqDPVooYwtB7IAvoU/mTdNunVhZagvu+wyXHbZZQdjuG0F5xyDuTJ6OhIwDSYFwHbwzs2EasganSjV7zZjMrJd3pJJjXbZDsHYGadHEBUmGtWwZqJhUieUMcYSEEbgZs75r0M2eQ3Akcrf8733DgnwiNdTGSXbxY6BHEYKol4MuexRz+BQvjyhH1CCG7HirAdOkyNXHNdtyWTdznacKm0z/jwCf19RdYcmGiatIWBCGf0ZgA2c8+9FbHYPgL/xoofeDGCIc767VWM62NAMwSRf8TYLdBXomZP/hzyEZcfFtr7smPvUHkxEUQ+NfrdZHkEr+O52GgKdGhpL0bk6ylBPYEPQ6vDRVlJDpwO4AMBaxthq772vAVgAAJzznwC4F8B7AWwCkAPwyRaO5+Bj4t5XbUPQHtJKJ4wb51U+m2hwxyEWq99thlZiO62ihsaeKxGGQtlByjJqRtMBPh3VkTDHmEcQnjugvj+R77NWRw21zBBwzp8AUHXUXDzpf9eqMbQbMTUUBnElgpN82LxFb00Gbyqqlk090CajplBDrSkFMd4KqyoKZQenfutBfOvcE/D+xfPqPnZnyhpTZrFG3UVkE0/oxjSHQtTQ1AUPfTmVEbwMPkUUbQkmsMcuMR5qyHU5kpZ4FJvButiu21KPoBlRQ/mSg+GCrWVVVwNd346kMSZqSqODnPDfalJoBHGtockHHtuBCshCfN7fVamhwHcmMsYjFtsuR8Jz+Z0mcPtOizWCZqycZWvPOmsz0bE7EiZslzfsOTkuBy2myxEawUQOYW51raHYEDQRUWWogdrdyp555hmZP7B48WLceeedrRrmhAAPeALV5q3J0OlNnRtLY8gjMA0G02DN0Qhc3hLhUxqCJhiZRju6qYYAaNwrEcbWgGWwQBJZ88TiA6NFfO6mVS0Jbogb00wiVJShVj+scY/9yZ/8CVauXInVq1fj/vvvx2c/+1mZkXwoQa7yoRuAcLFY/38iY1zho2QIGGsKNeQ4rSkOR6fYqKELgyNppvr2JQ1BUhiCsV5jy2SRoaTOOC/+dY9twX3r9mD5M9vHtZ8wxD2LJwlCy1DbDr575b/ir971Fiw7+aSqZagzmYwsPlcoFOqKpJiUCHBD1agh2mgiR3MQ1FXyWKgh0zBgGM0513KLNIJmegRkqOrt0UzHlB5Bg+W+bYfDMhgsw4iMGhqvR9CTFs/vYK75HoHbYo/gkCtDvec//gPFDc0tQ5067o2Y87WvVd0mrAz1I4//UZahftMR05EbGapahnrFihX41Kc+hW3btuHGG2/UqpIeKuDK/5zzOqOGDsbIxgfHBRgTYx2LWGwa8DyC5kQNtYQakuGjTaCGGtwXXZdM0vK+19j5uZzDMBgYi+5BMF4jPC2TBICWUENuHDU0ORBWhvoPj3hlqC0LnNcuQ33aaafhxRdfxLPPPourrroKhUKhbefTKqiTu/rcTXpqiHOkLeKvGw8ftQxDaAQTOKHM5/WbY6zEvur1CMT26bF6BK4rPYKoVpXN8giGW6gRtIooOOSWnLVW7q1AVBnqxSctVbaq/yY77rjj0NXVhXXr1mHZsmXNH3A7wf0X6uQ/2cVi2+XoSJrIl52Gu5S5XBGLxzkZuS4H53qIZLNgNzh5V0Ojoai+RmA09D31+3SNNbFYLe8xzmtGdG5rPIJYLJ7wiCpDffwJJ8gy1BzCYLz+DceElqF+9dVXpTi8bds2bNy4EQsXLmzbObUKKjXk1vII5GetHtX44bocaS8XYGwaQXOihmzJ4zf3oqlieFPCR71LVK93YVdQQ2PTCILGVg3XHe+1p2sURw1NUUSVod67Z48sQ33aspNxw4034ZUDefzPz2+qKEP9xBNPYPHixViyZAnOPfdc/PjHP8asWbPadEYthHdDc65P/uEJZbTtxLcEjsslbTE2jYDBYKxmfPymfaP47I0rI6mRZgq62n7HUV01DDS++vMIxHZjpYYcl8M0GRKmoeURUBMhg40/oYy+P5gvyfdGizbufH7nuPar7nsydiibMogqQ71/pIjdQ3kA38Kiw7pQdlxs789h0ZsWV5ShvuCCC3DBBRccpBG3D+qjphuC6G0ngR3QDEHjGoELk9VHDT3zaj9+9+Je7B0u4MgZmdB9if+be9GaXYrBlR5BvYZA/N8xRmNruxwmY6F5BJZhAHDHfc3IWA4pUUP3rt2Nf7r9BZx21EzM6+2I+mpN0DMQewSTEv6Nxbn/I07kVPaDBRExJF6LvgTR12QyaAQO50gnxkYNNZJQVrKdqsegSZrz5vY/Vn+fZngbTsMaAYWPehpBox4BpzyCgFisUEbjvV70/WGlKB4Jx42ONwjfIxjXbiIRG4IWggf+IjFpKhsCNY2AHhwrwhD42ccHaXDjgEYNjYW2qFMsLtrVV/xazaMm0kPquMY7qan7azRqiBLKGhaLHbHytwym6wKuC9P08gu8Y+RLzpiMgmrEic7MlRxt/GMF7TtOKKuBCckj88BLb4xT2hAoL7gUwIzqUUPjvFwH495wOUeKxOIGf18pFteRR0CTcBQ906qOW+rvQ5PavWt3Y99wdIjzQLaEu54P7zMlo4YarTU0xjwCusbBzOKyKzwC0ggcl+OMbz+MXz67o8rewqEaj3xZGACqlDpeLyqOGqoD6XQafX19E84YqKPh3P97KhsCWYYafn2eSI+A/h/H78o5R19fH9Lp9Jj3UQ9sR2QHJ83Gq2O63JuMalBkgL8SjppY1PebqROoq92y7cJ2XHz+5ufw3h88HvmdG/64FV+6dTX6RouV+2swJ0HtRwCMRSx2YZkMCUP/faSnYBpwXI6RQhl92RJe3jvS0P7FMfxz6RsVgnG2ZGvjHytaHTV0SIjF8+fPx86dOzHRGtsP58uSL3T6RdbhAe8GMYbHLhxNZmSLNgZyZYwkTSQtA4O5MkZTJnJFB2bgmuRLDvqyJZgGAx8c+0SeTqcxf/788Q69KkQuAJAwWcPUkO2IrNeGPIKI7TSPoIm5BE5gFU3Hp/s5DCu39QMQ4ZQzu1Kh+2s8s3gcYrHnEahGRHpjXHgKI97zun+k0njVcwzCQK6EI2dkkCs62vjHCvp6HDVUBYlEAkcddVS7h1GB7/7+JVz7sHAxf/LXS2Ew4DP3rAIAbL36fe0cWtvwi6e24t/ueRHvO3EuTjyiC1fdtxGXnPl6/ODhTdjwjbMlBwwAv31hF75wz/PozSSw+t/e3b5B1wHi+ROWMaZkp6RlwDBqF50r1qCGWqURBDuwqcfJlWwZ3y/H4bhYvX0QAOTkqoImxnqv1Xgzi13OZWSWnk0sPAXHFdoB5QDsD/Fi6jkGoT8rDORok6mhWCyehBmpHzwAACAASURBVAjWMVH/nmg01sECXQPH4VJIm94pvKVcyQ7dthniZKvheIXjrDFkB8uIljqoIV8srp5HEHw9Xujho64Wgrl6x2DF9hv3jCDr/b6hhqDhWkOBonNjSCgzDZFHEKTP/EQzf6wHxuARqEMayAlDIMXi8VJDsUYweaHyqsFCYPSQTDX4CU8cea9nbWdKrCZzgWvSqKDYTjicw2QYU5kI8iaMwGo1DLXEYnVibWYp6mArTnWcz20bqNh+lfLeSKEy01bWLaqzpPV4qSHH5bBMyiPQ6TOhEQiPgMY6fo9A7Ic8gvFTQ55HEBuCyQc3sDrTxaTGbzQVz20fwIu7hsa1j3ZAegSui3zJQSZpyoebIi0I9MDabmuasTcTjuvz/I2KtI6X7GSy2rH/tBKOuh7ayr1FeQRlRy9zvWZn5X24ZscgEqaYtKpRQ2MOH2246Jzw2IRHwAPv+78bjXWkYKNQbmyxpl6TnGcAyMttNJIsat9x9dFJCPUeD3oEfdloka0eXPnb9bjmdy+Nax/NAuccv1mzq66Hmrwk2xXUUCZpSUMQ5REAE98rcIhiMBtPTGooj6BcI6FMW3y0Jo/Adrh2/FFv8iyUHfzlj57Eyq392DWUx9GzugAAwyEeQaMaAW0/1jIe8vepyCwWGgElNapjPdDgYo3GmDCZ9PizUiwep0bgXf6YGpqEcHnQI/Bvhr4q0Rb1oGS7ki9uNzbuGcEXlz+PJ145UHNbimRxXI582UZH0kSnJzQGKQT1WZ8MhsA09MSkRr5rmaLWEBnKPUMFPLB+b8W2E9EjKHrZztv7c1i9YxD/dPsL2DdcxKLDOwE0RyOgc6FcjbF4BAYTUUNqyKpuILg21kYjh1wu+iJ3pizpCTQrfJSuf6vKUMeGoIUINsZWH8z+7PioIcdtTTvCsYBc6CC1EwbVIyiUXaQThqzBsnMgH7otABSdia2puFxMNGPVCGiSIm/ipqe34fM3r6rYlibAKKrBDpRPaBbU+VoNHwV8AdvyVqv7R4rYM1zA3Gkd6Eya1aOGGkwoS5giV6PRek6uN+EnjIBY7Oi9IEY0j6CxxRpRfJ1JS3oCFD467szimBqavAiKxeoE0ehNFoTt8qaGB44HjfC9NNE5rqAXkqYwBEnTwNa+bOi2gJgwXJdjMDe+69YqqH2HGw0VpMgVQ9EXRou2EGUD15QmziiqoVUegSYW20GPwDNO3uQ8UrSRKzmY3ZNCdzoRLhYrnenqMZx0LgYDklbjSXs2lZIwdbHYdl0ZseVw4REQ+9KoR+B4XdA6UyayRRsl21USAOOooSkL1+VSMAuu4MN400YwkTwCWQO/jvGo9fJLtgvLFKuxI2d0YNuBnLZtsL7Nvet24/SrH5Zp+63GUL6Mj173NHYO5Gpuq/UUaNA+S6FZCR+VImPgmgYn3SDKgTo62hgdV9I4jSJYdI4m4s6kKfcZXN3P7kmjO21FeATKmOvRlrwOY4wxJAJJYfWAKKBEIPPb9mg53yOwMX+6qOraqEbgeh5BJmkhW7K1cOjxawSCdmpVL/PYELQQjsuRMA35WssrGOcKQX0Y241GPALyklzFIwCAhTM7Kz2CQA38vcNFZEuOTNZpNV49kMVTW/rw4q7hmtvSJEBhiI1A8tRKZjGJjUExtWatoSrU0Id+8hSOvez+hsamjlGOwfHv5UzKQrHsho5VGoJimFjsb1uPYEyGFhirR0B5BNU1guFCGTM6k+jNJBr3CFyxYu9MmciVHC1EfLztPSkhrlWIDUEL4XDfELiKRpAwo0MMd/Tn8OzW/tr7dlrToDwM614bqlp7RbYwrGM8ruIRlB3fY1o4SxgCHqDTCCXblZNHMLqoVSjXEGZVUFKYMZbwUe7nEdCx8qXw6CBfLK4dNRQcR1jiVyNjlPtVMou7UpbipYQZgkRtj6CO1T1x/IDQCWp5BCXb1bahCd8KJJSVvRpRVAJ8uGCjO21hVleqcY+AcxhMdFHLFm3Ncx1/05vWlZcAYkPQUriuKB0AUCy8uAFTlhnpEfzZ9/6AD//kqZr7Ppix9f929zpcde+GyM/pvIJ8dhhoAnE8jyYhPYIMCmUX+5RVmBMIH1X580ZRKDsVmcu1UJZZvHUYAtfPDh5rQpnJwqihcI8gaoU5Xo1gMFcKHb96v5YdV3obmSrU0OHdqWhqSItC4uCcV/X0NI/ArF3G4yu3rcHf37q64vsJg8njAT7lZBl+0bmedALdaavh+4x+x86k5xEo3x/vos3lHEYLZ+vYELQQDoekPtQ8gqQVHWJIq6taySwkth4M5Muu1mwjCJn4VYf7q3sELhKeoVw4S4Qabj2QrdgW8MViwJ8kb16xDTc8+Wpd53D53S/i4pueq2tbAnk49dB4jeQChH3XMgyYiqdIHkFwcqVJN+oYdhWNgBB1b+VLDs749iO4Z01l6Wg6nuVNpHScTs8j4Fy/H7tTFjpTVrRYHDAs//2HzTj5ygewZyi8rLXjNkYN7RzIYVu/fi9RiQlA16os08/qHinY6OmwhLEZY/ObjBc+SpFDQH2LpKr7dmNqaNJCFYtdT9w1WHTZZRX7hqu7pQ4/eGJx2XGr0jFSI6iDG3fkSkxQQ6pGAEDTCdRnp6jQEfSAff3OdbjiN+vrOoe9IwXsHsxXvF923Ejhvl6PgLqtGVIjGFv4qKn0LM5FUEOShqkjaijKawhboQOiPs5o0cbukMmYfrd0woTt+lFDXSkLnAvKSh3r4T2i2mhP2gpdROiag4tbVmwHAIyG6AmAnxkM1EkNOa4M3aTvU7lpwF+0SMrI61A2nC+jO51AcizFAx3xO3YmTWSLjswhCJ7vWEABBa1CbAhaCFUstj2PgGKWoybx7rRIrtpTpeEHQBrBwfEIbMetSqs0EjXkKNsKakjc3PN6O2Aw4DUllyBIDUkhNeCy7xupfq3ouGEJeNc9tgUfuPaJ0O+Ua/Dx6r4BVISA9o0Wcf51T9Ucn5rd6nDdEJQCtXhk+Ggd1UejJp+wFTrgU25hkyxdgpRloGxzjRoChIFSr++caaJseHfa8pIf9YWEbrDcUOOjbe/4GoHwCKrfa8WyWzERk1gM+IbUVjSCfNlB0XbRnbKQssbmEViGiBrKlx3N4I6XGuJenkqr0DJDwBj7X8bYPsbYuojP38EYG2KMrfb+/VurxtIukKvIGFUfdWv2pp3l1W2vZQhIbD0YKDtcc3OD8Cf3esIA9TwCWqGZBkNvJokBpfG3Sh8UFUMQNEov7Khdc0kYgspz2DNUiJyE6o0Bl20EAxrBS3tH8PSWfqwPiToayJYkT+16QqDBmJxw8yGlJDjnckx1JZRFbBNF81UzBHSOKctA2fW9M8oKL5Zd7X480gvB7E4nAFR6IVFGPuqeVjWCsPDRda8N4e9ueU7eg5UegSvDRwG1jpVYjJiMyRyV7rRVl9cRhOv6eQSAHn46bmqI++ffCrTSI7gBwNk1tnmcc77E+/eNFo6lLSBe0vL4R73kbZQhECWZ99ZaIbmVyUZjRa5k44vLn8eO/vB4edutzyOoJ2qIhkx5BEQNAcD0TEITDCM9Am+1PKdHrDpf2Fk7GoaOF0TZEUk/YWXBabKopRHQ5C2MvCHHSe8Xyvpxh/JlvPmqh/C7F/d6Y3O9+wIVxk41BELkFK8d10Wh7FTcA6r3EvyMyjNQQ/UgqGZQmOdE1yCdML0SE2KbTIo8AkeO9ZaLTsM/vudYAL6HW2EIAh6BP+YoEVx4TYBHDQXO7Y+bD+D/Xtgtq4aSR8AVKtLwGtOox5TajsnkIqSnIzGmEFWpEXjGUQ0/HX9C2SSNGuKcPwagdhzkIQw1pND1onzU5JUwUFGt2h6BO+6KhoS7V+/Cb9bswo8e2RT6ednrHaBOiFfdtwF3rxaiYiNRQ7StiBryNRQAmNGZ1AxBUCz2NQIxqdAKaXVI9csg3AhqSBiB8Ae13KBHYDLdI6D3g57IYK6Eou1iR3/O1xfIiHh9K8h4qMarFJgw3/iv9+Nvf75S23e18FEq9x2liVT1CNRAByV0ucvbZ9H2NYJj53TLjmS+R6AfU/1th/O+kYji5VWPIIy2yZdcbV8lx4XL1f4NfokJwP9ty46vEdA5dqcTYxOLPUGXPAKKgKN+yOOBWFSOaxdV0W6N4C2MsTWMsfsYY8dHbcQY+wxjbCVjbOVEa0dZDbKGjHeTkeBVrSUhvR8VPQGIm8Ll43c3Ca96kTrzp4e3z6SHRq0ldMuK7bh79S4AikdQj0bgbSKjhjSPICkbegDBPAJH0QjEOOghX1unRxBmCGjMYau/evMIiK8n2o+0G5rsigGPgMYxUrQ1fYE8AvU6qxNjsMUiAPzhZf150OpbVRgCMUFFicX1UEPkEfgagU8N0fcoEgyo4hEoHtjm/aP+eUXc0yTqAqjIDgaAXJnKR5e1c8gWbbiu8KREBznmHcenMy3T0CJyejOJMXWac70SE75HUEBn0oRl1tY0asE5hBPKngPwOs75YgDXArgrakPO+XWc82Wc82WHHXbYQRvgeEFuJ4WmkeBVzSOgG7SaRyCzc3k4bfHiriF8QeFLa2HLfmEIejPJqmMi8a3gCWHbPSpJagR1iNcyfNRbVaqGIOgROF6CDiAmxKBYXPJW2gO5cu3J2vPIgteEIoPCaSM/xLDqvrluCFzF2AFAIeARkGEYKZT173oLBJWGUycQzRBolFGlgQgbN/H5tamhSi2FfreUJ9RKjUChhmjiVOk+8hiCAr/6e21RQobDrvVAtuQ9S2K/YbRNPtANjc4hV3LkNaZ8AUDxCBQvnTCnJ42kadRd3feFnYNYs2NQegR0znuHi+hMWd5CcHyLNlFi4hA0BJzzYc75qPf6XgAJxtisdo2nFaAbg2rI6PVookQxccNU8whqJQ2t2NKP376wG4MRD3wQrx4QK7Iow0EPDYlvxH0StUGGop5uU3R+NDkmldXj9E7hEfgiKvdbE6rUUMnnsun5rVX5VFa7DBoCp5ohqNMjcHWx2Hb17wXj9kteJdXRgu8R0ILBdbmc1NQxAPoErVbffGWvv6LW7o2gRuBdyyhqSBrYkPtAisUBjUCKxbYrf3/VuBMnH7xP1XFu3uePPzjBv7J3BCd/8wGse22oamYxRVkNF8pe+RKx/9Gieo0NP2pI8QgSXocywuE9Kc/g1Td5X33fRvzHvRsEj28wGUm1rS+Leb0dFX2SxwLSG1uFthkCxtgc5pk4xtip3lj62jWeVoCyAYkaIsGLKh2GgW6YfSOFSJFSNwTRfG49vCTnHFv7ctqxg58HJ2DiPou2i/0jxcbyCFzar/hf0wgySZQd7rf341xOXsESExRBM60j4b1XPQuUxhikaWjSC5v8GjUE0tsjkZmTIQhQQ9IjsOW1lbWGONdyNjSNQHmtGhdVLNfaMAbGTfeTysmrqEcjSHsaAU2kvkfgouQ4cqFDIKMQnFTV+1/1CIIUyp7hAjgHdg0VZBx9IqQMdV4aAlv7LXMl/Rr74dyupFhVj2BWVxIpy2woaihXEmGnLhc8PmkxLgdeNzODhGnU9SxWg8NbV3kUaG346HIATwE4ljG2kzH2t4yxixljF3ubfAjAOsbYGgA/AHA+b3NH92B9kvFCUkNM1Qj0mjJByNW1w9EfUXJZnbDDuEc1a7IWtIm8yr4Af9WlRkNs7881lEcQTKSzDN0jAIABr98rRUokLQNFx5VGhEo0c+7TWYVSjVh/KdzW7xGUGqWGGNNWf1EeAY1h1OOvAWi9DDRDoHkE/muVannhNV8sDzZm18bp/R2VRzBSrBI1pHoErt+83tcIHC1BkOCLs+FGCQhE10R4bIDf70CIxfo1pYXASKEcuE6OpLw6PL6e9ksLl4SiEVD+Q9Iy4HJg075RfPx/nq5a8ZYi2ogBII8AAF43sxOmwcatEbiuT5O2Alardsw5/2iNz38I4IetOv5Y8I+3r4HtcvzoYyc3ZX8O1x9wNYuxnhIB+Yhs3mruv/jcW8nWcfO9vLe6UKdO7vQwqI29dwzk/KihOjyC4OSkCoszOsXqvj9XwoKZGRkpkfJWZ75H4K/6pEdQrs8jCE749IDmSg4uvnEV/v6sY3DsnG7v3P0Ip2qQk3mglHSkR2ATn132V6tKNFkUNaSvdP1tNuz28xTsKvcGjWe4YKNvtCgjewjZKoaAdpW2DJlJDAQ8AtvVPDw6LxrLmh2D4ACWHNmL4K1GRd6CkXBqQp2aRxCcWIkaHCnYGoWWK9nY4ZURnz+9AwnDp4bo3ra8iC3AD0kmyvKZV/vx5KY+bO/P4bi5PRXXRZy7g4RpSLGY6DIAeN2MTNM0gknpEUxG7BzIY2dELP1YQLweJZBR1FC1CpX1JARVW/UBaqx+7ZvvtUH/fMM40bDJZ/9IUbbM296Xr4ga2jdSwOOvhEd3BemupDJxTM+QRyA8IYqUSHrhgmqJCZrQezPCEEQZTYKkhgIrSTrn7f053P/iHvxx84GKz2p6BAr1YIV5BEGxWIkaqvAIeEAsjqCG1G3Uc3dcLvMFojyCNTsGccq3Hqyocksr5/DMYvIIDO+YZAh8jaDkuJrmA+jU0F/86En85Y+eFPsLeIbzesUEXI9HUE0sHs6XtfFni47Mj1kwIyMXHrZqCExfIyCPgMZN3lPQ21V7VVAgg/QIUqpHkBHNcMZLDbmTNLN4MqJoOxWrt/FAFYs1j6BKg3MRSUPNbKJD6Qhhk7e/Qq9986mrv7C8BPXBlB7BSBEzO5OY05P2PAKubXvTU9vwtzesDE/SCpxTMGoIgIwcokxNMgRq1BBN6L0djRqCgEZAk7L3wKthjmTYaiWUye5ZlAsQoJSiqKGgRmAwBs6hlUZQV75Fu9Ioq+cGiAkraRqhsev0d1+2BJejIoFwpI7wURLvyQPzxWIH5UCCIIAKcVaO09W9h3nTOuT4Vahj8T0CUbRR/V1yJdUj0A3m9v4cGAOOmN4hjYlODfmZynO9cZBBI2E9qH+9vHcET23pw9qdQ3KRQklrSdOQx1kwMyP6WI+BGnpl7wie3iJkU2qF2irEhkBByXYrVm/jAbmKZlAjqOoRuEhb4mGry2vwavZcsvx5vLRnRPtePTdfVEiifC9CI5jVlcKRMzp0jYDESE+wCxt/0LZpeQSkEeQUj8AznGrZ7VxJ9QjEd2pFDZEBitIIyACo/Hk1j+ChDXsx5GWiuppG4G/vRhgfqREoUUNEKwHAaDFcIyiFGAIWmPD9gAQ/dv3+dXtE9EzAMAdj+31qqPJa0jHIEJDhlR5B2dWqyRIsRZwllD29h5InAci+1VFRXQC0qCEAuGfNLvl7+YYg4BGUHGzvz2FOT1qKwLRfnxoyZDmI2R41lDIpCzu8+fyoQqMJQ+DKhR/zdIJM0sRhXakxVaQFgB88vAlfu3MtAF9vbBViQ6CgZLs1yz83gqBHYDuupA+iqo/arh8pE51ur9JHLnYO5HHPml24beUO7fN6bj6alFIRhbzUB5FWqvtHizisO4XZPWnsGy4oYrPP4av71sYeOG/VEHR7MdfkEchCYYbhTR5cjoM8Nz9qqJZHQOcbpIY845UP8wjCo4YGsiX87c9X4s7nd2qfmwZkdrB6rsWgR+D9LYqcideWagiUMYRFDXUkTHm+GU+8JcikRY+X3jdcwMU3rcK9a3dXnEcwn2C0WviopIY8j6DkgDG96FwpkCAIhHsE+0eKcF0eMAS1qSHi8Yn6+tKtq3HPGpHUqGsEisEs2tjZn8eRMzLeeHzajPZtmUwK1kGNwKeG9HGpRrNkC6Oi1gPqTFlYMCMDxvSQ4kaQLdrS4DoccfXRgwVhCJpIDXE9b0DNI4ia5O0qHK+6jfqaHuinX+3TPq/n5qOHpjNlRWTXKh6Bt1I9MCIMQcoyNdHNTzwLr6Ufdk5Jy7+5GWMylwDwDSmVdqbvci44WkDRCGrmEdTwCIrkEVTSMsEx0+oxX9YNhWkYWiAAeQSVYrH/N52HGnZJkw9jQbGYVuEm8iWKhLG0oACVfrRdLn+LotLPgTASiISpphGEeQSWR4OIc3RQsqtFDfn73D1UgMN9CgvwKZngtVbDRIMeAQD0j4p7hRYfwxEeARXBU2sN0bESJpMBEFQ+29cIvJpPgXGpwjp5v0RlAsBh3SkcM7tbHnMs1FC+5MiFKeccZuvsQGwIVJSc5noEqljscr3WUJRHUHZcpBPUzMatcHWBQCNxh8vJZP2uYQwXyg15BFT4LRFxs9oBj4Bzjv2eIRDRG340Dz0seTn5RGeoEqxA26UZmSQOjOoegenRHOr5kLGoJhaPFm187P89jS37RyPzCILU0HAINRSMvqLxBT0G04AMDebcH29FQpnyew7mFEPAiBqykTAZOrzkLQKNPZO0kPP2mUmaFeHEaqc0v2y1Kz0UxsSKN8ojqBY+2pEkj8CWodCUhRtGDRkGg8F073bvcMGbNP0Jd67nEQS9Uk0jMH2xWF6/vEggKyi5Gep9N5AtYe9IAQvII1DCWenetgwDx80REUFq+Cjg3w9Bj4Dul3zJkfuiMtQA8JO/XoorPiCq5phGdCOqash5ZbGBWCw+qKCa6s1KZ1A9Aqo+Sm571I0hoj58augvf/QkfvyoXgxOfajUxiouB1Zu7ZeeQD03X8kWkR6WYYQmhAU9guG84P8P60rJmi++JqFTQ9VWloQglXD0YZ2ybDMJZKLHs6sbAo8+6u2I1gge2rAXf9zch+8+8HJkZjGNsSo1FLgfiLqyA59TXSk6T7p0UVFDgG8ILG9SBcTKvCNhetfXPzaNPZM0ZUJeJmmGagRkPGWze5fDcYG/OukI3P13p+PI6R0V50rjqscjyJUcacRTliEpkmTIstXy7hP67u6hgngWmO9RHNFLYnEVasibCNWfYzBX1q7vSMHWxv/yvhFwDhw5Q+zfrzXkl81OmAz/34dPxP9dcgZ6vCJ50hDkqQps0CPQS1rQ9aXJel5vhwx+SIxRIyiUAoYgpoYODugGqrfGSC2odeZlZrG3wo2MGnK4XHU5Lse+4SL2BuoOBUtMDCkruxVb+hvUCBwkLUNWlawYj2IcsiUbo94k3522pMtbqRHoReGixg7o1BAAvPnomXhtMI8d/TnpEfiZ2f53Kdmup8PSjqmCjMX0TCKSr6cHXBWLX947gqc298nPgmPuywoaoRy4ztR0CIBXRVScf1QeAQBZBkR0KBPvjRRtZJKiJn7RdnHPml3oz5bk/akmLImOYfr94F8zV9JJjsvhco5MysSJ83vRnU5o3g9RHZmkWbPoHCAML9EsqYTiEYSUyEx6Bo1yDvYM5UUdKS8izDQYDvNyGoL0ZJhYvGfIb140lC/J335mZxKjRVv+bRlM5smQR6DWGqJ72zIMZJIWjp83Te6XtA2pEQQWSdmSHlxgOzyyQqhIKGt8TsmVbaktui0uOteyhLLJBrXpR6HsaELWWOF4NwaJw7ZDTcqr5wgQNWS7HGXXrZhQgxEYZAhmdaWwf6QoJ6O6PQIv3K1aBU5ATLaqO01NxINRSrkqGkE1sRgATjt6BgDg6S19UiCzDEM+uIyJFSFN8inLRDphhFJ6VF9+eiYZGT7qawS+R/C937+Ml/eO4Ijp4bx132jAI5CRP9A9Au9QUeGjADDkGTS1zMFowUYmaaJQdrB/pIhLlj+PL591jCZEEjpTQY9A1wjkipL7ce6AqLmvLiDIEM7oTGLnQL4iSsXvRyB+r5ynEQDiN6Cooa505ZRieR4dGdY9w0IsppIPs7qSMAzh+VUklGlisTjehW9diKLtYtW2AQzmypIWPLwnjb5sSdKG0zuTMueFkgRV8VoVi4OQvRu86xJcDPgLB//zqOYxlskqKMl6QLkaBS90OmW10SNgjHUyxgzlb4MxlmnZiNoE2/WbfqgruBVb+mRYZqOQ/QgMf+WcMPXmJSqo9glRQ7QKDk6owbjx4byNpGmgO21pYZb1VB8tOS5SCSOyVK76XraoxL2blWGdRC3lqoQhBotnBQ3BMYd3ozeTwIpX+8W2zBfbHC4iiwARCw+IBzaTtEJrDVHHqWkdCTludRJ2FQFafbD3DBeQLdmKBqBfR+kRBPIMKEIMEPdTVGaxphEoHgG5/iPFMjqSJpKWISe1zftH5dg7lEVKR8KqSDC0PNHadlSNwDME3oq4O21hRDEEpA/M9OiMynuOjueLxWp/AFF9lId6BGTI6XruGcpLzjthMRzWnZLbBe9ZdRw0Yc/sSuFf3nscZvekMZgvy4XHbE/oPeBFAE339KOjZ3XKvghqrSGfGgrzYkztulRSQ6QpkZjsemUgQgxBiEbguBy3PrtdO1/OuVZ9lxYQxbIje1a0CvVQQw8BUCf+DIAHWzOc9iGqoNdld63D9x96eUz7pBvDZL5YLDSCcNqGJlJadZU9HjP4UOpUgPAIejosGabWSK0hTSwO0Qhold+dsjyPwKdBqJiWbOlIHkE5mhqyXT2yJPgQGgbDaUfNwDOv9vvUkJdA5LgupnkPt+oRdCRMuXpSQR4B8xK16HwJqiZCGkG+7GD3UF6KgOp5EehhDWoIauSPo1BmFeGjtisNmq8R+ElII55HkDB9Q7Blf1b5rfxrVqkR6M2PdI3Apy560gmtZSVNbDOiDEEYNaSUhRbx9E5F1BAgssfVFfjuoYIsmZA0DUkLWSGlI8ohHgFhWiaBwVxJLgJmdwuh94CkBMW5LJ7fK79jKR6BWmIiiERg9R0VPkr0Gufifgr1CELCR1dtG8BX71iLFa/62d1Pbe7Dqd96ELuH8uBKhjkVtGtlraF6DEGaykUDgPf6kPMINEOgrGSzRVsKQ5xz/GrljqoFqFSoCVEU/kgaQVj1URmr7XkEUU1T9MxijuFCGT0dCRmWKuPYGxCLE2a4RkDH7ulIaKtky/QrOdJEVw5QQ1EaAZUpAPTqo4QFMzKiGB73G/vYrojVpoebPIKkZaAjaSIfUmuIC9OAdgAAIABJREFUJlH1t1W9FHXSUYXTvcNFFMr+CjYY4XVAUkO6wSVuHvCpmLDrUCw7mOm1JB1UwkdpNZktCmoyYRrSUGzZPyr1HJXKqIwaEpORyL51pZEm6oJWlT1pS9MIfGpITMpFRzdeVPSMRNRcyVY0AtPTCHhFiQlAiMWqOLtvuCi1jC+fdSw++/ZFAISWEJww1dLmwQiz3o6ERg0FPQIyaifMV7h/RSOghYAVoWto4/CuMelHoyHhxiXbDeXxw8LFZbir4pW92peF7XLsHirIDmuA36+73RpBljF2Muf8OQBgjC0FkK/xnUmHouYRqEbBDym9f90e/NPtL2B7Xw5f8XqyVgO5v75YTFFEER6Bo/OwdNxgpIsdWAEO58voSSeksTHqrJpJ5y2ihljVUszTOkQ/YbWuDk3iFLFje1Uppegewou6vLpHQO+VHeFq09iIWqMEMuLpU5bheQR+yKqINPInUXXy10pqqFnVIdx0QZ5XhEcQ6ERGoa6AL87SvlTOvWi76OlIwDKY1AhUbyJXsoUhsAxJb2VLDnb056W4SujwIogohp00App8VI/ADWgElECZTpjSaM6Z5hmCcqVHQAYGEM+IRg2VHU8sDufI6R6RupIjno33nThX2y7Y06KaR9CbEZSfnwMgPAL6m7LOT1QMgaFcG1tSQ5VjDho08gh+9MgmrNw6IMOW1Uz0ou2G0jdhZahlaRNlUUmaTa7oaOHQhbIzIaKGvgTgNsbY44yxJwDcCuALLRtRmxBFDeVLDgreZ89tHwBQeZNEobLoHGUWh2sEQY+APJOKPILACnAoX8Y08ggU3rueiocl20VKegThVA4gDEG2ZPuRFgpFQYbTdrikhYDwDFXb1VeNUYZACOWBEhOcoyedAGN+Uhd5BOSFfPL6Z/HN364H4HsEqmHXqKEaGspIhFDY5x2bJhIpFnslJug8VQOiGyMHactEd9rSPALfEDjoSJhImn63M0DoVbO6knJVC/gRRCodSJ6JrVBDLtfFzGALSTJuc6aFl3ogmjOl/HZqWWi/+mj46pp+H4ocKpSdCkomLIS5GBI1RKDQ4d1eE6e5Xg7AvuGi/DtpGXjT3Gna9ygwQg18CBuzCjUQYt9IoXGPIHAP0YIkG2IIRou2Fg4tex200yPgnD/LGHsjAFoCv8Q5r6/11SRCydEtcK4kYrkLtoOCdxNv2C1EY3I5a0HLI3B8j4A8hCDoxkwl9Am2qkbgCI9g4cxO0YTDcWUYYj3ZjEXHxbRkIjKSiSbLzpTeq9byuHvAT+YqO662kgly4wDkKp8QyilbPuVkdCSkiMghVm9dKUs+gOQR0Mr5tcG8nIzCPYLqhkoFue16bSdXTt7BhDKK3weERqAa7ELZBXUCLdkuOlMWutKWllCmCo3phFGx4Bgp2rhk6ZHY2uc3cqF+AGrIcDJhwjK5pt+UHRec+3HuPUpT+cO6U+jPlmAZrIpY7HH6miGgPAITB+xSaPVRui50X2SSFgZyZeTLjhb9BCA0qbFs+5FiYRoBAOweFAQF1SvaP1JE0jTwidMX4qw3zZbh2P5xRGAE0T31eARkoEoeBbZ7UBifejyCMI2Arq9aToTuN7W0BOCLxW2tNcQY+zsAnZzzdZzzdQC6GGOfb9mI2gSVMli5dQAnXPF7bNo3Cs79lfnGPSLRKWzlPJQrV9Z/d6GJxaQRkGYQBN2YVHSOJq0gx+xoUSK+WCxdXldfqVaDDB+N6Mjk01Wmtm9RXkDcmCqFoq5woloeatRQSEicWraAPAIS9wyDyUnMYMIzySgeQcl2xYqq5IRmyqqUR61mIVSeQdVzBnJlKTzLPAOl6FyYRkDnIsfgeWGdSUtOJFSDikAaAYExYfQ+tHS+3I4x/1rRRGUrYrHt+jQd/R/lEQzkSpjemZS0ZMU9561Iw9pQijwCQQ2FGXbL8D0C6uebLzkVK1zSNVSUHVfqQsGJkN7f5XkEh3eLAm8lR1zfnnQitIcABUZIj6DKYoRABkpeT6kf+duoYrx2/iaryE6n74+WKj2CbMnW8mIKXnmQFjoEdVFDn+acy154nPMBAJ9u3ZDaA3US3LB7GI7Lsdlr6l4oi0nFLy2g/6i24+Lt1zyCW72ibwTHa10ny1A7fj+CUGrI22/QIwhSGOrKveRwDBdsTOtIyAdJho/WpRE4HjUUnu1MD0uHl7ikisW0IqRJznH17lphGoHjcI1eCKeGyMC4Uiwmzt0y/Obg9LB2JEzpSpdsF9miLamj4DiKVaihqBWXlsimhPcFexOrFUQd19UMSNAQJC1hwGjXavgonZN6bf7suNn4xFsXYnpnUk5cSaWOviNpKr+woe34eQRBQ9DjaS0kGPeNljCzMynDJsPoSCPgEegaQTQ1lDCZFEeJGsqXnYrrLRYjQY2ASy8lTCMAgN1egllnypIaUjX6ljKdq0YNVVBDugGIQjg1ZFTkR5C3rHoEKjWk3S9lJzJHoVmoRyw2GWOM2kgyxkwA9XEjkwjqjb93RKww6KHPlxysU9oBBm+GgVwZg7kydg3qGjop/dRRiVZrUT2LZfhowCMIHk+dmIbzorZQTzoheeFGPYKUJTj5ME+HbmC1yiTghY96D5vKZ6pREFEeAWkgYj9hbrk6WXhRJ64LxgT1QqtZ2k9H0heLS47wCNQualGlnIOT3czOpOzHrEI1kH2jaltF/TqrFUSD9fILmjFykLJMjRqxTKZNIqmEKVfXpsFw3QVL4bX41hq0WMrxaExqWZPgCraqR5BJygk0LHyUwj3lmL19pT1D7PLwCTihaQSeR1B2KmiUsBDmkuNiemcSx87uxusP79I+o14UuwYL0mPqzYighlQVQ5AwvHBWpVVlEJbBJCUF+M9BrVa2UdRQhVjsRGsE2RCNYCJEDd0P4FbG2E+9vz8L4L6WjahNUCcLEpv6vcShgu1iq9ZgO2gIqAKi/+Op7QtFeKMD24szVguTMeXHpZuFYrWLURqBo05MftKU6TXAcMzwsFMC6R+MMRk+yhweSpWQcUgnfZEPgFce2l+5E9Rs1VCPQNEIEibTzp+QUCgnOo4opiYeKprEqnkEah/cYjlcIwhen8O6U6GGQKXiKDehN5Oo6FdAXcboPDWPQNUmPOOrlooINn3vSJjy/DqTpnadJCVjGVqUEo1F5HjoGoH0CAIaARnuvmwJx83p8Q1BIHyU6uiofDp5hGnLlPsJnVRNw+9fkFSpocB2IWGWJdtFd9rC7/7+bRX7Ja+mP1uS16i3Do8gYQnNye9QVnkPMuYX0wMUj6CGIQibrEVCZIRGEGoIHN2z9qihdkcNfRXAwwAu9v6tBdDRshG1CeoPTLQCxaqXbDe0GNnKrf340i+fl5Ox6s6pvHFHwkKh5PgagfeDBhfstF9azRQjoobU1QVlufZ0JHzus4pHUCg7OO0/HsLdq0UddxL4qJJoEGWFGlLPMaFGDSmTnBqbHpxMaEy+IQi//aRYbLve5GrImiumwdDlTWJ0nTKeoaUyIdmio1E4mkagUUP69elKWUKkjYgYAfyHdWZnUl6bbX1ZWIbIkNVLTNTQCBSPwAxQQ+mEISfdroCoSpO/2glLpanIqJSdSo3AiPIIsiXM6Ez6915ZFF8cULrFmYY/QQL+BDqrO6mVdA4iYTC/WqrS49gMROsQZaMiSncQ18iU92WHZ2BIN1C9ziAsQ5SyoGMlQqKGAN2YhOX0ZJKVxzBDzl9tX0oINQS5cGqoQGJxO6uPcs5dACsAbAVwKoAzAWxo2YjaBHWypd9sQJlMyCiokQ2PvXIAd63ehU37Rb5dsHcsQB6B4ZVw1ld+QTfYdnSPwNcIAppECGc9TU0oq1J9dLhQxkjBxkavbEax7EquOTxqSLwX7ExFIi6gV4Os6RFwXyOINAQB+oGMFEVOBD2CtBdLP1q0ZWN18uq601bFJOyfmz6+VMJETzqB+TP0dY6aUKbWdaLr9cLOIRwzuxvphKlRQ6ohCArWSU8sJqjJaIAuFldE1yjUkOqBiOP6GoGaWSypIe8QnUkLBoMsWz6YL2N6p0INOS4e3rgPp131EAayJSkWA/5kT8emjF4AoZSMGkevGrXgz580K0sxlCMikQhUnoImZYokquoRmAbKtr9gCvMIaDyEsA53YdGDURpBdPiouDddl8ucgmzRrvAIRDJg5CmNG5HUEGPsGAAf9f4dgMgfAOf8na0bTvsQxmf35/xJrT9bRMqr0knbUk2dl71JVeX1/Br1DJmkJY2LyiMHw/zpZvEjNyI8AmViIm+kJ01iMa/grlXQ5LzP00Go1pAqBGtjIkNA1JBNvCoLXalR2V7atwrXFfWcankE6vuGkkfAmKtTQ952Gc9IqUZo12Be1F9KWdrDq2kEigdWtF2kLQNfe+9xcDnHl3+1xr8Grm4IEibzqneK/gwv7BzCe0+YAwA6NaScfpCeSlmm5gEEw0dVsTgT9AiUuvw0iUkv0PF0KNfQDUFALDYMht6MaAI0mCuBc3hise+NDeXzKNku9o8WNWoiaRnIKmWoqb0jEEUNqZnQuvELblcuiHGu3zWMXMlGOaJ+EeF/LlyG/3thN46a1QlA9QiqGwJVE4s0BMo+ZNSQ8qPO9Ar0qQgTdBNelOAV97yItyyaifccP8dvV6rkI9BjPRoMH7WdyDpGzUI1jWAjgMcB/DnnfBMAMMb+vmUjaTPCyiGQRiBel9CZssDgrySpFO1L0hD4+1CpoYRSUsE0DLlqEKsM372UfHzAIyg5rqYnOMrNOKCUYxYcqwuXG97+QwyB7fcdJvoiaZooW7yCn4V3rgbzHyy6QS3TqGhCAvjUUHfaCs1OBfwJPKx2PaA/gKZCDRlMTGCdnlFKJXyxGNANwWuDeZG9q/C86vkDfmZxV8pC0S4hlTDxlycdUbXst0jeS3qeoYvt/TkM5cs44QhRz0Y1BK4WNeRzzS4X1zMJ3fMxNY/AzyPoSgXi4JUaP1aIRiA6pQkxVGoEjk4NAWIi6xvVq3WmlPBR+q2zXr9jUzEENGbAL+0ARCcIEtRzCU5sap/l7/7+JVFqISISiXDM7G4cc1a3/LsejcDyPExZdK4BaqhUwyMIm6wpanD5M9sxlC/jPcfP8cNHPUOg3rsVYnHZbXnUUDVn468A7AbwCGPs/zHG3gWghZGs7QVNFurvSG3wAFFfpjPlNQvxQtzIraP8gkKEWKxyidU8gmD0iUppqCsRdYKnhKSulCVXztUyi2lC2jdclDc1RZ+EagSueBBlqKjSYzcs4kdtIRkV7USTTZghAfSJQxWlyw73PAJPI/C2I3446BH0ZhKiBLA35g6vJo48N+/hJuqFjF2wBLmuEZQwrcOSZTBe2CmiyaiMgToxi9LBeoit7BGd0MViEXrqHzOtRA2pFBJdE7pOkopSvEC6fxwnxCNQbvAZniEgr3JmZxIpJXyUJqNs0dGiVuj3Ic/kcMUjCI8aqs8jSCii6mjRxkix7GlY9U87vZ11eARKWXNaXIRup/wgjqtfR0BUQQ0iqugcIH576YkHEsro3rUMhqxXYsJg4noWbEeWq2kVIq8W5/wuzvn5AN4I4BGIUhOHM8b+mzH27paNqE0oKatDQp+mERTRmbSQsPwJM1iKNpQaYoiMDqlInlE4y6AhUHUCv6SBf8yutCXL3QbzCEq2Uv+HPILRonwtKAbDK8UdzJEQrjm5z7TKp1ryBL+jUxkdCRNpy6woQ03jolj1aLHYv+EFNaQbBhk+mvCjhgBfbAOERzDNq+fjt3jUm67Q70i/TzqwP0JQI5jWkZBJbmtfG0LSNGR/Wk0j4FwamaAhSJq6WGwZwcxinxoKisU0sapise4RUFe3yjwCddKb1ZVCX7boewSB8FFpCEq2qH4Z4RH0pC15zaKihgi6RlCZR0D3bL7sIFuMTlKLQn1RQ36tobBkMoJ6XBk+6riY1ZWEZTDNE4o6J/Gevx/Sruh3yXt1hMgQzJmWRrYkPALxHBmecN/mzGLOeZZzfgvn/P0A5gN4HiKS6JACPSgUVgfodFH/aEmWBi4FqCGCWhNfLU2srjATSgOSYC6BWvvEMlhkjRxfS6CHjyFlmZ5Y7IfFUZLRP9y2Bpf+8nkAvkfQny3JzNmUZchVd5BOsh1XqzRKExqVoSaklUYeGa+WfiQ1FJhIgiBDAejZuvQ3eQT0oNIEPhxI9+/1ylPIOv5J3SOg37ErpeclqL9R8JqQIUgYIrfhwKjo30znpCWUKV25CgFDnEqYNcNHKes6E6CGZEKZZchVue266Bstit/LUPIIAtSQei1ndiXRly3JBc/MLt8QFG2/8FmuZGsegYwa8iY4xvxJMWz1nlCOGYyU0rZTItfyJQfZoo1yDWooCNIIklWjhgwvaohrYwtC1whc6eV97NQFuPfSP5Xls1WErdpVj4jCk0vKImm0aEtDMK+3Q1JDHUlLVnYlarRVaEiH5pwPcM6v45y/q1UDahekIehIhH6eLYnaKEklxI2oIYI6cdNiP0gNUc9ioFLMVcsZmwbTVtSqIQjmG9BERqvAoEewZf8oNu0TkU3qPikBLmn5fH9FHLfjNzoBfA9EGAd9BQuIiTKTMpFSRHX/mnjUkOVPZGFQy06o0UmAoCPkxJ3QqRw1xBeAXLnTOWeSpiba+nWULG8//sQmwxITZohGkJDNcoq2q5XV9lfowvB1JoV2Q3H2ZBypxIR6nrpGoFBDFeGjfh4BHW/1jkEs/eaDyJYcmKbf1a0UCDhQjzGzM4XBXFmuUnszCRm9VFI0gtGiI/IIIjwCwKeHVCMur4kykatGrYIaMvxnK+f1682XnUgKMQyUbVxdLGZe1JBbt0egVnLNpCwcM7tbalQqwnannudQviz7OxOyiiE4ordDUkMdSUNWdlVLiLcCLQxImlwoOYKT6wyJDSaQR0A0TbAvgZZhK0XThEY1qBpBhSFQOibV4xHQzU7tASmhzK9E6cqxUJipus+dAzm5H3qoK0peO6IhOa3K1PBRzSPwznE4X0YmYcn2hdq+XN0jqCd81GA6NRQWNUSZ2MNBQ5DxqCHpEegRRCQW06pdjT1PK0K0mgw0lCvLch4lx0Wx7GrfUz0Cqj47Z1paGl0/UsmsmBSDYrGkhpIR1JASPrpHEbgThoF0QrS6rMgjUDUCryfCuteGhD7gnUfSMjRqKFe0vUYy4nsy41kx0BQ5FJpHEEENBSc2Mq6A73m6PPo+CUM9JSaoFIuISKrtEXSlLJSVCKxEwBNVEd6hTH9v/0hRuw9HizYG8+L5nNebRslxfYrV8wjUEuKtQGwIPFCGbbVexZ0pS3Nfg9SQGvJFq6zZ3Smt+qFp+KUEKj0CP5zNNIxQGkN8z5XF6wCgK0Vt+JhXa8jV9j+UK2MgV4Lrcs0j2NHveQRKclgwA1KUxfA1goLyMOiGQLweyvttFos1PIKoh1AXi/UHyTQMSd/JPAKihhSxGPA8AsMvptfpNXGRrTVJLE7qYjEAdCTJyPgx8BTrPY2S9xwuazX549M1AtNgmNfbgV1etcpIj4DpJSa0zOKqCWXitVrHf99IAd1pC2WHSy8pzCOY5QmrK7cNyPBLuq5qP4Zs0Q4Vi1VaZbYXzx+2etfFYp3207fTPQJCtdV9ENPrEItFoxzu0WhVPALFENiOK5v10PthSWuhYnHAkO0bKWoLO6KGkqaBmV5joAOjRUENWaKgXzujhqYURNq/KSeVsIvemRTRIvQjqtQQCbcktlII4uE9aS1Sgnr9AtEeAUXkqDSGTg1RNI0YK7U9tAwDLvcnONsrhTxStOFyMUmHegTK6jMsoUcrMOc9oAbT469lWQzbxbSOhHRpVZBGUDOhTHmIDSOoEfgeED2I0hsp6Iag16NwCDRJ7B8p4tJfPo/HXtkPQKWG1F7A/r5p3BTrPS2TlPWPimVXWxnqeQTi4Z3f24HXPI9AFeg7Ax6BukJOVROLFYqGjqd6o0nLQE9a7+1MRlldsVLUy1C+rBkCKiJHk3G25ISKxaoIOmcaUUMhYrGyXTWxmKhNzrl2PtVW7UF0Jk10K8XnwpAwRIVS2+Wh1W+Dx+1MmRo1RNFqdB/rC5Xw8FEV+4aLKDl+u9LRgo1dgwXMnpaS12f/SBEdCUENFTyxOKwcS7MQGwIPVGqBeL/DuyuFoAyFj3px/VmvZg8AzPFcY1rFkyh0eHdKo4bUxKFoj8DwNAI9/p08DserWUQ3GE2MMrLH9quBjhT9RJX+XEmbnCkZJmmaSi/XQCST4/c0BkT4KNUICqOGABGNoibeyfNzdGooKhpEfT9Y+tg0jYrMYuLoKzQCj/MmLPZCPO98/jXcvXoXHn/lAACVGlI8AtUQeL8Tue9CLBZRQwUvOYygRvFQM5F5vR3YM1wQq0rb9whogWAw8ZAHPQK65kGxWI3np+PR6v375y/BP59znBTUg+06NY2gy4+DP+qwSo8gH+ERSI1AmaBfN7NTXpsg1Mm2ekKZWKkXApRiI9QQYwx3fP6t+NQZR0VuQ21Zy44bmUMA+IJzVzohcjKUcGvAX4ioHlt91JDIjyBqLlu0sXnfKBYd1iX3dWC0hEzSkgX9gDaXmBgrGGP/yxjbxxhbF/E5Y4z9gDG2iTH2AmPs5FaNpR4UbTHhEd9MKxx1BSM8ArFqEat/YKG3kprrNcWgyXrvcAFdKQudKUujhtT4+4qoISWPwDL11pG3rNiO07/9sBf/7Dd1V8dI+5Uegcs1uqQ/W5LUTmfS9A2B5U/09N39I0Vc+L/PYM9QwfNifI1ATkSRhiAZqhFQGGbCNMACHoWKRIBqUScMCltdPH8ajp3TrR07nBryv3vi/F4YDLjxqa3a/oKehfo6nfBDGknQm+YlqgGCwoiihqh/whHTO+C4HM9uHcDyZ7YDECt+ooZoxSyzfpmeuV3ZwMX3qOg7FLG25MhedKUsaSyDRW7VOXVWp7/YOVrzCExt4ZEt6a0S1aqohHe98XDce8mf4sgZle3M1cm2I2nK6JdKsVjc87kA5dqIIQBEkpka/ReEJfsR8Mh7EPDPsztlCY/ACRgCbwESjP6qPJ4/fsZ8jYAS0oYLZWw5QIbAy+NwXHQkRNAFaZENXoaG0EqP4AYAZ1f5/BwAb/D+fQbAf7dwLDVBFSHJzae2dxSFAPhiMTU/AYDj5orJaJG3oqLiWvtHijjcC6nTPQJDPlDBCB2VGgreUC/vHUF/toTRgi2ThmRRMikW699R45MBzxB44ztyRkaLGqLJKF9yUCg7+MPL+/GHl/f//+29d5gcV52w+56q6jg5akYjjUY5y7YsR8myDc4sGBNsPrOkBWyCCb4LawzLLnD3Arv3M7ssaT+W9cXm8xIWw34GG3tZGxtwFrYkW5IVrZw1OfR0OveP6lNdVR2mJ0vq8z6PH4+6q6tOpfM7v8ymgz2eqKFYMuW82B7TkGsyLKQRuMtu+PMQ3LhNAf6Kl2pV9H/uWMfNa2YD2ZV8btRQ0PMSVoUtFjRXOo1M7GMZrhVermALB7I9gd2CQI29P5b0RI/4M4uVRgDwf/1sI7/efASwJxm10le/Uf8PZyrDFjINeTQCU5mGvJNUVYGJ0L1iVdnokF3QqOP1xZK5zmKfRuD2ERiGYNnM3CYw4H1OAma2p0FOZnHmfP3ReKW2hi0V9Q7bdZmK+wiEsIWXu4CfEhDuooeKvNVHXVFejZUhx0dQnwl13Xmsn1gizfymSs+9rgrbQRfqPpyRUUNSyt8DnUU2uRG4X9o8B9QKIVqLbD8h/PLlgzm2ZMh1FrdU2y9vVTjgrGAqQxYByzYNDWYe1nULGnn4k+tYu6AR8GoEyrzkVuG91UcLaASuRCGFsvUOJlKuMgLKWazCR723M5lO52gESvOZWRvxRB+p39714Gbee+8Lnv4LAU/UUNqJFvEXSVM0VAbz+wicRDhb0JVkGjKE52XNt+IKZjQMdV/V9fBrBKYhnFIQ7nNzXmyXrd8dPgr2vfEKAnu/A8PJws7ijObWVmsvKo70xLigo473XTKHhTMqHSHkFwTqmBfMrec9F89hZZuv564qQ+3O+I5nq8JCtrqoH/f1E0I4q9KOhqwgqI7YdZSy4aNJ51zArRGUNn24hXHAlX/iv/3qvPzv52gSykpBafUjRQ2FLNtCoLYvyTRUxEdQFQ7QnCl1PpxM01AZRAh4ZvcpwF5Muvf1zjWzCQWyvRzOSNNQCbQB7pZeBzOf5SCEuE0IsUEIseHEiRNjPuCx3hh3/nQT//nyoZzvlI+goTJIZchyqhpGAlnhEHXyCKSjEUSDFstn1uSUaT7eN+wpxqXMQ26nYL7kLVDCwntrVPjn4HDSLiyWzzTke6hTael5qZRGELIMx/QFXtPQzuN9vLi3k6d3nXS+92YWZ4uNCddq3e0wbawM5c0jUKYwdX6FNAL3fk1DeMIUC9WOD1umoxEoLc4uMZE9hmUIzpld4/ztnLuKPnLZ+iNBr7koLb2CQP2+P+4VBOrapNOSlLQnBqURAHxg7Vy+fOOKbGXRoOkyCWU1AnWc//utK3Ii2dQx3AsMtWospEUo/IK0oTJEW23Ec4zqsEXfUCKrEcRTzrlA1uZfzKziJui6l4YhnOvln9jUhO8XBKM1DY2EEzU0Qh7B21a38bnrl2TCstO5pqE8GkH+bmf2Z9Vhi+aqECf6hoknU0SDFmvnN7L1iF2iZp5LIxACzp9TR9jKNl2alhITpxOZJLY1Uso1TU1NY96PmqRVKJ8bVY75/Zd28KtPrHNsde6a5xVB0wkf9fdgVROHihw63hfzOJzVPjwaQYGEMndkkWIwnn0p3WUE3GPwP4SJVK5pyE6AMh3nNqiWh5mVZSZCYWcmAc0ej+GYg4YSKc9xsjHVeTSCZNpTssLf0rEU+6whhMfGXOhlCAcMp/+vWuXmagQGaxc0Ul8R5NoVLc74Q3k0ArdpCHI1AnW9pPSeu1sjSGdMeNGgRV3Gca2FsMEUAAAgAElEQVQ0R0U0aOUxDRV/LdV1c2sTyq6urlshG7l/8j1/Ti3rfGOyNYKEJ3zUjmMnc4zss1wKSnC5S2NArkah9ueuYOv+3UShfBGqdlUhVs2q5X2XdjiBATkageMjGEkjyGpptdEg3UNxpyfFO86fBdhCorEyyKy6CJ9640J+/9krnWOoezuZpqFSOpRNFoeA2a5/z8p8NmmoiBh/dUnAaXgdDVrMbbTYsNe2aoUzSR1g33AVNaQcOMrOq1YFQ/EUvbEksUTaoxFEXRoBmYVyrkagVsxGXhMI2LkLqbQ3pNOJGvK9WG4fQW00YPdXEORoBO4SE/kIuCZt1W5T4W5XqGjK+AhkJpRVlR3I1l8SfObaxTkmD88xLQPiqlVl7vH8hAOm0z2sLhrMCG2vic0UgrmNFbz0xav59+f38/DmIz4fQW74qMonSGWEajDjR3KbK/KZhlJpVRbA/ve8pkqCppETVVMRMl29AnKvZd5r484jUNFcPh9BZQmmIYC/e+vKnG2qwwG6BhPO/RqIJz29FpRGUGpcuxqjWjRkw0/92+XXCCbDRwB2gEhVAc3JOy7buZzrI/C++1DcR1AVDlATCdAzmHDmm2uXt1AZspjXVOmEh9559SLntyHLcErYT7A89I5x8nY9Ig8BdwghfgJcBPRIKY9M5gFVY+yjPTG2H+3jZP+ws0JTLfEUSspHAqYj+StD2TwClUymVuPq5R1KpDiRqTDY5NII1PfuSS1XI0gjRG6TEjeDw7aa7tYIqgqYhmwfQRJDwOy6KKcG4k4XrlaPIDDzJgJFgyaD8ZTHNAReVd1J6nL9vs6VpapMbuASBKbgPRfPyXt+/mOo5vWKQpOPe/Jc3V7n+F/85SkU6t4ETMGC5kpmVIc8JpxsQpnSCNJOVrEQXm0mX/ho1kdgf/7tW8/L65iMBi1nBazG5y965yfrLM5OzkMJOzPerV1UBE2nnpSilFVldcRy7pUQ9jNXF80KNaVBlaoRZMuOZ6Od8o1FPc9+p/9E+wiyEXBJ6qKFo4vc27vbfoaKmIbyDTUrCCyqw5aTAR+0DCJBk79/+ypPTombfFnrk8GkCQIhxI+BK4BGIcRB4G+BAICU8l+AR4AbgF3AIPCByRqLwq0R/MOjr7FhXxcvf/FqDCPTu9d1F9VKPxTIhpRGQ3a2ZyIlHY1AOXfcHbyOqazivBqBgd30LY9GkJbOaq/QTR9MpJzM4pw8ggIaQXUkQENlkM6BuFOgrsVXOtj9Ui9rrSYtJU1VIf6w86RdV6iAw1YdU0XO1EUDnlX2cCLlZGaOxukVdE02Hjt/gWWRe1X+8SvnY5kLc66J+7hZQWCwoq2G5z9/lWd/EZ9pKJXxEagVvXtMoTwJZWlXZjFAa03+7q4VoexkXrJG4DINuaO9/Lb0qnAgRxCUcu3dZqW6aJDuwbhHE3RW9CVO0Opa5fw+Tz8CyA0DHk2toVJQ12/I5e8qun0h01Dm/27BnTePwHQJApdGqPbzplWFY2TcZsIz0jQkpfwfI3wvgY9P1vHzoQTB0d6YY/PdcbyPJS3VnpUrZLtehQOmY/9XeQSJVJr+YdWMO1uTBuyHa+8pu9F9m2uFGQ1m7fhSZswHeaqPqkmh0AM6OJwkmcpEDfkcg37hkcw4i2siAeqjQXYe66c6HCAcyOcszh7vlgtm875LO/jLTJcuv0bg8RFY3slLZauql0Stor7x2x1898ndeceZD3c1T/fxCvsIzMz33knafSz3302uiK5i+1MvohKqShC4TWke05DTdEiW1FUqGrSca6tu+Ug+guaqMK01YRY0V3o0An+kUFXY4mivLVQd81NJGkF2smrMLCAGhpPOueQrMVGMwqYhn0ZgeU1DVWE7jHWincXuCLhS/A+2czk3oUwlfoYCyneYvwxE1kcQ8JgGS9F03BpB2TuLJwqnxWQ8xf5Ou7zC83tsX4AqMaFwm4bUi6kyi5Np6TSUcG8H9srs5f3d1FfYjh+F2zTk2JHz9CJWL01hH0HKMTmoF1FNAP6H2tEIwgHqK+y2hKpNYlU44ESs+AvIqYdVZZ76Y/49ZiJDOYvt/zdmfuN0usrYrlUXt2Ln5ibgTI7CJ4QKTdzeSca/H/9x1TgLTTLXLm/h01ctdKpqJlM+QVAgmc4wBEJkSkyUUB9mdXsd583OdDcrUSOoiQZ49u43cu7sWo+Q9E8s6rlwJzSWMplUuwRKY0aw98WSnvwFKN1U4TcN5UtIg+zzrExlqszzRDuLndyLeLJo1JB7+4TLNOS+zp+/YSk3njszG/mV55q4TUNuQZCveqmf6kjhst0TSVkJAn8TeIAXXrcFwXDSqxFkwwddpiFX/RdVJCpb+CyrEby8v4vzZtd6aoMo05Cn+mieJjDufAN1fDdD8WQ2j8CXeep/qN2TV11FkMF4iu7BhLPPlppwtl6K62VTD5+Kvgn4TEfuydiJGrK8GoGKLFEvjyq5AaPUCMTIeQSQXTn5J0OzwG9DlunJB/Azuz7Kp69a5CkZ4TUN5dcIwL537lpDxfjoFfP5p3ed5xnfSILAjXv/+UxDMHLmqx+3RqDuZ/9wsmiJiWKoaziSRqCeXxX91ejTLicKRyNIpErSagKGVyNwm6o+uG4uy2fWZE26RU1Do9cIFjRXOn+fkQllpyP+yppLWqp4/vVOpJTEfVUk1csTCZiEg7ZWYJnZePvuobjHwRPKZCEe642x+8QA57V7E5eUxlC8H0E2rtmJ0DAMz2SlNAJPZnGB8NFUpsREdcSiITOpH+2JORNNa03ElSWaqxE4gsDILfOgcMeUW4ZwKlr6WzSqFn1Q2qrU7VAszVk8skbgvz7NVaERzQ7ucNBCGoG/CqWZEQSjLR0shMAQIzuL3eS7F4p8GkFJgiDsNQ0pDN+EPtqEMjU+d2iwd7uMRhBLEDCFI5Am2jSkmtekZWnCzDIFaZl9lvNN4GYRTd7jLM7jIyjGguZsP+YJvgweykoQuAuqGQJuPLeNk/3DdA7Ec3wE1ZkY9NpokLBlOiYg9VB2DyY88cNCCKIBk+f22FmCq9vrPMeOuDQCf3tBRdLVMUk9oJbpzcAdHE6SzBSdUyvlimCBPIJ0mp6hpKMRAPS5MmHbG6J5V7hqIlDCwzINT5JXPlONZRjcefUiblptx0Urs9Kx3mFSaclJV//nUqJNHPOBL0JnpKihXI2g8G8/cvl83n1Re9FxOGWeU2n6Ysns9SrgI1C/Ub2jRxvpYRpiRB+Bf3tFrmnIHqu/6OFIuM0Rja4uXEqoOdVjSzw357kxvMLaP5agoxHYxRxVo/uJFgTuYnulmIbU8VWwQ7EKq/kWOR0NFbz/0g6uWNTkNQ2VIAjc20+mj2A6w0ennLjLNDS7PupkoA5nevq6b3BlyOI/P76WBc2VLGmpYk2HPbGrh6JrMJ6TvRkJmuw41o8QsGq2VyNw5xGoG3q0J8bvd5xg/SI7SS6Zlq6VRXbVFbRwoj8GMxpBwDSojQZoqgo5KzW/Q1dlFleHA86kDtlJ8zPXLOaDmSqN+XwE9Y4gyL7IiZQ30sJt7/34lQucz+c12SrtnhP9nNde6xF6o3UWe/wThQSBq6mKm2LaxNszyTzFUL/pGshWHgWveSDkm7gNka01NFp1/nPXL+XiefUlby8y5TrUM+FG2fpHinP3M5JGUMjGXwjHJOQ3DeVEDWU1gkjQdEyeEy0I3MX2ShFmalx2KLUo6gcoVHTuS29ZDnibWZWaH9FaE+ZIT0wLgolCdaQCWJBJ8AH7Bqdl7o1ZkUl4WtNRz5oO++VUv+kaiDv2U4V6CC6d35ArJDyZxfY+fvjMXo71xtj+d9djGsITPpq1qwqPCq4EQTgguG39PN55fjYnzz1Bq5ry8WTazmx1CQK1EqmvCGbNPx4fgdIIlL3fZRNO+AROnrpDYE+YjZVB9pwYcJr0KEZrGiq2qlcUMg15IojG8CKp8zrlFwSua51TAiITd54apWkIcATzaMeYSsucc8+ahtyZryPvL5xpihNPpr0aQea3AffzUALq2coxDRXwEfQO2fH9ShBMdELZaDWCbDG8ZEG7fjbIo/i+okETK/Oul3pe85sqOdITYxLlQHmahj75hgV86LJ5zo1QdYNKuTHqYT41EPdEVwBO/sCHL5uX87uoK8RTvYwqPltl/7rDR93/dzvZVCNxu2VjgPaGbNlfjzM0YDpOt4qQmVcjcONuiK6+r/dF1jgTQB4HpZlnUpjXVMnuE/0e/4B9rNGZhgrlMLhRY/avHtVYhRibs83RCAa9gqCYs1gJ9VKcxROB3xmrcJzFozQNQVYrWDazmpvOa6O5KsSSFru6aLZncYk+AsP7/OTreWx/79YILGcxNdEJZdFgNhKwlGdRjWswnircZ7uA38OPEFnfR74OZ/lQlY2P9uRWRJgoyksjyAiC91zSQVNViMe2HAVwQkFLeeDUDe+LJQuW+r18UW49pBtWtpBM2TXIlcBQ5p7OgTj1FUG79okz6WZfbvVszagOMRDPVh8tNDawJydVqC4SNKkOBxwTQj7bpHop3TbJypDFl968jMsXN3u28UYN5dcIwH6AH9tyzBMxBCVqBK4yBKWUmFCheIVMQ2MNvVMT56mMj6Mmmm0L6hzb7ywWwu5ZLCc3G9Q/xlLCR0u9DtURi5P9w1SHA/zjLed6vlPPSKEyFn4CPsFRKLNYfS+lXezxxnNnUunr5zERCCFoqAhxqHuoaGMa/7gG4smCgsC/gCtGTSRA50C85GioSxc0ct+z+wpWlJ0IykoQKB+B31Y5Ko3A9bK5nWoAv//slQQskbelXGtNhNsvnw/kqufdmdVmKp1NcHE/WGoya6kOezQCP4VWqdGgiWEI6qIBTvbH88Yvq/PyaznvXzs3Zxv36j8bQZJHI2ispHPgADuP9WW2LZx0kzseextVslpRaFXvmIb8zuJR2rP9qOvc6TcN+YSu55hTrRE4UTnecVy5uJnbL5/n1L2H0rWi6jyOZsWqWTU8+NFLnPyHkci21vQ6m3Oqj/o6mc1pqCjaaWw8NFYGOdQ9VHLUENilNgrNEcV8BH6URlCqaeja5S08+NFLS77eY6EsTUPKvKNqpoxGELgnGr9G0N4QLVhKwI1fpVbF0txRJpbLV6BenKaqULb6aJ4H2BvJkpscp8Lm8q1EbCd2/laDzv6VluIOJXXMRbn7nJdRaZ/b00lV2KI9073K3X+5EM5kUaKzOFTAWexEYY1xQjYLCIJCJSbs74RdYqKEzOKJIKsReI9VVxHk7uuX5s18HonqTN/pfIJDCMH5c+pL7qFr+UyLhYrOzayNOI7t0eRSjIWsb6wUjcA+z4F4KT6C0jQCGJ3J6/w5dTqPYKJQzmL/A9mfsaWXoqoFPIJgbAqV/2VU9mc7fNS7grUyTWHsptwBu+hcASdkoclJvVzq4S/0klmm4YlzzvneWfXkmobyvQDzM5FDrxzqobkqxF3XLQHwlLcohN9ZrE53RGdxgfDRsb5EjmlowDZv5SsxEc6TR5B0MovHdNhR4e6tkA+Ps71EB291eOJMMm4zJxTOI4gGLa5fYdfdmWz5qQI9SlkguNuSBgvY9Z12oyUMXD1D/gXEdHL6jGQKUBqB/8VRGkFpgsAVXVOkL2ox/C+jMg2p/AD3GC3Dzl6uCgeIBE0G4slMi72RNILRC4KAIYpqBFmnscs05ItyctNeH+X8OXbY7cBwimuWt7D3628qegyF21ns3n/BEhOFNII8Du7R4NYIQi5HejGNwPYRjC1qaDxjLLS69WRXlziec2bVsmrWxJgi/MEGjs8gj1BS9fn/sHPsDahKwSmfUopf0AkfLewjsEax4FDm14l2go+H02ckU0A8JTNtDb2CoG9UUUMTrxF0DtgaSSKVW2vIMkRGEFhUhOxuRakCdvaRTEP1FYVNQwC10aCnKmnO/vMklBWrTW8YgnvfdwHLWqu5ec3IMftuAi7TELgSdgrconABZ/FonHj5UMftHIh7BJhbGObTQlQ5k8lU57NjLC4ISsnM9vPh9fO4/y8uHP/gcI/P69TOZza7aG49bbURPn/D0gk5diFULkGpRefA9hGERjINjUIjmOiw2PFQVs7iRCqd9wXORg2NrAq7X/piZpRi+F/G7sE4PYMJEqm0a+WbnXRvvbCdnqEEx/uGSaalXT43n4+ggAOzVI3gxx++mNqKYqahXH/ASDHlNdEAj3zqsoL7LIQ/HM/JYRip6JzvRS1muiqFrGkozoKmbN0Xt6bhX1VapnBqLI1VExnLGAtrBC5n+xRoKIWOP1KtIbAF59Ofe8OkjylbULEEH4FyFieKOYtLD0pY2VbDguZKT2WC6eb0GckUkEylPSv6cUcNjVUj8D0s+zsHWfv3T9A/nKQqk1Vquibda5bbbRV/+PTrAPS6KkG68WgEHh/ByM5iwJOTkI98oaLjNb0UIpSjERSf0J08ghyNoLAzuxTUJCCl15GuxpPf8W4QT2b6zE6JRmAUHAt4hfRURDH5EcKOWKv1rYSnwmxWCMdHUEoeQeb62tnb+bfPlhIfeX/Xr2zl+pWFexBMB2UlCOIpbxp+1llcuiDIV5NntPiflT/t62I448hWkUj5zDBqQrfDR3PHWqhrltII1CporBEZzqrHEz6a60CeCPwreX8xPj+FNAJ/rf/R4l5Be7NsRea4udfSFDj3c2p9BPmP5T6HaZADAPzyY2udHhBKYE2FkCxEQ56M+kK436sRw0enUbiNh7ISBImUt55QKGMK6htFQlmx8NFScdeHgeyk8cMPXOBkb/pXwpDtmub+3o1bOLgLl6lY8BVtNbTXR+kYYeVfiGz4qDucc3I0An9+wkhhoErw5SsJ7R7naHEfz916VAi7GGD+5DyDwUTSM/7JxN/4JXc8GWEoKDnkc6LpaKxw/p4sLXI0LGmp4iOXz+eyhbnJn3485uQRooYmeD00ZZSdIAjkke6jchZPQPgo4BEEal+XL2pyXtR8E1iFy6aY7yVSYZZSZgVWJGA6K6/5TZX8/q+uHPOY8yWPjbZJSan4zQfFyvxCYWdxtirk2MbhbWbjrS1lmSJvcp5pCCdXYips8qWGj06HWSgfp4NGYJkGn7t+SWnbuhdYha7xKJzFpyNnqPwaG7YgyOcjGE0eQfalio4jzlo9MKqeypKWKs9qzXl58zSMcX/vx7FdZyao8Yyx0L7z1fifLI1AvYPFGn+AqzRyAdPQeH0E4NUI7H2K/BqBmRUEU1NrKP+5u8cD0+MozseFc+u5bf08ls+snu6hlIT7GVCFKP0ETjNhO1rKShDEk14fgZlJVhqNj0A5I6vC1rjUbDVxqr7Gi2ZU5f3enbh0zqxaZ/vCgsDrOJzIOi35GpIUqhszXvylji1TFC0cN1L46HgTysBbkhnsc88nCAyRDR+dzlpD7vHA9Jpi3FSFA3z+hqUlF12bbtxzxkUFSoRbk/QeTBVlJQj8piGwXx4namgUPoKxOooV6oGZWWvH7S9p8QmCPJOuZRp8YG0HAFsO9+bdr1q9qAmqYgJD1LK26Ow1vHrZDD591UJPddOJYHFLFXMbK2itVoLPKDqR1UQCLGutZmmrd5VZLOGtFNwaSI5GYIq8k5llCKeb1dT6CIovDs7USWq6cT87i5qrim6jTUNnAH7TENgrSLV6G42PYLyVANWDM7fRjk1fNtOrchaKBLnlArv/wI3nziy6XzVBTaRGkC9WWvX2nWgn5NLWan73mSs81T6LTapBy+CRT12WU/l1ohLKINdHEDCNvGUCwpkMcJjaqKFCjszTzUdwpuGeMwoJ09HUGjodKUNnca4gyPd3IVRxtonSCK5a1sybVrU4pRgU7oQyN1XhAK9/7YaCE6/SJNQENZE+gmyryqlfP1iGGNOkOu6EsiI+Ats0lHt9owGTWCLjLJ7SzOIRJqkzdLU63SizY7Hs+NEklJ2OlJUgiKckkaBPEDgZrKWbDwKmMWEaQUXQ4pw85WX9pRXcFFt9+xOdJjJ7sVA3sqnAMowxvWTj1wiyv/PnDCyfWe205HTjbRY/psOOiqxGUNxHoE1DY6OpKsRvPnVZjh/PzZluGiorQZBIpnNK9aoJM2gZJZs3gqYx5hwChXo5C63Yxxqfrybr8KREDU1f/Ldl5pZyKAXHwT3GF7RYpM23b12d93O3IJia8NH8yXTZ78/sSep0wO978qM0xzNV2JaVjyCZLmwaGk0lwBVtNayalT+MrFTUhF3Ihp8vfLQUAr5JYXJMQ9MhCIwxTapmARNbyccdw4sdDbjzPSb/FSu11tCZarY4E6gOB6gKnbnr6jN35GMg4SsxAS5BMIpQth/fdvG4x2I6GkH+W5ANHx3dROI3E0ysaWh8dXvGdWxDjGlSHm8M/VhWeG7z41T2I/DXWXK+H2eZDc3IvPeSOVy1dMZ0D2PMlJUgiCfzaATKuTrFJWHVhF1oxT5SJm0h7JVzdnU4oRrBCE7JycQyikcNFf7d1JuzIi7hO5UdygqHjxb2N2kmhqpwgMUt4zMXTydlJQgSqbSnLyq4NYKpFwRCFKkYOcZJ1145Z2PuJzR8NE9uw1RhjRA+Wux3MD6zyBf/bBkXF0gkykc0ULwm1ETjzx3x4ziLtWVIU4CyEwQT4SOYCExDEA2YBR3UWbvu6MalJkz1+4oJFQTT5yNY2lKNlCNv52c0TcUL8cFRNlB3a2FTWYa6cNG5Mzu0UTP5lJkgyOMjMKdPI4gUsd9nX+6xaATCmawn0kcw3izd8fCJNy4c0++mYxIMuwTBadGY5jSrNaQ5/ZjU2U8IcZ0QYrsQYpcQ4nN5vn+/EOKEEGJj5r8PTeZ44sU0gmkQBMXs92ON9LAMA9MUjiYxsaahM8/WPBEawWjxmIamsProSGWotUagKcSkaQRCCBP4DnA1cBB4UQjxkJRyq2/Tn0op75iscSiklPlrDU2XaUgUFwTZzOLRm4YsQzCrLsKchihLWwsnwYwWJ2poGkxDY8XIZIJPqSBwO4unQiMo0UegBYGmEJNpGroQ2CWl3AMghPgJcCPgFwRTQiotkTJ31RSaRo2g2Gp9rFm8KrqmsTLEU5+9clxj9DNSc5jTFcswpjSZyhs+evpoBNo0pCnEZAqCNuCA698HgYvybPd2IcR6YAdwp5TygH8DIcRtwG0A7e3tYxqMKix3uoSPfnDdXIr5PseeWTx5k9505hGMB9PlM5kKpj58tLg/aayhyJryYbrf6F8BHVLKVcBvgfvybSSl/L6Uco2Uck1T08it5fIRT9lFwAqahqZYEFyzvIVrM03p8zHWjFjLEKPORi6V6cwsHg9jDT0dK1MePjpCrSHtI9CMxGTOfoeA2a5/z8p85iClPCWlHM788wfA+ZM1mGRGEPhflukSBCMxt7GCj14xn/Ul9FR1UxsNUhOZnMSWRTPsHgEzayKTsv/J4oKOepbPHF9JkNEQmeKoodpogHAgfyVUcPkItGlIU4DJNA29CCwUQszFFgDvAm51byCEaJVSHsn88y3AtskaTGHTUP6m59ONaQjuuq60nqpu7rpuMYPx1CSMKNsj4Ezj3vdfMKXHC1mG0zt6KkxDN6+ZzdoFjVoj0IyZSRMEUsqkEOIO4DHABO6VUm4RQnwF2CClfAj4pBDiLUAS6ATeP1njSTimodMjoWyyqI0GqY1O9yjKGyHsZMGBeGpKJt9wwGR+nnLYivG269Sc/UxqQpmU8hHgEd9nf+P6+27g7skcg+J08xFozm4iQSUIpnsktmAyDcEZ5trRTCGnwWM6NSiNwL/y14JAMxkoP8HpErLpLjui0fgpm9kvkczvIwipEhPmxGXgajSqJ8HpMvmaQpw2Qklz+lE2gsAxDZ0hUUOaMxulEZwugmCsZbw15UHZzH4J7SPQTCGRwOklCExTaGexpiBlM/sVjBqapuqjmrMbVUfqdIndH2uHN015UDaz30jho6HTIbxDc9bgOItPk8nXEOK0EUqa04+ymf3ijrM4v2koFCibS6GZAhzT0Gky+dZGA1RPUsa55synbBrTjBg+qjUCzQQSPc00gnvffwFVIS0INPkpG0HwppWtXLN8htNlS9FeH2VOQ5SFMyaubr9GoyqQni52+Vl1Ot1cU5iyEQSGIQgZubkCk1G3X6M53aKGNJpilI0g0Gimkjef00rAEoQDOlFRc/qjDeMazSQwr6mSj12xYLqHodGUhBYEGo1GU+ZoQaDRaDRljhYEGo1GU+ZoQaDRaDRljhYEGo1GU+ZoQaDRaDRljhYEGo1GU+ZoQaDRaDRljhYEGo1GU+ZoQaDRaDRljhYEGo1GU+ZoQaDRaDRljhYEGo1GU+ZoQaDRaDRljhYEGo1GU+ZoQaDRaDRljhYEGo1GU+ZoQTCJSCn58rNf5r4t93k+7451k0qnpmlUZw5pmeZXu39FV6wr7/f98X56472TcuxkOsnJoZMlb/9a52v8xWN/wX1b7iOeio/qWFJKnjvyHD989Yf0DPeMdqhTRn+8n0f3Psovdv4CKWXebY4NHCORSkzK8Z878hwvHn3R+ffRgaOkZbrk3/9u/+/4xBOf4At//ILnd/dvuZ9vv/ztUY2lM9bJA9seoC/eN6rfjYfvbvwum09snpR9657FI5COxRCWhbBGf6l+tedX/HzHzwGwDIt3L303j+x5hC8+/UVuWXILf3XBX+X9XTKdZDA5SHWwOjsOmaYv3kdNqAYpJd96+VsEzSC3r7odIbwN0rtiXWw4toGr2q9yvtt2ahv7+vZx7ZxrEULw3JHnqA3VsqR+CYf6D/EPL/wD713+Xs6fcb5nX1JKvvnSN+mN9/LhlR+mtbKVrlgX3cPdtFW2ETSDDCWHeGzvY1wz5xp+tv1nPLr3UVorWvnU6k/x8vGXuWzWZTRGGjnQe4BnjzzLsoZlLKxbyPc2fo/njjwHQNgKc8f8D3D+/MsQhr0+eXDng3zl2a9w9Yz13LNEIQsAABdZSURBVHP1PyNMk65YF7/d91uqglX8zxf/J4PJQW5efDNNkSZumHcD9eF6AHqGe/jDoT9wfcf1mIbJxuMbORU7xZWzr8QQ2fXPw3se5vH9j7OubR2/3fdbblpwE2ErzDc2fIN9vfu497p7Oa/5PLac2sKe7j0srV+KaZhYwmJW1Sx2de/ix6/9mF/v+TUALx59kR+/9mO+ePEXWVC7gK+98DX+fOmfs6ZlDXu697C/bz+rZ6zmS898ies6ruOajmu4b8t93POnewB4fP/jfP+a7/PE/id4bO9jXDn7Sp46+BQrGlfQHetmT88eljcup8Kq4OqOq9nfu5+AEWBNyxq6Y93Uhmt5dveThIMRzpt9kedePrDtAZ4+9DQrGldQGajkxgU3UhOqcb4fTAzy8OsP0zPcw7q2dSypX+J8t7NrJ3c8fgeHBw4DUBWsYmHtQv71lX9ld/dultQv4ZbFt3Drw7cSCURor2oHoCnaxN9e8rc0Rhrpi/dxcugkdaE6asO17O7ezfc3f59ZVbO4fdXtxFIxzzOfSCXYfHIzu7t3M7NyJp984pMk00luXXorp4ZO8ejeR7li9hV8dd1X+cPBP/Do3kd5//L388C2B+io6eCGuTdQF66jPlzPxuMbufPJO6kJ1dAZ62TNjDXctPAmtpzawj1/uoe0TPOG9jewvXM7V8+5mldOvkJapplbM5fnjjzHm+e/mYARYEfXDv5927/zX/v+i754HxuObuBtC99GyAxxYeuFJNNJHtv7GFXBKs6fcT7PHX6On+/8OTcvupkrZl+R8652x7qpDlVjCIOuWBdPHniSG+bdQCKVQCRTRAhgRKM8e/hZvrfpewCsalqVd94YD6KQZJ+QnQtxHfBNwAR+IKX8uu/7EHA/cD5wCrhFSrm32D7XrFkjN2zYMKbxJE+d4vBf3UXk/NVEb3k76aBFJA69FYK6UB3PP/wDNr/0GLuaUiyafS5vOv/d9P757fTNqOTZv3wjwe5B0g01XNtxLfv79pPcf4B5W7vZWNPNjOZ51C5dwZ7+/VgYrOqv564n/pIZFTNIt7fy38f+wOK6xRw+9BqJyjDCMHjkbY8QNINUB6s51H+IU0OneHjTz0g9+DCLXh+m7y/fQ8uubgKtLfwsuoU/HfsTn1nzGYZTw/zjn/6RxQckVwdWEr/6EoyTPWyK72HFzPPY9tofqXx2C1d9+Ctcs/JtfPX5r/KT7T8B4MMrP8ysWJSvbv0mqw4H+NDhhRw/sIN/W5/g+KwKvlnzYeYn6xi67FxahkI82Pd77vnjV0EIQhXVfP7Cu/nWw3/N8YokbWYTVy24lt93vsipfdtpm7eKzSdfYWn9Uvb27mUoOQTAheGlXGou5P7jv6azwl6JWYbF/H0J1g+30zWnDuO117nxN10caI/w03e1QnMDu7p3UdWf5ovf74FlC9l853Xcv/V+BhIDALRWtDKvZh5PH34agKgV5fJZl/PmxDKe+dN/8r9bdvOO+jdQO3MuTz/6b9T3pNmzuoXqaB0rGlewsG4h92y4h2Q6iUQSNsPEUjEA5lTPIZlOEu2N8/aLP8g9G+4hkfaudC9quYhtndtIppOsbVvL3Rfezc6unXz9xa9zfPA462et5zev/wZTmFw+63KeOfwMZv8Q79rbyn+2HWHFXsmVs6/gIbmJ83pqWf9qmq+et5++xW0cHTyKgUFSJqkJ1dAz3IMhDNqr2tnbuxeRlnzkN2k2dwheOqeC21fdzj+99E9c0z2Lt9+/l3gAnrzjEl5vSHHTwpswhckX/vgFakO1dA3bGlZbZRt/t/SzzE/U8rsDv+MXO39BV7KXA40QDka5edHNbDqxiRkVM3hi/xOsORzhQ4vey/9r/TcnTh3ggw/2cazRYu/1K/hj/yY6krWcqJK8sf2NnBw6yaztXSx+6BU2rGti/8pm9h3ZxlAgjQiHeWfj1cz554d4fabJswvSDFVaHKtK87FzP8ZFrRfxs+0/4/H9jyP6B7lis+SFxQKzuZn3vVTF0O6d/NuNUS7veAPPbH0UhMHq7QnWvyr5zRrBxiUhzFgcISEeCXDl7Cs48uqLLNsvuf36v+GzsQfY2b2LqzuuZterf+SqxzuZdShOf1Tw9GLJRXsttjcleOhig1jIQCK5Zs41fPnSL/O2h95Gb7yXtTPX0p6q4QcHfgZCYKQlnzl8Ds3P7uKfrhjgYJNg/jGD9qNJNqyM0H5giDtfm0fksnU8dXGUyr0naf/Rk3zr4i7qz1nDW+a/he9s/A5HB47SUd2Bse8wn/iPIaIpkx/cuYR9Riezugy+e/2/UjG7Y0zznxDiT1LKNXm/myxBIIQwgR3A1cBB4EXgf0gpt7q2+RiwSkr5ESHEu4CbpJS3FNvvWAVBerCbjR98N6FNezDSkBaQMsBMw0/WG8wUtVzxZKfnN10VUGfPOextho7j8B/rBN0VgpoBuGFDmspYdvvD9fD7FQbn7U6z+FD2c7OpkdfWzSa2ZSsrdwwjl8/jJ417WXDMoKE7xcllrTxVe5RrXpKs3CcxJKQswbAhiWasDC8tNNl0bQcb43uJDsOHXqph/iv2ePc1CeackCQseHqpYNEhycxOiAUFyaowg8khYsvn8fSty9n71MP81c/TCAFGGnojgCGoSlhsnR9k6WsD9vEFmBK2t8HckybBQJBnOuIs3peioQ/SlolIpRgIwSuLQ1yyaZits+HZ9U3cNfednHryCbr2HiExp5Xq518jlISUZWBdsZbhXTs4VRegZdMhRDr7/HXOb6R6fydWIs3BjgoeuTjAbdtb4eVtAPxxmWBRfyVNl1zBcMSieusBQrX1VL7lzzi+ZwuPiS10b97AjU/ECKRg98oG5r9yio1zBSsOCqxEmt7GKPsW11C15zhHatJUiDDndFeTChjUrFvPxvR+IlaEcxZdxrGtL2H85Fc8eKlg+3VL+Kz1Jvp3bMXoHcB8eRubI6c4NbOCdyx8O9GTJxl8+VXCy1bQe+QAx3dsRALBSAV7L27iVdFFRWs7y3+3l0Xb8psTRCBAKhxg7wyDVMTkopvfyoFZC1lozeLwv3wbMympa69CdL5MX/vlxP6/h0iFAnzjbSYzj8RZ3FfJ6pd6GWiqxBxOYgwN89T6Ombt6OTVOQZydgsfabwRy4IjtSEOff87dBzMNeNYF63m6xcd50DsCPNCDfTEh7npSBsrf/0aAKm7P8qGX9/LhZuHEAiQkqQlsJKSrnM7mGk1EFl1Dn2PPkr8yBGElCQCgkBCkqyv4tHrG1n2+OvMOSEwU9n7P1gdpNeIs2224ERjgKX1S1ny4jEC+4+SNg1ETTWisxuAprvvouqcxey+7ZPQ14+QQEUUBgYRb1iL3LyV9OAgB85ppXLrfhp6sqYgY/VKfro2ReehfXzg10MEhMXR5TMQew7Q0g29lQbV/WmSNRXsu2IRREJs3P88qw6YHKhLsfZdd9LwXy/R/+STdC2aQWLNMsK/20D1kT6SBsi6ahIfeieBb/2IwGAcTBNSKRImBFLw8AWCS7dK6gZgqCrI6/VJDtZLTsyv48bNEV4LdXLetmGSkSDW4DAnW6MwOMSMzjT1H/gAM+7Kb0kYiekSBJcAX5JSXpv5990AUsqvubZ5LLPNs0IICzgKNMkigxqrIHj8/3k3M3/0Er98o2DrbIP1O6E6AaIzzapd9uH2LE6z/vxK6JEc70rR/1KcYxdZzN4Sg1MmkaY0Q8dNZ5+JJsFL1wVY12PQG0sTeDGB1SWJR9M8uNbixqDBwq7jnNpeRexUACMgqekYoHd/hNSwSW8FxOoE9YclVhrSYYisCtA6N0g6kWbfb4aIrLAYTvUgX4lAImvSEFaaxmUDyHA9nS/HqZvfTzpp0LknihQC3hDiqZNxRBIWxgVtO9KYEUFyWJJqMGiYZWFUC04uN5kfE3Q9E6dvb4JTrQn2L0gz80SEExGDhZtTVDcKjKEhersCvNJhsGpmkMYeMIKCvu2DDHebVLYN0dUZJjBkq75mME2oAWKnDLrnmMSWmCzcIenbEydcG2e4L0jF7ACNSzuJdyUwqhqJtodIHNhP74EIXXuqSfZLQDLj4mGO7YzCqTThujix7iBICNYZJPvT+BbqDMxMkgwEqNknYaYBh9MEaw0aLwzRvTXO0JEUoWaToZ40pgGVbRapmGTwYBLpc90E6g0SnWkQgHoqBURaTYa60jBkfygMSaQhTqwniBU1eW0m7DckVx5PIY97XXH7LoCVA/1UNg3z3bZq5IDFp/pOEWhqZN8jAsOCZF+KdDL7OzMsMEKQ6Mm+GuFmg+FTKWQqY24woG5lkKaLQqQTkoMPDxI7niZdITAGcl8ps0qw7xyTkw2CZWmDucPDJI73cHxTNUiRs33VfIvkgGToqH2RGi8IUr0oQN+eJH2xNDuCko6NSayoQbzLnnjbr0+S7utlsLMasypK96tDJAZMpAmzbogQqjKI96RJ9EliJ5KcSkiM/SmMzALIjAhaLg8zdDxFalASnWXSuyPB4KEkwpAIC+rmD2EGk9StaeLkRsHJF4axoilCNUmGToWItkJlczcVbSb9nY2cfD5Gatg+v/AMk1nXhyF1iH3pOG0DMwjPrCR2Ms3xp2MMHso+EAebofUUmCkwAlCzSNC7K0lq2CRYZ9C8eoiA1cP+J5tIDQusCkHzujCxYyn6G5O8bwXc+VCKZXsEVgW0XB7hyJNDSCtJutc2PQeqIDUMla2DNJ83RF9nK8efiROdaVLZEaDqz95J4C2fz7k3pTBdguAdwHVSyg9l/v0e4CIp5R2ubV7NbHMw8+/dmW1O+vZ1G3AbQHt7+/n79u0b9XgGjmznuX/5a9avqiOQyi7jZVoyuH8Qa+E5hCIx6D2Y/U5KhBAkrRaSwwFCkS6Guuuw5HGs0BDCFB6bn5QSWdmGqJoBxzYjkNCyEmI9pE/sQYQqEe0XIK0o8tBGxMBhhBCkYilih/oJt1ZgRq2c49OwkOSQZHDzDmTruYgjm4iumI9VacHJHUgzhJh9IYRriG95HnlqP6HmCEkpkUgCwqB/Zw/dL5/ADJk0vXEWVmUg/4VqWAhWCI5tITvzAa3nQtMS5Cs/R8ik83HKrGM43kpkUSvse4Gh3YehYR6RS65CbP2F/VS7CUShZRWc3A5DXVDZArWz4cgmSCWgeRmkE6QPb2PwYJzwuRdgJY+SOHaYVLqK8PJzkAc3IpMxDMsg2Z9g+NggwYYwwyeGCay+hmCdidz9B2KHBojMqSR2ZJBATRCrosA5q+udko4TNNE1TGooRaStghNPHEKYgop51YRnRhGmgTAFMi2RaQmResTsNQjTgIMvwlAXgzLFLhljZaCeIXMNRt9uhl7ZTLIvQeNV85z7xbFXkfFBRF1H5hrY1ysZmc/g8RBy33MIklTMq8aMWqRrFzFcvZae73+N+ovqiPVWM3ysn9qlYEUthJl9HtOJNEP7+4h2VDN8fBCZloTmtpMKtDD8ygais8MYAZeQMkPQeg6xra8wvPcgVDTCjBWIg88TbjYI1IVIx9MM7OzBCBpULKhBGLkCA6Bn8ylSQ0nqL5sPM1bAiW0Q6yFlNhLrsgiHj2EG8889znUFhCFyjpHoGebE744hgzU0rGsm3NEGwUo49irINEMH+wksXIlVGYYTr4EZhNZzoGsvDBwnJaoZOBKA7v1Uzo/Y18DzHGad/emkLdAEICyD4c4YyZ44kbYKjHAIOWMVsueI/S6Ha6B5GemDmxjac4xgXYhAbcjekTDZ1dBOU+18qjoPI05uxXZVCWheRt+eOENbXqPxggCGiTNv0LXXe3GW/BmsurnQI1yUM14QuBmPj0Cj0WjKlWKCYDLDRw8Bs13/npX5LO82GdNQDbbTWKPRaDRTxGQKgheBhUKIuUKIIPAu4CHfNg8B78v8/Q7giWL+AY1Go9FMPJOWRyClTAoh7gAeww4fvVdKuUUI8RVgg5TyIeDfgB8JIXYBndjCQqPRaDRTyKQmlEkpHwEe8X32N66/Y8A7J3MMGo1GoymOLjGh0Wg0ZY4WBBqNRlPmaEGg0Wg0ZY4WBBqNRlPmTGrRuclACHECGH1qsU0jUHpt4bOHcjzvcjxnKM/z1udcGnOklE35vjjjBMF4EEJsKJRZdzZTjuddjucM5Xne+pzHjzYNaTQaTZmjBYFGo9GUOeUmCL4/3QOYJsrxvMvxnKE8z1uf8zgpKx+BRqPRaHIpN41Ao9FoND60INBoNJoyp2wEgRDiOiHEdiHELiHE56Z7PJOFEGKvEOIVIcRGIcSGzGf1QojfCiF2Zv5fN93jHC9CiHuFEMczzY3UZ3nPU9j8c+bebxZCrJ6+kY+dAuf8JSHEocz93iiEuMH13d2Zc94uhLh2ekY9PoQQs4UQvxNCbBVCbBFCfCrz+Vl7r4uc8+TdaynlWf8fdhns3cA8IAhsApZN97gm6Vz3Ao2+z/4B+Fzm788Bfz/d45yA81wPrAZeHek8gRuA32B3HLwYeH66xz+B5/wl4DN5tl2Wec5DwNzM829O9zmM4ZxbgdWZv6uAHZlzO2vvdZFznrR7XS4awYXALinlHillHPgJcOM0j2kquRG4L/P3fcBbp3EsE4KU8vfYPSzcFDrPG4H7pc1zQK0QonVqRjpxFDjnQtwI/ERKOSylfB3Yhf0enFFIKY9IKV/K/N0HbAPaOIvvdZFzLsS473W5CII24IDr3wcpfmHPZCTwX0KIPwkhbst8NkNKeSTz91FgxvQMbdIpdJ5n+/2/I2MGuddl9jvrzlkI0QGcBzxPmdxr3znDJN3rchEE5cQ6KeVq4Hrg40KI9e4vpa1LnvUxw+VynsD3gPnAucAR4J7pHc7kIISoBB4EPi2l7HV/d7be6zznPGn3ulwEwSFgtuvfszKfnXVIKQ9l/n8c+CW2inhMqceZ/x+fvhFOKoXO86y9/1LKY1LKlJQyDfwrWZPAWXPOQogA9oT4gJTyF5mPz+p7ne+cJ/Nel4sgeBFYKISYK4QIYvdGfmiaxzThCCEqhBBV6m/gGuBV7HN9X2az9wH/Z3pGOOkUOs+HgPdmIkouBnpcZoUzGp/9+ybs+w32Ob9LCBESQswFFgIvTPX4xosQQmD3Nt8mpfyG66uz9l4XOudJvdfT7SGfQk/8Ddje993AF6Z7PJN0jvOwowc2AVvUeQINwOPATuC/gfrpHusEnOuPsdXjBLZN9IOFzhM7guQ7mXv/CrBmusc/gef8o8w5bc5MCK2u7b+QOeftwPXTPf4xnvM6bLPPZmBj5r8bzuZ7XeScJ+1e6xITGo1GU+aUi2lIo9FoNAXQgkCj0WjKHC0INBqNpszRgkCj0WjKHC0INBqNpszRgkCjmUKEEFcIIX493ePQaNxoQaDRaDRljhYEGk0ehBB/LoR4IVP3/X8JIUwhRL8Q4h8zNeIfF0I0ZbY9VwjxXKYY2C9dtfEXCCH+WwixSQjxkhBifmb3lUKInwshXhNCPJDJJNVopg0tCDQaH0KIpcAtwFop5blACng3UAFskFIuB54C/jbzk/uBu6SUq7AzP9XnDwDfkVKeA1yKnRUMdjXJT2PXkZ8HrJ30k9JoimBN9wA0mtOQNwLnAy9mFusR7KJmaeCnmW3+N/ALIUQNUCulfCrz+X3Af2RqPrVJKX8JIKWMAWT294KU8mDm3xuBDuCPk39aGk1+tCDQaHIRwH1Syrs9HwrxRd92Y63PMuz6O4V+DzXTjDYNaTS5PA68QwjRDE5/3DnY78s7MtvcCvxRStkDdAkhLst8/h7gKWl3ljoohHhrZh8hIUR0Ss9CoykRvRLRaHxIKbcKIf4au9ObgV3t8+PAAHBh5rvj2H4EsMsg/0tmot8DfCDz+XuA/yWE+EpmH++cwtPQaEpGVx/VaEpECNEvpayc7nFoNBONNg1pNBpNmaM1Ao1GoylztEag0Wg0ZY4WBBqNRlPmaEGg0Wg0ZY4WBBqNRlPmaEGg0Wg0Zc7/D9iWHLLwRlkBAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5bnA8d8zM8lMdrIRAgk7omwBBFHRglvFrcrVVlsVtSp2cel1qXZT661Xe1utdblq664t7gsuvSqCgHVhV2STnSQEsu+ZbPPeP85JHCAJQ8hkkpzn+/nMh7PNmeedE84z7/ue8x4xxqCUUsq5XJEOQCmlVGRpIlBKKYfTRKCUUg6niUAppRxOE4FSSjmcJgKllHI4TQRK9RAi8rGIXBXpOJTzaCJQ7RKR6qBXQETqguYv7sT+OjzRichQETEi4jm8yPsuEbnc/o4ujHQsqu/QRKDaZYyJb3kBu4Bzgpb9I9LxOdRlQCkwpzs/VJNz36aJQB0yEXGJyG0islVESkTkZRFJsdf5ROQFe3m5iCwXkQwRuRs4EXjYrlE8fIifOVBE5otIqYhsEZGrg9YdIyIrRKRSRPaKyP0dxWKvSxKRJ0WkQETyReQPIuK2140UkcUiUiEixSLyUgdxvSIie+xtl4jI2KB1z4jIIyLyrohUicgXIjIiaP1pIrLRfu/DgBzkOxgCzADmAqeLyICgdW4R+bV9TKpEZKWIZNvrxorIh/Z3t1dEfh0U3x+C9jFTRPKC5neIyK0i8hVQIyKeoONeJSLrRWT2fjFeLSIbgtZPFpFbROS1/bZ7UET+2lF5VTcyxuhLXwd9ATuAU+3pG4DPgSzACzwOzLPXXQO8DcQCbuBoINFe9zFwVQefMRQwgKeNdUuA/wV8wESgCDjZXvcZcKk9HQ8cG0Isb9hxxwH9gWXANfa6ecBvsH4o+YATOoj5x0CC/T08AKwJWvcMUAIcA3iAfwAv2uvSgCrgAiAK+E+g6SDfz++AZfb0WuCmoHW32MtGYyWUHCDVjq0AuMkuSwIwLSi+PwTtYyaQt98xXwNkAzH2su8DA+3v5kKgBsgMWpcPTLVjGAkMATLt7frZ23mAQuDoSP9d68s+1pEOQF+948W+iWADcErQukyg0f4P/mPgU2BCG/v4+CAnuqG0kQjsE1EzkBC07B7gGXt6CfB7IG2/97UZC5AB1Lec3OxlPwQW2dPPAX8Dsg7xO+pnx59kzz8DPBG0/kxgoz09B/g8aJ0AeQf5fjYDv7CnfwV8GbRuE3BuG+/5IbC6nf2Fkgh+fJAyr2n5XOB94IZ2tvsXcLU9fTawPtJ/0/r69qVNQ6ozhgBv2M0t5ViJoRnrBPs81gnhRRHZLSL/IyJRh/l5A4FSY0xV0LKdwCB7+krgCGCj3fxztr28vViGYP0KLwgqw+NYNQOAX2KdmJeJyDoR+XFbQdnNMffaTSWVWCdOsH7tt9gTNF2LVWNpKVNuywpjnSFzaYeITAeGAS/ai/4JjBeRifZ8NrC1jbe2tzxU+8QkInNEZE3Q9zaOb8vb0Wc9C1xiT1+CdWxUD6GJQHVGLnCGMaZf0MtnjMk3xjQaY35vjBkDHI/166+lY7OzQ93uBlJEJCFo2WCsZgiMMZuNMT/EOpH/EXhVROI6iCUXq0aQFhR/ojFmrL2/PcaYq40xA7Gal/5XREa2EdePgHOBU4EkrBoNHKSt31aAdeK03iAiwfNtuMze7xoR2QN8EbQcu0wj2nhfLjC8nX3WYDWbtRjQxjatx8zuo/g7cC2QaozpB3zNt+VtLwaAN4EJIjIO6zjoxQY9iCYC1RmPAXfbJwZEJF1EzrWnTxKR8XbHayVWk1HAft9e2j8pBfPaHb0+EfFhnfA/Be6xl03AqgW8YH/mJSKSbowJAOX2PgLtxWKMKQA+AO4TkUSxOr9HiMgMe3/fF5Esez9lWCfDljIES8BKKCVYJ9T/DqFsLd4FxorIf4h1Rc71tH0ixv4OfoDVSTwx6HUd8CP7/U8A/yUio8QyQURSgXeATBH5hYh4RSRBRKbZu14DnCkiKXbH8y8OEnMc1ndRZMd1BVaNoMUTwM0icrQdw8iWvxFjjB94Fasms8wYsyv0r0qFmyYC1Rl/BeYDH4hIFVbHccvJZQDWf/hKrCajxXzbDPBX4AIRKRORBzvYfzVQF/Q6GauteyhW7eAN4A5jzAJ7+1nAOhGptj/jImNM3UFimQNEA+uxTvavYvV1gNXZ+YW9v/lY7d7b2ojzOawmqnx7P593UKZ9GGOKsTpX78VKJKOAf7ez+Xn29/CcXVvZY4zZAzyF1S8zC7gfeBkrwVUCT2L1gVQBpwHnYDVTbQZOsvf7PPAlVpPWB0C7V0fZMa8H7sPqnN8LjA+O2RjzCnA31sm+CqsWkBK0i2ft92izUA8jVtOkUkqFl4gMBjYCA4wxlZGOR31LawRKqbATERdwI9bls5oEehi9W1ApFVYiEofVlLQTqxlL9TDaNKSUUg6nTUNKKeVwva5pKC0tzQwdOjTSYSilVK+ycuXKYmNMelvrel0iGDp0KCtWrIh0GEop1auIyM721mnTkFJKOZwmAqWUcjhNBEop5XC9ro9AKdV3NTY2kpeXh9/vj3QovZbP5yMrK4uoqNAH/dVEoJTqMfLy8khISGDo0KFYA7KqQ2GMoaSkhLy8PIYNGxby+7RpSCnVY/j9flJTUzUJdJKIkJqaesg1Kk0ESqkeRZPA4enM9+eYRLBpTxX3fbCJ4ur6SIeilFI9imMSwdaiah5auEUTgVKqQ/Hx8QffqI9xTCKIcltFbWrWQfaUUiqYgxKB1W7W0NzWEweVUqp9a9as4dhjj2XChAnMnj2bsrIyAB588EHGjBnDhAkTuOiiiwBYvHgxEydOZOLEiUyaNImqqioA/vSnPzF16lQmTJjAHXfcAUBNTQ1nnXUWOTk5jBs3jpde6vAhcWHjmMtHo+0aQWOTJgKleoPfv72O9bu79hk2YwYmcsc5Yw/5fXPmzOGhhx5ixowZ3H777fz+97/ngQce4N5772X79u14vV7Ky63HZf/5z3/mkUceYfr06VRXV+Pz+fjggw/YvHkzy5YtwxjD9773PZYsWUJRUREDBw7k3XffBaCioqJLyxuqsNUIRCRbRBaJyHoRWSciN7SxzUwRqRCRNfbr9nDFE+WxE4E2DSmlDkFFRQXl5eXMmDEDgMsuu4wlS5YAMGHCBC6++GJeeOEFPB7rd/X06dO58cYbefDBBykvL8fj8fDBBx/wwQcfMGnSJCZPnszGjRvZvHkz48eP58MPP+TWW29l6dKlJCUlRaSM4awRNAE3GWNWiUgCsFJEPrQfgB1sqTHm7DDGAXzbR9CoTUNK9Qqd+eXe3d59912WLFnC22+/zd13383atWu57bbbOOuss3jvvfeYPn0677//PsYYfvWrX3HNNdccsI9Vq1bx3nvv8dvf/pZTTjmF228P2+/hdoWtRmCMKTDGrLKnq4ANwKBwfd7BaB+BUqozkpKSSE5OZunSpQA8//zzzJgxg0AgQG5uLieddBJ//OMfqaiooLq6mq1btzJ+/HhuvfVWpk6dysaNGzn99NN56qmnqK6uBiA/P5/CwkJ2795NbGwsl1xyCbfccgurVq2KSBm7pY9ARIYCk4Av2lh9nIh8CewGbjbGrGvj/XOBuQCDBw/uVAxaI1BKhaK2tpasrKzW+RtvvJFnn32Wn/zkJ9TW1jJ8+HCefvppmpubueSSS6ioqMAYw/XXX0+/fv343e9+x6JFi3C5XIwdO5YzzjgDr9fLhg0bOO644wDrEtUXXniBLVu2cMstt+ByuYiKiuLRRx+NSJnD/sxiEYkHFgN3G2Ne329dIhAwxlSLyJnAX40xozra35QpU0xnHkyzvbiGk/78MX+5MIfZk7IO/galVLfbsGEDRx11VKTD6PXa+h5FZKUxZkpb24f18lERiQJeA/6xfxIAMMZUGmOq7en3gCgRSQtHLC1NQ41N2lmslFLBwnnVkABPAhuMMfe3s80AeztE5Bg7npJwxNN6+WhAm4aUUipYOPsIpgOXAmtFZI297NfAYABjzGPABcBPRaQJqAMuMmFqq4rS+wiUUqpNYUsExphPgA6HwTPGPAw8HK4Ygul9BEop1TYdYkIppRzOOYnApZePKqVUWxyTCFwuweMSTQRKqYN68803ERE2btwY6VC6hWMSAYDHLdpHoJQ6qHnz5nHCCScwb968sH1Gc3Nz2PZ9qByVCKLcLhr0qiGlVAeqq6v55JNPePLJJ3nxxRcB66R98803M27cOCZMmMBDDz0EwPLlyzn++OPJycnhmGOOoaqqimeeeYZrr722dX9nn302H3/8MWDdUXzTTTeRk5PDZ599xl133cXUqVMZN24cc+fOpeWiyS1btnDqqaeSk5PD5MmT2bp1K3PmzOHNN99s3e/FF1/MW2+91SVldsww1GDdS6BNQ0r1Ev+6Dfas7dp9DhgPZ9zb4SZvvfUWs2bN4ogjjiA1NZWVK1eybNkyduzYwZo1a/B4PJSWltLQ0MCFF17ISy+9xNSpU6msrCQmJqbDfdfU1DBt2jTuu+8+AMaMGdM6yNyll17KO++8wznnnMPFF1/MbbfdxuzZs/H7/QQCAa688kr+8pe/cN5551FRUcGnn37Ks88+2yVfi+NqBJoIlFIdmTdvXutDZi666CLmzZvHggULuOaaa1qHmk5JSWHTpk1kZmYydepUABITE1vXt8ftdnP++ee3zi9atIhp06Yxfvx4Fi5cyLp166iqqiI/P5/Zs2cD4PP5iI2NZcaMGWzevJmioiLmzZvH+eeff9DPC5WjagRRHtFHVSrVWxzkl3s4lJaWsnDhQtauXYuI0NzcjIi0nuxD4fF4CASNYOD3+1unfT4fbre7dfnPfvYzVqxYQXZ2Nnfeeec+27Zlzpw5vPDCC7z44os8/fTTh1i69jmuRqD3ESil2vPqq69y6aWXsnPnTnbs2EFubi7Dhg0jJyeHxx9/nKamJsBKGKNHj6agoIDly5cDUFVVRVNTE0OHDmXNmjWtw1QvW7aszc9qOemnpaVRXV3Nq6++CkBCQgJZWVmt/QH19fXU1tYCcPnll/PAAw8AVrNSV3FUItA+AqVUR+bNm9faJNPi/PPPp6CggMGDBzNhwgRycnL45z//SXR0NC+99BLXXXcdOTk5nHbaafj9fqZPn86wYcMYM2YM119/PZMnT27zs/r168fVV1/NuHHjOP300/epdTz//PM8+OCDTJgwgeOPP549e/YAkJGRwVFHHcUVV1zRpeUO+zDUXa2zw1ADnPPQJ6QneHnq8tCreUqp7qPDUHestraW8ePHs2rVqg4fa9mjhqHuaaLcekOZUqp3WrBgAUcddRTXXXddlz/b2FGdxR69j0Ap1Uudeuqp7Ny5Myz7dlSNQPsIlOr5eltzdU/Tme/PUYkgSoeYUKpH8/l8lJSUaDLoJGMMJSUl+Hy+Q3qfo5qG9IYypXq2rKws8vLyKCoqinQovZbP5yMr69Cey+6sRODRRKBUTxYVFcWwYcMiHYbjOKppyOoj0CqnUkoFc1Qi0MtHlVLqQA5LBNo0pJRS+3NcItD7CJRSal8OSwR6+ahSSu3PYYlAm4aUUmp/jksETQFDIKC1AqWUauGoRBDtsYrbGNBagVJKtXBUIohyC4A+pUwppYI4LBHYNQLtJ1BKqVaOTAT6uEqllPqWoxJBdGuNQJuGlFKqRdgSgYhki8giEVkvIutE5IY2thEReVBEtojIVyLS9sM9u0iUx+ojaNSbypRSqlU4Rx9tAm4yxqwSkQRgpYh8aIxZH7TNGcAo+zUNeNT+Nyw8Lu0jUEqp/YWtRmCMKTDGrLKnq4ANwKD9NjsXeM5YPgf6iUhmuGLSPgKllDpQt/QRiMhQYBLwxX6rBgG5QfN5HJgsEJG5IrJCRFYczgMroluahrSPQCmlWoU9EYhIPPAa8AtjTGVn9mGM+ZsxZooxZkp6enqnY9HLR5VS6kBhTQQiEoWVBP5hjHm9jU3ygeyg+Sx7WVhoIlBKqQOF86ohAZ4ENhhj7m9ns/nAHPvqoWOBCmNMQbhiitLLR5VS6gDhvGpoOnApsFZE1tjLfg0MBjDGPAa8B5wJbAFqgSvCGM+39xHo5aNKKdUqbInAGPMJIAfZxgA/D1cM+2u9j0CbhpRSqpWj7izWy0eVUupAzkoELu0jUEqp/TkqEfiirOLWNTRFOBKllOo5HJUIUuO9RLtd5JXXRToUpZTqMRyVCNwuISs5htzS2kiHopRSPYajEgHA4NRYdpZoIlBKqRaOSwRDUmLZVVKLdeWqUkopxyWC7JRYquqbKK9tjHQoSinVIzguEQxJjQNgl/YTKKUU4MBEMDglFoCdmgiUUgpwcCLQK4eUUsriuEQQE+0mPcHLLr1ySCmlAAcmAoD+CV6KqusjHYZSSvUIjkwEafFeijURKKUU4OBEUFLdEOkwlFKqR3BoIoimqLpebypTSikcmwi8NDQFqKrXUUiVUsqZiSAhGkCbh5RSCocmgtQ4L4B2GCulFA5NBGnxdiKo0kSglFLOTAR201BxjTYNKaWUIxNBSmw0IlojUEopcGgi8LhdJMdGax+BUkrh0EQA1r0EetWQUko5OhHoMBNKKQUOTgTpCV4KtY9AKaWcmwiyk2PZXV5HU3Mg0qEopVREOTYRDE6JpSlg2F3uj3QoSikVUSElAhF5XUTOEpE+kzgGp7Y8srImwpEopVRkhXpi/1/gR8BmEblXREYf7A0i8pSIFIrI1+2snykiFSKyxn7dfghxH7YhLYlAn1SmlHK4kBKBMWaBMeZiYDKwA1ggIp+KyBUiEtXO254BZh1k10uNMRPt112hBt0VMhJ8RHtc7NJnFyulHC7kph4RSQUuB64CVgN/xUoMH7a1vTFmCVB6+CGGh8slZCfH6LOLlVKOF2ofwRvAUiAWOMcY8z1jzEvGmOuA+MP4/ONE5EsR+ZeIjD2M/XTKkNQ4dmqNQCnlcJ4Qt3vQGLOorRXGmCmd/OxVwBBjTLWInAm8CYxqa0MRmQvMBRg8eHAnP+5Ag1Ni+WJbCcYYRKTL9quUUr1JqE1DY0SkX8uMiCSLyM8O54ONMZXGmGp7+j0gSkTS2tn2b8aYKcaYKenp6YfzsfvITomlpqGZstrGLtunUkr1NqEmgquNMeUtM8aYMuDqw/lgERkg9s9wETnGjqXkcPZ5qNLireGoS3U4aqWUg4XaNOQWETH2095FxA1Ed/QGEZkHzATSRCQPuAOIAjDGPAZcAPxURJqAOuAi081Pk0+OtYpQXquJQCnlXKEmgv8DXhKRx+35a+xl7TLG/PAg6x8GHg7x88MiJU5rBEopFWoiuBXr5P9Te/5D4ImwRNSN+sVat0CUax+BUsrBQkoExpgA8Kj96jNaawTaNKSUcrCQEoGIjALuAcYAvpblxpjhYYqrW8REuYn2uCjTRKCUcrBQrxp6Gqs20AScBDwHvBCuoLqLiJASG02Z9hEopRws1EQQY4z5CBBjzE5jzJ3AWeELq/v0i43S+wiUUo4WamdxvT0E9WYRuRbI5/CGlugxUuK0RqCUcrZQawQ3YI0zdD1wNHAJcFm4gupOybHR2keglHK0g9YI7JvHLjTG3AxUA1eEPapulBynTUNKKWc7aI3AGNMMnNANsURESmw05bUNBALdelOzUkr1GKH2EawWkfnAK0Drsx2NMa+HJapu1C82moCBl1fkMn1kGtkpsZEOSSmlulWofQQ+rAHhTgbOsV9nhyuo7tRyU9ltr6/loYWbIxyNUkp1v1DvLO5T/QLBWoaZAPhie499oJpSSoVNqHcWPw0c0IhujPlxl0fUzfonWDdKR7td7CypZU+FnwFJvoO8Syml+o5Qm4beAd61Xx8BiVhXEPV6YwYm8tbPp/PKT44DYNmOUrYUVnHeI/9md3ldhKNTSqnwC7Vp6LXgeftZA5+EJaIIyMnuR1NzgHivhy+2lfDZ1hLW5Jbzwuc7+eWsIyMdnlJKhVWoNYL9jQL6d2UgkeZxuzhhZBpvrs7nrTX5ALy8Io/G5kCEI1NKqfAKKRGISJWIVLa8gLexnlHQp9zxvTFEeVzUNjRz3ckjKa6u5+53N1Dp1xvOlFJ9V6hNQwnhDqQnyEyK4e9zpvDvLcVcd/Io8srqeObTHdQ3NXPPf0yIdHhKKRUWoV41NBtYaIypsOf7ATONMW+GM7hImDo0halDUwD4y4UTKaioY0thn+gXV0qpNoXaR3BHSxIAMMaUYz2Mvs9LT/BRVFUf6TCUUipsQk0EbW0X6vAUvVp6vFcTgVKqTws1EawQkftFZIT9uh9YGc7Aeor+iV5qGpqpqW+KdChKKRUWoSaC64AG4CXgRcAP/DxcQfUk6fFeAK0VKKX6rFCvGqoBbgtzLD1SeoKdCKrrGZoWF+FolFKq64V6H8GH9pVCLfPJIvJ++MLqOVoTgdYIlFJ9VKhNQ2n2lUIAGGPK6GN3FrenvyYCpVQfF2oiCIjI4JYZERlKG6OR9kXJsdG4XUJhlT/SoSilVFiEegnob4BPRGQxIMCJwNywRdWDuFxCWny01giUUn1WSDUCY8z/AVOATcA84CbAMWM0pyd4eXlFHsfcvYC/LdmqzzdWSvUpoQ4xcRVwA5AFrAGOBT7DenRln+dvtEYgrW8K8N/vbSQ9wcvsSVkRjkoppbpGqH0ENwBTgZ3GmJOASUB5R28QkadEpFBEvm5nvYjIgyKyRUS+EpHJhxR5N5qUbV0w9c51J5AWH82Sb4ojHJFSSnWdUBOB3xjjBxARrzFmIzD6IO95BpjVwfozsJ5rMAqrv+HREGPpdnedO45lvzmF7JRYjhuRxr+3FGOMNg8ppfqGUBNBnn0fwZvAhyLyFrCzozcYY5YAHT0N/lzgOWP5HOgnIpkhxtOtYqLdrc82Pn5EKoVV9WwtqolwVEop1TVCvbN4tj15p4gsApKA/zvMzx4E5AbN59nLCvbfUETmYl+lNHjw4P1Xd6vjR6QC8NnWYkb2j49oLEop1RUO+VGVxpjFxpj5xpiGcATUzmf+zRgzxRgzJT09vbs+tk2DU2JJT/Cyelc5gYChWgejU0r1cp19ZnFXyAeyg+az7GU9mogwqn88W4tr+OeyXUy/dyH+xuZIh6WUUp0WyUQwH5hjXz10LFBhjDmgWagnGp4ex7aiar7YXkpFXSNbi/QJZkqp3itsD5cRkXnATCBNRPKwnmgWBWCMeQx4DzgT2ALUAleEK5auNjwtnip/E59usS4j3VJYzdiBSRGOSimlOidsicAY88ODrDf00mcaDE+3hqMuqbG6SbbqM42VUr1YJJuGeq0R6fteLbRhTxU/+vvnfLRhb4QiUkqpznPEc4e72qB+MXg9LuqbAozOSGDhxkKaA4aR/eM55aiMSIenlFKHRGsEneByCcPS4oj3eph5ZDrN9iB0uaW1EY5MKaUOndYIOum0MRkUVtZzRP+E1mW5ZY4ZkFUp1YdoIuikm75rDbWUW1rLkNRYhqXF8dnWEowxiEiEo1NKqdBp09Bhyk6JZfEtJ3Hykf2pbwq0PsBGB6VTSvUWmgi6SHZyLAC5ZbV8uqWYsXe8T0GFNhUppXo+TQRdJDslBoDc0jreWJ1PbUMzy3eURTgqpZQ6OE0EXSTLrhHsLKll0aZCANblV0QyJKWUCokmgi7ii3KTnuDlna92U1zdgEtgrZ0IKuoa+fUbaznxfxayepfWEpRSPYsmgi6Uk5XE5sJq3C7hjPGZfJ1fgTGGm1/5kpeW5+JvDPCjv3/B21/ujnSoSinVSi8f7UKPXnI0S74pojlgKK5u4N2vCvhsawkLNuzl2pNGMue4oVzz/Aqum7eauoZmfjA1++A7VUqpMNNE0IWi3K7WISa+yisH4NbXv8Ilwo+mDSY9wctL1xzHqfcvZsGGvYzoH8/DCzcTMPCXCyeSEhcdyfCVUg6lTUNhMnZgEudPziKvrI5ZYweQmWRdVRTldjExux9r8yt45tMdfL6tlMXfFPHKityD7FEppcJDE0GYuF3CfT/I4bPbTuFP35+wz7rxg5IoqPDz8cZCvjs2g6OHJPPqyjy9CU0pFRGaCMJsQJKP2Oh9W+DGD7IeYlNV38Rxw1O54OgsNhdW82WeXm6qlOp+mggiYOygJFqGIzpuRCpnTcgkLtrNI4u2RDYwpZQjaSKIgHivh+FpcQxM8jE4JZZEXxQ/O2kkH67fy2dbS1iTW84tr3xJTX0T9U3N2mSklAorvWooQm6ddSSBoJFKrzxhGP/8YhfX/nMVIkJxdT2DkmN4ZUUep43J4M7vjQVge3ENw9LiIhm6UqqP0RpBhHx37ABmjctsnfdFuXnuymOI83qoa2hidEYCDyzYTH55Hc99toNNe6r4cP1eTvrzxyz5pihygSul+hytEfQgI9Ljee+GE6nyN/J1fiVXP7eC2ZMGsWDDXm5/62v8TQEA3ltbwHeOSI9wtEqpvkITQQ8T7/UQ7/UwINHH45cezXdGpTN9ZBo3v/IlAAk+Dws27OXud9eTnuBl7ndGRDhipVRvp4mghxIRTh87AIALjs6ipr6Jd9cWcMHkLH752lf8fel23C7htDED9ukzaA4YmgOGaI+2+imlQqNni17isuOH8vI1xzFr/AASfR5OG5OB1+Pizx9sAqC8tgFjDL9982vOfHAp/sbmCEeslOottEbQyyT6olh668kk+jzc/e4Gnv50B7tKajn1L4v5zZlH8c6Xu6mqb+LGl9ewvbiWQf183PTd0RyVmRjp0JVSPZTWCHqhpJgoRIRjhqXQHDA8+9kOGpoC3POvDVTVN5GVHMN7a/fQ1Bxg+Y4ybn3tK4yxmoy2FFZFOnylVA+jNYJeLCe7HwAvL7cGrPM3BoiLdvPaT4/ns60lnDUhk9dX5XHra2t5eUUuCzYU8uH6vTx2ydF8urWYYWlxXDF9WCSLoJTqATQR9GIZiT4yEr3sraxnQlYSeyr8nDAyjYxEH+dNGgTA7ElZPPjRFm59bS0ugZS4aH756pdU+puIcgunHJnB4NTYCJdEKRVJmgh6uZysfnywfi/HDk/lqhOHEXUe9qQAABOnSURBVLffAHfRHhfPXXkMGwoqGZ2RwPqCSm54cQ1HDkhgZ0ktVz67nPGDkvj1WUeRFu89YP+lNQ3Eed14PW4KK/0s2lTIf0zOIsqtrYpK9RVhTQQiMgv4K+AGnjDG3Lvf+suBPwH59qKHjTFPhDOmviYn20oEkwf3o3+Cr81tRqTHMyI9vnV6b6Wf744ZwKJNhTz/+U7eXVvA17sreO7H0xiQ5OOJpdt4Yul2pg1P4e0vd5OR6GP6yDQ+XL+XirpGVuwo44KjsxiWFkdiTBRPfrKdFz7fSWp8NLMnZXHZcUPwuF2UVNfz6zfWctHUwZx0ZP/WePZU+HEJ9E/0sXlvFa+vzuenM0fwzL93MCEriZmj+7dZDqVUeEi4BjQTETfwDXAakAcsB35ojFkftM3lwBRjzLWh7nfKlClmxYoVXRxt77WlsJo75n/N/158NEkxUZ3ax6dbi7nq2RVEe1ycmzOQ5z/fSUaij4IKP+dNHMjuCj+5pbWMykhgaGosz322E4DYaDdJMVEUVPg5cVQaNfVNrNpVTkail+kj0tiwp4oNBZX4olw8e8UxTBueyrOf7uCO+esAuPakkWzcU8mCDYUk+DxU+ZsAOHpIMmeMG8DRQ5KZt2wXu8v9nDk+kxNHpfHu2gIyk3ycclQGjy/eSrTbxXWnjGq3bMYYquubiPd6Wsd1UsqJRGSlMWZKm+vCmAiOA+40xpxuz/8KwBhzT9A2l6OJoEfYVlTNba+tZeWuMsZkJvLi3GPxuAWvx73PdsYYPly/FxHhjdV5lFQ3cMOpozh+RBrGGD7aUMgbq/NZtqMUf0Mzvzt7DA8v2sKu0lqGpMays6SWU4/qjzGwdEsxTc0Bjh6SzKY9Vfxy1pHUNTTzxup81hdUAtad1v0TvGwrriEu2k1Ng3V/hC/Khb/RGnLj3IkD2VpUTU19Mw1NAaYOTebM8Zn86+s9fLh+L9X1TUwblsIvTj2CHSU1FFfVc+Ex2QfUoCpqG0HoMKEaY8grq2NgvxjcLk0sqveIVCK4AJhljLnKnr8UmBZ80rcTwT1AEVbt4T+NMQc8s1FE5gJzAQYPHnz0zp07wxKzgoamAFFu6ZJfz4GAweUSKv2NPLF0OxsLKjl6SDI/PmEYBeV+Tr7vY5qNYcktJ5GVHLPPZ24oqGT5jlLOGp9JYkwUv3z1K7YVVfPn7+dQXN3AY4u3MnN0Ov/eUsKCDXuZOjSZAfbjQN//eg8NzQESfR5mjRtA/wQfT3yyrTVxAPRP8HLR1GyOHZHKccNTeeerAv7zpTU0BQwzR6dz/w+sZ0iv3lXGXz/aTHZyLN8dm8ELn+/k/XV7SY6NYlhaHDNH9+eqE4exu7yO3eV+pg5NISbaTXPAsHFPJbtKaskvr2Nk/3imDUsFYFdpLdkpMa0PLDLGUNvQTGy0lXS15qLCoScnglSg2hhTLyLXABcaY07uaL9aI+g77v9gE6W1DfzhvPGd3kdjc4CiqnoG9otpXbarpJYdJTVMG57SWqPZWVLDlsJqjshIoMrfxK2vfcW63RUEDKTFR1NS08CUIckcNzyVxxZvIz3ByxnjBvDkv7eTEhtNpb+RxmaDxyVc/Z3hFFfVs724hhU7y/aJJzPJx/Ej0vhiewl5ZXUHxOtxCU0BgwjMGjuAhqYAn28roaahGa/HRVPAcPG0wcREuXnus53ERrsxWEOHxHs9DEjyMSDJR2ai9a+/sZmUOC9ej4un/r2dMZmJ5GT3Y/mOUgoq/Fxy7BBio9wkxUYRCBgWbipk8aYiYqPd3HDqERw5IIHc0lqKq+vJL/fz3TEZbCioJCPRx+gBCazbXUFWciz9E7xs3FPFwo2FFFXVM2N0Opv2VOHzuJgyNIWi6npeWpbLkNRYvt5dwcCkGE4bk0FFXSOV/iYyk3xsLaym2RjGDUzapzbVP9GLS4T1uytJiokiNT6atHgv1fVNFFbVk50cQ2ZSDJ9vLyEmys20YSkYA+sLKhk9IIEot4sXl+3irTW7OenIdIalxRPv9VDb0MTeynrAeirg2vwK4rxuThuTsc9TA3NLa8krqyMzyYcvyk1GonefZNwcMCzbXkpWcgzZKbEUVvkpqqpv7W/btKeK5oDB43axvbiaqUNTGD8oCU8bF1R8nV/B9uIaxg5MZLjdb9fYHMAtgsv+Tlr+pvdW+knwRTGyf/yh/rdoU49tGtpvezdQaoxJ6mi/mghUV/E3NvP6qnxW7ypjQJKPn8wYQZzXw1d55fz0hVXkl9fxvZyB/Pd/jKfK38iuklqyU2L3STqLNhWyckcZw9PjiPN6eHLpdvLL68hOieEHU7I5IiOBzCQfX+VXsDavAn9jM6My4tlQUMW8L3YRE+1m1rgBZCbFUFpTz97KeuZ/uRuwEkVqfDQuEVwCVf4mCir87K30s7uibp8aDsCI9DgKq+qp8lt9IkkxUeSX75uMXALTR6aRV1bH9uKaDr+fpJgoKuoaAas/qNZulov2uGhoChywfUpcNGW1DYxIjyevrPaA+ERAgMBhnnIG9YvB5YLc0jpmjk4nLd7LqyvzWi+lDnUfk4ckU9fQxKJNRTQHBTUg0cfQtFjqGgPU1jfhb2omt/TApN6RaI+LIzLiSYqJorjKuvIu2uPi822lrduM7B9PXLSbjXuqSE/wcuzwVJZ8U0RRdT3Bp+XMJB+VdY3UNwWY+53h/HLWkYcUS4tIJQIPVnPPKVhXBS0HfmSMWRe0TaYxpsCeng3caow5tqP9aiJQ3aGitpE1eeV8Z1Ra2JpqGpsDuET2+XVsjOHxJdtoDhh+NnNEu59tjKGyrglvlIv1BZXkldVx5rgBuETYU+knMSaKaLeLL/PKiXa7qKhrxCXCiP5xZCbFUNfQzN+XbiPa42JMZiJJMVEk+Dy8t7aAIzISWJ1bzs6SGs4cn0lJdQPbiqoZlhbH2TkD8XpcLN9RyrhBSQQCsHBjIbUNTVxy7BBcIkR7XJTWNLCzpIbUOC/xPg/5ZXUM7OezfzXX7FOOXaW1NDYbJmYnUVPfTElNPcVVDXijXGQmxZBbWktuWS1jByZRVtvAkm+KqG1oZkR6HE98sh23CD+ZMYL/PO0I9lT6KatpoNLfiC/KzcCkGOqbmlm1q4zRGYlU1DWybHsp3+ytYvWuMnzRbmYe0Z+Zo9Mpqqqnyt/Iyl3l7Kmow+txE+d1U9cYYPakgVTUNlJW29haa9laWM3AfjGttRJ/YzODU2L5bFsJX+dXsHFPFVX+JtITvNQ2NFHlb+K4EamcM2Egy3eU8vGmIgLGMLJ/PMu2l7K1qJrTxgxgeFpc6z1Cu0prWb2rnLR4L74oF9OGpzKjk0PQRyQR2B98JvAA1uWjTxlj7haRu4AVxpj5InIP8D2gCSgFfmqM2djRPjURKKVaLNteSnJsFKMyEiIdymFrDpiwXoAQsUQQDpoIlFLq0HWUCPT2UKWUcjhNBEop5XCaCJRSyuE0ESillMNpIlBKKYfTRKCUUg6niUAppRxOE4FSSjmcJgKllHI4TQRKKeVwmgiUUsrhNBEopZTDaSJQSimH00SglFIOp4lAKaUcThOBUko5nCYCpZRyOE0ESinlcJoIlFLK4TQRKKWUw2kiUEoph9NEoJRSDqeJQCmlHE4TgVJKOZwmAqWUcjhNBEop5XCaCJRSyuE0EfQ2xsCSP8He9ZGORCnVR2gi6G32roOFf4Cl90U6EqVUHxHWRCAis0Rkk4hsEZHb2ljvFZGX7PVfiMjQcMbT4y29H756peNtNsy3/v3mfWiq/3a5MbDoHlg/P3zxHYqynTD/OqgujHQk+6rcbcVVkRfpSDqvrgzmXw9F34S2faT+NnavhnduhMa6rt1v8Rar/LWlXbfP3GXw3i3Q1NB1+zxU4ShXiDzh2rGIuIFHgNOAPGC5iMw3xgS3aVwJlBljRorIRcAfgQvDFVOP9s378NHvwR0NmTmQfkTb262fD94kqK+ArYtg9Cxr+bo3YPG9EBVrvT95SPfFvj9j4K2fw46lUFcOFz4fuViCGQNv/wI2v28lhItfBZFIR3XoPvgdrH4eCr6Eqz4C90H+G0fib6OxDl69Ekq3gjceTrura/YbaIY3roH8FdDcCLMfPfx91lfBK1dAZR7EpcOMXx7+Pg9VOMp1CMQYE54dixwH3GmMOd2e/xWAMeaeoG3et7f5TEQ8wB4g3XQQ1JQpU8yKFSsOPaAtC+D93xz6+7pLRT4kZlq/oF1u6w9yf8ZA8SY47b9gyZ/BHQVxada68lxIHgrlOyEqBmJTuzX8fTQ3QOk2yJ4GuV9A6iirTJEWaIKSLUFxjQRX2H4LhUfL30BLGZKHgsfX8Xsi8bfRUAMVuVacecshrZ0fNoeqyQ9lOyD7WMj9HNJGH34yr6+yfhhkTbFqMakjuyTUQxJquSZdCsdf26mPEJGVxpgpba0L5/+CQUBu0HweMK29bYwxTSJSAaQCxcEbichcYC7A4MGDOxeNNxHSR3fuvd1hwHg48SYrEax4CmgnFw6aDJMugZhk2PLht8szc2DGrdYJeHUP+AU+/vtw4s2w8L+sE1BPcdQ5MPPXsPiPULI50tF0zoiT4dQ74IvHrBPXwUTqb2P6DdbfwUd3QW3xwbcP1eQ5cOzPrf1WdlET38jTYPSZsPAuq+ktEkIpV3z/sHx0OGsEFwCzjDFX2fOXAtOMMdcGbfO1vU2ePb/V3qbdv5pO1wiUUsrBOqoRhLOzOB/IDprPspe1uY3dNJQElIQxJqWUUvsJZyJYDowSkWEiEg1cBOx/2cJ84DJ7+gJgYUf9A0oppbpe2PoI7Db/a4H3ATfwlDFmnYjcBawwxswHngSeF5EtQClWslBKKdWNwnrJhDHmPeC9/ZbdHjTtB74fzhiUUkp1TO8sVkoph9NEoJRSDqeJQCmlHE4TgVJKOVzYbigLFxEpAjp7q2oa+9217BBOLLcTywzOLLeWOTRDjDFtjF3TCxPB4RCRFe3dWdeXObHcTiwzOLPcWubDp01DSinlcJoIlFLK4ZyWCP4W6QAixInldmKZwZnl1jIfJkf1ESillDqQ02oESiml9qOJQCmlHM4xiUBEZonIJhHZIiK3RTqecBGRHSKyVkTWiMgKe1mKiHwoIpvtf5MjHefhEpGnRKTQfrhRy7I2yymWB+1j/5WITI5c5J3XTpnvFJF8+3ivEZEzg9b9yi7zJhE5PTJRHx4RyRaRRSKyXkTWicgN9vI+e6w7KHP4jrUxps+/sIbB3goMB6KBL4ExkY4rTGXdAaTtt+x/gNvs6duAP0Y6zi4o53eAycDXBysncCbwL0CAY4EvIh1/F5b5TuDmNrYdY/+de4Fh9t+/O9Jl6ESZM4HJ9nQC8I1dtj57rDsoc9iOtVNqBMcAW4wx24wxDcCLwLkRjqk7nQs8a08/C5wXwVi6hDFmCdYzLIK1V85zgeeM5XOgn4hkdk+kXaedMrfnXOBFY0y9MWY7sAXr/0GvYowpMMassqergA1Yzzrvs8e6gzK357CPtVMSwSAgN2g+j46/2N7MAB+IyEoRmWsvyzDGFNjTe4CMyIQWdu2Vs68f/2vtZpCngpr9+lyZRWQoMAn4Aocc6/3KDGE61k5JBE5ygjFmMnAG8HMR+U7wSmPVJfv8NcNOKSfwKDACmAgUAPdFNpzwEJF44DXgF8aYyuB1ffVYt1HmsB1rpySCfCA7aD7LXtbnGGPy7X8LgTewqoh7W6rH9r+FkYswrNorZ589/saYvcaYZmNMAPg73zYJ9Jkyi0gU1gnxH8aY1+3FffpYt1XmcB5rpySC5cAoERkmItFYz0aeH+GYupyIxIlIQss08F3ga6yyXmZvdhnwVmQiDLv2yjkfmGNfUXIsUBHUrNCr7df+PRvreINV5otExCsiw4BRwLLuju9wiYhgPdt8gzHm/qBVffZYt1fmsB7rSPeQd2NP/JlYve9bgd9EOp4wlXE41tUDXwLrWsoJpAIfAZuBBUBKpGPtgrLOw6oeN2K1iV7ZXjmxriB5xD72a4EpkY6/C8v8vF2mr+wTQmbQ9r+xy7wJOCPS8XeyzCdgNft8BayxX2f25WPdQZnDdqx1iAmllHI4pzQNKaWUaocmAqWUcjhNBEop5XCaCJRSyuE0ESillMNpIlCqG4nITBF5J9JxKBVME4FSSjmcJgKl2iAil4jIMnvc98dFxC0i1SLyF3uM+I9EJN3edqKIfG4PBvZG0Nj4I0VkgYh8KSKrRGSEvft4EXlVRDaKyD/sO0mVihhNBErtR0SOAi4EphtjJgLNwMVAHLDCGDMWWAzcYb/lOeBWY8wErDs/W5b/A3jEGJMDHI91VzBYo0n+Amsc+eHA9LAXSqkOeCIdgFI90CnA0cBy+8d6DNagZgHgJXubF4DXRSQJ6GeMWWwvfxZ4xR7zaZAx5g0AY4wfwN7fMmNMnj2/BhgKfBL+YinVNk0ESh1IgGeNMb/aZ6HI7/bbrrPjs9QHTTej/w9VhGnTkFIH+gi4QET6Q+vzcYdg/X+5wN7mR8AnxpgKoExETrSXXwosNtaTpfJE5Dx7H14Rie3WUigVIv0lotR+jDHrReS3WE96c2GN9vlzoAY4xl5XiNWPANYwyI/ZJ/ptwBX28kuBx0XkLnsf3+/GYigVMh19VKkQiUi1MSY+0nEo1dW0aUgppRxOawRKKeVwWiNQSimH00SglFIOp4lAKaUcThOBUko5nCYCpZRyuP8HNp7njqXwwAAAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from urllib.request import ProxyBasicAuthHandler\n",
        "import torch.nn.functional as nnf\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "\n",
        "#loss\n",
        "L2Loss = torch.nn.MSELoss()\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "train_accu = []\n",
        "train_losses = []\n",
        "train_accu1 = []\n",
        "train_accu2 = []\n",
        "train_accu3 = []\n",
        "train_losses1 = []\n",
        "train_losses2 = []\n",
        "train_losses3 = []\n",
        "val_accu = []\n",
        "val_losses = []\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    running_loss = 0\n",
        "    running_loss1 = 0\n",
        "    running_loss2 = 0\n",
        "    running_loss3 = 0\n",
        "    total = 0\n",
        "    total1 = 0\n",
        "    total2 = 0\n",
        "    total3 = 0\n",
        "    correct = 0\n",
        "    correct1 = 0\n",
        "    correct2 = 0\n",
        "    correct3 = 0\n",
        "\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = L2Loss(gts, pre_res[0]) \n",
        "            loss2    = L2Loss(gts, pre_res[1])\n",
        "            loss3    = L2Loss(gts, pre_res[2])\n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "\n",
        "            #loss graph\n",
        "            running_loss1 += loss1.item()\n",
        "            running_loss2 += loss2.item()\n",
        "            running_loss3 += loss3.item()\n",
        "            predicted1 = pre_res[0]\n",
        "            predicted2 = pre_res[1]\n",
        "            predicted3 = pre_res[2]\n",
        "            total1 += images.size(0)\n",
        "            total2 += gts.size(0)\n",
        "            total3 += depths.size(0)\n",
        "            #correct1 += float(torch.sum(predicted1 == gts.data))\n",
        "            #correct2 += float(torch.sum(predicted2 == gts.data))\n",
        "            #correct3 += float(torch.sum(predicted3 == gts.data))\n",
        "            correct1 += predicted1.eq(images).sum().item()\n",
        "            correct2 += predicted2.eq(gts).sum().item()\n",
        "            correct3 += predicted3.eq(depths).sum().item()\n",
        "\n",
        "            running_loss += loss_all.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = torch.sum(gt + loss + predicted)\n",
        "            total += images.size(0)\n",
        "            correct += float(correct1 + correct2 + correct3)\n",
        "            \n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "\n",
        "        train_loss = running_loss/len(train_loader)\n",
        "        train_loss1=running_loss1/len(train_loader)\n",
        "        train_loss2=running_loss2/len(train_loader)\n",
        "        train_loss3=running_loss3/len(train_loader)\n",
        "        accu1= correct1/total1\n",
        "        accu2= correct2/total2\n",
        "        accu3= correct3/total3 \n",
        "        accu = correct/total\n",
        "           \n",
        "        train_accu1.append(round(accu1, 3))\n",
        "        train_accu2.append(round(accu2, 3))\n",
        "        train_accu3.append(round(accu3, 3))\n",
        "        train_losses1.append(float(train_loss1))\n",
        "        train_losses2.append(float(train_loss2))\n",
        "        train_losses3.append(float(train_loss3))\n",
        "        train_accu.append(round(accu, 3))\n",
        "        train_losses.append(float(train_loss))\n",
        "\n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "           \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0.0\n",
        "\n",
        "    correct1 = 0.0\n",
        "    correct2 = 0.0\n",
        "    correct3 = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-4)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-4)\n",
        "            mae = np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "            mae = np.mean((gt - res)**2)\n",
        "            mae_sum += mae\n",
        "\n",
        "            #loss graph\n",
        "            running_loss += mae_sum\n",
        "            pre1, pre2, predicted = pre_res\n",
        "            #outputs = float(torch.sum(gt + depth + predicted))\n",
        "            total += test_loader.size\n",
        "\n",
        "            #correct1 += float(torch.sum(pre1 == image.data))\n",
        "            #correct2 += float(torch.sum(pre2 == image.data))\n",
        "            #correct3 += float(torch.sum(predicted == image.data))\n",
        "\n",
        "            correct += predicted.eq(image).sum().item()\n",
        "            #correct += float(torch.sum(predicted == image).item())\n",
        "\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "       \n",
        "        val_loss=running_loss/len(test_loader)\n",
        "        accu= 100 * correct/total\n",
        "        val_accu.append(round(accu, 3))\n",
        "        val_losses.append(float(val_loss))\n",
        "\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                #torch.save(model.state_dict(), save_path+'SPNet_epoch_best_Combine_Loss_only_with_RGB_as_depth.pth')\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_l2_loss.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n",
        "\n",
        "plt.plot(train_losses, '-')\n",
        "plt.plot(train_losses1,'-')\n",
        "plt.plot(train_losses2,'-')\n",
        "plt.plot(train_losses3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Combined_loss','Loss1', 'Loss2', 'Loss3'])\n",
        "plt.title('Train Losses')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_accu, '-')\n",
        "plt.plot(train_accu1,'-')\n",
        "plt.plot(train_accu2,'-')\n",
        "plt.plot(train_accu3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Acc')\n",
        "plt.legend(['Combined_Accuracy','Acc1', 'Acc2', 'Acc3'])\n",
        "plt.title('Train Accuracy')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(val_losses,'-')\n",
        "plt.plot(val_accu,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Losses','Accuracy'])\n",
        "plt.title('Test Losses and Accuracy')\n",
        " \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HneuM16wUntF"
      },
      "source": [
        "## Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "TsPGafxUUsQO",
        "outputId": "1627bc7b-ce3d-4fdc-a00b-0410c4c679a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USE GPU 0\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b5730a33da2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Checkpoint/SPNet_new/SPNet_best_epoch_structure_loss.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Checkpoint/SPNet_new/SPNet_best_epoch_structure_loss.pth'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os, argparse\n",
        "import cv2\n",
        "\n",
        "def test_arguments():\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument('--testsize', type=int, default=352, help='testing size')\n",
        "  parser.add_argument('--gpu_id',   type=str, default='0', help='select gpu id')\n",
        "  parser.add_argument('--test_path',type=str, default='/content/tmp/testdataset/',help='test dataset path')\n",
        "  return parser.parse_args(\"\")\n",
        "\n",
        "opt = test_arguments()\n",
        "\n",
        "dataset_path = opt.test_path\n",
        "\n",
        "#set device for test\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        " \n",
        "\n",
        "#load the model\n",
        "model = SPNet(32,50)\n",
        "model.cuda()\n",
        "\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Checkpoint/SPNet_new/SPNet_best_epoch_structure_loss.pth'))\n",
        "model.eval()\n",
        "\n",
        "#test\n",
        "test_datasets = ['NJU2K','NLPR', 'DES'] \n",
        "\n",
        "test_datasets = ['DES'] \n",
        "\n",
        "\n",
        "for dataset in test_datasets:\n",
        "    save_path = '/content/drive/MyDrive/test_maps/SPNet_new/' + dataset + '/'\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "        \n",
        "    image_root  = str(dataset_path + dataset + '/RGB/')\n",
        "    gt_root     = str(dataset_path + dataset + '/GT/')\n",
        "    depth_root  = str(dataset_path + dataset + '/depth/')\n",
        "    test_loader = test_dataset(image_root, gt_root,depth_root, opt.testsize)\n",
        "    for i in range(test_loader.size):\n",
        "        image, gt,depth, name, image_for_post = test_loader.load_data()\n",
        "        gt      = np.asarray(gt, np.float32)\n",
        "        gt     /= (gt.max() + 1e-8)\n",
        "        image   = image.cuda()\n",
        "        depth   = depth.cuda()\n",
        "        pre_res = model(image,depth)\n",
        "        res     = pre_res[2]     \n",
        "        res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "        res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "        res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "        \n",
        "        print('save img to: ',save_path+name)\n",
        "        cv2.imwrite(save_path+name,res*255)\n",
        "    print('Test Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_GSFjpOi58H"
      },
      "source": [
        "#PNG to Nifti File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAas9xX7zEMG",
        "outputId": "6790641f-611b-410b-c276-f61ff8af075f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.1.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.4 MB 36 kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install SimpleITK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVnG8oPlnt3X"
      },
      "outputs": [],
      "source": [
        "import SimpleITK as sitk\n",
        "import os\n",
        "\n",
        "dirPth = '/content/drive/MyDrive/test_maps/SPNet_new/DES/'\n",
        "file_names = [dirPth + f for f in os.listdir(dirPth) if f.endswith('.png')]\n",
        "\n",
        "#file_names = glob.glob('*.png')\n",
        "reader = sitk.ImageSeriesReader()\n",
        "reader.SetFileNames(file_names)\n",
        "vol = reader.Execute()\n",
        "sitk.WriteImage(vol, dirPth + 'des_psnrMse_ssim_100.nii.gz')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "spnet_with_different_input.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0390d01cfe2149f0bdbf1a26ad40c45c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ed9816fb8804fe583cbfc794d11a84e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28b330d1b30443659e9d565aea0f4981": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35cd0d7de3e340728900e43624a8286f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "457bfe5cf38f4941a75626a6f6b40d0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48cb2939a71e47bbbca478f30376bbcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e4737a2b68049c9aaa7594eda512bfe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "749fc344b5d8455198bffc92dbaf17eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b1844a4952148c287c4288f72fddfb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0390d01cfe2149f0bdbf1a26ad40c45c",
            "placeholder": "​",
            "style": "IPY_MODEL_b54e8dfc22b9420eb947f1411fafe9dd",
            "value": "100%"
          }
        },
        "93a3b65787b44d459b8e1335edb0de63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b1844a4952148c287c4288f72fddfb2",
              "IPY_MODEL_ead21855f0544cf19fd8f5c6563f9bfc",
              "IPY_MODEL_bfb44701317349bfa693af3b83d81207"
            ],
            "layout": "IPY_MODEL_749fc344b5d8455198bffc92dbaf17eb"
          }
        },
        "9b83c730a3c648f1a0eda2504f2c9850": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a23243cf8fc441389fd50a34828f9fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c74748b9f48a407e9794456f46a0eace",
              "IPY_MODEL_d7d51bc216514adc9f29a056ff6ae6d2",
              "IPY_MODEL_d0977e3fa9634ff2aa66ca36eef0d991"
            ],
            "layout": "IPY_MODEL_c83165c488014758beea79ce6b512d2e"
          }
        },
        "a80a0775846d49f8ad894df38234318d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab803beac7464f99a0b5bfb6ed7a1a82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b54e8dfc22b9420eb947f1411fafe9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfb44701317349bfa693af3b83d81207": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_457bfe5cf38f4941a75626a6f6b40d0d",
            "placeholder": "​",
            "style": "IPY_MODEL_dc2b83eed6aa428b877444949b69e410",
            "value": " 98.4M/98.4M [00:26&lt;00:00, 7.95MB/s]"
          }
        },
        "c74748b9f48a407e9794456f46a0eace": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab803beac7464f99a0b5bfb6ed7a1a82",
            "placeholder": "​",
            "style": "IPY_MODEL_35cd0d7de3e340728900e43624a8286f",
            "value": "100%"
          }
        },
        "c83165c488014758beea79ce6b512d2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0977e3fa9634ff2aa66ca36eef0d991": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e4737a2b68049c9aaa7594eda512bfe",
            "placeholder": "​",
            "style": "IPY_MODEL_48cb2939a71e47bbbca478f30376bbcf",
            "value": " 98.4M/98.4M [00:23&lt;00:00, 12.9MB/s]"
          }
        },
        "d7d51bc216514adc9f29a056ff6ae6d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a80a0775846d49f8ad894df38234318d",
            "max": 103197949,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ed9816fb8804fe583cbfc794d11a84e",
            "value": 103197949
          }
        },
        "dc2b83eed6aa428b877444949b69e410": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ead21855f0544cf19fd8f5c6563f9bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b83c730a3c648f1a0eda2504f2c9850",
            "max": 103197949,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28b330d1b30443659e9d565aea0f4981",
            "value": 103197949
          }
        },
        "4aab51725d094305b48b1e6ab82923f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2bdf7d4bc154a1597accd674deff3cf",
              "IPY_MODEL_96b77619610a444da3d2a37dd1c1cf9b",
              "IPY_MODEL_8b929346dbda497a9a1b45994d4ba7d9"
            ],
            "layout": "IPY_MODEL_d5ed82d93d574b4d96fb05969330b968"
          }
        },
        "f2bdf7d4bc154a1597accd674deff3cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4005bfc2243c485a9ecb69ef8f893de0",
            "placeholder": "​",
            "style": "IPY_MODEL_03a2c64c771c4ac49fadd72fbedbe079",
            "value": "100%"
          }
        },
        "96b77619610a444da3d2a37dd1c1cf9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3edab5e7c41407e9b36940f85212a6d",
            "max": 103197949,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec57cbd665a0402997c9107e3731f6fb",
            "value": 103197949
          }
        },
        "8b929346dbda497a9a1b45994d4ba7d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44f6b8c32ea144f8b52f063cbc7c01c2",
            "placeholder": "​",
            "style": "IPY_MODEL_e7f4eeabae814a58907ad9eb10f7becb",
            "value": " 98.4M/98.4M [00:20&lt;00:00, 14.6MB/s]"
          }
        },
        "d5ed82d93d574b4d96fb05969330b968": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4005bfc2243c485a9ecb69ef8f893de0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03a2c64c771c4ac49fadd72fbedbe079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3edab5e7c41407e9b36940f85212a6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec57cbd665a0402997c9107e3731f6fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44f6b8c32ea144f8b52f063cbc7c01c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7f4eeabae814a58907ad9eb10f7becb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}